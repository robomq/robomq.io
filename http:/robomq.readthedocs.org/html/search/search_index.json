{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"What is RoboMQ? RoboMQ is a Message Queue as Service platform hosted on cloud and also available as an Enterprise hosting option. This Software as a Service platform is an integrated message queue hub, analytics engine, management console, dashboard and monitoring & alerts; all managed and hosted in a secure, reliable and redundant infrastructure. Key Features Key features of RoboMQ platform are: Cloud centric - built for the cloud, Internet of Things (IoT) and an heterogeneous environment of SaaS, COTS and enterprise hosted application Scalable - platform is auto scalable through horizontal scaling and load balancing Expandable - built on the core strength of message oriented middleware, functions and feature sets can be added without impacting existing application and feature set Reliable delivery with options for persistant or durable messages Monitoring, dashboards, analytics and alerts - we keep developing new add-ons based on the expandability of the platform Multiple choices of protocols for your devices and application - support for MQTT, AMQP, STOMP and HTTP/REST Support for multiple programming languages - with the support built for standard protocols like MQTT, AMQP, STOMP and HTTP/REST libraries supporting these protocols by default support RoboMQ Secure connection - RoboMQ has obtained certificate from certificate authority and supports SSL (secure socket layer) connection for all available protocols Platform components The key components RoboMQ are: AMQP based broker cluster with redundancy built-in Management UI console for real time monitoring, and managing Message Queue hub and user & access control Analytics and dashboard for the messaging activity Analytics and visualization platform providing insights based on message content Alerts and notification based on configurable threshold from message content RoboMQ platform is an expandable platform that allows addition of business specific application components which feed on the same stream of information, in parallel. RoboMQ comes bundled with few application components like monitoring dashboard for messaging activity, data driven analytics and alerts. Similar applications can be added to expand the platform. For each application component, multiple processes or workers can be added be added to handle increased demand or load.","title":"What is RoboMQ.io"},{"location":"#what-is-robomq","text":"RoboMQ is a Message Queue as Service platform hosted on cloud and also available as an Enterprise hosting option. This Software as a Service platform is an integrated message queue hub, analytics engine, management console, dashboard and monitoring & alerts; all managed and hosted in a secure, reliable and redundant infrastructure.","title":"What is RoboMQ?"},{"location":"#key-features","text":"Key features of RoboMQ platform are: Cloud centric - built for the cloud, Internet of Things (IoT) and an heterogeneous environment of SaaS, COTS and enterprise hosted application Scalable - platform is auto scalable through horizontal scaling and load balancing Expandable - built on the core strength of message oriented middleware, functions and feature sets can be added without impacting existing application and feature set Reliable delivery with options for persistant or durable messages Monitoring, dashboards, analytics and alerts - we keep developing new add-ons based on the expandability of the platform Multiple choices of protocols for your devices and application - support for MQTT, AMQP, STOMP and HTTP/REST Support for multiple programming languages - with the support built for standard protocols like MQTT, AMQP, STOMP and HTTP/REST libraries supporting these protocols by default support RoboMQ Secure connection - RoboMQ has obtained certificate from certificate authority and supports SSL (secure socket layer) connection for all available protocols","title":"Key Features"},{"location":"#platform-components","text":"The key components RoboMQ are: AMQP based broker cluster with redundancy built-in Management UI console for real time monitoring, and managing Message Queue hub and user & access control Analytics and dashboard for the messaging activity Analytics and visualization platform providing insights based on message content Alerts and notification based on configurable threshold from message content RoboMQ platform is an expandable platform that allows addition of business specific application components which feed on the same stream of information, in parallel. RoboMQ comes bundled with few application components like monitoring dashboard for messaging activity, data driven analytics and alerts. Similar applications can be added to expand the platform. For each application component, multiple processes or workers can be added be added to handle increased demand or load.","title":"Platform components"},{"location":"ADP-to-AD_Connector/","text":"ADP to AD Integration ADP is the leader in business outsourcing services, analytics and compliance expertise. ADP's unmatched experience, deep insights, and cutting-edge technology have transformed human resources from a back-office administrative function to a strategic business advantage. ADP provides HRMS (Human Resource Management Systems), Payroll and Finance critical to business operations of Any company. As organization move to the cloud and to distributed and de-centralized architecture, the key challenge is integrating HR and Payroll data with the rest of the enterprise systems like Identity Management, Resource planning, scheduling and finance systems Integrating ADP HR and Payroll to rest of the enterprise ADP Connector The ADP connector allows businesses to optimize and automate processes by integrating data between ADP and business-critical SaaS, enterprise applications, Cloud services, mobile apps and IoT devices. Using this connector, businesses can create real-time connectivity between the ADP HCM applications and Microsoft Active Directory, LDAP, Billing, Finance, Issues/Tracking Systems and services. Integrating ADP HR and Payroll to rest of the enterprise RoboMQ provides connectors to ADP HR and Payroll using ADP-R (ADP Report) tool as input source of information ThingsConnect suite of adapters and connectors to make ADP data available to and from enterprise systems for payroll processing, Identity Management (including Role Based Access Control (RBAC) and employee life cycle management. Customers use RoboMQ's ThingsConnect suite for leading-edge integration of devices, enterprise systems, and applications to build automation of manual processes, optimization of their IT environments. RoboMQ In Action: ADP to AD Integration Solution RoboMQ's leading-edge integration capabilities helped a leading global sports entertainment company automate their employee on-boarding and life cycle management by integrating ADP with Active Directory (AD) and automatically provisioning access to enterprise system based on roles and privileges: When a new employee starts working at any company location, their information is entered into the company\u2019s ADP HR system. For new employees, RoboMQ creates identities in Active Directory and provisions them into enterprise applications based on role or security groups ensuring that each employee has a single and unique account across all systems with associated access levels. RoboMQ automatically generates a random password for them along with default attributes and account control settings. It then handles sending welcome or other on-boarding emails to the responsible office manager based on job role and/or location. For existing employees, RoboMQ updates account settings, change of roles (i.e promotions, transfer, etc.), or change of status (i.e. long term leave, termination, or re-hire). By integrating ADP with Active Directory, significant savings result by removing the costly and tedious manual ticket processing, identity creation and access grants by system administrators. This solution also handles automatically creating tickets/cases for audit trails and provides mechanisms for alerts and notification. Once this solution is implemented the new employee has all the accounts and application access created and he or she is ready to go from the day one!!! Optionally, organization using Single Sign On (SSO) solutions like Centrify benefit from single sign on and auto provisioning. ADP to AD Integration enables company IT and HR teams to focus on more strategic business priorities. RoboMQ offers its ThingsConnect suite as pre-built Microservices for easy and rapid deployment allowing expandable systems capable of adopting change in the future without having to replace the overall on-boarding or payroll processes.","title":"ADP to AD"},{"location":"ADP-to-AD_Connector/#adp-to-ad-integration","text":"ADP is the leader in business outsourcing services, analytics and compliance expertise. ADP's unmatched experience, deep insights, and cutting-edge technology have transformed human resources from a back-office administrative function to a strategic business advantage. ADP provides HRMS (Human Resource Management Systems), Payroll and Finance critical to business operations of Any company. As organization move to the cloud and to distributed and de-centralized architecture, the key challenge is integrating HR and Payroll data with the rest of the enterprise systems like Identity Management, Resource planning, scheduling and finance systems Integrating ADP HR and Payroll to rest of the enterprise","title":"ADP to AD Integration"},{"location":"ADP-to-AD_Connector/#adp-connector","text":"The ADP connector allows businesses to optimize and automate processes by integrating data between ADP and business-critical SaaS, enterprise applications, Cloud services, mobile apps and IoT devices. Using this connector, businesses can create real-time connectivity between the ADP HCM applications and Microsoft Active Directory, LDAP, Billing, Finance, Issues/Tracking Systems and services.","title":"ADP Connector"},{"location":"ADP-to-AD_Connector/#integrating-adp-hr-and-payroll-to-rest-of-the-enterprise","text":"RoboMQ provides connectors to ADP HR and Payroll using ADP-R (ADP Report) tool as input source of information ThingsConnect suite of adapters and connectors to make ADP data available to and from enterprise systems for payroll processing, Identity Management (including Role Based Access Control (RBAC) and employee life cycle management. Customers use RoboMQ's ThingsConnect suite for leading-edge integration of devices, enterprise systems, and applications to build automation of manual processes, optimization of their IT environments.","title":"Integrating ADP HR and Payroll to rest of the enterprise"},{"location":"ADP-to-AD_Connector/#robomq-in-action-adp-to-ad-integration-solution","text":"RoboMQ's leading-edge integration capabilities helped a leading global sports entertainment company automate their employee on-boarding and life cycle management by integrating ADP with Active Directory (AD) and automatically provisioning access to enterprise system based on roles and privileges: When a new employee starts working at any company location, their information is entered into the company\u2019s ADP HR system. For new employees, RoboMQ creates identities in Active Directory and provisions them into enterprise applications based on role or security groups ensuring that each employee has a single and unique account across all systems with associated access levels. RoboMQ automatically generates a random password for them along with default attributes and account control settings. It then handles sending welcome or other on-boarding emails to the responsible office manager based on job role and/or location. For existing employees, RoboMQ updates account settings, change of roles (i.e promotions, transfer, etc.), or change of status (i.e. long term leave, termination, or re-hire). By integrating ADP with Active Directory, significant savings result by removing the costly and tedious manual ticket processing, identity creation and access grants by system administrators. This solution also handles automatically creating tickets/cases for audit trails and provides mechanisms for alerts and notification. Once this solution is implemented the new employee has all the accounts and application access created and he or she is ready to go from the day one!!! Optionally, organization using Single Sign On (SSO) solutions like Centrify benefit from single sign on and auto provisioning. ADP to AD Integration enables company IT and HR teams to focus on more strategic business priorities. RoboMQ offers its ThingsConnect suite as pre-built Microservices for easy and rapid deployment allowing expandable systems capable of adopting change in the future without having to replace the overall on-boarding or payroll processes.","title":"RoboMQ In Action: ADP to AD Integration Solution"},{"location":"AMQP/","text":"Introduction RoboMQ supports AMQP 0-9-1 as the main module of our broker. Its port is 5672 , SSL port is 5671 . AMQP (Advanced Message Queuing Protocol) is a networking protocol that enables conforming client applications to communicate with conforming messaging middleware brokers. Messaging brokers receive messages from producers (applications that publish them, also known as publishers) and route them to consumers (applications that process them). Since AMQP is a network protocol, the producers, consumers and the broker can all reside on different machines. The AMQP 0-9-1 Model has the following view of the world: messages are published to exchanges, which are often compared to post offices or mailboxes. Exchanges then distribute message copies to queues using rules called bindings. Then AMQP brokers either deliver messages to consumers subscribed to queues, or consumers fetch / pull messages from queues on demand. Queues, exchanges and bindings are collectively referred to as AMQP entities. When publishing a message, producers may specify various message headers (message properties). Some of these headers may be used by the broker, however, the rest of it is completely opaque to the broker and is only used by applications that receive the message. Networks are unreliable and applications may fail to process messages therefore the AMQP model has a notion of message acknowledgement: when a message is delivered to a consumer the consumer notifies the broker, either automatically or as soon as the application developer chooses to do so. When message acknowledgement is in use, a broker will only completely remove a message from a queue when it receives a notification for that message (or group of messages). In certain situations, for example, when a message cannot be routed, messages may be returned to producers, dropped, or, if the broker implements an extension, placed into a so-called \"dead letter queue\". Producers choose how to handle situations like this by publishing messages using certain parameters. AMQP 0-9-1 is a programmable protocol in the sense that AMQP entities and routing schemes are defined by applications themselves, not a broker administrator. Accordingly, provision is made for protocol operations that declare queues and exchanges, define bindings between them, subscribe to queues and so on. This gives application developers a lot of freedom but also requires them to be aware of potential definition conflicts. In practice, definition conflicts are rare and often indicate a misconfiguration. Applications declare the AMQP entities that they need, define necessary routing schemes and may choose to delete AMQP entities when they are no longer used. You can read the full documentation of AMQP or go through a simple tutorial of AMQP for details. Now, before proceeding to the following chapters, we assume that you already know AMQP protocol more or less, at least the basic concepts e.g broker, exchange, queue, producer, consumer, etc. AMQP use cases We will provide examples of five messaging scenarios, each in five languages, including Python, Node.js, PHP, Java and C or C++. The five messaging scenarios includes one-to-one, broadcast, routing key, routing filter (topic) and request-reply. They are respectively elaborated in the beginning of each's chapter. In the examples, details vary among five scenarios, but the typical procedure is as following. AMQP producer will publish a \"Hello World!\" message through a exchange with a routing key through RoboMQ broker. AMQP consumer will create exchange and queue, then bind them with the routing key and start consuming messages from the queue. It will print the message as it receives messages. All examples have implemented automatic reconnecting, which is crucial in real production. The example code provided bellow could be the short version, it might have omitted some advanced details. For full version code, please go to our SDK repository on GitHub. Before testing the example code, replace hostname, yourvhost, username and password with the real variables in your network environment. Always run consumer first to create the exchange and queue for producer to send messages to.","title":"AMQP Introduction"},{"location":"AMQP/#introduction","text":"RoboMQ supports AMQP 0-9-1 as the main module of our broker. Its port is 5672 , SSL port is 5671 . AMQP (Advanced Message Queuing Protocol) is a networking protocol that enables conforming client applications to communicate with conforming messaging middleware brokers. Messaging brokers receive messages from producers (applications that publish them, also known as publishers) and route them to consumers (applications that process them). Since AMQP is a network protocol, the producers, consumers and the broker can all reside on different machines. The AMQP 0-9-1 Model has the following view of the world: messages are published to exchanges, which are often compared to post offices or mailboxes. Exchanges then distribute message copies to queues using rules called bindings. Then AMQP brokers either deliver messages to consumers subscribed to queues, or consumers fetch / pull messages from queues on demand. Queues, exchanges and bindings are collectively referred to as AMQP entities. When publishing a message, producers may specify various message headers (message properties). Some of these headers may be used by the broker, however, the rest of it is completely opaque to the broker and is only used by applications that receive the message. Networks are unreliable and applications may fail to process messages therefore the AMQP model has a notion of message acknowledgement: when a message is delivered to a consumer the consumer notifies the broker, either automatically or as soon as the application developer chooses to do so. When message acknowledgement is in use, a broker will only completely remove a message from a queue when it receives a notification for that message (or group of messages). In certain situations, for example, when a message cannot be routed, messages may be returned to producers, dropped, or, if the broker implements an extension, placed into a so-called \"dead letter queue\". Producers choose how to handle situations like this by publishing messages using certain parameters. AMQP 0-9-1 is a programmable protocol in the sense that AMQP entities and routing schemes are defined by applications themselves, not a broker administrator. Accordingly, provision is made for protocol operations that declare queues and exchanges, define bindings between them, subscribe to queues and so on. This gives application developers a lot of freedom but also requires them to be aware of potential definition conflicts. In practice, definition conflicts are rare and often indicate a misconfiguration. Applications declare the AMQP entities that they need, define necessary routing schemes and may choose to delete AMQP entities when they are no longer used. You can read the full documentation of AMQP or go through a simple tutorial of AMQP for details. Now, before proceeding to the following chapters, we assume that you already know AMQP protocol more or less, at least the basic concepts e.g broker, exchange, queue, producer, consumer, etc.","title":"Introduction"},{"location":"AMQP/#amqp-use-cases","text":"We will provide examples of five messaging scenarios, each in five languages, including Python, Node.js, PHP, Java and C or C++. The five messaging scenarios includes one-to-one, broadcast, routing key, routing filter (topic) and request-reply. They are respectively elaborated in the beginning of each's chapter. In the examples, details vary among five scenarios, but the typical procedure is as following. AMQP producer will publish a \"Hello World!\" message through a exchange with a routing key through RoboMQ broker. AMQP consumer will create exchange and queue, then bind them with the routing key and start consuming messages from the queue. It will print the message as it receives messages. All examples have implemented automatic reconnecting, which is crucial in real production. The example code provided bellow could be the short version, it might have omitted some advanced details. For full version code, please go to our SDK repository on GitHub. Before testing the example code, replace hostname, yourvhost, username and password with the real variables in your network environment. Always run consumer first to create the exchange and queue for producer to send messages to.","title":"AMQP use cases"},{"location":"Atlassian%20JIRA%20-%20Connector/","text":"Atlassian JIRA Connector Description The JIRA connector allows businesses to optimize and automate processes by integrating data between JIRA and business-critical SaaS, enterprise applications, Cloud services, mobile apps and IoT devices. The connector gives users the ability to perform various operations, like tracking of issues and issue statistics, working with issues, comments, work logs, attachments, projects, user groups and other information, across third party applications and services.","title":"Atlassian JIRA"},{"location":"Atlassian%20JIRA%20-%20Connector/#atlassian-jira-connector","text":"Description The JIRA connector allows businesses to optimize and automate processes by integrating data between JIRA and business-critical SaaS, enterprise applications, Cloud services, mobile apps and IoT devices. The connector gives users the ability to perform various operations, like tracking of issues and issue statistics, working with issues, comments, work logs, attachments, projects, user groups and other information, across third party applications and services.","title":"Atlassian JIRA Connector"},{"location":"Database_Connector/","text":"Database Connector As Internet of things evolves, these small footprint microprocessor devices with some kind of network connectivity, will join the existing Internet of people, processes and systems. \u201cThingsConnect\u201d suite of connectors and adapter is positioned to allow these devices on varied platforms to connect to application systems, mobile platforms and enterprise applications through variety of protocols and cross protocol conversion capabilities. To this end, we have offer Database connectors for RoboMQ that can allow all the major relational databases to connect to and from RoboMQ middleware platform . This connector is tested against Oracle, MySQL and PostgresSQL and it is compatible with any ODBC compliant relational database. That is a long way of saying any relational database\u2026 All you need is an ODBC driver for that particular database. Fig 1: Schematic of the Database connector What does this really mean for you? At a high level you can include databases and database driven application easily into the integrations using RoboMQ. You could receive messages over RoboMQ using any of MQTT, AMQP, Stomp, WebStomp or REST protocols and persist them into the database. At the same time, you could select information from the database and publish it as a message that could be consumed by clients using any of the above mentioned messaging and integration protocols. So essentially it is a full two integration of relational databases with RoboMQ. The connector can be run as a client inside the corporate firewall or on the cloud. No firewalls are needed since it makes outbound connections to RoboMQ. For the ease of deployment and management it is packaged as a Docker container. You simply get the container and run it. Any future updates are automatically available to you as the updates to the Docker container itself. You of course have an option to run it as a regular program. There are some additional details like it supports JSON as well as delimited ASCII data interchange method. The connector also has error handling built in with the provision of the \u201cdead letter\u201d queues. Any messages that cannot be handled are routed to the dead letter queue and can be handled on a case-by-case basis manually by the operations team. So what are you waiting for? Check out our database connector on our free trial , and let us know your feedback. To learn more about the many other connectors that RoboMQ offerers check back on our connectors page(link)! If you have any other questions please reach out to us as, sales@robomq.io and we would love to help.","title":"Database"},{"location":"Database_Connector/#database-connector","text":"As Internet of things evolves, these small footprint microprocessor devices with some kind of network connectivity, will join the existing Internet of people, processes and systems. \u201cThingsConnect\u201d suite of connectors and adapter is positioned to allow these devices on varied platforms to connect to application systems, mobile platforms and enterprise applications through variety of protocols and cross protocol conversion capabilities. To this end, we have offer Database connectors for RoboMQ that can allow all the major relational databases to connect to and from RoboMQ middleware platform . This connector is tested against Oracle, MySQL and PostgresSQL and it is compatible with any ODBC compliant relational database. That is a long way of saying any relational database\u2026 All you need is an ODBC driver for that particular database. Fig 1: Schematic of the Database connector What does this really mean for you? At a high level you can include databases and database driven application easily into the integrations using RoboMQ. You could receive messages over RoboMQ using any of MQTT, AMQP, Stomp, WebStomp or REST protocols and persist them into the database. At the same time, you could select information from the database and publish it as a message that could be consumed by clients using any of the above mentioned messaging and integration protocols. So essentially it is a full two integration of relational databases with RoboMQ. The connector can be run as a client inside the corporate firewall or on the cloud. No firewalls are needed since it makes outbound connections to RoboMQ. For the ease of deployment and management it is packaged as a Docker container. You simply get the container and run it. Any future updates are automatically available to you as the updates to the Docker container itself. You of course have an option to run it as a regular program. There are some additional details like it supports JSON as well as delimited ASCII data interchange method. The connector also has error handling built in with the provision of the \u201cdead letter\u201d queues. Any messages that cannot be handled are routed to the dead letter queue and can be handled on a case-by-case basis manually by the operations team. So what are you waiting for? Check out our database connector on our free trial , and let us know your feedback. To learn more about the many other connectors that RoboMQ offerers check back on our connectors page(link)! If you have any other questions please reach out to us as, sales@robomq.io and we would love to help.","title":"Database Connector"},{"location":"IotAnalytics-walkthrough/","text":"IoT Analytics Introduction In most cases watching is better than reading! While avid novelists might disagree, we in the world of Internet and Things (IoT) would prefer an effective, precise and intelligent visual representation of the plethora of information continuously generated by our beloved sensors. RoboMQ IoT analytics does exactly this and much more. RoboMQ IoT Analytics helps you efficiently monitor and elegantly represent your data while providing intelligent, selective and crucial information in a simple and legible manner. Keep a close watch on all your devices, monitor your sensors, organize your data visualizations and get total and seamless control over your IoT analytics. Overview and advantages IoT Analytics Flow IoT Analytics Producer Setup Familiarize with the UI Set Up datasources Create Dashboards Add Panels Setup the Panel Panel Metrics Top Bar Timeline Editor Final My Dashboard Overview and advantages Jack runs a business of providing storages and warehouses for commodity retailers, initially, with a small but growing business he was fine with physically monitoring the warehouses. But as the business grew, so did the complexity of managing it and the sheer scope of parameters and locations to monitor increased as well. Jack then set up several sensors in his warehouses collecting data like temperature, humidity, movements, luminance, power consumption etc which replaced his age old method of collecting this data manually with specific handheld devices. These new sensors constantly collect the data and send it as messages to RoboMQ IoT Integration Platform . Now all that he needs is an easy to use app to monitor and analyze the data collected by these sensors anywhere and at anytime. RoboMQ IoT Analytics does exactly the same and much more... Jack can visualize his data, follow the trends it takes and manage his business much more effectively with this analytics. He simply opens his RoboMQ IoT Analytics application from his computer, phone or tablet and monitors his warehouses with a few clicks, saving himself a lot of time and money which was spent physically monitoring the warehouses with help of few employees. Not only the old method time consuming but it could also be inaccurate at times and the constant monitoring was almost impossible. With IoT Analytics, it\u2019s as easy as it gets. Now he can act on the slightest irregularity in the data, delegate his employees at the right place on the right time all while relaxing in his office, saving effort, money and time. He can also add other users to the application with limited permissions so they can view the data and report or act accordingly. Simple yet elegant, the IoT Analytics allows Jack to get total automated control with no programming needed!!! A simple producer code is all that is needed to send the data from sensors to the RoboMQ and IoT Analytics takes care of the rest. Jack simply drags and drops the widgets that he wants for visualization and he is all set to go.. IoT Analytics schematics The Sensors send data as AMQP, MQTT or STOMP messages to RoboMQ message Broker using a simple producer code. The IoT Analytics listener constantly listens for these messages and writes to the respective real time analytics database. The IoT analytics dashboard can easily be built by simple drag and drop of visualization components like graphs, single-stats or tables with continuous data feed from sensors with guaranteed delivery. Now that we have seen the flow, let\u2019s dive a bit deeper into IoT Analytics, learn and understand the key components and while at it, help Jack here set up the system for his warehouses. Let\u2019s start with helping him set up a producer which will send his data to the MQTT broker on RoboMQ. You always have the option to use any other protocol like STOMP, HTTP/REST, AMQP or JMS. IoT Analytics Producer Set Up As per the flow, we will first make a producer for Jack\u2019s devices. Its very simple... In order to set up Message Producer on devices to see the generated data on your dashboard, you will need to run a 'message producer' script on the devices to send data to RoboMQ. In this guide, we will walk you through a simple producer example. Configuration To configure the producer to send data to RoboMQ broker, you will need to provide the following information in a JSON format file named producer.config { \"deviceID\": \"well1\", \"broker\": { \"host\": \"trial.robomq.io\", \"vhost\": \"test\", \"username\": \"test\", \"password\": \"test\" } } deviceID is a unique identifier of a device. Fill out the broker section with your tenant credentials provided by RoboMQ. Prerequisites Producer can talk to RoboMQ using any messaging protocol. In this example, we are using MQTT. The only dependency for the producer is to install an open-source client implementation of MQTT. We will use paho from eclipse foundation . To install paho module on a IoT device, simply run: pip install paho-mqtt Core producer functions are written in python module \"producerMQTT.py\". This module is used by the program sending device sensor data. It has functions for reading the configuration file, and defines methods for connecting to broker and sending the messages. If not specified, messages will be sent using the default routing key called \"sensors\". Device Simulator If you have access to a physical device, great...Else you can use a python simulator code for this exercise. With a device you can write a similar producer/sender program like the simulator program described below. The simulator program \"sensorSimulator.py\" sends randomly generated data to simulate information sent by the sensor. The script imports producerMQTT module and connect to RoboMQ. This program generates random numbers and assigns them to the measurements like temperature, humidity etc.. This is to simulate a device collecting data from its sensors. In the real world, you will simply write your own code to read data from sensors and put them in the message payload. message = {} message[\"intruder\"] = random.randint(0, 1) message[\"temperature\"] = random.uniform(32, 212) message[\"humidity\"] = random.uniform(0, 100) message[\"luminance\"] = random.uniform(0, 100) Once the message payload is constructed, it calls the send() method in producerMQTT to send the above data to RoboMQ. Build Analytics dashboard Familiarize with the UI Once you are provisioned for the trial or a paid subscription to RoboMQ, you get an email with login credentials and the links to the IoT Analytics application. The link will be something like the following: https://trial.robomq.io/iotanalytics/ Once you click on it, you will be redirected to the following login page. If you have not signed up, you can sign up for a Free Trial at RoboMQ website. Login page Following is the main page seen after you log in. The Home page has 3 major sections: Main menu : On left hand side we see the main control menu which contains options such as Datasources, Dashboards, User Profile, Organization and Sign Out link. Navigation Bar : On the top, we see the blue navigation bar which has the timeline editor and few other options and settings related to the dashboards. Dashboard List : The most prominent section you will see here is the dashboard list, which allows the user to bookmark a few dashboards for quick access. These chosen dashboards will be shown under the \"Starred\" Dashboards section. Main page Your RoboMQ IoT Analytics comes provisioned with a datasource, two dashboards - one a \"Panel Type\" and another \"Sample Dashboard\" Panel Types dashboard Panel type dashboard is there to show the different types of panels available in the app. Since the dashboard is editable, feel free to play around and get familiar with the components of the panels. Sample Dashboard Sample dashboard is a large dashboard containing panels of all kinds of graphs, which we will use to play around and get ideas for making our own dashboards. Now let\u2019s make a simple dashboard with the following steps: Set Up the datasources The datasources are the source of data from which the application plots the graphs and widgets. It is a real time time-series database to which RoboMQ listeners are continuously pumping your sensor data. We have got you covered here, because we have included a complete datasource for you and it is named after your vhost or tenant ID. Create Dashboards Now we can go ahead and create a new dashboard as shown in the image below by clicking \"Home\" button followed by \"+NEW\" button Create Dashboard Add Panels Once we have created an empty dashboard, we can add row using the \"ADD ROW\" button and in each row we can add panels using the green button on the left-top-corner of each row. The following image illustrates it, in the example below we are creating a panel of type graph. Create Panel Setup the Panel As we can see in the images below, the panel setup has several tabs- General: General defines parameters like name of the panel, the span that it should cover in the row, height etc. Metrics: Metrics is the key tab which defines what metric, measurement or query the panel is to display. Axes & Grid: Here we can customize how the graph looks, we can name the axes, change the units on the Y axes, add visual thresholds etc. Display Styles: This tab can be used to define how the graph lines look. Its very useful when we have many series in the same panel. Time Range: Time range can be used to define offsets in time Axis relative to the timeline defined by the timeline Editor available at the Nav bar. Panel Setup Panel Metrics In the above images, we can see the control is already in the metrics tab. First chose which datasource we are getting the data from, simply choose the one we have made for you named after your tenant name. Now choose which measurement to read from at \"FROM\", it will automatically populate a list of measurements available from your datasource. After choosing the measurement, chose the field that you are looking for at \"SELECT\u201d. The UI will automatically list all existing fields under the above selected measurement for you to chose from. Save the dashboard and set the timeline Now you are almost done and ready to save the dashboard and set the timeline. Top Bar You can create as many panels and rows as setup above. Setup and ensure effective visualization of the required metrics or measurements. Save the dashboard by clicking on the save icon on the top nav bar. If needed, we can also delete the dashboard from the settings icon. TimeLine Editor In the image below, we see the timeline Editor at the right side corner of the top nav-bar. This lets us scale the time axis as per our requirement giving us a viewing range of as early a last five minutes to as long as past 5 years. In the timeline editor, we see the ranges it provides and also the refresh setup that refreshes the panels after the set interval. The icon marked by the light bulb sign refreshes the timeline when you click it. Finally your IoT dashboard Above we see the final example dashboard which monitors the different sensors in two Warehouses. This is just a brief introduction to the unlimited potential IoT Analytics brings for the customers using IoT devices in their business. You can correlate and visualize your device and sensor data with few clicks and no programming needed... Feel free to browse through the IoT Analytics and explore the application. If you would like to try IoT Analytics for yourself go to our website and request a Free Trial . For more information on RoboMQ and its product features, check out our website RoboMQ or email us at sales@robomq.io.","title":"IoT Analytics"},{"location":"IotAnalytics-walkthrough/#introduction","text":"In most cases watching is better than reading! While avid novelists might disagree, we in the world of Internet and Things (IoT) would prefer an effective, precise and intelligent visual representation of the plethora of information continuously generated by our beloved sensors. RoboMQ IoT analytics does exactly this and much more. RoboMQ IoT Analytics helps you efficiently monitor and elegantly represent your data while providing intelligent, selective and crucial information in a simple and legible manner. Keep a close watch on all your devices, monitor your sensors, organize your data visualizations and get total and seamless control over your IoT analytics. Overview and advantages IoT Analytics Flow IoT Analytics Producer Setup Familiarize with the UI Set Up datasources Create Dashboards Add Panels Setup the Panel Panel Metrics Top Bar Timeline Editor Final My Dashboard","title":"Introduction"},{"location":"IotAnalytics-walkthrough/#overview-and-advantages","text":"Jack runs a business of providing storages and warehouses for commodity retailers, initially, with a small but growing business he was fine with physically monitoring the warehouses. But as the business grew, so did the complexity of managing it and the sheer scope of parameters and locations to monitor increased as well. Jack then set up several sensors in his warehouses collecting data like temperature, humidity, movements, luminance, power consumption etc which replaced his age old method of collecting this data manually with specific handheld devices. These new sensors constantly collect the data and send it as messages to RoboMQ IoT Integration Platform . Now all that he needs is an easy to use app to monitor and analyze the data collected by these sensors anywhere and at anytime. RoboMQ IoT Analytics does exactly the same and much more... Jack can visualize his data, follow the trends it takes and manage his business much more effectively with this analytics. He simply opens his RoboMQ IoT Analytics application from his computer, phone or tablet and monitors his warehouses with a few clicks, saving himself a lot of time and money which was spent physically monitoring the warehouses with help of few employees. Not only the old method time consuming but it could also be inaccurate at times and the constant monitoring was almost impossible. With IoT Analytics, it\u2019s as easy as it gets. Now he can act on the slightest irregularity in the data, delegate his employees at the right place on the right time all while relaxing in his office, saving effort, money and time. He can also add other users to the application with limited permissions so they can view the data and report or act accordingly. Simple yet elegant, the IoT Analytics allows Jack to get total automated control with no programming needed!!! A simple producer code is all that is needed to send the data from sensors to the RoboMQ and IoT Analytics takes care of the rest. Jack simply drags and drops the widgets that he wants for visualization and he is all set to go..","title":"Overview and advantages"},{"location":"IotAnalytics-walkthrough/#iot-analytics-schematics","text":"The Sensors send data as AMQP, MQTT or STOMP messages to RoboMQ message Broker using a simple producer code. The IoT Analytics listener constantly listens for these messages and writes to the respective real time analytics database. The IoT analytics dashboard can easily be built by simple drag and drop of visualization components like graphs, single-stats or tables with continuous data feed from sensors with guaranteed delivery. Now that we have seen the flow, let\u2019s dive a bit deeper into IoT Analytics, learn and understand the key components and while at it, help Jack here set up the system for his warehouses. Let\u2019s start with helping him set up a producer which will send his data to the MQTT broker on RoboMQ. You always have the option to use any other protocol like STOMP, HTTP/REST, AMQP or JMS.","title":"IoT Analytics schematics"},{"location":"IotAnalytics-walkthrough/#iot-analytics-producer-set-up","text":"As per the flow, we will first make a producer for Jack\u2019s devices. Its very simple... In order to set up Message Producer on devices to see the generated data on your dashboard, you will need to run a 'message producer' script on the devices to send data to RoboMQ. In this guide, we will walk you through a simple producer example.","title":"IoT Analytics Producer Set Up"},{"location":"IotAnalytics-walkthrough/#configuration","text":"To configure the producer to send data to RoboMQ broker, you will need to provide the following information in a JSON format file named producer.config { \"deviceID\": \"well1\", \"broker\": { \"host\": \"trial.robomq.io\", \"vhost\": \"test\", \"username\": \"test\", \"password\": \"test\" } } deviceID is a unique identifier of a device. Fill out the broker section with your tenant credentials provided by RoboMQ.","title":"Configuration"},{"location":"IotAnalytics-walkthrough/#prerequisites","text":"Producer can talk to RoboMQ using any messaging protocol. In this example, we are using MQTT. The only dependency for the producer is to install an open-source client implementation of MQTT. We will use paho from eclipse foundation . To install paho module on a IoT device, simply run: pip install paho-mqtt Core producer functions are written in python module \"producerMQTT.py\". This module is used by the program sending device sensor data. It has functions for reading the configuration file, and defines methods for connecting to broker and sending the messages. If not specified, messages will be sent using the default routing key called \"sensors\".","title":"Prerequisites"},{"location":"IotAnalytics-walkthrough/#device-simulator","text":"If you have access to a physical device, great...Else you can use a python simulator code for this exercise. With a device you can write a similar producer/sender program like the simulator program described below. The simulator program \"sensorSimulator.py\" sends randomly generated data to simulate information sent by the sensor. The script imports producerMQTT module and connect to RoboMQ. This program generates random numbers and assigns them to the measurements like temperature, humidity etc.. This is to simulate a device collecting data from its sensors. In the real world, you will simply write your own code to read data from sensors and put them in the message payload. message = {} message[\"intruder\"] = random.randint(0, 1) message[\"temperature\"] = random.uniform(32, 212) message[\"humidity\"] = random.uniform(0, 100) message[\"luminance\"] = random.uniform(0, 100) Once the message payload is constructed, it calls the send() method in producerMQTT to send the above data to RoboMQ.","title":"Device Simulator"},{"location":"IotAnalytics-walkthrough/#build-analytics-dashboard","text":"","title":"Build Analytics dashboard"},{"location":"IotAnalytics-walkthrough/#familiarize-with-the-ui","text":"Once you are provisioned for the trial or a paid subscription to RoboMQ, you get an email with login credentials and the links to the IoT Analytics application. The link will be something like the following: https://trial.robomq.io/iotanalytics/ Once you click on it, you will be redirected to the following login page. If you have not signed up, you can sign up for a Free Trial at RoboMQ website.","title":"Familiarize with the UI"},{"location":"IotAnalytics-walkthrough/#login-page","text":"Following is the main page seen after you log in. The Home page has 3 major sections: Main menu : On left hand side we see the main control menu which contains options such as Datasources, Dashboards, User Profile, Organization and Sign Out link. Navigation Bar : On the top, we see the blue navigation bar which has the timeline editor and few other options and settings related to the dashboards. Dashboard List : The most prominent section you will see here is the dashboard list, which allows the user to bookmark a few dashboards for quick access. These chosen dashboards will be shown under the \"Starred\" Dashboards section.","title":"Login page"},{"location":"IotAnalytics-walkthrough/#main-page","text":"Your RoboMQ IoT Analytics comes provisioned with a datasource, two dashboards - one a \"Panel Type\" and another \"Sample Dashboard\"","title":"Main page"},{"location":"IotAnalytics-walkthrough/#panel-types-dashboard","text":"Panel type dashboard is there to show the different types of panels available in the app. Since the dashboard is editable, feel free to play around and get familiar with the components of the panels.","title":"Panel Types dashboard"},{"location":"IotAnalytics-walkthrough/#sample-dashboard","text":"Sample dashboard is a large dashboard containing panels of all kinds of graphs, which we will use to play around and get ideas for making our own dashboards. Now let\u2019s make a simple dashboard with the following steps:","title":"Sample Dashboard"},{"location":"IotAnalytics-walkthrough/#set-up-the-datasources","text":"The datasources are the source of data from which the application plots the graphs and widgets. It is a real time time-series database to which RoboMQ listeners are continuously pumping your sensor data. We have got you covered here, because we have included a complete datasource for you and it is named after your vhost or tenant ID.","title":"Set Up the datasources"},{"location":"IotAnalytics-walkthrough/#create-dashboards","text":"Now we can go ahead and create a new dashboard as shown in the image below by clicking \"Home\" button followed by \"+NEW\" button Create Dashboard","title":"Create Dashboards"},{"location":"IotAnalytics-walkthrough/#add-panels","text":"Once we have created an empty dashboard, we can add row using the \"ADD ROW\" button and in each row we can add panels using the green button on the left-top-corner of each row. The following image illustrates it, in the example below we are creating a panel of type graph. Create Panel","title":"Add Panels"},{"location":"IotAnalytics-walkthrough/#setup-the-panel","text":"As we can see in the images below, the panel setup has several tabs- General: General defines parameters like name of the panel, the span that it should cover in the row, height etc. Metrics: Metrics is the key tab which defines what metric, measurement or query the panel is to display. Axes & Grid: Here we can customize how the graph looks, we can name the axes, change the units on the Y axes, add visual thresholds etc. Display Styles: This tab can be used to define how the graph lines look. Its very useful when we have many series in the same panel. Time Range: Time range can be used to define offsets in time Axis relative to the timeline defined by the timeline Editor available at the Nav bar. Panel Setup","title":"Setup the Panel"},{"location":"IotAnalytics-walkthrough/#panel-metrics","text":"In the above images, we can see the control is already in the metrics tab. First chose which datasource we are getting the data from, simply choose the one we have made for you named after your tenant name. Now choose which measurement to read from at \"FROM\", it will automatically populate a list of measurements available from your datasource. After choosing the measurement, chose the field that you are looking for at \"SELECT\u201d. The UI will automatically list all existing fields under the above selected measurement for you to chose from.","title":"Panel Metrics"},{"location":"IotAnalytics-walkthrough/#save-the-dashboard-and-set-the-timeline","text":"Now you are almost done and ready to save the dashboard and set the timeline.","title":"Save the dashboard and set the timeline"},{"location":"IotAnalytics-walkthrough/#top-bar","text":"You can create as many panels and rows as setup above. Setup and ensure effective visualization of the required metrics or measurements. Save the dashboard by clicking on the save icon on the top nav bar. If needed, we can also delete the dashboard from the settings icon.","title":"Top Bar"},{"location":"IotAnalytics-walkthrough/#timeline-editor","text":"In the image below, we see the timeline Editor at the right side corner of the top nav-bar. This lets us scale the time axis as per our requirement giving us a viewing range of as early a last five minutes to as long as past 5 years. In the timeline editor, we see the ranges it provides and also the refresh setup that refreshes the panels after the set interval. The icon marked by the light bulb sign refreshes the timeline when you click it.","title":"TimeLine Editor"},{"location":"IotAnalytics-walkthrough/#finally-your-iot-dashboard","text":"Above we see the final example dashboard which monitors the different sensors in two Warehouses. This is just a brief introduction to the unlimited potential IoT Analytics brings for the customers using IoT devices in their business. You can correlate and visualize your device and sensor data with few clicks and no programming needed... Feel free to browse through the IoT Analytics and explore the application. If you would like to try IoT Analytics for yourself go to our website and request a Free Trial . For more information on RoboMQ and its product features, check out our website RoboMQ or email us at sales@robomq.io.","title":"Finally your IoT dashboard"},{"location":"MQTT/","text":"Introduction Before reading this chapter, we assume that you already have the basic concepts of message queue, e.g broker, exchange, queue, producer, consumer, etc. Knowing AMQP protocol would very much facilitate understanding MQTT. RoboMQ supports MQTT 3.1 as an extension to the AMQP broker. Its port is 1883 , SSL port is 8883 . MQTT stands for Message Queue Telemetry Transport. It is a publish / subscribe, extremely simple and lightweight messaging protocol, designed for constrained devices and low-bandwidth, high-latency or unreliable networks. The design principles are to minimize network bandwidth and device resource requirements whilst also attempting to ensure reliability and some degree of assurance of delivery. These principles also turn out to make the protocol ideal of the emerging \"machine-to-machine\" (M2M) or \"Internet of Things\" (IoT) world of connected devices, and for mobile applications where bandwidth and battery power are at a premium. Full documentation of MQTT RoboMQ builds MQTT adapter on top of AMQP exchanges and queues. Messages published to MQTT topics use a topic exchange (amq.topic by default) internally. Subscribers consume from queues bound to the topic exchange. This both enables interoperability with other protocols and makes it possible to use the Management GUI to inspect queue sizes, message rates, and so on. Vhost specification MQTT protocol itself does not have the concept of vhost and so all MQTT libraries do not provide vhost argument. However, RoboMQ broker supplemented this feature. You can optionally specify a vhost while connecting, by prepending the vhost to the username and separating with a colon. For example, /:guest . If no vhost is specified, it will use the default vhost \"/\". Durability and Persistence RoboMQ MQTT adapter assumes two primary usage scenarios: QoS stands for quality of service in MQTT. RoboMQ supports QoS up to 1. Transient clients that use transient messages (non-persistent, QoS=0). It uses non-durable, auto-delete queues that will be deleted when the client disconnects. Stateful clients that use durable subscriptions (non-clean sessions, QoS=1). It uses durable queues. Whether the queues are auto-deleted is controlled by the client's clean session flag. Clients with clean sessions use auto-deleted queues, others use non-auto-deleted ones. For transient (QoS=0) publishes, RoboMQ will publish messages as transient (non-persistent). Naturally, for durable (QoS=1) publishes, persistent messages will be used internally. Queues created for MQTT subscribers will have names starting with mqtt-subscription-, one per subscription QoS level. MQTT use cases We will provide examples in five languages, including Python, Node.js, PHP, Java and C++. In the examples, MQTT producer will first ask user for the quantity of messages, then publish the certain number of test messages to a particular topic through MQTT broker. MQTT consumer will subscribe the same topic and print the topic and payload as it receives messages. All examples have implemented automatic reconnecting, which is crucial in real production. The example code provided bellow could be the short version, it might have omitted some advanced details. For full version code, please go to our SDK repository on GitHub. Before testing the example code, replace hostname, yourvhost, username and password with the real variables in your network environment. Always run consumer first to create the exchange and queue for producer to send messages to. Python Prerequisite The Python library we use for this example can be found at https://eclipse.org/paho/clients/python/ . Its source code is at https://git.eclipse.org/c/paho/org.eclipse.paho.mqtt.python.git/ . You can install it through sudo pip install paho-mqtt . Finally, import this library in your program. import paho.mqtt.client as mqtt The full documentation of this library is at https://pypi.python.org/pypi/paho-mqtt . This library is built on the basis of a C++ library mosquitto. The documentation of mosquitto is at https://mosquitto.org . Producer The first thing we need to do is to establish a connection with the RoboMQ broker. RoboMQ allows you to specify vhost along with username. See Vhost specification section for the detail. Set keep alive to 60 seconds, so that client will confirm the connectivity with broker. Many MQTT libraries, including this one, require network looping to complete and maintain the connection with broker. There could be several loop functions for you to choose. If none of them are called, incoming network data will not be processed and outgoing network data may not be sent in a timely fashion. client = mqtt.Client(client_id=\"\", clean_session=True, userdata=None, protocol=\"MQTTv31\") client.username_pw_set(vhost + \":\" + username, password) client.connect(server, port, keepalive=60, bind_address=\"\") client.loop_start() After that, producer can send messages to a particular topic. client.publish(topic, payload=message, qos=1, retain=False) At last, producer will stop loop and disconnect with the RoboMQ broker. client.loop_stop() client.disconnect() Consumer The same as producer, consumer needs to connect to the RoboMQ broker and start loop. Not as the producer, this consumer loops forever. client.loop_forever() The callback function of connecting is to subscribe a topic, so that consumer knows where to listen to. The second argument in subscribe() function is QoS. def onConnect(client, userdata, rc): client.subscribe([(topic, 1)]) Once it receives a message from the queue bound by the topic, it will trigger the callback function onMessage() to print the topic and message payload. def onMessage(client, userdata, message): print(\"Topic: \" + message.topic + \", Message: \" + message.payload) The callback functions should be preset before connecting to the RoboMQ broker. client.on_connect = onConnect client.on_message = onMessage When you no longer need it, you can also unsubscribe a topic. client.unsubscribe(topic) Putting it together producer.py import time import paho.mqtt.client as mqtt server = \"hostname\" port = 1883 vhost = \"yourvhost\" username = \"username\" password = \"password\" topic = \"test/any\" try: client = mqtt.Client(client_id=\"\", clean_session=True, userdata=None, protocol=\"MQTTv31\") client.username_pw_set(vhost + \":\" + username, password) client.connect(server, port, keepalive=60, bind_address=\"\") #connect client.loop_start() #start loop msgNum = int(input(\"Quantity of test messages: \")) for i in range(msgNum): message = \"test msg \" + str(i + 1) client.publish(topic, payload=message, qos=1, retain=False) #publish time.sleep(1) client.loop_stop() #stop loop client.disconnect() except Exception, e: print e consumer.py import time import paho.mqtt.client as mqtt server = \"hostname\" port = 1883 vhost = \"yourvhost\" username = \"username\" password = \"password\" topic = \"test/#\" \"\"\" * This method is the callback on connecting to broker. * @ It subscribes the target topic. \"\"\" def onConnect(client, userdata, rc): #event on connecting client.subscribe([(topic, 1)]) #subscribe \"\"\" * This method is the callback on receiving messages. * @ It prints the message topic and payload on console. \"\"\" def onMessage(client, userdata, message): #event on receiving message print(\"Topic: \" + message.topic + \", Message: \" + message.payload) while True: try: client = mqtt.Client(client_id=\"\", clean_session=True, userdata=None, protocol=\"MQTTv31\") client.username_pw_set(vhost + \":\" + username, password) client.on_connect = onConnect client.on_message = onMessage client.connect(server, port, keepalive=60, bind_address=\"\") #connect client.loop_forever() #automatically reconnect once loop forever except Exception, e: #when initialize connection, reconnect on exception print \"Exception handled, reconnecting...\\nDetail:\\n%s\" % e time.sleep(5) Node.js Prerequisite The Node.js library we use for this example can be found at https://github.com/adamvr/MQTT.js . You can install the library through sudo npm install mqtt . Finally, require this library in your program. var mqtt = require(\"mqtt\"); The full documentation of this library is at https://github.com/mqttjs/MQTT.js/wiki . Producer The first thing we need to do is to establish a connection with the RoboMQ broker. RoboMQ allows you to specify vhost along with username. See Vhost specification section for the detail. Set keep alive to 60 seconds, so that client will confirm the connectivity with broker. var client = mqtt.connect(\"mqtt://\" + server + \":\" + port, {username: vhost + \":\" + username, password: password, keepalive: 60, clean: true, will: null}); Using this library, you will probably incorporate most other functions in the callback on connect. client.on(\"connect\", callback); After that, producer can send messages to a particular topic. client.publish(topic, message, {qos: 1, retain: false}); At last, producer will disconnect with the RoboMQ broker. The end() function contains disconnecting. client.end(); Consumer The first step is the same as producer, consumer needs to connect to the RoboMQ broker. In the callback function on connect, next step is to subscribe a topic, so that consumer knows where to listen to. It uses a callback function to handle incoming messages. Once it receives a message from the queue bound by the topic, it will print the topic and message payload. client.subscribe(topic, {qos: 1, dup: false}) .on(\"message\", function(topic, payload, packet) { console.log(\"Topic: \" + topic + \", Message: \" + payload); }); When you no longer need it, you can also unsubscribe a topic. client.unsubscribe(topic, callback); Putting it together producer.js var mqtt = require(\"mqtt\"); var server = \"hostname\"; var port = \"1883\"; var vhost = \"yourvhost\"; var username = \"username\"; var password = \"password\"; var topic = \"test/any\"; var client = mqtt.connect(\"mqtt://\" + server + \":\" + port, {username: vhost + \":\" + username, password: password, keepalive: 60, clean: true, will: null}); client.on(\"connect\", function() { //this library automatically reconnects on errors //ask user to input the number of test messages process.stdout.write(\"Quantity of test messages: \"); process.stdin.on(\"data\", function (msgNum) { //send certain number of messages try { for(var i = 1; i <= msgNum; i++){ var message = \"test msg \" + i; client.publish(topic, message, {qos: 1, retain: false}); } } catch(ex) { console.log(ex); process.exit(-1); } //shut down producer after messages sent setTimeout(function() { client.end(); //includes disconnect() process.exit(0); }, msgNum); }); }); consumer.js var mqtt = require(\"mqtt\"); var server = \"hostname\"; var port = \"1883\"; var vhost = \"yourvhost\"; var username = \"username\"; var password = \"password\"; var topic = \"test/#\"; var client = mqtt.connect(\"mqtt://\" + server + \":\" + port, {username: vhost + \":\" + username, password: password, keepalive: 60, clean: true, will: null}); client.on(\"connect\", function() { //this library automatically reconnects on errors try { client.subscribe(topic, {qos: 1, dup: false}) //chainable API .on(\"message\", function(topic, payload, packet) { //event handling console.log(\"Topic: \" + topic + \", Message: \" + payload); }); } catch(ex) { console.log(ex); } }); PHP Prerequisite The PHP library we use for this example can be found at https://github.com/mgdm/Mosquitto-PHP/ . This library depends on php 5.3+ and libmosquitto , so first ensure that your have them installed. You may obtain the package using PECL sudo pecl install Mosquitto-alpha . Now you should see mosquitto.so in your php shared library directory, e.g /usr/lib/php5/20121212/ . Finally, edit your php.ini . In Dynamic Extensions section, add one line extension=mosquitto.so . After installation, you don't need to explicitly require this library in your PHP script. Your PHP interpreter will integrate it for you. Producer The first thing we need to do is to establish a connection with the RoboMQ broker. RoboMQ allows you to specify vhost along with username. See Vhost specification section for the detail. In the constructor of client, first parameter is client ID, second is boolean flag for clean session. The third parameter of connect function is keep alive the in seconds. Set keep alive to 60 seconds, so that client will confirm the connectivity with broker. $client = new Mosquitto\\Client(\"1\", true); $client->setCredentials($vhost.\":\".$username, $password); $client->connect($server, $port, 60); After that, producer can send messages to a particular topic. The third parameter is QoS, fourth is boolean flag for retain. $client->publish($topic, $message, 1, false); Many MQTT libraries, including this one, require network looping to complete and maintain the connection with broker. There could be several loop functions for you to choose. If none of them are called, incoming network data will not be processed and outgoing network data may not be sent in a timely fashion. It is strongly recommended that you call loop() each time you send a message. $client->loop(); At last, producer will disconnect with the the RoboMQ broker. $client->disconnect(); Consumer The first step is the same as producer, consumer needs to connect to the RoboMQ broker. Not as the producer, this consumer loops forever. $client->loopForever(); The next step is to subscribe a topic, so that consumer knows where to listen to. The second argument in subscribe() function is QoS. client->subscribe(topic, 1); Once it receives a message from the queue bound by the topic, it will trigger the callback function onMessage() to print the topic and message payload. function onMessage($message) { printf(\"Topic: %s, Message: %s\\n\", $message->topic, $message->payload); } The callback functions should be preset before connecting to the RoboMQ broker. Foe example, $client->onMessage(\"onMessage\"); When you no longer need it, you can also unsubscribe a topic. client->unsubscribe(topic, qos); Putting it together producer.php <?php $server = \"hostname\"; $port = \"1883\"; $vhost = \"yourvhost\"; $username = \"username\"; $password = \"password\"; $topic = \"test/any\"; try { $client = new Mosquitto\\Client(\"1\", true); //clientid=\"1\", clean_session=true $client->setCredentials($vhost.\":\".$username, $password); $client->connect($server, $port, 60); //keepalive=60 echo \"Quantity of test messages: \"; $msgNum = rtrim(fgets(STDIN), PHP_EOL); for ($i = 1; $i <= $msgNum; $i++) { $message = \"test msg \".$i; $client->publish($topic, $message, 1, false); //publish test messages to the topic $client->loop(); //frequently loop to to keep communications with broker sleep(1); } $client->disconnect(); } catch (Exception $e) { echo $e; } ?> consumer.php <?php $GLOBALS[\"client\"] = $client; $GLOBALS[\"topic\"] = $topic; $server = \"hostname\"; $port = \"1883\"; $vhost = \"yourvhost\"; $username = \"username\"; $password = \"password\"; $topic = \"test/#\"; function subscribe() { $GLOBALS[\"client\"]->subscribe($GLOBALS[\"topic\"], 1); //qos=1 } /** * This method is the callback on receiving messages. * @ It prints the message topic and payload on console. */ function onMessage($message) { printf(\"Topic: %s, Message: %s\\n\", $message->topic, $message->payload); } while (true) { try { $client = new Mosquitto\\Client(\"0\", true); //clientid=\"0\", clean_session=true $client->setCredentials($vhost.\":\".$username, $password); $client->onConnect(\"subscribe\"); $client->onMessage(\"onMessage\"); $client->connect($server, $port, 60); //keepalive=60 $client->loopForever(); //automatically reconnect when loopForever } catch (Exception $e) { //when initialize connection, reconnect on exception echo \"Exception handled, reconnecting...\\nDetail:\\n\".$e.\"\\n\"; sleep(5); } } ?> Ruby Prerequisite The Ruby gem we use for this example can be found at https://rubygems.org/gems/mqtt . Its source code is at https://github.com/njh/ruby-mqtt You can install it through gem install mqtt . Finally, require this gem in your program. require 'mqtt' The full documentation of this gem is at https://www.rubydoc.info/gems/mqtt/ . Producer The first thing we need to do is to establish a connection with the RoboMQ broker. RoboMQ allows you to specify vhost along with username. See Vhost specification section for the detail. Set keep alive to 60 seconds, so that client will confirm the connectivity with broker. client = MQTT::Client.connect( :host => server, :port => port, :username => \"#{vhost}:#{username}\", :password => password, :version => \"3.1.0\", :keep_alive => 60, :clean_session => true, :client_id => \"\", :will_qos => 1, :will_retain => false ) After that, producer can send messages to a particular topic. client.publish(topic, msg) At last, producer will disconnect with the RoboMQ broker. client.disconnect Consumer The first step is the same as producer, consumer needs to connect to the RoboMQ broker. Next step is to subscribe a topic, so that consumer knows where to listen to. subscription = client.subscribe([topic,1]) To receive a message, use the get method. This method will block until a message is available. If you give it a block, then the block will be executed for every message received. client.get do |topic, message| onMessage(topic, message) end When you no longer need it, you can also unsubscribe a topic. client.unsubscribe(topic) Putting it together producer.rb require \"mqtt\" # connection options server = \"hostname\" port = 1883 vhost = \"yourvhost\" username = \"username\" password = \"password\" topic = \"test/any\" print \"Quantity of test messages: \" msgNum = gets.to_i # create connection begin client = MQTT::Client.connect( :host => server, :port => port, :username => \"#{vhost}:#{username}\", :password => password, :version => \"3.1.0\", :keep_alive => 60, :clean_session => true, :client_id => \"\", :will_qos => 1, :will_retain => false ) # publish messages (1..msgNum).each do |counter| msg = \"test msg #{counter}\" client.publish(topic, msg) sleep 1 end client.disconnect end consumer.rb require \"mqtt\" # connection options server = \"hostname\" port = 1883 vhost = \"yourvhost\" username = \"username\" password = \"password\" topic = \"test/any\" # event on receiving message def onMessage(topic, message) puts \"Topic: #{topic}, Message: #{message}\" end # create connection and keep getting messages loop do begin # connect client = MQTT::Client.connect( :host => server, :port => port, :username => \"#{vhost}:#{username}\", :password => password, :version => \"3.1.0\", :keep_alive => 60, :clean_session => true, :client_id => \"\", ) # subscribe client.subscribe([topic,1]) client.get do |topic, message| onMessage(topic, message) end rescue MQTT::ProtocolException => pe puts \"Exception handled, reconnecting...\\nDetail:\\n#{pe.message}\" sleep 5 end end Java Prerequisite The Java library we use for this example can be found at https://www.eclipse.org/paho/clients/java/ . Download the library jar file at https://repo.eclipse.org/content/repositories/paho-releases/org/eclipse/paho/mqtt-client/0.4.0/mqtt-client-0.4.0.jar , import this library in your program import org.eclipse.paho.client.mqttv3.*; and compile your source code with the jar file. For example, javac -cp \".:./mqtt-client-0.4.0.jar\" Producer.java Consumer.java Run the producer and consumer classes. For example, java -cp \".:./mqtt-client-0.4.0.jar\" Consumer java -cp \".:./mqtt-client-0.4.0.jar\" Producer Of course, you can eventually compress your producer and consumer classes into jar files. The full documentation of this library is at http://www.eclipse.org/paho/files/javadoc/index.html . Producer The first thing we need to do is to establish a connection with the RoboMQ broker. RoboMQ allows you to specify vhost along with username. See Vhost specification section for the detail. Set keep alive to 60 seconds, so that client will confirm the connectivity with broker. private String broker = \"tcp://\" + server + \":\" + port; private String clientId = MqttClient.generateClientId(); private MemoryPersistence persistence = new MemoryPersistence(); client = new MqttClient(broker, clientId, persistence); MqttConnectOptions connOpts = new MqttConnectOptions(); connOpts.setUserName(vhost + \":\" + username); connOpts.setPassword(password.toCharArray()); connOpts.setKeepAliveInterval(60); connOpts.setCleanSession(true); client.connect(connOpts); After that, producer can send messages to a particular topic. It is remarkable that the message argument of publish() function isn't a String. Instead, it is a instance of MqttMessage class. Message payload text is the argument of the constructor of MqttMessage class. It has some public methods to set the headers, e.g. setQos() , setRetained() , etc. client.publish(topic, message); At last, producer will disconnect with the RoboMQ broker. client.disconnect(); Consumer The first step is the same as producer, consumer needs to connect to the RoboMQ broker. Next step is to subscribe a topic, so that consumer knows where to listen to. You need to set the callback on message before subscribe. Once it receives a message from queue bound by the topic, it will call the overridden function messageArrived() to print the topic and message payload. The second parameter of subscribe() function is QoS. private class onMessage implements MqttCallback { public void messageArrived(String topic, MqttMessage message) { System.out.println(\"Topic: \" + topic + \", Message: \" + (new String(message.getPayload()))); } public void connectionLost(Throwable cause) {} public void deliveryComplete(IMqttDeliveryToken token) {} } onMessage callback = new onMessage(); client.setCallback(callback); client.subscribe(topic, 1); When you no longer need it, you can also unsubscribe a topic. client.unsubscribe(topic); Putting it together Producer.java import org.eclipse.paho.client.mqttv3.MqttClient; import org.eclipse.paho.client.mqttv3.MqttConnectOptions; import org.eclipse.paho.client.mqttv3.MqttException; import org.eclipse.paho.client.mqttv3.MqttMessage; import org.eclipse.paho.client.mqttv3.persist.MemoryPersistence; import java.util.Scanner; public class Producer { private MqttClient client; private String server = \"hostname\"; private String port = \"1883\"; private String broker = \"tcp://\" + server + \":\" + port; private String vhost = \"yourvhost\"; private String username = \"username\"; private String password = \"password\"; private String topic = \"test/any\"; private String clientId = MqttClient.generateClientId(); private MemoryPersistence persistence = new MemoryPersistence(); private void produce() { try { client = new MqttClient(broker, clientId, persistence); MqttConnectOptions connOpts = new MqttConnectOptions(); connOpts.setUserName(vhost + \":\" + username); connOpts.setPassword(password.toCharArray()); connOpts.setKeepAliveInterval(60); connOpts.setCleanSession(true); client.connect(connOpts); System.out.print(\"Quantity of test messages: \"); Scanner scanner = new Scanner(System.in); int msgNum = scanner.nextInt(); for (int i = 0; i < msgNum; i ++) { MqttMessage message = new MqttMessage((\"test msg \" + Integer.toString(i + 1)).getBytes()); message.setQos(1); message.setRetained(false); client.publish(topic, message); try { Thread.sleep(1000); } catch (Exception e) {} } client.disconnect(); } catch(MqttException me) { System.out.println(me); System.exit(-1); } } public static void main(String[] args) { Producer p = new Producer(); p.produce(); } } Consumer.java import org.eclipse.paho.client.mqttv3.MqttClient; import org.eclipse.paho.client.mqttv3.MqttConnectOptions; import org.eclipse.paho.client.mqttv3.MqttException; import org.eclipse.paho.client.mqttv3.MqttMessage; import org.eclipse.paho.client.mqttv3.persist.MemoryPersistence; import org.eclipse.paho.client.mqttv3.MqttCallback; import org.eclipse.paho.client.mqttv3.IMqttDeliveryToken; public class Consumer { private MqttClient client; private String server = \"hostname\"; private String port = \"1883\"; private String broker = \"tcp://\" + server + \":\" + port; private String vhost = \"yourvhost\"; private String username = \"username\"; private String password = \"password\"; private String topic = \"test/#\"; private String clientId = MqttClient.generateClientId(); private MemoryPersistence persistence = new MemoryPersistence(); private boolean connected = false; /** * This method is the overridden callback on receiving messages. * @ It is event-driven. You don't call it in your code. * @ It prints the message topic and payload on console. * @ There're other callback functions provided by this library. */ private class onMessage implements MqttCallback { public void messageArrived(String topic, MqttMessage message) { System.out.println(\"Topic: \" + topic + \", Message: \" + (new String(message.getPayload()))); } public void connectionLost(Throwable cause) { System.out.printf(\"Exception handled, reconnecting...\\nDetail:\\n%s\\n\", cause.getMessage()); connected = false; //reconnect on exception } public void deliveryComplete(IMqttDeliveryToken token) { } } private void consume() { while (true) { try { client = new MqttClient(broker, clientId, persistence); MqttConnectOptions connOpts = new MqttConnectOptions(); connOpts.setUserName(vhost + \":\" + username); connOpts.setPassword(password.toCharArray()); connOpts.setKeepAliveInterval(60); connOpts.setCleanSession(true); client.connect(connOpts); onMessage callback = new onMessage(); client.setCallback(callback); client.subscribe(topic, 1); //qos=1 connected = true; while (connected) { //check connection status try { Thread.sleep(5000); } catch (Exception e) {} } } catch(MqttException me) { //reconnect on exception System.out.printf(\"Exception handled, reconnecting...\\nDetail:\\n%s\\n\", me); try { Thread.sleep(5000); } catch(Exception e) {} } } } public static void main(String[] args) { Consumer c = new Consumer(); c.consume(); } } Go Prerequisite The Go library we use for this example can be found at https://eclipse.org/paho/clients/golang/ . Its GitHub repository is at https://github.com/eclipse/paho.mqtt.golang . You can install it through go get github.com/eclipse/paho.mqtt.golang . Finally, import this library in your program. import MQTT \"github.com/eclipse/paho.mqtt.golang\" The full documentation of this library is at https://godoc.org/git.eclipse.org/gitroot/paho/org.eclipse.paho.mqtt.golang.git . This library depends on Google's websockets package, which is installed with go get golang.org/x/net/websocket Producer The first thing we need to do is to establish a connection with the RoboMQ broker. RoboMQ allows you to specify vhost along with username. See Vhost specification section for the detail. Set keep alive to 60 seconds, so that client will confirm the connectivity with broker. Although the library provides an AutoReconnect connection option, we discourage you to use it. The reason will be explained in the Consumer section. connOpts := MQTT.NewClientOptions().AddBroker(fmt.Sprintf(\"tcp://%s:%d\", server, port)) connOpts.SetUsername(fmt.Sprintf(\"%s:%s\", vhost, username)) connOpts.SetPassword(password) connOpts.SetClientID(\"0\") connOpts.SetCleanSession(true) connOpts.SetKeepAlive(60 * time.Second) connOpts.SetAutoReconnect(false) client := MQTT.NewClient(connOpts) client.Connect() After that, producer can send messages to a particular topic. The second parameter is QoS, third is boolean flag for retain. client.Publish(topic, 1, false, message) At last, producer will disconnect with the RoboMQ broker. The parameter 250 is the number of milliseconds to wait for existing work to be completed. client.Disconnect(250) Consumer The first step is the same as producer, consumer needs to connect to the RoboMQ broker. As we mentioned in the Producer section, AutoReconnect is set to false when connecting to the RoboMQ broker. It matters for consumers because AutoReconnect will only recover the connection, it won't resubscribe the topics. Therefore, a more robust approach is letting your code handle reconnecting and resubscribing on its own. The next step is to subscribe a topic, so that consumer knows where to listen to. The second argument in subscribe() function is QoS, the third one is the callback function to handle incoming messages. client.Subscribe(topic, 1, OnMessage) Once it receives a message from the queue bound by the topic, it will trigger the callback function onMessage() to print the topic and message payload. var OnMessage MQTT.MessageHandler = func(client MQTT.Client, msg MQTT.Message) { fmt.Printf(\"Topic: %s, Message: %s\\n\", msg.Topic(), msg.Payload()) } When you no longer need it, you can also unsubscribe a topic. client.Unsubscribe(topic) Putting it together producer.go package main import ( \"fmt\" MQTT \"github.com/eclipse/paho.mqtt.golang\" \"os\" \"time\" ) var server = \"hostname\" var port = 1883 var vhost = \"yourvhost\" var username = \"username\" var password = \"password\" var topic = \"test/any\" func main() { connOpts := MQTT.NewClientOptions().AddBroker(fmt.Sprintf(\"tcp://%s:%d\", server, port)) connOpts.SetUsername(fmt.Sprintf(\"%s:%s\", vhost, username)) connOpts.SetPassword(password) connOpts.SetClientID(\"1\") connOpts.SetCleanSession(true) connOpts.SetKeepAlive(60 * time.Second) connOpts.SetAutoReconnect(false) // Create and start a client using the above ClientOptions client := MQTT.NewClient(connOpts) if token := client.Connect(); token.Wait() && token.Error() != nil { fmt.Printf(\"Failed to connect, err: %v\\n\", token.Error()) os.Exit(1) } var msgNum int fmt.Print(\"Quantity of test messages: \") fmt.Scanf(\"%d\", &msgNum) for i := 0; i < msgNum; i++ { message := fmt.Sprintf(\"test msg %d\", i+1) // QoS = 1, retained = false token := client.Publish(topic, 1, false, message) // Use PublishToken to confirmed receipt from the broker token.Wait() if token.Error() != nil { fmt.Printf(\"Failed to publish, err: %v\\n\", token.Error()) os.Exit(1) } time.Sleep(time.Second) } client.Disconnect(250) } consumer.go package main import ( \"fmt\" MQTT \"github.com/eclipse/paho.mqtt.golang\" \"time\" ) var server = \"hostname\" var port = 1883 var vhost = \"yourvhost\" var username = \"username\" var password = \"password\" var topic = \"test/#\" /** * This function is the callback on receiving messages. * @ It prints the message topic and payload on console. */ var OnMessage MQTT.MessageHandler = func(client MQTT.Client, msg MQTT.Message) { fmt.Printf(\"Topic: %s, Message: %s\\n\", msg.Topic(), msg.Payload()) } func main() { connOpts := MQTT.NewClientOptions().AddBroker(fmt.Sprintf(\"tcp://%s:%d\", server, port)) connOpts.SetUsername(fmt.Sprintf(\"%s:%s\", vhost, username)) connOpts.SetPassword(password) connOpts.SetClientID(\"0\") connOpts.SetCleanSession(true) connOpts.SetKeepAlive(60 * time.Second) connOpts.SetAutoReconnect(false) // Infinite loop to auto-reconnect on failure for { // Create and start a client using the above ClientOptions client := MQTT.NewClient(connOpts) if token := client.Connect(); token.Wait() && token.Error() != nil { fmt.Printf(\"Failed to connect, err: %v\\n\", token.Error()) } // QoS = 1 if token := client.Subscribe(topic, 1, OnMessage); token.Wait() && token.Error() != nil { fmt.Printf(\"Failed to subscribe, err: %v\\n\", token.Error()) } // Constantly checking connectivity for client.IsConnected() { time.Sleep(time.Second) } fmt.Println(\"Restarting in 5 seconds...\") time.Sleep(5 * time.Second) } } C++ Prerequisite The C++ library we use for this example can be found at http://mosquitto.org/ . You will find elaborate installation guide at https://mosquitto.org/download/ . Install the library according to your operating system. The recommended approach is installing from the source. First, download the latest source package, uncompress it and enter its root directory; Then, run the following two commands: make sudo make install Include this library in your program #include <mosquitto.h> and compile it by g++ producer.cpp -o producer -lmosquitto g++ consumer.cpp -o consumer -lmosquitto See the full documentation of this library at https://mosquitto.org/documentation/ . Producer The first thing we need to do is to establish a connection with the RoboMQ broker. RoboMQ allows you to specify vhost along with username. See Vhost specification section for the detail. Remember to mosquitto_lib_init(); before creating the mosquitto instance. Many MQTT libraries, including this one, require network looping to complete and maintain the connection with broker. There could be several loop functions for you to choose. If none of them are called, incoming network data will not be processed and outgoing network data may not be sent in a timely fashion. Using this library, you usually starts loop right after connecting. The second parameter of mosquitto_new() function is boolean flag for clean session. The fourth parameter of mosquitto_connect() function is keep alive time in seconds. Set keep alive to 60 seconds, so that client will confirm the connectivity with broker. string vhusn = vhost + \":\" + usn; const char *username = vhusn.c_str(); struct mosquitto *mosq = NULL; mosquitto_lib_init(); mosq = mosquitto_new(NULL, true, NULL); mosquitto_username_pw_set(mosq, username, password); mosquitto_connect(mosq, host, port, 60)); mosquitto_loop_start(mosq); After that, producer can send messages to a particular topic. The fourth argument is length of payload char array; The sixth argument is QoS; The seventh argument is boolean flag for retain. mosquitto_publish(mosq, NULL, topic, 20, payload, 1, false); At last, producer will stop loop and disconnect with the RoboMQ broker. mosquitto_loop_stop(mosq, true); mosquitto_disconnect(mosq); mosquitto_destroy(mosq); mosquitto_lib_cleanup(); Consumer The first step is the same as producer, consumer needs to connect to the RoboMQ broker and start the loop. Not as the producer, this consumer loops forever. while(!mosquitto_loop_forever(mosq, 0, 1)){ } Then you need to set some callback functions. They play an significant role when using this library. Callback on receiving message is indispensable. void onMessage(struct mosquitto *mosq, void *userdata, const struct mosquitto_message *message) { if(message->payloadlen) { printf(\"Topic: %s, Message: %s\\n\", (char*)message->topic, (char*)message->payload); } else { printf(\"Topic: %s, Message: (null)\\n\", message->topic); } fflush(stdout); } mosquitto_message_callback_set(mosq, onMessage); Finally, you need to subscribe a topic, so that consumer knows where to listen to. Once it receives a message from the queue bound by the topic, it will call onMessage() function to print the topic and message payload. mosquitto_subscribe(mosq, NULL, topic, 1); When you no longer need it, you can also unsubscribe a topic. mosquitto_unsubscribe(mosq, NULL, topic); Putting it together producer.cpp #include <stdio.h> #include <iostream> #include <mosquitto.h> #include <exception> #include <stdlib.h> #include <unistd.h> using namespace std; //The library automatically reconnects to broker string hst = \"hostname\"; const char *host = hst.c_str(); int port = 1883; string vhost = \"yourvhost\"; string usn = \"username\"; string vhusn = vhost + \":\" + usn; const char *username = vhusn.c_str(); string pwd = \"password\"; const char *password = pwd.c_str(); string tpc = \"test/any\"; const char *topic = tpc.c_str(); /** * This is the main method which creates and runs producer instance. * @Looping is essential for this MQTT library to work. * @Exceptions on connection and publish error. */ int main(int argc, char *argv[]) { int keepalive = 60; bool clean_session = true; struct mosquitto *mosq = NULL; //create producer and connect to broker mosquitto_lib_init(); mosq = mosquitto_new(NULL, clean_session, NULL); mosquitto_username_pw_set(mosq, username, password); if(mosquitto_connect(mosq, host, port, keepalive)) { printf(\"Error: Failed to connect\\n\"); return 1; } //usually start loop right after connecting mosquitto_loop_start(mosq); //send certain number of test messages int msgNum; cout << \"Quantity of test messages: \"; cin >> msgNum; char payload[20]; for (int i = 1; i <= msgNum; i++) { sprintf(payload, \"test msg %d\", i); try { mosquitto_publish(mosq, NULL, topic, 20, payload, 1, false); } catch(exception& e) { printf(\"Error: Failed to publish message\\n%s\\n\", e.what()); return 1; } sleep(1); } //stop producer mosquitto_loop_stop(mosq, true); mosquitto_disconnect(mosq); mosquitto_destroy(mosq); mosquitto_lib_cleanup(); return 0; } consumer.cpp #include <stdio.h> #include <iostream> #include <mosquitto.h> #include <exception> #include <stdlib.h> #include <unistd.h> using namespace std; //The library automatically reconnects to broker string hst = \"hostname\"; const char *host = hst.c_str(); int port = 1883; string vhost = \"yourvhost\"; string usn = \"username\"; string vhusn = vhost + \":\" + usn; const char *username = vhusn.c_str(); string pwd = \"passwrod\"; const char *password = pwd.c_str(); string tpc = \"test/#\"; const char *topic = tpc.c_str(); /** * This method is the callback on connecting broker. * @It is event-driven. You don't call it in your code. * @It subscribes the specific topic. * @There're other callback functions provided by this library. */ void onConnect(struct mosquitto *mosq, void *userdata, int result) { if (!result) { try { mosquitto_subscribe(mosq, NULL, topic, 1); } catch (exception& e) { printf(\"Error: Failed to subscribe\\n%s\\n\", e.what()); } } else { printf(\"Error: Failed to connect\\n\"); } } /** * This method is the callback on receiving messages. * @It is event-driven. You don't call it in your code. * @It prints the message topic and payload on console. * @There're other callback functions provided by this library. */ void onMessage(struct mosquitto *mosq, void *userdata, const struct mosquitto_message *message) { if(message->payloadlen) { printf(\"Topic: %s, Message: %s\\n\", (char*)message->topic, (char*)message->payload); } else { printf(\"Topic: %s, Message: (null)\\n\", message->topic); } fflush(stdout); } /** * This is the main method which creates and sets consumer instance. * @Looping is essential for this MQTT library to work. * @Exceptions on connection and subscription error. */ int main(int argc, char *argv[]) { int keepalive = 60; bool clean_session = true; struct mosquitto *mosq = NULL; mosquitto_lib_init(); mosq = mosquitto_new(NULL, clean_session, NULL); mosquitto_username_pw_set(mosq, username, password); mosquitto_connect_callback_set(mosq, onConnect); mosquitto_message_callback_set(mosq, onMessage); mosquitto_connect(mosq, host, port, keepalive); //looping is essential for consumer to work while(!mosquitto_loop_forever(mosq, 0, 1)){ } return 0; }","title":"MQTT"},{"location":"MQTT/#introduction","text":"Before reading this chapter, we assume that you already have the basic concepts of message queue, e.g broker, exchange, queue, producer, consumer, etc. Knowing AMQP protocol would very much facilitate understanding MQTT. RoboMQ supports MQTT 3.1 as an extension to the AMQP broker. Its port is 1883 , SSL port is 8883 . MQTT stands for Message Queue Telemetry Transport. It is a publish / subscribe, extremely simple and lightweight messaging protocol, designed for constrained devices and low-bandwidth, high-latency or unreliable networks. The design principles are to minimize network bandwidth and device resource requirements whilst also attempting to ensure reliability and some degree of assurance of delivery. These principles also turn out to make the protocol ideal of the emerging \"machine-to-machine\" (M2M) or \"Internet of Things\" (IoT) world of connected devices, and for mobile applications where bandwidth and battery power are at a premium. Full documentation of MQTT RoboMQ builds MQTT adapter on top of AMQP exchanges and queues. Messages published to MQTT topics use a topic exchange (amq.topic by default) internally. Subscribers consume from queues bound to the topic exchange. This both enables interoperability with other protocols and makes it possible to use the Management GUI to inspect queue sizes, message rates, and so on.","title":"Introduction"},{"location":"MQTT/#vhost-specification","text":"MQTT protocol itself does not have the concept of vhost and so all MQTT libraries do not provide vhost argument. However, RoboMQ broker supplemented this feature. You can optionally specify a vhost while connecting, by prepending the vhost to the username and separating with a colon. For example, /:guest . If no vhost is specified, it will use the default vhost \"/\".","title":"Vhost specification"},{"location":"MQTT/#durability-and-persistence","text":"RoboMQ MQTT adapter assumes two primary usage scenarios: QoS stands for quality of service in MQTT. RoboMQ supports QoS up to 1. Transient clients that use transient messages (non-persistent, QoS=0). It uses non-durable, auto-delete queues that will be deleted when the client disconnects. Stateful clients that use durable subscriptions (non-clean sessions, QoS=1). It uses durable queues. Whether the queues are auto-deleted is controlled by the client's clean session flag. Clients with clean sessions use auto-deleted queues, others use non-auto-deleted ones. For transient (QoS=0) publishes, RoboMQ will publish messages as transient (non-persistent). Naturally, for durable (QoS=1) publishes, persistent messages will be used internally. Queues created for MQTT subscribers will have names starting with mqtt-subscription-, one per subscription QoS level.","title":"Durability and Persistence"},{"location":"MQTT/#mqtt-use-cases","text":"We will provide examples in five languages, including Python, Node.js, PHP, Java and C++. In the examples, MQTT producer will first ask user for the quantity of messages, then publish the certain number of test messages to a particular topic through MQTT broker. MQTT consumer will subscribe the same topic and print the topic and payload as it receives messages. All examples have implemented automatic reconnecting, which is crucial in real production. The example code provided bellow could be the short version, it might have omitted some advanced details. For full version code, please go to our SDK repository on GitHub. Before testing the example code, replace hostname, yourvhost, username and password with the real variables in your network environment. Always run consumer first to create the exchange and queue for producer to send messages to.","title":"MQTT use cases"},{"location":"MQTT/#python","text":"","title":"Python"},{"location":"MQTT/#prerequisite","text":"The Python library we use for this example can be found at https://eclipse.org/paho/clients/python/ . Its source code is at https://git.eclipse.org/c/paho/org.eclipse.paho.mqtt.python.git/ . You can install it through sudo pip install paho-mqtt . Finally, import this library in your program. import paho.mqtt.client as mqtt The full documentation of this library is at https://pypi.python.org/pypi/paho-mqtt . This library is built on the basis of a C++ library mosquitto. The documentation of mosquitto is at https://mosquitto.org .","title":"Prerequisite"},{"location":"MQTT/#producer","text":"The first thing we need to do is to establish a connection with the RoboMQ broker. RoboMQ allows you to specify vhost along with username. See Vhost specification section for the detail. Set keep alive to 60 seconds, so that client will confirm the connectivity with broker. Many MQTT libraries, including this one, require network looping to complete and maintain the connection with broker. There could be several loop functions for you to choose. If none of them are called, incoming network data will not be processed and outgoing network data may not be sent in a timely fashion. client = mqtt.Client(client_id=\"\", clean_session=True, userdata=None, protocol=\"MQTTv31\") client.username_pw_set(vhost + \":\" + username, password) client.connect(server, port, keepalive=60, bind_address=\"\") client.loop_start() After that, producer can send messages to a particular topic. client.publish(topic, payload=message, qos=1, retain=False) At last, producer will stop loop and disconnect with the RoboMQ broker. client.loop_stop() client.disconnect()","title":"Producer"},{"location":"MQTT/#consumer","text":"The same as producer, consumer needs to connect to the RoboMQ broker and start loop. Not as the producer, this consumer loops forever. client.loop_forever() The callback function of connecting is to subscribe a topic, so that consumer knows where to listen to. The second argument in subscribe() function is QoS. def onConnect(client, userdata, rc): client.subscribe([(topic, 1)]) Once it receives a message from the queue bound by the topic, it will trigger the callback function onMessage() to print the topic and message payload. def onMessage(client, userdata, message): print(\"Topic: \" + message.topic + \", Message: \" + message.payload) The callback functions should be preset before connecting to the RoboMQ broker. client.on_connect = onConnect client.on_message = onMessage When you no longer need it, you can also unsubscribe a topic. client.unsubscribe(topic)","title":"Consumer"},{"location":"MQTT/#putting-it-together","text":"producer.py import time import paho.mqtt.client as mqtt server = \"hostname\" port = 1883 vhost = \"yourvhost\" username = \"username\" password = \"password\" topic = \"test/any\" try: client = mqtt.Client(client_id=\"\", clean_session=True, userdata=None, protocol=\"MQTTv31\") client.username_pw_set(vhost + \":\" + username, password) client.connect(server, port, keepalive=60, bind_address=\"\") #connect client.loop_start() #start loop msgNum = int(input(\"Quantity of test messages: \")) for i in range(msgNum): message = \"test msg \" + str(i + 1) client.publish(topic, payload=message, qos=1, retain=False) #publish time.sleep(1) client.loop_stop() #stop loop client.disconnect() except Exception, e: print e consumer.py import time import paho.mqtt.client as mqtt server = \"hostname\" port = 1883 vhost = \"yourvhost\" username = \"username\" password = \"password\" topic = \"test/#\" \"\"\" * This method is the callback on connecting to broker. * @ It subscribes the target topic. \"\"\" def onConnect(client, userdata, rc): #event on connecting client.subscribe([(topic, 1)]) #subscribe \"\"\" * This method is the callback on receiving messages. * @ It prints the message topic and payload on console. \"\"\" def onMessage(client, userdata, message): #event on receiving message print(\"Topic: \" + message.topic + \", Message: \" + message.payload) while True: try: client = mqtt.Client(client_id=\"\", clean_session=True, userdata=None, protocol=\"MQTTv31\") client.username_pw_set(vhost + \":\" + username, password) client.on_connect = onConnect client.on_message = onMessage client.connect(server, port, keepalive=60, bind_address=\"\") #connect client.loop_forever() #automatically reconnect once loop forever except Exception, e: #when initialize connection, reconnect on exception print \"Exception handled, reconnecting...\\nDetail:\\n%s\" % e time.sleep(5)","title":"Putting it together"},{"location":"MQTT/#nodejs","text":"","title":"Node.js"},{"location":"MQTT/#prerequisite_1","text":"The Node.js library we use for this example can be found at https://github.com/adamvr/MQTT.js . You can install the library through sudo npm install mqtt . Finally, require this library in your program. var mqtt = require(\"mqtt\"); The full documentation of this library is at https://github.com/mqttjs/MQTT.js/wiki .","title":"Prerequisite"},{"location":"MQTT/#producer_1","text":"The first thing we need to do is to establish a connection with the RoboMQ broker. RoboMQ allows you to specify vhost along with username. See Vhost specification section for the detail. Set keep alive to 60 seconds, so that client will confirm the connectivity with broker. var client = mqtt.connect(\"mqtt://\" + server + \":\" + port, {username: vhost + \":\" + username, password: password, keepalive: 60, clean: true, will: null}); Using this library, you will probably incorporate most other functions in the callback on connect. client.on(\"connect\", callback); After that, producer can send messages to a particular topic. client.publish(topic, message, {qos: 1, retain: false}); At last, producer will disconnect with the RoboMQ broker. The end() function contains disconnecting. client.end();","title":"Producer"},{"location":"MQTT/#consumer_1","text":"The first step is the same as producer, consumer needs to connect to the RoboMQ broker. In the callback function on connect, next step is to subscribe a topic, so that consumer knows where to listen to. It uses a callback function to handle incoming messages. Once it receives a message from the queue bound by the topic, it will print the topic and message payload. client.subscribe(topic, {qos: 1, dup: false}) .on(\"message\", function(topic, payload, packet) { console.log(\"Topic: \" + topic + \", Message: \" + payload); }); When you no longer need it, you can also unsubscribe a topic. client.unsubscribe(topic, callback);","title":"Consumer"},{"location":"MQTT/#putting-it-together_1","text":"producer.js var mqtt = require(\"mqtt\"); var server = \"hostname\"; var port = \"1883\"; var vhost = \"yourvhost\"; var username = \"username\"; var password = \"password\"; var topic = \"test/any\"; var client = mqtt.connect(\"mqtt://\" + server + \":\" + port, {username: vhost + \":\" + username, password: password, keepalive: 60, clean: true, will: null}); client.on(\"connect\", function() { //this library automatically reconnects on errors //ask user to input the number of test messages process.stdout.write(\"Quantity of test messages: \"); process.stdin.on(\"data\", function (msgNum) { //send certain number of messages try { for(var i = 1; i <= msgNum; i++){ var message = \"test msg \" + i; client.publish(topic, message, {qos: 1, retain: false}); } } catch(ex) { console.log(ex); process.exit(-1); } //shut down producer after messages sent setTimeout(function() { client.end(); //includes disconnect() process.exit(0); }, msgNum); }); }); consumer.js var mqtt = require(\"mqtt\"); var server = \"hostname\"; var port = \"1883\"; var vhost = \"yourvhost\"; var username = \"username\"; var password = \"password\"; var topic = \"test/#\"; var client = mqtt.connect(\"mqtt://\" + server + \":\" + port, {username: vhost + \":\" + username, password: password, keepalive: 60, clean: true, will: null}); client.on(\"connect\", function() { //this library automatically reconnects on errors try { client.subscribe(topic, {qos: 1, dup: false}) //chainable API .on(\"message\", function(topic, payload, packet) { //event handling console.log(\"Topic: \" + topic + \", Message: \" + payload); }); } catch(ex) { console.log(ex); } });","title":"Putting it together"},{"location":"MQTT/#php","text":"","title":"PHP"},{"location":"MQTT/#prerequisite_2","text":"The PHP library we use for this example can be found at https://github.com/mgdm/Mosquitto-PHP/ . This library depends on php 5.3+ and libmosquitto , so first ensure that your have them installed. You may obtain the package using PECL sudo pecl install Mosquitto-alpha . Now you should see mosquitto.so in your php shared library directory, e.g /usr/lib/php5/20121212/ . Finally, edit your php.ini . In Dynamic Extensions section, add one line extension=mosquitto.so . After installation, you don't need to explicitly require this library in your PHP script. Your PHP interpreter will integrate it for you.","title":"Prerequisite"},{"location":"MQTT/#producer_2","text":"The first thing we need to do is to establish a connection with the RoboMQ broker. RoboMQ allows you to specify vhost along with username. See Vhost specification section for the detail. In the constructor of client, first parameter is client ID, second is boolean flag for clean session. The third parameter of connect function is keep alive the in seconds. Set keep alive to 60 seconds, so that client will confirm the connectivity with broker. $client = new Mosquitto\\Client(\"1\", true); $client->setCredentials($vhost.\":\".$username, $password); $client->connect($server, $port, 60); After that, producer can send messages to a particular topic. The third parameter is QoS, fourth is boolean flag for retain. $client->publish($topic, $message, 1, false); Many MQTT libraries, including this one, require network looping to complete and maintain the connection with broker. There could be several loop functions for you to choose. If none of them are called, incoming network data will not be processed and outgoing network data may not be sent in a timely fashion. It is strongly recommended that you call loop() each time you send a message. $client->loop(); At last, producer will disconnect with the the RoboMQ broker. $client->disconnect();","title":"Producer"},{"location":"MQTT/#consumer_2","text":"The first step is the same as producer, consumer needs to connect to the RoboMQ broker. Not as the producer, this consumer loops forever. $client->loopForever(); The next step is to subscribe a topic, so that consumer knows where to listen to. The second argument in subscribe() function is QoS. client->subscribe(topic, 1); Once it receives a message from the queue bound by the topic, it will trigger the callback function onMessage() to print the topic and message payload. function onMessage($message) { printf(\"Topic: %s, Message: %s\\n\", $message->topic, $message->payload); } The callback functions should be preset before connecting to the RoboMQ broker. Foe example, $client->onMessage(\"onMessage\"); When you no longer need it, you can also unsubscribe a topic. client->unsubscribe(topic, qos);","title":"Consumer"},{"location":"MQTT/#putting-it-together_2","text":"producer.php <?php $server = \"hostname\"; $port = \"1883\"; $vhost = \"yourvhost\"; $username = \"username\"; $password = \"password\"; $topic = \"test/any\"; try { $client = new Mosquitto\\Client(\"1\", true); //clientid=\"1\", clean_session=true $client->setCredentials($vhost.\":\".$username, $password); $client->connect($server, $port, 60); //keepalive=60 echo \"Quantity of test messages: \"; $msgNum = rtrim(fgets(STDIN), PHP_EOL); for ($i = 1; $i <= $msgNum; $i++) { $message = \"test msg \".$i; $client->publish($topic, $message, 1, false); //publish test messages to the topic $client->loop(); //frequently loop to to keep communications with broker sleep(1); } $client->disconnect(); } catch (Exception $e) { echo $e; } ?> consumer.php <?php $GLOBALS[\"client\"] = $client; $GLOBALS[\"topic\"] = $topic; $server = \"hostname\"; $port = \"1883\"; $vhost = \"yourvhost\"; $username = \"username\"; $password = \"password\"; $topic = \"test/#\"; function subscribe() { $GLOBALS[\"client\"]->subscribe($GLOBALS[\"topic\"], 1); //qos=1 } /** * This method is the callback on receiving messages. * @ It prints the message topic and payload on console. */ function onMessage($message) { printf(\"Topic: %s, Message: %s\\n\", $message->topic, $message->payload); } while (true) { try { $client = new Mosquitto\\Client(\"0\", true); //clientid=\"0\", clean_session=true $client->setCredentials($vhost.\":\".$username, $password); $client->onConnect(\"subscribe\"); $client->onMessage(\"onMessage\"); $client->connect($server, $port, 60); //keepalive=60 $client->loopForever(); //automatically reconnect when loopForever } catch (Exception $e) { //when initialize connection, reconnect on exception echo \"Exception handled, reconnecting...\\nDetail:\\n\".$e.\"\\n\"; sleep(5); } } ?>","title":"Putting it together"},{"location":"MQTT/#ruby","text":"","title":"Ruby"},{"location":"MQTT/#prerequisite_3","text":"The Ruby gem we use for this example can be found at https://rubygems.org/gems/mqtt . Its source code is at https://github.com/njh/ruby-mqtt You can install it through gem install mqtt . Finally, require this gem in your program. require 'mqtt' The full documentation of this gem is at https://www.rubydoc.info/gems/mqtt/ .","title":"Prerequisite"},{"location":"MQTT/#producer_3","text":"The first thing we need to do is to establish a connection with the RoboMQ broker. RoboMQ allows you to specify vhost along with username. See Vhost specification section for the detail. Set keep alive to 60 seconds, so that client will confirm the connectivity with broker. client = MQTT::Client.connect( :host => server, :port => port, :username => \"#{vhost}:#{username}\", :password => password, :version => \"3.1.0\", :keep_alive => 60, :clean_session => true, :client_id => \"\", :will_qos => 1, :will_retain => false ) After that, producer can send messages to a particular topic. client.publish(topic, msg) At last, producer will disconnect with the RoboMQ broker. client.disconnect","title":"Producer"},{"location":"MQTT/#consumer_3","text":"The first step is the same as producer, consumer needs to connect to the RoboMQ broker. Next step is to subscribe a topic, so that consumer knows where to listen to. subscription = client.subscribe([topic,1]) To receive a message, use the get method. This method will block until a message is available. If you give it a block, then the block will be executed for every message received. client.get do |topic, message| onMessage(topic, message) end When you no longer need it, you can also unsubscribe a topic. client.unsubscribe(topic)","title":"Consumer"},{"location":"MQTT/#putting-it-together_3","text":"producer.rb require \"mqtt\" # connection options server = \"hostname\" port = 1883 vhost = \"yourvhost\" username = \"username\" password = \"password\" topic = \"test/any\" print \"Quantity of test messages: \" msgNum = gets.to_i # create connection begin client = MQTT::Client.connect( :host => server, :port => port, :username => \"#{vhost}:#{username}\", :password => password, :version => \"3.1.0\", :keep_alive => 60, :clean_session => true, :client_id => \"\", :will_qos => 1, :will_retain => false ) # publish messages (1..msgNum).each do |counter| msg = \"test msg #{counter}\" client.publish(topic, msg) sleep 1 end client.disconnect end consumer.rb require \"mqtt\" # connection options server = \"hostname\" port = 1883 vhost = \"yourvhost\" username = \"username\" password = \"password\" topic = \"test/any\" # event on receiving message def onMessage(topic, message) puts \"Topic: #{topic}, Message: #{message}\" end # create connection and keep getting messages loop do begin # connect client = MQTT::Client.connect( :host => server, :port => port, :username => \"#{vhost}:#{username}\", :password => password, :version => \"3.1.0\", :keep_alive => 60, :clean_session => true, :client_id => \"\", ) # subscribe client.subscribe([topic,1]) client.get do |topic, message| onMessage(topic, message) end rescue MQTT::ProtocolException => pe puts \"Exception handled, reconnecting...\\nDetail:\\n#{pe.message}\" sleep 5 end end","title":"Putting it together"},{"location":"MQTT/#java","text":"","title":"Java"},{"location":"MQTT/#prerequisite_4","text":"The Java library we use for this example can be found at https://www.eclipse.org/paho/clients/java/ . Download the library jar file at https://repo.eclipse.org/content/repositories/paho-releases/org/eclipse/paho/mqtt-client/0.4.0/mqtt-client-0.4.0.jar , import this library in your program import org.eclipse.paho.client.mqttv3.*; and compile your source code with the jar file. For example, javac -cp \".:./mqtt-client-0.4.0.jar\" Producer.java Consumer.java Run the producer and consumer classes. For example, java -cp \".:./mqtt-client-0.4.0.jar\" Consumer java -cp \".:./mqtt-client-0.4.0.jar\" Producer Of course, you can eventually compress your producer and consumer classes into jar files. The full documentation of this library is at http://www.eclipse.org/paho/files/javadoc/index.html .","title":"Prerequisite"},{"location":"MQTT/#producer_4","text":"The first thing we need to do is to establish a connection with the RoboMQ broker. RoboMQ allows you to specify vhost along with username. See Vhost specification section for the detail. Set keep alive to 60 seconds, so that client will confirm the connectivity with broker. private String broker = \"tcp://\" + server + \":\" + port; private String clientId = MqttClient.generateClientId(); private MemoryPersistence persistence = new MemoryPersistence(); client = new MqttClient(broker, clientId, persistence); MqttConnectOptions connOpts = new MqttConnectOptions(); connOpts.setUserName(vhost + \":\" + username); connOpts.setPassword(password.toCharArray()); connOpts.setKeepAliveInterval(60); connOpts.setCleanSession(true); client.connect(connOpts); After that, producer can send messages to a particular topic. It is remarkable that the message argument of publish() function isn't a String. Instead, it is a instance of MqttMessage class. Message payload text is the argument of the constructor of MqttMessage class. It has some public methods to set the headers, e.g. setQos() , setRetained() , etc. client.publish(topic, message); At last, producer will disconnect with the RoboMQ broker. client.disconnect();","title":"Producer"},{"location":"MQTT/#consumer_4","text":"The first step is the same as producer, consumer needs to connect to the RoboMQ broker. Next step is to subscribe a topic, so that consumer knows where to listen to. You need to set the callback on message before subscribe. Once it receives a message from queue bound by the topic, it will call the overridden function messageArrived() to print the topic and message payload. The second parameter of subscribe() function is QoS. private class onMessage implements MqttCallback { public void messageArrived(String topic, MqttMessage message) { System.out.println(\"Topic: \" + topic + \", Message: \" + (new String(message.getPayload()))); } public void connectionLost(Throwable cause) {} public void deliveryComplete(IMqttDeliveryToken token) {} } onMessage callback = new onMessage(); client.setCallback(callback); client.subscribe(topic, 1); When you no longer need it, you can also unsubscribe a topic. client.unsubscribe(topic);","title":"Consumer"},{"location":"MQTT/#putting-it-together_4","text":"Producer.java import org.eclipse.paho.client.mqttv3.MqttClient; import org.eclipse.paho.client.mqttv3.MqttConnectOptions; import org.eclipse.paho.client.mqttv3.MqttException; import org.eclipse.paho.client.mqttv3.MqttMessage; import org.eclipse.paho.client.mqttv3.persist.MemoryPersistence; import java.util.Scanner; public class Producer { private MqttClient client; private String server = \"hostname\"; private String port = \"1883\"; private String broker = \"tcp://\" + server + \":\" + port; private String vhost = \"yourvhost\"; private String username = \"username\"; private String password = \"password\"; private String topic = \"test/any\"; private String clientId = MqttClient.generateClientId(); private MemoryPersistence persistence = new MemoryPersistence(); private void produce() { try { client = new MqttClient(broker, clientId, persistence); MqttConnectOptions connOpts = new MqttConnectOptions(); connOpts.setUserName(vhost + \":\" + username); connOpts.setPassword(password.toCharArray()); connOpts.setKeepAliveInterval(60); connOpts.setCleanSession(true); client.connect(connOpts); System.out.print(\"Quantity of test messages: \"); Scanner scanner = new Scanner(System.in); int msgNum = scanner.nextInt(); for (int i = 0; i < msgNum; i ++) { MqttMessage message = new MqttMessage((\"test msg \" + Integer.toString(i + 1)).getBytes()); message.setQos(1); message.setRetained(false); client.publish(topic, message); try { Thread.sleep(1000); } catch (Exception e) {} } client.disconnect(); } catch(MqttException me) { System.out.println(me); System.exit(-1); } } public static void main(String[] args) { Producer p = new Producer(); p.produce(); } } Consumer.java import org.eclipse.paho.client.mqttv3.MqttClient; import org.eclipse.paho.client.mqttv3.MqttConnectOptions; import org.eclipse.paho.client.mqttv3.MqttException; import org.eclipse.paho.client.mqttv3.MqttMessage; import org.eclipse.paho.client.mqttv3.persist.MemoryPersistence; import org.eclipse.paho.client.mqttv3.MqttCallback; import org.eclipse.paho.client.mqttv3.IMqttDeliveryToken; public class Consumer { private MqttClient client; private String server = \"hostname\"; private String port = \"1883\"; private String broker = \"tcp://\" + server + \":\" + port; private String vhost = \"yourvhost\"; private String username = \"username\"; private String password = \"password\"; private String topic = \"test/#\"; private String clientId = MqttClient.generateClientId(); private MemoryPersistence persistence = new MemoryPersistence(); private boolean connected = false; /** * This method is the overridden callback on receiving messages. * @ It is event-driven. You don't call it in your code. * @ It prints the message topic and payload on console. * @ There're other callback functions provided by this library. */ private class onMessage implements MqttCallback { public void messageArrived(String topic, MqttMessage message) { System.out.println(\"Topic: \" + topic + \", Message: \" + (new String(message.getPayload()))); } public void connectionLost(Throwable cause) { System.out.printf(\"Exception handled, reconnecting...\\nDetail:\\n%s\\n\", cause.getMessage()); connected = false; //reconnect on exception } public void deliveryComplete(IMqttDeliveryToken token) { } } private void consume() { while (true) { try { client = new MqttClient(broker, clientId, persistence); MqttConnectOptions connOpts = new MqttConnectOptions(); connOpts.setUserName(vhost + \":\" + username); connOpts.setPassword(password.toCharArray()); connOpts.setKeepAliveInterval(60); connOpts.setCleanSession(true); client.connect(connOpts); onMessage callback = new onMessage(); client.setCallback(callback); client.subscribe(topic, 1); //qos=1 connected = true; while (connected) { //check connection status try { Thread.sleep(5000); } catch (Exception e) {} } } catch(MqttException me) { //reconnect on exception System.out.printf(\"Exception handled, reconnecting...\\nDetail:\\n%s\\n\", me); try { Thread.sleep(5000); } catch(Exception e) {} } } } public static void main(String[] args) { Consumer c = new Consumer(); c.consume(); } }","title":"Putting it together"},{"location":"MQTT/#go","text":"","title":"Go"},{"location":"MQTT/#prerequisite_5","text":"The Go library we use for this example can be found at https://eclipse.org/paho/clients/golang/ . Its GitHub repository is at https://github.com/eclipse/paho.mqtt.golang . You can install it through go get github.com/eclipse/paho.mqtt.golang . Finally, import this library in your program. import MQTT \"github.com/eclipse/paho.mqtt.golang\" The full documentation of this library is at https://godoc.org/git.eclipse.org/gitroot/paho/org.eclipse.paho.mqtt.golang.git . This library depends on Google's websockets package, which is installed with go get golang.org/x/net/websocket","title":"Prerequisite"},{"location":"MQTT/#producer_5","text":"The first thing we need to do is to establish a connection with the RoboMQ broker. RoboMQ allows you to specify vhost along with username. See Vhost specification section for the detail. Set keep alive to 60 seconds, so that client will confirm the connectivity with broker. Although the library provides an AutoReconnect connection option, we discourage you to use it. The reason will be explained in the Consumer section. connOpts := MQTT.NewClientOptions().AddBroker(fmt.Sprintf(\"tcp://%s:%d\", server, port)) connOpts.SetUsername(fmt.Sprintf(\"%s:%s\", vhost, username)) connOpts.SetPassword(password) connOpts.SetClientID(\"0\") connOpts.SetCleanSession(true) connOpts.SetKeepAlive(60 * time.Second) connOpts.SetAutoReconnect(false) client := MQTT.NewClient(connOpts) client.Connect() After that, producer can send messages to a particular topic. The second parameter is QoS, third is boolean flag for retain. client.Publish(topic, 1, false, message) At last, producer will disconnect with the RoboMQ broker. The parameter 250 is the number of milliseconds to wait for existing work to be completed. client.Disconnect(250)","title":"Producer"},{"location":"MQTT/#consumer_5","text":"The first step is the same as producer, consumer needs to connect to the RoboMQ broker. As we mentioned in the Producer section, AutoReconnect is set to false when connecting to the RoboMQ broker. It matters for consumers because AutoReconnect will only recover the connection, it won't resubscribe the topics. Therefore, a more robust approach is letting your code handle reconnecting and resubscribing on its own. The next step is to subscribe a topic, so that consumer knows where to listen to. The second argument in subscribe() function is QoS, the third one is the callback function to handle incoming messages. client.Subscribe(topic, 1, OnMessage) Once it receives a message from the queue bound by the topic, it will trigger the callback function onMessage() to print the topic and message payload. var OnMessage MQTT.MessageHandler = func(client MQTT.Client, msg MQTT.Message) { fmt.Printf(\"Topic: %s, Message: %s\\n\", msg.Topic(), msg.Payload()) } When you no longer need it, you can also unsubscribe a topic. client.Unsubscribe(topic)","title":"Consumer"},{"location":"MQTT/#putting-it-together_5","text":"producer.go package main import ( \"fmt\" MQTT \"github.com/eclipse/paho.mqtt.golang\" \"os\" \"time\" ) var server = \"hostname\" var port = 1883 var vhost = \"yourvhost\" var username = \"username\" var password = \"password\" var topic = \"test/any\" func main() { connOpts := MQTT.NewClientOptions().AddBroker(fmt.Sprintf(\"tcp://%s:%d\", server, port)) connOpts.SetUsername(fmt.Sprintf(\"%s:%s\", vhost, username)) connOpts.SetPassword(password) connOpts.SetClientID(\"1\") connOpts.SetCleanSession(true) connOpts.SetKeepAlive(60 * time.Second) connOpts.SetAutoReconnect(false) // Create and start a client using the above ClientOptions client := MQTT.NewClient(connOpts) if token := client.Connect(); token.Wait() && token.Error() != nil { fmt.Printf(\"Failed to connect, err: %v\\n\", token.Error()) os.Exit(1) } var msgNum int fmt.Print(\"Quantity of test messages: \") fmt.Scanf(\"%d\", &msgNum) for i := 0; i < msgNum; i++ { message := fmt.Sprintf(\"test msg %d\", i+1) // QoS = 1, retained = false token := client.Publish(topic, 1, false, message) // Use PublishToken to confirmed receipt from the broker token.Wait() if token.Error() != nil { fmt.Printf(\"Failed to publish, err: %v\\n\", token.Error()) os.Exit(1) } time.Sleep(time.Second) } client.Disconnect(250) } consumer.go package main import ( \"fmt\" MQTT \"github.com/eclipse/paho.mqtt.golang\" \"time\" ) var server = \"hostname\" var port = 1883 var vhost = \"yourvhost\" var username = \"username\" var password = \"password\" var topic = \"test/#\" /** * This function is the callback on receiving messages. * @ It prints the message topic and payload on console. */ var OnMessage MQTT.MessageHandler = func(client MQTT.Client, msg MQTT.Message) { fmt.Printf(\"Topic: %s, Message: %s\\n\", msg.Topic(), msg.Payload()) } func main() { connOpts := MQTT.NewClientOptions().AddBroker(fmt.Sprintf(\"tcp://%s:%d\", server, port)) connOpts.SetUsername(fmt.Sprintf(\"%s:%s\", vhost, username)) connOpts.SetPassword(password) connOpts.SetClientID(\"0\") connOpts.SetCleanSession(true) connOpts.SetKeepAlive(60 * time.Second) connOpts.SetAutoReconnect(false) // Infinite loop to auto-reconnect on failure for { // Create and start a client using the above ClientOptions client := MQTT.NewClient(connOpts) if token := client.Connect(); token.Wait() && token.Error() != nil { fmt.Printf(\"Failed to connect, err: %v\\n\", token.Error()) } // QoS = 1 if token := client.Subscribe(topic, 1, OnMessage); token.Wait() && token.Error() != nil { fmt.Printf(\"Failed to subscribe, err: %v\\n\", token.Error()) } // Constantly checking connectivity for client.IsConnected() { time.Sleep(time.Second) } fmt.Println(\"Restarting in 5 seconds...\") time.Sleep(5 * time.Second) } }","title":"Putting it together"},{"location":"MQTT/#c","text":"","title":"C++"},{"location":"MQTT/#prerequisite_6","text":"The C++ library we use for this example can be found at http://mosquitto.org/ . You will find elaborate installation guide at https://mosquitto.org/download/ . Install the library according to your operating system. The recommended approach is installing from the source. First, download the latest source package, uncompress it and enter its root directory; Then, run the following two commands: make sudo make install Include this library in your program #include <mosquitto.h> and compile it by g++ producer.cpp -o producer -lmosquitto g++ consumer.cpp -o consumer -lmosquitto See the full documentation of this library at https://mosquitto.org/documentation/ .","title":"Prerequisite"},{"location":"MQTT/#producer_6","text":"The first thing we need to do is to establish a connection with the RoboMQ broker. RoboMQ allows you to specify vhost along with username. See Vhost specification section for the detail. Remember to mosquitto_lib_init(); before creating the mosquitto instance. Many MQTT libraries, including this one, require network looping to complete and maintain the connection with broker. There could be several loop functions for you to choose. If none of them are called, incoming network data will not be processed and outgoing network data may not be sent in a timely fashion. Using this library, you usually starts loop right after connecting. The second parameter of mosquitto_new() function is boolean flag for clean session. The fourth parameter of mosquitto_connect() function is keep alive time in seconds. Set keep alive to 60 seconds, so that client will confirm the connectivity with broker. string vhusn = vhost + \":\" + usn; const char *username = vhusn.c_str(); struct mosquitto *mosq = NULL; mosquitto_lib_init(); mosq = mosquitto_new(NULL, true, NULL); mosquitto_username_pw_set(mosq, username, password); mosquitto_connect(mosq, host, port, 60)); mosquitto_loop_start(mosq); After that, producer can send messages to a particular topic. The fourth argument is length of payload char array; The sixth argument is QoS; The seventh argument is boolean flag for retain. mosquitto_publish(mosq, NULL, topic, 20, payload, 1, false); At last, producer will stop loop and disconnect with the RoboMQ broker. mosquitto_loop_stop(mosq, true); mosquitto_disconnect(mosq); mosquitto_destroy(mosq); mosquitto_lib_cleanup();","title":"Producer"},{"location":"MQTT/#consumer_6","text":"The first step is the same as producer, consumer needs to connect to the RoboMQ broker and start the loop. Not as the producer, this consumer loops forever. while(!mosquitto_loop_forever(mosq, 0, 1)){ } Then you need to set some callback functions. They play an significant role when using this library. Callback on receiving message is indispensable. void onMessage(struct mosquitto *mosq, void *userdata, const struct mosquitto_message *message) { if(message->payloadlen) { printf(\"Topic: %s, Message: %s\\n\", (char*)message->topic, (char*)message->payload); } else { printf(\"Topic: %s, Message: (null)\\n\", message->topic); } fflush(stdout); } mosquitto_message_callback_set(mosq, onMessage); Finally, you need to subscribe a topic, so that consumer knows where to listen to. Once it receives a message from the queue bound by the topic, it will call onMessage() function to print the topic and message payload. mosquitto_subscribe(mosq, NULL, topic, 1); When you no longer need it, you can also unsubscribe a topic. mosquitto_unsubscribe(mosq, NULL, topic);","title":"Consumer"},{"location":"MQTT/#putting-it-together_6","text":"producer.cpp #include <stdio.h> #include <iostream> #include <mosquitto.h> #include <exception> #include <stdlib.h> #include <unistd.h> using namespace std; //The library automatically reconnects to broker string hst = \"hostname\"; const char *host = hst.c_str(); int port = 1883; string vhost = \"yourvhost\"; string usn = \"username\"; string vhusn = vhost + \":\" + usn; const char *username = vhusn.c_str(); string pwd = \"password\"; const char *password = pwd.c_str(); string tpc = \"test/any\"; const char *topic = tpc.c_str(); /** * This is the main method which creates and runs producer instance. * @Looping is essential for this MQTT library to work. * @Exceptions on connection and publish error. */ int main(int argc, char *argv[]) { int keepalive = 60; bool clean_session = true; struct mosquitto *mosq = NULL; //create producer and connect to broker mosquitto_lib_init(); mosq = mosquitto_new(NULL, clean_session, NULL); mosquitto_username_pw_set(mosq, username, password); if(mosquitto_connect(mosq, host, port, keepalive)) { printf(\"Error: Failed to connect\\n\"); return 1; } //usually start loop right after connecting mosquitto_loop_start(mosq); //send certain number of test messages int msgNum; cout << \"Quantity of test messages: \"; cin >> msgNum; char payload[20]; for (int i = 1; i <= msgNum; i++) { sprintf(payload, \"test msg %d\", i); try { mosquitto_publish(mosq, NULL, topic, 20, payload, 1, false); } catch(exception& e) { printf(\"Error: Failed to publish message\\n%s\\n\", e.what()); return 1; } sleep(1); } //stop producer mosquitto_loop_stop(mosq, true); mosquitto_disconnect(mosq); mosquitto_destroy(mosq); mosquitto_lib_cleanup(); return 0; } consumer.cpp #include <stdio.h> #include <iostream> #include <mosquitto.h> #include <exception> #include <stdlib.h> #include <unistd.h> using namespace std; //The library automatically reconnects to broker string hst = \"hostname\"; const char *host = hst.c_str(); int port = 1883; string vhost = \"yourvhost\"; string usn = \"username\"; string vhusn = vhost + \":\" + usn; const char *username = vhusn.c_str(); string pwd = \"passwrod\"; const char *password = pwd.c_str(); string tpc = \"test/#\"; const char *topic = tpc.c_str(); /** * This method is the callback on connecting broker. * @It is event-driven. You don't call it in your code. * @It subscribes the specific topic. * @There're other callback functions provided by this library. */ void onConnect(struct mosquitto *mosq, void *userdata, int result) { if (!result) { try { mosquitto_subscribe(mosq, NULL, topic, 1); } catch (exception& e) { printf(\"Error: Failed to subscribe\\n%s\\n\", e.what()); } } else { printf(\"Error: Failed to connect\\n\"); } } /** * This method is the callback on receiving messages. * @It is event-driven. You don't call it in your code. * @It prints the message topic and payload on console. * @There're other callback functions provided by this library. */ void onMessage(struct mosquitto *mosq, void *userdata, const struct mosquitto_message *message) { if(message->payloadlen) { printf(\"Topic: %s, Message: %s\\n\", (char*)message->topic, (char*)message->payload); } else { printf(\"Topic: %s, Message: (null)\\n\", message->topic); } fflush(stdout); } /** * This is the main method which creates and sets consumer instance. * @Looping is essential for this MQTT library to work. * @Exceptions on connection and subscription error. */ int main(int argc, char *argv[]) { int keepalive = 60; bool clean_session = true; struct mosquitto *mosq = NULL; mosquitto_lib_init(); mosq = mosquitto_new(NULL, clean_session, NULL); mosquitto_username_pw_set(mosq, username, password); mosquitto_connect_callback_set(mosq, onConnect); mosquitto_message_callback_set(mosq, onMessage); mosquitto_connect(mosq, host, port, keepalive); //looping is essential for consumer to work while(!mosquitto_loop_forever(mosq, 0, 1)){ } return 0; }","title":"Putting it together"},{"location":"MS-Active%20Directory/","text":"MS Active Directory Connector The Microsoft Active Directory connector makes it simple for the IT organization to integrate Active Directory with other applications, systems and services to automate the management (provisioning, modification, and deprovisioning) of users and user groups within the Enterprise.","title":"MS Active Directory"},{"location":"MS-Active%20Directory/#ms-active-directory-connector","text":"The Microsoft Active Directory connector makes it simple for the IT organization to integrate Active Directory with other applications, systems and services to automate the management (provisioning, modification, and deprovisioning) of users and user groups within the Enterprise.","title":"MS Active Directory Connector"},{"location":"Oracle-Database_Connector/","text":"Oracle Database Connector As you probably already know, the Oracle Database is a Relational Database Management System (RDBMS) produced and marketed by Oracle Corporation. Oracle database is comprised of a collection of datasets or tables. These tables are used to store and retrieve related information which is essential to building many of the business applications required to solve business problem of all types and sizes. Oracle is an integral part of software systems used by many businesses, providing persistence, retrieval and management and analysis of data. Oracle database is a common data store for many of the analytics, visualization and BI/DWH applications. Oracle RDBMS being such an integral part of an enterprise applications, there is almost always a need for integration to it to store or to retrieve data as part of business workflows or Enterprise Application Integration (EAI) and even IoT initiatives. The good news is that integrating or connecting with Oracle database using RoboMQ SaaS and IoT integration platform is a breeze! Fig 1: Schematic of Oracle database connector of RoboMQ RoboMQ is an integration middleware platform targeted at \u201cEnterprise IoT\u201d. It is a world where the devices, sensors, clouds, SaaS applications, mobility and enterprise applications connect together to create business workflows. RoboMQ is built on Microservices and hybrid cloud architecture, allowing the applications and devices to collaborate across clouds and networks with no location restrictions. RoboMQ\u2019s key differentiation in the market place is it being protocol agnostic or API-less . Devices and systems integrate using their choice of protocol or languages with no product specific APIs mandated by RoboMQ. This is achieved by \u201c ThingsConnect \" suite of connectors and adapters, which provides integration hooks for all IoT devices, all integration protocols, systems, database and applications. To support relational databases systems, RoboMQ provides Database connectors for all major databases including Oracle. You can send and receive data to and from Oracle database and make it part of any integration workflow built using RoboMQ middleware. All you need is the JDBC connectivity to your Oracle database. What does this really mean for you? At a high level you can include databases and database driven applications easily into the integrations built using RoboMQ. You could receive messages over RoboMQ using any of MQTT, AMQP, Stomp, WebStomp or REST protocols and persist them into the database. At the same time, you can select information from the database and publish it as a message that could be consumed by clients using any of the above mentioned messaging and integration protocols. So essentially it is a full two way integration of Oracle database with RoboMQ. Setting up the Oracle database connector is incredibly easily. All you need is to collect the Oracle database connection information and user credential and configure the RoboMQ Oracle connector. ThingsConnect Oracle connector like almost anything with RoboMQ is a microservice that runs as an independent and atomic docker container. You provide the connection and the credential configuration in a config file and mount the configuration to the docker container. This is as simple as 1-2-3: Obtain Oracle database information and credential Put the configuration information in a config file Run the connector which is a Docker container or a microservice The Oracle database connector can be run anywhere as a docker container with the following single line command: $ docker run -d --name oracle_connector -v path/to/config:/opt/thingsConnect/config/x-adapter/ oracledbconnector:v1.00 Seems too simple and easy, yes it is... The connector can be run as a docker container inside the corporate firewall or on the cloud. No firewalls are needed since it always makes outbound IP connection to RoboMQ. When you run the docker container, it pulls the image from the docker repository and runs a Docker container from it. Any future updates are automatically available to you as the updates to the Docker image itself. You do however have the option to run the connector as a standalone traditional program not using the docker technology. There are some additional details like it supports JSON as well as delimited ASCII data (CSV or any delimited text format) interchange methods. The connector also has error handling built in with the provision of the \u201cdead letter\u201d queues. Any messages that cannot be handled are routed to the dead letter queue. The robust error handling provided as core part of RoboMQ product provides email/SMS or phone alert and an ability to create a ticket or a case in ticketing system like ServiceNow, Jira or Salesforce. These errors or the tickets created by the connector can then be handled on a case-by-case basis by the operations or support teams. In addition to it, you get the Error Analytics component of RoboMQ which provides a strategic root cause analysis and visualization of errors in your integrations. So what are you waiting for? Try out our Oracle Database connector and let us know your feedback. To learn more about this and many other connectors that RoboMQ offerers check back on our connectors page! If you have any other questions please reach out to us at, sales@robomq.io and we would love to help.","title":"Oracle Database"},{"location":"Oracle-Database_Connector/#oracle-database-connector","text":"As you probably already know, the Oracle Database is a Relational Database Management System (RDBMS) produced and marketed by Oracle Corporation. Oracle database is comprised of a collection of datasets or tables. These tables are used to store and retrieve related information which is essential to building many of the business applications required to solve business problem of all types and sizes. Oracle is an integral part of software systems used by many businesses, providing persistence, retrieval and management and analysis of data. Oracle database is a common data store for many of the analytics, visualization and BI/DWH applications. Oracle RDBMS being such an integral part of an enterprise applications, there is almost always a need for integration to it to store or to retrieve data as part of business workflows or Enterprise Application Integration (EAI) and even IoT initiatives. The good news is that integrating or connecting with Oracle database using RoboMQ SaaS and IoT integration platform is a breeze! Fig 1: Schematic of Oracle database connector of RoboMQ RoboMQ is an integration middleware platform targeted at \u201cEnterprise IoT\u201d. It is a world where the devices, sensors, clouds, SaaS applications, mobility and enterprise applications connect together to create business workflows. RoboMQ is built on Microservices and hybrid cloud architecture, allowing the applications and devices to collaborate across clouds and networks with no location restrictions. RoboMQ\u2019s key differentiation in the market place is it being protocol agnostic or API-less . Devices and systems integrate using their choice of protocol or languages with no product specific APIs mandated by RoboMQ. This is achieved by \u201c ThingsConnect \" suite of connectors and adapters, which provides integration hooks for all IoT devices, all integration protocols, systems, database and applications. To support relational databases systems, RoboMQ provides Database connectors for all major databases including Oracle. You can send and receive data to and from Oracle database and make it part of any integration workflow built using RoboMQ middleware. All you need is the JDBC connectivity to your Oracle database. What does this really mean for you? At a high level you can include databases and database driven applications easily into the integrations built using RoboMQ. You could receive messages over RoboMQ using any of MQTT, AMQP, Stomp, WebStomp or REST protocols and persist them into the database. At the same time, you can select information from the database and publish it as a message that could be consumed by clients using any of the above mentioned messaging and integration protocols. So essentially it is a full two way integration of Oracle database with RoboMQ. Setting up the Oracle database connector is incredibly easily. All you need is to collect the Oracle database connection information and user credential and configure the RoboMQ Oracle connector. ThingsConnect Oracle connector like almost anything with RoboMQ is a microservice that runs as an independent and atomic docker container. You provide the connection and the credential configuration in a config file and mount the configuration to the docker container. This is as simple as 1-2-3: Obtain Oracle database information and credential Put the configuration information in a config file Run the connector which is a Docker container or a microservice The Oracle database connector can be run anywhere as a docker container with the following single line command: $ docker run -d --name oracle_connector -v path/to/config:/opt/thingsConnect/config/x-adapter/ oracledbconnector:v1.00 Seems too simple and easy, yes it is... The connector can be run as a docker container inside the corporate firewall or on the cloud. No firewalls are needed since it always makes outbound IP connection to RoboMQ. When you run the docker container, it pulls the image from the docker repository and runs a Docker container from it. Any future updates are automatically available to you as the updates to the Docker image itself. You do however have the option to run the connector as a standalone traditional program not using the docker technology. There are some additional details like it supports JSON as well as delimited ASCII data (CSV or any delimited text format) interchange methods. The connector also has error handling built in with the provision of the \u201cdead letter\u201d queues. Any messages that cannot be handled are routed to the dead letter queue. The robust error handling provided as core part of RoboMQ product provides email/SMS or phone alert and an ability to create a ticket or a case in ticketing system like ServiceNow, Jira or Salesforce. These errors or the tickets created by the connector can then be handled on a case-by-case basis by the operations or support teams. In addition to it, you get the Error Analytics component of RoboMQ which provides a strategic root cause analysis and visualization of errors in your integrations. So what are you waiting for? Try out our Oracle Database connector and let us know your feedback. To learn more about this and many other connectors that RoboMQ offerers check back on our connectors page! If you have any other questions please reach out to us at, sales@robomq.io and we would love to help.","title":"Oracle Database Connector"},{"location":"REST/","text":"Introduction Browse the chapter of AMQP Introduction first if you're new to AMQP. RoboMQ innovatively provides REST interface over the AMQP broker. It's only accessible over HTTPS. Our REST interface facilitates using RoboMQ from any HTTP client. Therefore, it allows you send and receive messages without installing a message queue client library, writing and running a client program. Some common scenarios of interacting with our REST interface are Integrate any devices or applications with RoboMQ message queue system by making HTTP calls from them. Send and receive messages through simple HTTP client for easy testing, such as cURL. Get rid of programming. Send and receive messages from Web browser with a JavaScript HTTP client. No library installation is required. Usage HTTP GET and POST methods are supported. Each transaction consists of one AMQP message per HTTP request-response. GET method gets a message from a particular queue, which is bound to an exchange with a routing key. POST method publishes a message to a particular exchange with a routing key, and finally delivers it to a queue. Request URL: URL format of HTTP request requires AMQP parameters to locate the message source or destination. https://{hostname}/rest/{vhost}/{exchangeName}/{queueName}/{routingkey} Authentication: There are 2 authentication mechanisms that the REST interface will accept. They are secret token header and HTTP basic auth. You need to apply one of them. If you apply both, the basic auth will be ignored. Secret Token Header: set a HTTP header in request as the credential. You will need to provide RoboMQ the header name and value for us to add it into server records. HTTP Basic Auth: submit your RoboMQ username:password via HTTP basic auth. Certificate: In case the HTTP client you use requires the CA certificate to verify RoboMQ 's certificate, download it from https://www.tbs-x509.com/AddTrustExternalCARoot.crt GET: GET method requires no additional HTTP header or body in the request. POST: You can optionally set a X-AMQP-Properties HTTP header in POST request. It will be an object containing key-value pairs of any available AMQP message properties. For example, X-AMQP-Properties: {\"contentType\": \"text/plain\", \"deliveryMode\": 2} Find more details on AMQP message properties in the Properties section. The HTTP request body will be sent as the AMQP message body. Make sure the Content-Type header matches the actual MIME type of the body. Response GET: If the GET request succeeds, the response will be either status code 200 and the message that is fetched, or status code 204 which indicates the target queue is currently empty. The HTTP body in 200 response is the AMQP message body and there are 2 HTTP headers X-AMQP-Envelop and X-AMQP-Properties , respectively containing the envelop and properties of the AMQP message, for example HTTP Headers: X-AMQP-Envelop: {\"deliveryTag\":1,\"redelivered\":false,\"exchange\":\"testEx\",\"routingKey\":\"testKey\",\"messageCount\":0} X-AMQP-Properties: {\"contentType\":\"text/plain\",\"headers\":{},\"deliveryMode\":2,\"correlationId\":\"0053b20e-a462-435d-8697-cd43fc22c4c7\",\"messageId\":\"0053b20e-a462-435d-8697-cd43fc22c4c7\"} HTTP Body: Hello World All errors will be responded with status code and error description in HTTP body. POST: The response for POST request is either 200 OK or error status code and description in HTTP body. Missing resources: For both GET and POST methods, if any of the exchange, queue or binding doesn't exist, server will create it with the following default arguments: type (exchange): topic durable (exchange & queue): true auto-delete (exchange & queue): false internal (exchange): false Properties The X-AMQP-Properties HTTP header in the response of GET and POST request should be a JSON object. All available properties are listed bellow. mandatory (boolean): if true, the message will be returned if it is not routed to a queue (i.e., if there are no bindings that match its routing key). immediate (boolean): in the specification, this instructs the server to return the message if it is not able to be sent immediately to a consumer. No longer implemented in RabbitMQ, and if true, will provoke a channel error, so it's best to leave it out. deliveryMode (boolean or numeric): Either 1 or falsey, meaning non-persistent; or, 2 or truthy, meaning persistent. That's just obscure though. Use the option persistent instead. persistent (boolean): If truthy, the message will survive broker restarts provided it's in a queue that also survives restarts. Corresponds to, and overrides, the property deliveryMode. contentType (string): a MIME type for the message content contentEncoding (string): a MIME encoding for the message content correlationId (string): usually used to match replies to requests, or similar replyTo (string): often used to name a queue to which the receiving application must send replies, in an RPC scenario (many libraries assume this pattern) messageId (string): arbitrary application-specific identifier for the message expiration (string): if supplied, the message will be discarded from a queue once it's been there longer than the given number of milliseconds. In the specification this is a string; numbers supplied here will be coerced to strings for transit. timestamp (positive number): a timestamp for the message CC (string or array of string): an array of routing keys as strings; messages will be routed to these routing keys in addition to that given as the routingKey parameter. A string will be implicitly treated as an array containing just that string. This will override any value given for CC in the headers parameter. NB The property names CC and BCC are case-sensitive. BCC (string or array of string): like CC, except that the value will not be sent in the message headers to consumers. userId (string): If supplied, RabbitMQ will compare it to the username supplied when opening the connection, and reject messages for which it does not match. appId (string): an arbitrary identifier for the originating application type (string): an arbitrary application-specific type for the message headers (object): application specific headers to be carried along with the message content. The value as sent may be augmented by extension-specific fields if they are given in the parameters, for example, 'CC', since these are encoded as message headers; the supplied value won't be mutated REST use case We will provide complete examples of HTTP call to our REST interface using cURL, but you may use any other tool or language to make the calls. The only prerequisite is that you have cURL client installed. cURL comes with most Linux systems. For windows, you may need to download curl.exe and place it into your system directory, e.g. C:\\Windows\\System32\\curl.exe . GET Secret Token: curl -X GET -i https://{hostname}/rest/{yourvhost}/testEx/testQ/testKey \\ -H 'X-Secret-Token: {token}' Basic Auth: curl -X GET -i https://{username}:{password}@{hostname}/rest/{yourvhost}/testEx/testQ/testKey POST Secret Token: curl -X POST -i https://{hostname}/rest/{yourvhost}/testEx/testQ/testKey \\ -H 'X-Secret-Token: {token}' \\ -H 'X-AMQP-Properties: {\"contentType\": \"text/plain\", \"deliveryMode\": 2}' \\ -d 'Hello World' Basic Auth: curl -X POST -i https://{hostname}/rest/{yourvhost}/testEx/testQ/testKey \\ -u {username}:{password} \\ -H 'X-AMQP-Properties: {\"contentType\": \"text/plain\", \"deliveryMode\": 2}' \\ -d 'Hello World'","title":"REST"},{"location":"REST/#introduction","text":"Browse the chapter of AMQP Introduction first if you're new to AMQP. RoboMQ innovatively provides REST interface over the AMQP broker. It's only accessible over HTTPS. Our REST interface facilitates using RoboMQ from any HTTP client. Therefore, it allows you send and receive messages without installing a message queue client library, writing and running a client program. Some common scenarios of interacting with our REST interface are Integrate any devices or applications with RoboMQ message queue system by making HTTP calls from them. Send and receive messages through simple HTTP client for easy testing, such as cURL. Get rid of programming. Send and receive messages from Web browser with a JavaScript HTTP client. No library installation is required.","title":"Introduction"},{"location":"REST/#usage","text":"HTTP GET and POST methods are supported. Each transaction consists of one AMQP message per HTTP request-response. GET method gets a message from a particular queue, which is bound to an exchange with a routing key. POST method publishes a message to a particular exchange with a routing key, and finally delivers it to a queue.","title":"Usage"},{"location":"REST/#request","text":"URL: URL format of HTTP request requires AMQP parameters to locate the message source or destination. https://{hostname}/rest/{vhost}/{exchangeName}/{queueName}/{routingkey} Authentication: There are 2 authentication mechanisms that the REST interface will accept. They are secret token header and HTTP basic auth. You need to apply one of them. If you apply both, the basic auth will be ignored. Secret Token Header: set a HTTP header in request as the credential. You will need to provide RoboMQ the header name and value for us to add it into server records. HTTP Basic Auth: submit your RoboMQ username:password via HTTP basic auth. Certificate: In case the HTTP client you use requires the CA certificate to verify RoboMQ 's certificate, download it from https://www.tbs-x509.com/AddTrustExternalCARoot.crt GET: GET method requires no additional HTTP header or body in the request. POST: You can optionally set a X-AMQP-Properties HTTP header in POST request. It will be an object containing key-value pairs of any available AMQP message properties. For example, X-AMQP-Properties: {\"contentType\": \"text/plain\", \"deliveryMode\": 2} Find more details on AMQP message properties in the Properties section. The HTTP request body will be sent as the AMQP message body. Make sure the Content-Type header matches the actual MIME type of the body.","title":"Request"},{"location":"REST/#response","text":"GET: If the GET request succeeds, the response will be either status code 200 and the message that is fetched, or status code 204 which indicates the target queue is currently empty. The HTTP body in 200 response is the AMQP message body and there are 2 HTTP headers X-AMQP-Envelop and X-AMQP-Properties , respectively containing the envelop and properties of the AMQP message, for example HTTP Headers: X-AMQP-Envelop: {\"deliveryTag\":1,\"redelivered\":false,\"exchange\":\"testEx\",\"routingKey\":\"testKey\",\"messageCount\":0} X-AMQP-Properties: {\"contentType\":\"text/plain\",\"headers\":{},\"deliveryMode\":2,\"correlationId\":\"0053b20e-a462-435d-8697-cd43fc22c4c7\",\"messageId\":\"0053b20e-a462-435d-8697-cd43fc22c4c7\"} HTTP Body: Hello World All errors will be responded with status code and error description in HTTP body. POST: The response for POST request is either 200 OK or error status code and description in HTTP body. Missing resources: For both GET and POST methods, if any of the exchange, queue or binding doesn't exist, server will create it with the following default arguments: type (exchange): topic durable (exchange & queue): true auto-delete (exchange & queue): false internal (exchange): false","title":"Response"},{"location":"REST/#properties","text":"The X-AMQP-Properties HTTP header in the response of GET and POST request should be a JSON object. All available properties are listed bellow. mandatory (boolean): if true, the message will be returned if it is not routed to a queue (i.e., if there are no bindings that match its routing key). immediate (boolean): in the specification, this instructs the server to return the message if it is not able to be sent immediately to a consumer. No longer implemented in RabbitMQ, and if true, will provoke a channel error, so it's best to leave it out. deliveryMode (boolean or numeric): Either 1 or falsey, meaning non-persistent; or, 2 or truthy, meaning persistent. That's just obscure though. Use the option persistent instead. persistent (boolean): If truthy, the message will survive broker restarts provided it's in a queue that also survives restarts. Corresponds to, and overrides, the property deliveryMode. contentType (string): a MIME type for the message content contentEncoding (string): a MIME encoding for the message content correlationId (string): usually used to match replies to requests, or similar replyTo (string): often used to name a queue to which the receiving application must send replies, in an RPC scenario (many libraries assume this pattern) messageId (string): arbitrary application-specific identifier for the message expiration (string): if supplied, the message will be discarded from a queue once it's been there longer than the given number of milliseconds. In the specification this is a string; numbers supplied here will be coerced to strings for transit. timestamp (positive number): a timestamp for the message CC (string or array of string): an array of routing keys as strings; messages will be routed to these routing keys in addition to that given as the routingKey parameter. A string will be implicitly treated as an array containing just that string. This will override any value given for CC in the headers parameter. NB The property names CC and BCC are case-sensitive. BCC (string or array of string): like CC, except that the value will not be sent in the message headers to consumers. userId (string): If supplied, RabbitMQ will compare it to the username supplied when opening the connection, and reject messages for which it does not match. appId (string): an arbitrary identifier for the originating application type (string): an arbitrary application-specific type for the message headers (object): application specific headers to be carried along with the message content. The value as sent may be augmented by extension-specific fields if they are given in the parameters, for example, 'CC', since these are encoded as message headers; the supplied value won't be mutated","title":"Properties"},{"location":"REST/#rest-use-case","text":"We will provide complete examples of HTTP call to our REST interface using cURL, but you may use any other tool or language to make the calls. The only prerequisite is that you have cURL client installed. cURL comes with most Linux systems. For windows, you may need to download curl.exe and place it into your system directory, e.g. C:\\Windows\\System32\\curl.exe .","title":"REST use case"},{"location":"REST/#get","text":"Secret Token: curl -X GET -i https://{hostname}/rest/{yourvhost}/testEx/testQ/testKey \\ -H 'X-Secret-Token: {token}' Basic Auth: curl -X GET -i https://{username}:{password}@{hostname}/rest/{yourvhost}/testEx/testQ/testKey","title":"GET"},{"location":"REST/#post","text":"Secret Token: curl -X POST -i https://{hostname}/rest/{yourvhost}/testEx/testQ/testKey \\ -H 'X-Secret-Token: {token}' \\ -H 'X-AMQP-Properties: {\"contentType\": \"text/plain\", \"deliveryMode\": 2}' \\ -d 'Hello World' Basic Auth: curl -X POST -i https://{hostname}/rest/{yourvhost}/testEx/testQ/testKey \\ -u {username}:{password} \\ -H 'X-AMQP-Properties: {\"contentType\": \"text/plain\", \"deliveryMode\": 2}' \\ -d 'Hello World'","title":"POST"},{"location":"SDK/","text":"RoboMQ has rich library of examples code in multiple programming languages supporting AMQP, MQTT and STOMP protocols. The SDK includes example code for multiple Messaging Integration Patterns (MEPs). All examples have implemented automatic reconnecting, which is crucial in real production. Supported protocols You can send and receive messages using RoboMQ platform from a choice of AMQP AMQP , MQTT and STOMP protocols. Each of the protocols can be used for variety of messaging integration patterns. MQTT and STOMP, being relatively light weight protocol, are ideal for small footprint devices. AMQP could be the protocol of choice for more capable applications and enterprise systems. AMQP use cases Following use cases using AMQP protocols are documented with code on the RoboMQ GitHub . One-to-one or direct messaging : point to point message transportation Broadcast : sending messages to all subscribed consumers Key based routing : routing messages to consumer based on key based subscription Filter based routing (Topic) : routing messages based on complex filter rules applied to routing keys Request and reply : two way request reply communication MQTT use cases MQTT (Message Queues for Telemetry Transport) is lighter weight protocol for device specific use cases supporting pub-sub messaging pattern. MQTT code examples are on RoboMQ GitHub STOMP use cases STOMP (Simple Text Oriented Messaging Protocol) is a HTTP like simple protocol and can be used for variety of use cases with very little programming. STOMP code examples are on RoboMQ GitHub Other use cases WebSTOMP WebSTOMP is a simple bridge exposing the STOMP protocol over emulated HTML5 WebSockets, which makes it possible to use RoboMQ from web browsers. WebSTOMP code examples are on RoboMQ GitHub SSL SSL RoboMQ has obtained certificate from certificate authority and supports SSL connection for all available protocols. SSL code examples are on RoboMQ GitHub Supported programming languages RoboMQ supports majority of the programming languages. For most programming languages, the client side libraries exists for AMPQ, MQTT and STOMP protocols. The SDK on GitHub contains examples in Python, Node.js, PHP, Java, C and C++. We continue to add examples in additional languages.","title":"SDK & example codes"},{"location":"SDK/#supported-protocols","text":"You can send and receive messages using RoboMQ platform from a choice of AMQP AMQP , MQTT and STOMP protocols. Each of the protocols can be used for variety of messaging integration patterns. MQTT and STOMP, being relatively light weight protocol, are ideal for small footprint devices. AMQP could be the protocol of choice for more capable applications and enterprise systems.","title":"Supported protocols"},{"location":"SDK/#amqp-use-cases","text":"Following use cases using AMQP protocols are documented with code on the RoboMQ GitHub . One-to-one or direct messaging : point to point message transportation Broadcast : sending messages to all subscribed consumers Key based routing : routing messages to consumer based on key based subscription Filter based routing (Topic) : routing messages based on complex filter rules applied to routing keys Request and reply : two way request reply communication","title":"AMQP use cases"},{"location":"SDK/#mqtt-use-cases","text":"MQTT (Message Queues for Telemetry Transport) is lighter weight protocol for device specific use cases supporting pub-sub messaging pattern. MQTT code examples are on RoboMQ GitHub","title":"MQTT use cases"},{"location":"SDK/#stomp-use-cases","text":"STOMP (Simple Text Oriented Messaging Protocol) is a HTTP like simple protocol and can be used for variety of use cases with very little programming. STOMP code examples are on RoboMQ GitHub","title":"STOMP use cases"},{"location":"SDK/#other-use-cases","text":"","title":"Other use cases"},{"location":"SDK/#webstomp","text":"WebSTOMP is a simple bridge exposing the STOMP protocol over emulated HTML5 WebSockets, which makes it possible to use RoboMQ from web browsers. WebSTOMP code examples are on RoboMQ GitHub","title":"WebSTOMP"},{"location":"SDK/#ssl-ssl","text":"RoboMQ has obtained certificate from certificate authority and supports SSL connection for all available protocols. SSL code examples are on RoboMQ GitHub","title":"SSL SSL"},{"location":"SDK/#supported-programming-languages","text":"RoboMQ supports majority of the programming languages. For most programming languages, the client side libraries exists for AMPQ, MQTT and STOMP protocols. The SDK on GitHub contains examples in Python, Node.js, PHP, Java, C and C++. We continue to add examples in additional languages.","title":"Supported programming languages"},{"location":"SSL/","text":"Introduction Before reading this chapter, we assume that you already know AMQP protocol. Knowing MQTT and STOMP would be great too. If not, please go through at least the Key based message routing section in User Guide. RoboMQ has obtained certificate from a certificate authority (CA) and supports SSL (secure socket layer) connection for all available protocols, including AMQP, MQTT, STOMP and WebSTOMP. The SSL ports of those four protocols are respectively AMQP: 5671, MQTT: 8883, STOMP: 61614, WebSTOMP: 15673. This chapter intends to introduce you the method to establish SSL connection between RoboMQ broker and your client program, except for WebSTOMP. The certificate of our root CA can be downloaded at http://www.tbs-x509.com/AddTrustExternalCARoot.crt . It is needed to verify the leaf certificate of RoboMQ because the latter one was granted by the root CA through a chain of trust. In most cases, your device or application trying to connect to RoboMQ broker are not like Web browsers. Browsers come with all CAs' certificates so they're inherently able to verify the RoboMQ certificate. That is why WebSTOMP client running inside a browser doesn't need any extra work to connect over SSL. In contrast, your device or application typically don't have the CA certificate to verify RoboMQ certificate. Therefore, if you choose to or have to verify the leaf certificate of RoboMQ in your client program, you will be required to download the root CA certificate at https://www.tbs-x509.com/AddTrustExternalCARoot.crt and import it in your program to achieve the verification. Otherwise, if you optionally ignore the certificate verification, it's not a necessity. An unfortunate fact is that not all message queue client libraries support SSL connection. Actually, only a small portion of them do. Hence, pick a capable library before you develop your SSL clients. SSL use cases We will provide examples of AMQP SSL clients of key based message routing scenario in Python. They are variants of the Python example in Key based message routing section. The only difference is that they connect over SSL, so we're going to focus on the connecting part of the code. The first example verifies RoboMQ certificate, while the second one doesn't. You may choose to follow any of them according to your specific demands. Please refer to the Key based message routing section in User Guide for library dependency, program logic, code comments and everything irrelevant with connecting itself. The example code provided bellow could be the short version, it might have omitted some advanced details. For full version code, please go to our SDK repository on GitHub. Before testing the example code, replace hostname, yourvhost, username and password with the real variables in your network environment. Always run consumer first to create the exchange and queue for producer to send messages to. Certificate verified Connect Compared to non-SSL connect method recapped bellow, credentials = pika.PlainCredentials(username, password) connection = pika.BlockingConnection(pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60)) SSL connect method adds two parameters. It sets ssl = True and passes SSL options. The \"cert_reqs\": ssl.CERT_REQUIRED in SSL options implies the client requires to verify server's certificate. credentials = pika.PlainCredentials(username, password) sslOptions = {\"cert_reqs\": ssl.CERT_REQUIRED, \"ca_certs\": caCert} parameters = pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60, ssl = True, ssl_options = sslOptions) connection = pika.BlockingConnection(parameters) If the root CA certificate file isn't provided or isn't the one downloaded at http://www.tbs-x509.com/AddTrustExternalCARoot.crt , client will fail to verify RoboMQ certificate thus fail to connect. Putting it together producer.py import pika import ssl server = \"hostname\" port = 5671 vhost = \"yourvhost\" username = \"username\" password = \"password\" caCert = \"./AddTrustExternalCARoot.crt\" #change it to the actual path to CA certificate exchangeName = \"testEx\" routingKey = \"test\" try: #connect credentials = pika.PlainCredentials(username, password) sslOptions = {\"cert_reqs\": ssl.CERT_REQUIRED, \"ca_certs\": caCert} parameters = pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60, ssl = True, ssl_options = sslOptions) connection = pika.BlockingConnection(parameters) channel = connection.channel() #send message properties = pika.spec.BasicProperties(content_type = \"text/plain\", delivery_mode = 1) channel.basic_publish(exchange = exchangeName, routing_key = routingKey, body = \"Hello World!\", properties = properties) #disconnect connection.close() except Exception, e: print e consumer.py import pika import ssl import time server = \"hostname\" port = 5671 vhost = \"yourvhost\" username = \"username\" password = \"password\" caCert = \"./AddTrustExternalCARoot.crt\" #change it to the actual path to CA certificate exchangeName = \"testEx\" queueName = \"testQ1\" routingKey = \"test\" #callback funtion on receiving messages def onMessage(channel, method, properties, body): print body while True: try: #connect credentials = pika.PlainCredentials(username, password) sslOptions = {\"cert_reqs\": ssl.CERT_REQUIRED, \"ca_certs\": caCert} parameters = pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60, ssl = True, ssl_options = sslOptions) connection = pika.BlockingConnection(parameters) channel = connection.channel() #declare exchange and queue, bind them and consume messages channel.exchange_declare(exchange = exchangeName, exchange_type = \"direct\", auto_delete = True) channel.queue_declare(queue = queueName, exclusive = True, auto_delete = True) channel.queue_bind(exchange = exchangeName, queue = queueName, routing_key = routingKey) channel.basic_consume(consumer_callback = onMessage, queue = queueName, no_ack = True) channel.start_consuming() except Exception, e: #reconnect on exception print \"Exception handled, reconnecting...\\nDetail:\\n%s\" % e try: connection.close() except: pass time.sleep(5) Certificate not verified Connect Compared to certificate-verified connect method above, certificate-not-verified connect method changes \"cert_reqs\": ssl.CERT_REQUIRED to \"cert_reqs\": ssl.CERT_NONE in SSL options. That implies the client doesn't require to verify server's certificate. credentials = pika.PlainCredentials(username, password) sslOptions = {\"cert_reqs\": ssl.CERT_NONE} parameters = pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60, ssl = True, ssl_options = sslOptions) connection = pika.BlockingConnection(parameters) Even if the root CA certificate is provided, it will be ignored. You can safely use this method to connect to RoboMQ broker over SSL without verification because RoboMQ is a trustworthy service provider. However, this way is generally not recommended for unknown services. Putting it together producer.py import pika import ssl server = \"hostname\" port = 5671 vhost = \"yourvhost\" username = \"username\" password = \"password\" exchangeName = \"testEx\" routingKey = \"test\" try: #connect credentials = pika.PlainCredentials(username, password) sslOptions = {\"cert_reqs\": ssl.CERT_NONE} parameters = pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60, ssl = True, ssl_options = sslOptions) connection = pika.BlockingConnection(parameters) channel = connection.channel() #send message properties = pika.spec.BasicProperties(content_type = \"text/plain\", delivery_mode = 1) channel.basic_publish(exchange = exchangeName, routing_key = routingKey, body = \"Hello World!\", properties = properties) #disconnect connection.close() except Exception, e: print e consumer.py import pika import ssl import time server = \"hostname\" port = 5671 vhost = \"yourvhost\" username = \"username\" password = \"password\" exchangeName = \"testEx\" queueName = \"testQ1\" routingKey = \"test\" #callback funtion on receiving messages def onMessage(channel, method, properties, body): print body while True: try: #connect credentials = pika.PlainCredentials(username, password) sslOptions = {\"cert_reqs\": ssl.CERT_NONE} parameters = pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60, ssl = True, ssl_options = sslOptions) connection = pika.BlockingConnection(parameters) channel = connection.channel() #declare exchange and queue, bind them and consume messages channel.exchange_declare(exchange = exchangeName, exchange_type = \"direct\", auto_delete = True) channel.queue_declare(queue = queueName, exclusive = True, auto_delete = True) channel.queue_bind(exchange = exchangeName, queue = queueName, routing_key = routingKey) channel.basic_consume(consumer_callback = onMessage, queue = queueName, no_ack = True) channel.start_consuming() except Exception, e: #reconnect on exception print \"Exception handled, reconnecting...\\nDetail:\\n%s\" % e try: connection.close() except: pass time.sleep(5)","title":"SSL"},{"location":"SSL/#introduction","text":"Before reading this chapter, we assume that you already know AMQP protocol. Knowing MQTT and STOMP would be great too. If not, please go through at least the Key based message routing section in User Guide. RoboMQ has obtained certificate from a certificate authority (CA) and supports SSL (secure socket layer) connection for all available protocols, including AMQP, MQTT, STOMP and WebSTOMP. The SSL ports of those four protocols are respectively AMQP: 5671, MQTT: 8883, STOMP: 61614, WebSTOMP: 15673. This chapter intends to introduce you the method to establish SSL connection between RoboMQ broker and your client program, except for WebSTOMP. The certificate of our root CA can be downloaded at http://www.tbs-x509.com/AddTrustExternalCARoot.crt . It is needed to verify the leaf certificate of RoboMQ because the latter one was granted by the root CA through a chain of trust. In most cases, your device or application trying to connect to RoboMQ broker are not like Web browsers. Browsers come with all CAs' certificates so they're inherently able to verify the RoboMQ certificate. That is why WebSTOMP client running inside a browser doesn't need any extra work to connect over SSL. In contrast, your device or application typically don't have the CA certificate to verify RoboMQ certificate. Therefore, if you choose to or have to verify the leaf certificate of RoboMQ in your client program, you will be required to download the root CA certificate at https://www.tbs-x509.com/AddTrustExternalCARoot.crt and import it in your program to achieve the verification. Otherwise, if you optionally ignore the certificate verification, it's not a necessity. An unfortunate fact is that not all message queue client libraries support SSL connection. Actually, only a small portion of them do. Hence, pick a capable library before you develop your SSL clients.","title":"Introduction"},{"location":"SSL/#ssl-use-cases","text":"We will provide examples of AMQP SSL clients of key based message routing scenario in Python. They are variants of the Python example in Key based message routing section. The only difference is that they connect over SSL, so we're going to focus on the connecting part of the code. The first example verifies RoboMQ certificate, while the second one doesn't. You may choose to follow any of them according to your specific demands. Please refer to the Key based message routing section in User Guide for library dependency, program logic, code comments and everything irrelevant with connecting itself. The example code provided bellow could be the short version, it might have omitted some advanced details. For full version code, please go to our SDK repository on GitHub. Before testing the example code, replace hostname, yourvhost, username and password with the real variables in your network environment. Always run consumer first to create the exchange and queue for producer to send messages to.","title":"SSL use cases"},{"location":"SSL/#certificate-verified","text":"","title":"Certificate verified"},{"location":"SSL/#connect","text":"Compared to non-SSL connect method recapped bellow, credentials = pika.PlainCredentials(username, password) connection = pika.BlockingConnection(pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60)) SSL connect method adds two parameters. It sets ssl = True and passes SSL options. The \"cert_reqs\": ssl.CERT_REQUIRED in SSL options implies the client requires to verify server's certificate. credentials = pika.PlainCredentials(username, password) sslOptions = {\"cert_reqs\": ssl.CERT_REQUIRED, \"ca_certs\": caCert} parameters = pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60, ssl = True, ssl_options = sslOptions) connection = pika.BlockingConnection(parameters) If the root CA certificate file isn't provided or isn't the one downloaded at http://www.tbs-x509.com/AddTrustExternalCARoot.crt , client will fail to verify RoboMQ certificate thus fail to connect.","title":"Connect"},{"location":"SSL/#putting-it-together","text":"producer.py import pika import ssl server = \"hostname\" port = 5671 vhost = \"yourvhost\" username = \"username\" password = \"password\" caCert = \"./AddTrustExternalCARoot.crt\" #change it to the actual path to CA certificate exchangeName = \"testEx\" routingKey = \"test\" try: #connect credentials = pika.PlainCredentials(username, password) sslOptions = {\"cert_reqs\": ssl.CERT_REQUIRED, \"ca_certs\": caCert} parameters = pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60, ssl = True, ssl_options = sslOptions) connection = pika.BlockingConnection(parameters) channel = connection.channel() #send message properties = pika.spec.BasicProperties(content_type = \"text/plain\", delivery_mode = 1) channel.basic_publish(exchange = exchangeName, routing_key = routingKey, body = \"Hello World!\", properties = properties) #disconnect connection.close() except Exception, e: print e consumer.py import pika import ssl import time server = \"hostname\" port = 5671 vhost = \"yourvhost\" username = \"username\" password = \"password\" caCert = \"./AddTrustExternalCARoot.crt\" #change it to the actual path to CA certificate exchangeName = \"testEx\" queueName = \"testQ1\" routingKey = \"test\" #callback funtion on receiving messages def onMessage(channel, method, properties, body): print body while True: try: #connect credentials = pika.PlainCredentials(username, password) sslOptions = {\"cert_reqs\": ssl.CERT_REQUIRED, \"ca_certs\": caCert} parameters = pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60, ssl = True, ssl_options = sslOptions) connection = pika.BlockingConnection(parameters) channel = connection.channel() #declare exchange and queue, bind them and consume messages channel.exchange_declare(exchange = exchangeName, exchange_type = \"direct\", auto_delete = True) channel.queue_declare(queue = queueName, exclusive = True, auto_delete = True) channel.queue_bind(exchange = exchangeName, queue = queueName, routing_key = routingKey) channel.basic_consume(consumer_callback = onMessage, queue = queueName, no_ack = True) channel.start_consuming() except Exception, e: #reconnect on exception print \"Exception handled, reconnecting...\\nDetail:\\n%s\" % e try: connection.close() except: pass time.sleep(5)","title":"Putting it together"},{"location":"SSL/#certificate-not-verified","text":"","title":"Certificate not verified"},{"location":"SSL/#connect_1","text":"Compared to certificate-verified connect method above, certificate-not-verified connect method changes \"cert_reqs\": ssl.CERT_REQUIRED to \"cert_reqs\": ssl.CERT_NONE in SSL options. That implies the client doesn't require to verify server's certificate. credentials = pika.PlainCredentials(username, password) sslOptions = {\"cert_reqs\": ssl.CERT_NONE} parameters = pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60, ssl = True, ssl_options = sslOptions) connection = pika.BlockingConnection(parameters) Even if the root CA certificate is provided, it will be ignored. You can safely use this method to connect to RoboMQ broker over SSL without verification because RoboMQ is a trustworthy service provider. However, this way is generally not recommended for unknown services.","title":"Connect"},{"location":"SSL/#putting-it-together_1","text":"producer.py import pika import ssl server = \"hostname\" port = 5671 vhost = \"yourvhost\" username = \"username\" password = \"password\" exchangeName = \"testEx\" routingKey = \"test\" try: #connect credentials = pika.PlainCredentials(username, password) sslOptions = {\"cert_reqs\": ssl.CERT_NONE} parameters = pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60, ssl = True, ssl_options = sslOptions) connection = pika.BlockingConnection(parameters) channel = connection.channel() #send message properties = pika.spec.BasicProperties(content_type = \"text/plain\", delivery_mode = 1) channel.basic_publish(exchange = exchangeName, routing_key = routingKey, body = \"Hello World!\", properties = properties) #disconnect connection.close() except Exception, e: print e consumer.py import pika import ssl import time server = \"hostname\" port = 5671 vhost = \"yourvhost\" username = \"username\" password = \"password\" exchangeName = \"testEx\" queueName = \"testQ1\" routingKey = \"test\" #callback funtion on receiving messages def onMessage(channel, method, properties, body): print body while True: try: #connect credentials = pika.PlainCredentials(username, password) sslOptions = {\"cert_reqs\": ssl.CERT_NONE} parameters = pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60, ssl = True, ssl_options = sslOptions) connection = pika.BlockingConnection(parameters) channel = connection.channel() #declare exchange and queue, bind them and consume messages channel.exchange_declare(exchange = exchangeName, exchange_type = \"direct\", auto_delete = True) channel.queue_declare(queue = queueName, exclusive = True, auto_delete = True) channel.queue_bind(exchange = exchangeName, queue = queueName, routing_key = routingKey) channel.basic_consume(consumer_callback = onMessage, queue = queueName, no_ack = True) channel.start_consuming() except Exception, e: #reconnect on exception print \"Exception handled, reconnecting...\\nDetail:\\n%s\" % e try: connection.close() except: pass time.sleep(5)","title":"Putting it together"},{"location":"STOMP/","text":"Introduction Before reading this chapter, we assume that you already have the basic concepts of message queue, e.g broker, exchange, queue, producer, consumer, etc. Knowing AMQP protocol would very much facilitate understanding STOMP. RoboMQ supports STOMP 1.0, STOMP 1.1 and STOMP 1.2 as an extension to the AMQP broker. Its port is 61613 , SSL port is 61614 . STOMP is the Simple (or Streaming) Text Orientated Messaging Protocol. It is much simpler than AMQP and so more handy for message queue novices. STOMP provides an interoperable wire format so that STOMP clients can communicate with any STOMP message broker to provide easy and widespread messaging interoperability among many languages, platforms and brokers. We would recommend STOMP if you are implementing a simple message queuing application without very complex demands on combination of exchanges and queues. Full documentation of STOMP The STOMP specification does not prescribe what kinds of destinations a broker must support, instead the value of the destination header in SEND and MESSAGE frames is broker-specific. Therefore, RoboMQ enriches STOMP with more destination types so it is now capable of most basic jobs AMQP can do. Message destinations RoboMQ gives its STOMP adapter the flexibility to support the destination types as bellow: /exchange -- SEND to arbitrary routing keys and SUBSCRIBE to arbitrary binding patterns; /queue -- SEND and SUBSCRIBE to queues managed by the STOMP gateway; /amq/queue -- SEND and SUBSCRIBE to queues created outside the STOMP gateway; /topic -- SEND and SUBSCRIBE to transient and durable topics; /temp-queue/ -- create temporary queues (in reply-to headers only). See more explanation regarding this topic at https://www.rabbitmq.com/stomp.html Thus, with STOMP, you can easily implement messaging clients in one-on-one, broadcast, routing key, routing filter or request-reply scenario by just specifying different types of destination. In the rest of this section, we are going to discuss how to switch among those scenarios with minimal change of code. Most times, it only needs to change one line. To know more about the differences among those scenarios, read first paragraph of the previous five pages introducing AMQP implementation of those scenarios. One-to-One This scenario is the most basic application of STOMP. If your destination in subscribe and send functions is in the format of /queue/queueName or /amq/queue/queueName , the consumers will receive the messages in a round-robin manner because this type of destination is mapped into exchange.default.queueName on RoboMQ broker. The default exchange has one special property that makes it very useful for simple applications: every queue that is created is automatically bound to it with a routing key which is the same as the queue name. Therefore, no matter how many consumers subscribe a same queueName, there will be only one queue created. Its name and routing key are both the queueName, and all consumers have subscribed it will receive messages from the queue in turn. /queue/queueName and /amq/queue/queueName behave almost the same. The only difference is that the former one is manged by the STOMP gateway, while the latter one is created outside the STOMP gateway. All example programs on this page are implemented for one-on-one scenario, but you will learn how to transform it into other scenarios quickly. Broadcast If your destination in subscribe and send functions is /exchange/amq.fanout , all the consumers will receive every message at the same time because this type of destination is mapped into exchange.fanout on RoboMQ broker. A fanout exchange routes messages to all of the queues that are bound to it and the routing key is ignored. In this case, each consumer will have its own queue. The queue names are auto-generated and they all are bound to the fanout exchange. Routing key If your destination in subscribe and send functions is /exchange/amq.direct/routingKey , messages will be broadcast to all queues bound to the direct exchange with that routingKey and consumers subscribing those queues will receive every message at the same time because this type of destination is mapped into exchange.direct.routingKey on RoboMQ broker. The way direct exchange works is as bellow: 1. A queue binds to the exchange with a routing key K; 2. When a new message with routing key R arrives at the direct exchange, the exchange routes it to the queue if K = R. In this case, each consumer will have its own queue. The queue names are auto-generated and they are bound to the direct exchange by their particular routing keys. Routing filter (Topic) You can implement the topic scenario by providing a destination started by /topic/ or /exchange/amq.topic/ . The essential difference between normal routing key and topic is that consumer can subscribe a topic with wild cards inside. In AMQP protocol, a message sent with a particular routing key will be delivered to all the queues that are bound with a matching binding key with or without wild cards. i.e. In STOMP, if your destination in send function is /topic/routingKey or /exchange/amq.topic/routingKey and in subscribe function is /topic/routingPattern or /exchange/amq.topic/routingPattern , messages will be delivered to all queues bound to the topic exchange with the routingPattern which matches the routingKey in send destination because this type of destination is mapped into exchange.topic.routingPattern on RoboMQ broker. There are 2 wild cards available as bellow: * (star) can substitute for exactly one word. # (hash) can substitute for zero or more words. For instance, publish key a.b.c matches subscribe key a.b.* or a.# , but doesn't match a.* . Specially, you can implement broadcast scenario by subscribing /topic/# , implement routing key scenario by making routingKey in subscribe function the same as routingPattern in send function. Request reply You can implement request-reply scenario with any destination type. In this case, all clients are both producer and consumer. One thing requester needs to do is adding a \"reply-to\" header to the message. The value of \"reply-to\" header will be the subscribing destination of requester. When replier receives a message, it will handle the message and send reply to the destination in \"reply-to\" header. STOMP protocol itself doesn't define \"reply-to\" header, but RoboMQ allows you to define any extra header by yourself. More scenarios The scenarios you can implement with RoboMQ STOMP adapter are more than the five ones above. For example, if you use destination type /temp-queue/routingKey , it will creates transient queues bound to the direct exchange. A transient queue will be automatically deleted once it receives a message. It can be used to implement RPC (remote procedure call), a variant of request-reply scenario. In RPC scenario, requester creates a transient queue to listen for reply as it sends a request. The queue will be automatically deleted once it receives the reply. You can also add your own exchanges in your vhost and incorporate them in STOMP destination, such as /exchange/user-added-exchange/routingKey . It will create an auto-named queue bound to user-added-exchange by the routingKey. This feature significantly extends RoboMQ STOMP adapter's capacity. Although we have talked so much about how our STOMP message destinations are lightweight but powerful, there's still things it can't do. For example, if you want to bind one queue with a non-default exchange and let multiple consumers subscribe the queue, you would have to ask for help from the AMQP protocol. STOMP use cases We will provide examples of one-to-one scenario in five languages, including Python, Node.js, PHP, Java and C. In the examples, STOMP producer will first ask user for the quantity of messages, then publish the certain number of test messages to a particular destination through STOMP broker. STOMP consumer will subscribe the same destination and print the message body as it receives messages. All examples have implemented automatic reconnecting, which is crucial in real production. The example code provided bellow could be the short version, it might have omitted some advanced details. For full version code, please go to our SDK repository on GitHub. Follow the Message destinations section and you will be able to switch it to other scenario by changing only the destination argument. Before testing the example code, replace hostname, yourvhost, username and password with the real variables in your network environment. Always run consumer first to create the exchange and queue for producer to send messages to. Python Prerequisite The Python library we use for this example can be found at https://pypi.python.org/pypi/stompest/ . Its GitHub repository is at https://github.com/nikipore/stompest . It supports STOMP version 1.0, 1.1 and 1.2. You can install it through sudo pip install stompest . Finally, import this library in your program. from stompest.config import StompConfig from stompest.protocol import StompSpec from stompest.sync import Stomp The full documentation of this library is at https://nikipore.github.io/stompest/ . Producer The first thing we need to do is to establish a connection with RoboMQ broker. In STOMP, username is called login and password is called passcode; vhost is passed in the host header of CONNECT(STOMP) frame. Set the outgoing heartbeat to 60000 milliseconds, so that client will confirm the connectivity with broker; but disable the incoming heartbeat because RoboMQ broker won't send heartbeat to client. Notice that stompest library reverses the order of outgoing and incoming heartbeats. client = Stomp(StompConfig(\"tcp://\" + server + \":\" + port, login = login, passcode = passcode, version = \"1.2\")) client.connect(versions = [\"1.2\"], host = vhost, heartBeats = (0, 60000)) After that, producer can send messages to a particular destination. In this example, it is a queue bound to the default exchange, but it can be replaced by other types of destinations to perform the corresponding messaging. The Message destinations section elaborates it. client.send(destination, body = message, headers = {\"content-type\": \"text/plain\"}, receipt = None) At last, producer will disconnect with the RoboMQ broker. client.disconnect() Consumer The first step is the same as producer, consumer needs to connect to RoboMQ broker. Next step is to subscribe a destination, so that consumer knows where to listen to. Once it receives a message from the destination, it will print the message body. If you set \"ack\": \"auto\" , you don't need client.ack(frame) . The \"id\" must be different for multiple subscriptions because client.receiveFrame() receives messages from any subscription and client needs to distinguish them by subscription ID. subscription = client.subscribe(destination, {\"ack\": \"client\", \"id\": \"0\"}) while True: frame = client.receiveFrame() print frame.body client.ack(frame) When you no longer need it, you can also unsubscribe a destination with its unique token. client.unsubscribe(subscription) Putting it together producer.py import time from stompest.config import StompConfig from stompest.sync import Stomp server = \"hostname\" port = \"61613\" vhost = \"yourvhost\" login = \"username\" passcode = \"password\" destination = \"/queue/test\" #There're more options other than /queue/... try: client = Stomp(StompConfig(\"tcp://\" + server + \":\" + port, login = login, passcode = passcode, version = \"1.2\")) client.connect(versions = [\"1.2\"], host = vhost, heartBeats = (0, 60000)) #CONNECT msgNum = int(input(\"Quantity of test messages: \")) for i in range(msgNum): message = \"test msg \" + str(i + 1) client.send(destination, body = message, headers = {\"content-type\": \"text/plain\"}, receipt = None) #SEND time.sleep(1) client.disconnect() #DISCONNECT except Exception, e: print e consumer.py import time from stompest.config import StompConfig from stompest.sync import Stomp server = \"hostname\" port = \"61613\" vhost = \"yourvhost\" login = \"username\" passcode = \"password\" destination = \"/queue/test\" #There're more options other than /queue/... while True: try: client = Stomp(StompConfig(\"tcp://\" + server + \":\" + port, login = login, passcode = passcode, version = \"1.2\")) client.connect(versions = [\"1.2\"], host = vhost, heartBeats = (0, 60000)) #CONNECT subscription = client.subscribe(destination, {\"ack\": \"client\", \"id\": \"0\"}) #SUBSCRIBE while True: frame = client.receiveFrame() try: print frame.body client.ack(frame) #ACK except: print \"Error: Can't handle message received, NACKing\" client.nack(frame) #NACK except Exception, e: #reconnect on exception print \"Exception handled, reconnecting...\\nDetail:\\n%s\" % e try: client.disconnect() except: pass time.sleep(5) Node.js Prerequisite The Node.js library we use for this example can be found at https://github.com/jmesnil/stomp-websocket . It supports STOMP version 1.0 and 1.1. You can install the library through sudo npm install stompjs . Finally, require this library in your program. var Stomp = require(\"stompjs\"); The full documentation of this library is at https://jmesnil.net/stomp-websocket/doc/ . Producer The first thing we need to do is to establish a connection with RoboMQ broker. In STOMP, username is called login and password is called passcode; vhost is passed in the host header of CONNECT(STOMP) frame. Set the outgoing heartbeat to 60000 milliseconds, so that client will confirm the connectivity with broker; but disable the incoming heartbeat because RoboMQ broker won't send heartbeat to client. var client = Stomp.overTCP(server, port); client.heartbeat.outgoing = 60000; client.heartbeat.incoming = 0; client.connect(login, passcode, success_callback, fail_callback, vhost); After that, producer can send messages to a particular destination. In this example, it is a queue bound to the default exchange, but it can be replaced by other types of destinations to perform the corresponding messaging. The Message destinations section elaborates it. client.send(destination, {\"content-type\": \"text/plain\"}, message); At last, producer will disconnect with the RoboMQ broker. client.disconnect(callback); Consumer The first step is the same as producer, consumer needs to connect to RoboMQ broker. Next step is to subscribe a destination, so that consumer knows where to listen to. Once it receives a message from the destination, it will call the callback function to print the message body. If you set ack: \"auto\" , you don't need message.ack(); . client.subscribe(destination, function(message) { console.log(message.body); message.ack(); }, {ack: \"client\"}); When you no longer need it, you can also unsubscribe a destination with its unique token. If so, you need to save the token when you subscribe. var subscription = client.subscribe(...); subscription.unsubscribe(); Putting it together producer.js var Stomp = require(\"stompjs\"); var server = \"hostname\"; var port = 61613; //It takes either string or int argument var login = \"username\"; var passcode = \"password\"; var vhost = \"yourvhost\"; var destination = \"/queue/test\"; //There're more options other than /queue/... var client = Stomp.overTCP(server, port); client.heartbeat.outgoing = 60000; client.heartbeat.incoming = 0; client.connect(login, passcode , function() { process.stdout.write(\"Quantity of test messages: \"); process.stdin.on(\"data\", function (msgNum) { for(var i = 1; i <= msgNum; i++){ var message = \"test msg \" + i; client.send(destination, {\"content-type\": \"text/plain\"}, message); } client.disconnect(function() { process.exit(0); }); }); } //callback function of connection failure , function(ex) { console.log(ex); process.exit(-1); } , vhost); consumer.js var Stomp = require(\"stompjs\"); var domain = require(\"domain\"); var server = \"hostname\"; var port = 61613; //It takes either string or int argument var login = \"username\"; var passcode = \"password\"; var vhost = \"yourvhost\"; var destination = \"/queue/test\"; //There're more options other than /queue/... //use domain module to handle reconnecting var client = null; var dom = domain.create(); dom.on(\"error\", consume); dom.run(consume); function consume() { client = Stomp.overTCP(server, port); client.heartbeat.outgoing = 60000; client.heartbeat.incoming = 0; client.connect(login, passcode , function() { //the callback for subscribe() function is actually the callback on message client.subscribe(destination, function(message) { try { console.log(message.body); message.ack(); } catch(ex) { console.log(\"Error: Can't handle message received, NACKing\"); message.nack(); } }, {ack: \"client\"}); //if ack:\"auto\", no need to ack in code } //callback function of connection failure , function(ex) { console.log(\"Exception handled, reconnecting...\\nDetail:\\n\" + ex); client.disconnect(function() {setTimeout(consume, 5000);}); } , vhost); } PHP Prerequisite The PHP library we use for this example can be found at https://php.net/manual/en/book.stomp.php . It supports STOMP version 1.0 and 1.1. This library depends on OpenSSL, if you want to use STOMP over SSL. In that case, first ensure that your have OpenSSL installed. Download the library from http://pecl.php.net/package/stomp and uncompress the tarball, enter stomp-x.x.x/ and install it by phpize ./configure make sudo make install Now you should see stomp.so in your php shared library directory, e.g /usr/lib/php5/20121212/ . Finally, edit your php.ini . In Dynamic Extensions section, add one line extension=stomp.so . You may see more installation approaches at https://php.net/manual/en/stomp.setup.php . Notice: this library is different with php5-stomp extension, do not mix them up. Producer The first thing we need to do is to establish a connection with RoboMQ broker. In STOMP, username is called login and password is called passcode; vhost is passed in the host header of CONNECT(STOMP) frame. Set the outgoing heartbeat to 60000 milliseconds, so that client will confirm the connectivity with broker; but disable the incoming heartbeat because RoboMQ broker won't send heartbeat to client. $client = new Stomp(\"tcp://\".$server.\":\".$port, $login, $passcode, array(\"host\" => $vhost, \"accept-version\" => \"1.0,1.1\", \"heart-beat\" => \"60000,0\")); After that, producer can send messages to a particular destination. In this example, it is a queue bound to the default exchange, but it can be replaced by other types of destinations to perform the corresponding messaging. The Message destinations section elaborates it. $client->send($destination, $message, array(\"content-type\" => \"text/plain\")); At last, producer will disconnect with the RoboMQ broker. This library contains disconnect function in client class's destructor. unset($client); Consumer The first step is the same as producer, consumer needs to connect to RoboMQ broker. Next step is to subscribe a destination, so that consumer knows where to listen to. Once it receives a message from the destination, it will print the message body. If you set \"ack\"=>\"auto\" , you don't need $client->ack($frame); . $client->subscribe($destination, array(\"ack\" => \"client\")); while(true) { if ($frame = $client->readFrame()) { echo $frame->body.PHP_EOL; $client->ack($frame); } } When you no longer need it, you can also unsubscribe a destination. $client->unsubscribe($destination); Putting it together producer.php <?php $server = \"hostname\"; $port = \"61613\"; $vhost = \"yourvhost\"; $login = \"username\"; $passcode = \"password\"; $destination = \"/queue/test\"; //There're more options other than /queue/... try { $client = new Stomp(\"tcp://\".$server.\":\".$port, $login, $passcode, array(\"host\" => $vhost, \"accept-version\" => \"1.0,1.1\", \"heart-beat\" => \"60000,0\")); echo \"Quantity of test messages: \"; $msgNum = rtrim(fgets(STDIN), PHP_EOL); for ($i = 1; $i <= $msgNum; $i++) { $message = \"test msg \".$i; $client->send($destination, $message, array(\"content-type\" => \"text/plain\")); sleep(1); } unset($client); } catch (StompException $e) { die($e->getMessage()); } ?> consumer.php <?php $server = \"hostname\"; $port = \"61613\"; $vhost = \"yourvhost\"; $login = \"username\"; $passcode = \"password\"; $destination = \"/queue/test\"; //There're more options other than /queue/... while (true) { try { $client = new Stomp(\"tcp://\".$server.\":\".$port, $login, $passcode, array(\"host\" => $vhost, \"accept-version\" => \"1.0,1.1\", \"heart-beat\" => \"60000,0\")); $client->subscribe($destination, array(\"ack\" => \"client\")); //if \"ack\"=>\"auto\", no need to ack in code while (true) { if ($frame = $client->readFrame()) { try { echo $frame->body.PHP_EOL; $client->ack($frame); } catch (Exception $e) { echo \"Error: Can't handle message received, NACKing\"; $client->nack($frame); } } } } catch (StompException $e) { echo \"Exception handled, reconnecting...\\nDetail:\\n\".$e->getMessage().PHP_EOL; unset($client); sleep(5); } } ?> Ruby Prerequisite The Ruby gem we use for this example can be found at https://rubygems.org/gems/stomp . Its GitHub repository is at https://github.com/stompgem/stomp . It supports STOMP version 1.0, 1.1 and 1.2. You can install it through gem install stomp . Finally, require this gem in your program. require 'stomp' The full documentation of this library is at https://www.rubydoc.info/github/stompgem/stomp/index . Producer The first thing we need to do is to establish a connection with RoboMQ broker. In STOMP, username is called login and password is called passcode; vhost is passed in the host header of CONNECT(STOMP) frame. Set the outgoing heartbeat to 60000 milliseconds, so that client will confirm the connectivity with broker; but disable the incoming heartbeat because RoboMQ broker won't send heartbeat to client. hash = { :hosts => [ {:login => login, :passcode => passcode, :host => server, :port => port}, ], :connect_headers => {\"host\" => vhost, \"accept-version\" => \"1.2\", \"heart-beat\" => \"60000,0\"} } connection = Stomp::Connection.new(hash) After that, producer can send messages to a particular destination. In this example, it is a queue bound to the default exchange, but it can be replaced by other types of destinations to perform the corresponding messaging. The Message destinations section elaborates it. connection.publish(destination, message, headers = {\"content-type\" => \"text/plain\"}) At last, producer will disconnect with the RoboMQ broker. connection.disconnect Consumer The first step is the same as producer, consumer needs to connect to RoboMQ broker. Next step is to subscribe a destination, so that consumer knows where to listen to. Once it receives a message from the destination, it will print the message body. If you set \"ack\": \"auto\" , you don't need connection.ack(message_id) . The \"id\" must be different for multiple subscriptions because connection.receive receives messages from any subscription and client needs to distinguish them by subscription ID. subscription = connection.subscribe(destination, {\"ack\" => \"client-individual\", \"id\" => \"0\"}) while msg = connection.receive puts msg.body # ack current message connection.ack(msg.headers['message-id']) end When you no longer need it, you can also unsubscribe a destination with its unique token. connection.unsubscribe(subscription) Putting it together producer.rb require 'stomp' # connection options server = \"hostname\" port = \"61613\" vhost = \"yourvhost\" login = \"username\" passcode = \"password\" destination = \"/queue/test\" print \"Quantity of test messages: \" msgNum = gets.to_i # stomp gem connect hash hash = { :hosts => [ {:login => login, :passcode => passcode, :host => server, :port => port}, ], :connect_headers => {\"host\" => vhost, \"accept-version\" => \"1.2\", \"heart-beat\" => \"60000,0\"} } begin # connect connection = Stomp::Connection.new(hash) # send messages (1..msgNum).each do |counter| message = \"test msg #{counter}\" connection.publish(destination, message, headers = {\"content-type\" => \"text/plain\"}) sleep 1 end # disconnect connection.disconnect end consumer.rb require 'stomp' # connection options server = \"hostname\" port = \"61613\" vhost = \"yourvhost\" login = \"username\" passcode = \"password\" destination = \"/queue/test\" # stomp gem connect hash hash = { :hosts => [ {:login => login, :passcode => passcode, :host => server, :port => port}, ], :connect_headers => {\"host\" => vhost, \"accept-version\" => \"1.2\", \"heart-beat\" => \"60000,0\", \"content-type\" => \"text/plain\"} } loop do begin # connect connection = Stomp::Connection.new(hash) # subscribe connection.subscribe(destination, {\"ack\" => \"client-individual\", \"id\" => \"0\"}) while msg = connection.receive puts msg.body # ack current message connection.ack(msg.headers['message-id']) end rescue => e puts \"Exception handled, reconnecting...\\nDetail:\\n#{e.message}\" sleep 5 end end Java Prerequisite The Java library we use for this example can be found at https://github.com/robomq/Gozirra . It supports STOMP version 1.0. You may clone the repository by git clone https://github.com/robomq/Gozirra.git . Import this library in your program import net.ser1.stomp.*; and compile your source code along with gozirra-robomq.jar. For example, javac -cp \".:./gozirra-robomq.jar\" Producer.java Consumer.java Run the producer and consumer classes. For example, java -cp \".:./gozirra-robomq.jar\" Consumer java -cp \".:./gozirra-robomq.jar\" Producer Of course, you can eventually compress your producer and consumer classes into jar files. Java7+ is required to compile with this library. Producer The first thing we need to do is to establish a connection with RoboMQ broker. In STOMP, username is called login and password is called passcode; vhost is passed in the host header of CONNECT(STOMP) frame. The library will automatically set the outgoing heartbeat to 60000 milliseconds and disable the incoming heartbeat, i.e. set it to 0. client = new Client(server, port, login, passcode, vhost); After that, producer can send messages to a particular destination. The third parameter of send() function is message headers. In this example, it is a queue bound to the default exchange, but it can be replaced by other types of destinations to perform the corresponding messaging. The Message destinations section elaborates it. HashMap headers = new HashMap(); headers.put(\"content-type\", \"text/plain\"); client.send(destination, message, headers); At last, producer will disconnect with the RoboMQ broker. client.disconnect(); Consumer The first step is the same as producer, consumer needs to connect to RoboMQ broker. Next step is to subscribe a destination, so that consumer knows where to listen to. Once it receives a message from the destination, it will call the overridden function message() to print the message body. client.subscribe(destination, new Listener() { public void message( Map headers, String body ) { System.out.println(body); } }); When you no longer need it, you can also unsubscribe a destination. client.unsubscribe(destination); Putting it together Producer.java import net.ser1.stomp.*; import java.util.HashMap; import java.util.Scanner; class Producer { private Client client; private String server = \"hostname\"; private int port = 61613; private String vhost = \"yourvhost\"; private String destination = \"/queue/test\"; //There're more options other than /queue/... private String login = \"username\"; private String passcode = \"password\"; private void produce() { try { client = new Client(server, port, login, passcode, vhost); System.out.print(\"Quantity of test messages: \"); Scanner scanner = new Scanner(System.in); int msgNum = scanner.nextInt(); HashMap headers = new HashMap(); headers.put(\"content-type\", \"text/plain\"); for (int i = 0; i < msgNum; i ++) { String message = \"test msg \" + Integer.toString(i + 1); client.send(destination, message, null); Thread.sleep(1000); } client.disconnect(); } catch(Exception e) { System.out.println(e); System.exit(-1); } } public static void main(String[] args) { Producer p = new Producer(); p.produce(); } } Consumer.java import net.ser1.stomp.*; import java.util.Map; class Consumer { private Client client; private String server = \"hostname\"; private int port = 61613; private String vhost = \"yourvhost\"; private String destination = \"/queue/test\"; //There're more options other than /queue/... private String login = \"username\"; private String passcode = \"password\"; private void consume() { while (true) { try { client = new Client(server, port, login, passcode, vhost); client.subscribe(destination, new Listener() { /** * This method is the overridden callback on receiving messages. * @ It is event-driven. You don't call it in your code. * @ It prints the message body on console. * @ There're other callback functions provided by this library. */ public void message(Map headers, String body) { System.out.println(body); } }); client.addErrorListener(new Listener() { public void message(Map header, String body) { System.out.printf(\"Exception handled, reconnecting...\\nDetail:\\n%s\\n\", body); //after connected, disconnect on error try { client.disconnect(); } catch(Exception e) {} } }); while (true) { //after connected, reconnect on connection lost if (!client.isSockConnected()) { break; } Thread.sleep(2000); //check interval must be short enough } } catch(Exception e) { //when initializing connection, reconnect on exception System.out.printf(\"Exception handled, reconnecting...\\nDetail:\\n%s\\n\", e); try { Thread.sleep(5000); } catch(Exception es) {} } } } public static void main(String[] args) { Consumer c = new Consumer(); c.consume(); } } Go Prerequisite The Go library we use for this example can be found at https://github.com/go-stomp/stomp/ . It supports STOMP version 1.0, 1.1 and 1.2. You can install it through go get github.com/go-stomp/stomp . Finally, import this library in your program. import \"github.com/go-stomp/stomp\" The full documentation of this library is at https://godoc.org/github.com/go-stomp/stomp . Producer The first thing we need to do is to establish a connection with RoboMQ broker. In STOMP, username is called login and password is called passcode; vhost is passed in the host header of CONNECT(STOMP) frame. Set the outgoing heartbeat to 60000 milliseconds, so that client will confirm the connectivity with broker; but disable the incoming heartbeat because RoboMQ broker won't send heartbeat to client. client, err := stomp.Dial(\"tcp\", net.JoinHostPort(server, port), stomp.ConnOpt.Login(login, passcode), stomp.ConnOpt.Host(vhost), stomp.ConnOpt.AcceptVersion(stomp.V12), stomp.ConnOpt.HeartBeat(60 * time.Second, 0 * time.Second)) After that, producer can send messages to a particular destination. In this example, it is a queue bound to the default exchange, but it can be replaced by other types of destinations to perform the corresponding messaging. The Message destinations section elaborates it. You can also set custom headers with the message. client.Send(destination, \"text/plain\", []byte(message), stomp.SendOpt.Header(\"key\", \"value\")) At last, producer will disconnect with the RoboMQ broker. client.Disconnect() Consumer The first step is the same as producer, consumer needs to connect to RoboMQ broker. Next step is to subscribe a destination, so that consumer knows where to listen to. Once it receives a message from the destination, it will print the message body. If you set AckAuto , you don't need client.Ack(msg) . sub, err := client.Subscribe(destination, stomp.AckClient) for { msg := <-sub.C fmt.Println(string(msg.Body)) client.Ack(msg) } When you no longer need it, you can also unsubscribe a destination with its unique token. sub.Unsubscribe() Putting it together producer.go package main import ( \"fmt\" \"github.com/go-stomp/stomp\" \"net\" \"os\" \"time\" ) var server = \"hostname\" var port = \"61613\" var vhost = \"yourvhost\" var login = \"username\" var passcode = \"password\" var destination = \"/queue/test\" // There're more options other than /queue/... func main() { // Connect to broker client, err := stomp.Dial(\"tcp\", net.JoinHostPort(server, port), stomp.ConnOpt.Login(login, passcode), stomp.ConnOpt.Host(vhost), stomp.ConnOpt.AcceptVersion(stomp.V12), stomp.ConnOpt.HeartBeat(60*time.Second, 0*time.Second)) if err != nil { fmt.Printf(\"Failed to connect, err: %v\\n\", err) os.Exit(1) } var msgNum int fmt.Print(\"Quantity of test messages: \") fmt.Scanf(\"%d\", &msgNum) for i := 0; i < msgNum; i++ { message := fmt.Sprintf(\"test msg %d\", i+1) err = client.Send(destination, \"text/plain\", []byte(message), stomp.SendOpt.Header(\"key\", \"value\")) if err != nil { fmt.Printf(\"Failed to publish, err: %v\\n\", err) os.Exit(1) } time.Sleep(time.Second) } client.Disconnect() } consumer.go package main import ( \"fmt\" \"github.com/go-stomp/stomp\" \"net\" \"time\" ) var server = \"hostname\" var port = \"61613\" var vhost = \"yourvhost\" var login = \"username\" var passcode = \"password\" var destination = \"/queue/test\" // There're more options other than /queue/... func main() { // Infinite loop to auto-reconnect on failure Loop: for { fmt.Println(\"Starting in 5 seconds...\") time.Sleep(5 * time.Second) // Connect to broker client, err := stomp.Dial(\"tcp\", net.JoinHostPort(server, port), stomp.ConnOpt.Login(login, passcode), stomp.ConnOpt.Host(vhost), stomp.ConnOpt.AcceptVersion(stomp.V12), stomp.ConnOpt.HeartBeat(60*time.Second, 0*time.Second)) if err != nil { fmt.Printf(\"Failed to connect, err: %v\\n\", err) continue Loop } // Subscribe to queue with client acknowledgement sub, err := client.Subscribe(destination, stomp.AckClient) if err != nil { fmt.Printf(\"Failed to subscribe, err: %v\\n\", err) continue Loop } fmt.Println(\"Started consuming messages.\") for { msg := <-sub.C if msg.Err != nil { fmt.Printf(\"Can't handle message received, NACKing... Error: %v\\n\", msg.Err) // Unacknowledge the message err = client.Nack(msg) if err != nil { fmt.Printf(\"Failed to NACK, err: %v\\n\", err) break } } fmt.Println(string(msg.Body)) // Acknowledge the message err = client.Ack(msg) if err != nil { fmt.Printf(\"Failed to ACK, err: %v\\n\", err) break } } } } C Prerequisite The C library we use for this example can be found at https://github.com/evgenido/stomp . It supports STOMP version 1.0, 1.1 and 1.2. You may clone it by git clone https://github.com/evgenido/stomp.git . Extract the library source code from /src/ and place it in your project directory. Include /path/to/stomp.h in your code, depending on where you place the library. For example, if your project structure is ./producer.c ./consumer.c ./stomp/frame.c ./stomp/frame.h ./stomp/hdr.c ./stomp/hdr.h ./stomp/stomp.c ./stomp/stomp.h Include this library in your program, for example #include \"./stomp/stomp.h\" and compile it by gcc -o producer producer.c stomp/* gcc -o consumer consumer.c stomp/* Producer The first thing we need to do is to establish a connection with RoboMQ broker. Using this library, you always construct the headers before sending a STOMP frame. In STOMP, username is called login and password is called passcode. Set the outgoing heartbeat to 60000 milliseconds, so that client will confirm the connectivity with broker; but disable the incoming heartbeat because RoboMQ broker won't send heartbeat to client. struct ctx client; stomp_session_t *session; session = stomp_session_new(&client); struct stomp_hdr conn_hdrs[] = { {\"login\", login}, {\"passcode\", passcode}, {\"vhost\", vhost}, {\"accept-version\", \"1.0,1.1,1.2\"}, {\"heart-beat\", \"60000,0\"}, }; err = stomp_connect(session, server, port, sizeof(conn_hdrs)/sizeof(struct stomp_hdr), conn_hdrs); After that, producer can send messages to a particular destination. In this example, it is a queue bound to the default exchange, but it cae an be replaced by other types of destinations to perform the corresponding messaging. The Message destinations section elaborates it. Notice that length of the message char array, content-length in headers and last argument of stomp_send() must be identical. char body[20] = \"test message\"; struct stomp_hdr send_hdrs[] = { {\"destination\", destination}, {\"content-type\", \"text/plain\"}, {\"content-length\", \"20\"}, }; err = stomp_send(session, sizeof(send_hdrs)/sizeof(struct stomp_hdr), send_hdrs, body, 20); When all messages have been sent, producer will disconnect with the RoboMQ broker. This example just force disconnect, but you could use receipt attribute in headers to gracefully disconnect. struct stomp_hdr disconn_hdrs[] = { }; err = stomp_disconnect(session, sizeof(disconn_hdrs)/sizeof(struct stomp_hdr), disconn_hdrs); Finally, to start running the whole process above, you have to call stomp_run() before the end of your program. The process won't stop until stomp_disconnect() is called. This is a special feature of this C library, most STOMP libraries don't need it. err = stomp_run(session); To cleanly close the client, you still need to free the session and exit at the very end. stomp_session_free(session); exit(EXIT_SUCCESS); Consumer The first step is the same as producer, consumer needs to connect to RoboMQ broker. Then you need to set a few callback functions. They play an significant role in this library. For example, callback on message and error. static void _message(stomp_session_t *s, void *ctx, void *session_ctx) { struct stomp_ctx_message *e = ctx; fprintf(stdout, \"%s\\n\", (const char *)e->body); } static void _error(stomp_session_t *session, void *ctx, void *session_ctx) { struct stomp_ctx_error *e = ctx; dump_hdrs(e->hdrc, e->hdrs); fprintf(stderr, \"Exception handled, reconnecting...\\nDetail:\\n%s\\n\", (const char *)e->body); struct stomp_hdr disconn_hdrs[] = { }; stomp_disconnect(session, sizeof(disconn_hdrs)/sizeof(struct stomp_hdr), disconn_hdrs); } stomp_callback_set(session, SCB_ERROR, _error); stomp_callback_set(session, SCB_MESSAGE, _message); Subsequently, subscribe a destination, so that consumer knows where to listen to. Once it receives a message from the destination, it will call _message() function to print the message body. If you set \"ack\": \"client\" in headers, you need to add stomp_ack() or stomp_nack() in _message() function. The id attribute in headers and the subscription token will be used when unsubscribe the destination. By the way, you can also see how to handle error using this library in the following code. struct stomp_hdr sub_hdrs[] = { {\"destination\", destination}, {\"ack\", \"auto\"}, {\"id\", \"0\"}, }; err = stomp_subscribe(session, sizeof(sub_hdrs)/sizeof(struct stomp_hdr), sub_hdrs); if (err<0) { perror(\"stomp\"); stomp_session_free(session); } else { subscription = err; } When you no longer need it, you can also unsubscribe a destination by the subscription ID and token. struct stomp_hdr unsub_hdrs[] = { {\"id\", \"0\"}, }; err = stomp_unsubscribe(session, subscription, sizeof(unsub_hdrs)/sizeof(struct stomp_hdr), unsub_hdrs); Finally, always remember to call stomp_run() at the end of your program; otherwise, nothing mentioned above will be actually executed. This functions is the driving force behind the client. Because this consumer example never calls stomp_disconnect() function, so it will be running forever after stomp_run() . Putting it together producer.c #include <stdlib.h> #include <stdio.h> #include <string.h> #include \"./stomp/stomp.h\" //depends on where you place the library struct ctx { const char *destination; }; /** * This is the method to print headers. */ static void dump_hdrs(int hdrc, const struct stomp_hdr *hdrs) { int i; for (i=0; i < hdrc; i++) { fprintf(stdout, \"%s:%s\\n\", hdrs[i].key, hdrs[i].val); } } /** * This is the callback method on error. * @It prints the error information. */ static void _error(stomp_session_t *session, void *ctx, void *session_ctx) { struct stomp_ctx_error *e = ctx; dump_hdrs(e->hdrc, e->hdrs); fprintf(stderr, \"%s\\n\", (const char *)e->body); } /** * This is the main method which creates and runs producer instance. * @Exceptions on connection and publish error. */ int main(int argc, char *argv[]) { char* server = \"hostname\"; char* port = \"61613\"; char* login = \"username\"; char* passcode = \"password\"; char* vhost = \"yourvhost\"; char* destination = \"/queue/test\"; //There're more options other than /queue/... int err; struct ctx client; stomp_session_t *session; session = stomp_session_new(&client); if (!session) { perror(\"stomp\"); exit(EXIT_FAILURE); } stomp_callback_set(session, SCB_ERROR, _error); struct stomp_hdr conn_hdrs[] = { {\"login\", login}, {\"passcode\", passcode}, {\"vhost\", vhost}, {\"accept-version\", \"1.0,1.1,1.2\"}, {\"heart-beat\", \"60000,0\"}, }; err = stomp_connect(session, server, port, sizeof(conn_hdrs)/sizeof(struct stomp_hdr), conn_hdrs); if (err) { perror(\"stomp\"); stomp_session_free(session); exit(EXIT_FAILURE); } struct stomp_hdr send_hdrs[] = { {\"destination\", destination}, {\"content-type\", \"text/plain\"}, {\"content-length\", \"20\"}, }; int msgNum, i; char body[20]; printf(\"Quantity of test messages: \"); scanf(\"%d\", &msgNum); for(i = 1; i <= msgNum; i++) { sprintf(body, \"test msg %d\", i); do { //in case sending failed, keep retrying err = stomp_send(session, sizeof(send_hdrs)/sizeof(struct stomp_hdr), send_hdrs, body, 20); sleep(1); } while(err); } struct stomp_hdr disconn_hdrs[] = { }; //could use receipt to gracefully disconnect err = stomp_disconnect(session, sizeof(disconn_hdrs)/sizeof(struct stomp_hdr), disconn_hdrs); if (err) { perror(\"stomp\"); stomp_session_free(session); exit(EXIT_FAILURE); } err = stomp_run(session); //necessary to actually run the process, stop when stomp_disconnect() called if (err) { perror(\"stomp\"); stomp_session_free(session); exit(EXIT_FAILURE); } stomp_session_free(session); exit(EXIT_SUCCESS); return 0; } consumer.c #include <stdlib.h> #include <stdio.h> #include <string.h> #include \"./stomp/stomp.h\" //depends on where you place the library struct ctx { const char *destination; }; /** * This is the method to print headers. */ static void dump_hdrs(int hdrc, const struct stomp_hdr *hdrs) { int i; for (i=0; i < hdrc; i++) { fprintf(stdout, \"%s:%s\\n\", hdrs[i].key, hdrs[i].val); } } /** * This is the callback method on receiving message. * @It prints the message body. */ static void _message(stomp_session_t *s, void *ctx, void *session_ctx) { struct stomp_ctx_message *e = ctx; fprintf(stdout, \"%s\\n\", (const char *)e->body); } /** * This is the callback method on error. * @It prints the error information and disconnect. */ static void _error(stomp_session_t *session, void *ctx, void *session_ctx) { struct stomp_ctx_error *e = ctx; dump_hdrs(e->hdrc, e->hdrs); fprintf(stderr, \"Exception handled, reconnecting...\\nDetail:\\n%s\\n\", (const char *)e->body); //disconnect for clean reconnecting later struct stomp_hdr disconn_hdrs[] = { }; stomp_disconnect(session, sizeof(disconn_hdrs)/sizeof(struct stomp_hdr), disconn_hdrs); } /** * This is the main method which creates and sets consumer instance. * @Exceptions on connection and subscription error. */ int main(int argc, char *argv[]) { char* server = \"hostname\"; char* port = \"61613\"; char* login = \"username\"; char* passcode = \"password\"; char* vhost = \"yourvhost\"; char* destination = \"/queue/test\"; //There're more options other than /queue/... int err; int subscription; struct ctx client; stomp_session_t *session; while (1) { session = stomp_session_new(&client); if (!session) { perror(\"stomp\"); } else { stomp_callback_set(session, SCB_ERROR, _error); stomp_callback_set(session, SCB_MESSAGE, _message); struct stomp_hdr conn_hdrs[] = { {\"login\", login}, {\"passcode\", passcode}, {\"vhost\", vhost}, {\"accept-version\", \"1.0,1.1,1.2\"}, {\"heart-beat\", \"60000,0\"}, }; err = stomp_connect(session, server, port, sizeof(conn_hdrs)/sizeof(struct stomp_hdr), conn_hdrs); if (err) { perror(\"stomp\"); stomp_session_free(session); } else { struct stomp_hdr sub_hdrs[] = { {\"destination\", destination}, {\"ack\", \"auto\"}, //could set \"ack\" header to \"client\" and manually stomp_ack() / stomp_nack() {\"id\", \"0\"}, }; err = stomp_subscribe(session, sizeof(sub_hdrs)/sizeof(struct stomp_hdr), sub_hdrs); if (err<0) { perror(\"stomp\"); stomp_session_free(session); } else { subscription = err; //if success, return sub token for unsubscribing later err = stomp_run(session); //necessary to actually run the process, stop when stomp_disconnect() called if (err) { perror(\"stomp\"); stomp_session_free(session); } } } } sleep(5); } return 0; }","title":"STOMP"},{"location":"STOMP/#introduction","text":"Before reading this chapter, we assume that you already have the basic concepts of message queue, e.g broker, exchange, queue, producer, consumer, etc. Knowing AMQP protocol would very much facilitate understanding STOMP. RoboMQ supports STOMP 1.0, STOMP 1.1 and STOMP 1.2 as an extension to the AMQP broker. Its port is 61613 , SSL port is 61614 . STOMP is the Simple (or Streaming) Text Orientated Messaging Protocol. It is much simpler than AMQP and so more handy for message queue novices. STOMP provides an interoperable wire format so that STOMP clients can communicate with any STOMP message broker to provide easy and widespread messaging interoperability among many languages, platforms and brokers. We would recommend STOMP if you are implementing a simple message queuing application without very complex demands on combination of exchanges and queues. Full documentation of STOMP The STOMP specification does not prescribe what kinds of destinations a broker must support, instead the value of the destination header in SEND and MESSAGE frames is broker-specific. Therefore, RoboMQ enriches STOMP with more destination types so it is now capable of most basic jobs AMQP can do.","title":"Introduction"},{"location":"STOMP/#message-destinations","text":"RoboMQ gives its STOMP adapter the flexibility to support the destination types as bellow: /exchange -- SEND to arbitrary routing keys and SUBSCRIBE to arbitrary binding patterns; /queue -- SEND and SUBSCRIBE to queues managed by the STOMP gateway; /amq/queue -- SEND and SUBSCRIBE to queues created outside the STOMP gateway; /topic -- SEND and SUBSCRIBE to transient and durable topics; /temp-queue/ -- create temporary queues (in reply-to headers only). See more explanation regarding this topic at https://www.rabbitmq.com/stomp.html Thus, with STOMP, you can easily implement messaging clients in one-on-one, broadcast, routing key, routing filter or request-reply scenario by just specifying different types of destination. In the rest of this section, we are going to discuss how to switch among those scenarios with minimal change of code. Most times, it only needs to change one line. To know more about the differences among those scenarios, read first paragraph of the previous five pages introducing AMQP implementation of those scenarios. One-to-One This scenario is the most basic application of STOMP. If your destination in subscribe and send functions is in the format of /queue/queueName or /amq/queue/queueName , the consumers will receive the messages in a round-robin manner because this type of destination is mapped into exchange.default.queueName on RoboMQ broker. The default exchange has one special property that makes it very useful for simple applications: every queue that is created is automatically bound to it with a routing key which is the same as the queue name. Therefore, no matter how many consumers subscribe a same queueName, there will be only one queue created. Its name and routing key are both the queueName, and all consumers have subscribed it will receive messages from the queue in turn. /queue/queueName and /amq/queue/queueName behave almost the same. The only difference is that the former one is manged by the STOMP gateway, while the latter one is created outside the STOMP gateway. All example programs on this page are implemented for one-on-one scenario, but you will learn how to transform it into other scenarios quickly. Broadcast If your destination in subscribe and send functions is /exchange/amq.fanout , all the consumers will receive every message at the same time because this type of destination is mapped into exchange.fanout on RoboMQ broker. A fanout exchange routes messages to all of the queues that are bound to it and the routing key is ignored. In this case, each consumer will have its own queue. The queue names are auto-generated and they all are bound to the fanout exchange. Routing key If your destination in subscribe and send functions is /exchange/amq.direct/routingKey , messages will be broadcast to all queues bound to the direct exchange with that routingKey and consumers subscribing those queues will receive every message at the same time because this type of destination is mapped into exchange.direct.routingKey on RoboMQ broker. The way direct exchange works is as bellow: 1. A queue binds to the exchange with a routing key K; 2. When a new message with routing key R arrives at the direct exchange, the exchange routes it to the queue if K = R. In this case, each consumer will have its own queue. The queue names are auto-generated and they are bound to the direct exchange by their particular routing keys. Routing filter (Topic) You can implement the topic scenario by providing a destination started by /topic/ or /exchange/amq.topic/ . The essential difference between normal routing key and topic is that consumer can subscribe a topic with wild cards inside. In AMQP protocol, a message sent with a particular routing key will be delivered to all the queues that are bound with a matching binding key with or without wild cards. i.e. In STOMP, if your destination in send function is /topic/routingKey or /exchange/amq.topic/routingKey and in subscribe function is /topic/routingPattern or /exchange/amq.topic/routingPattern , messages will be delivered to all queues bound to the topic exchange with the routingPattern which matches the routingKey in send destination because this type of destination is mapped into exchange.topic.routingPattern on RoboMQ broker. There are 2 wild cards available as bellow: * (star) can substitute for exactly one word. # (hash) can substitute for zero or more words. For instance, publish key a.b.c matches subscribe key a.b.* or a.# , but doesn't match a.* . Specially, you can implement broadcast scenario by subscribing /topic/# , implement routing key scenario by making routingKey in subscribe function the same as routingPattern in send function. Request reply You can implement request-reply scenario with any destination type. In this case, all clients are both producer and consumer. One thing requester needs to do is adding a \"reply-to\" header to the message. The value of \"reply-to\" header will be the subscribing destination of requester. When replier receives a message, it will handle the message and send reply to the destination in \"reply-to\" header. STOMP protocol itself doesn't define \"reply-to\" header, but RoboMQ allows you to define any extra header by yourself. More scenarios The scenarios you can implement with RoboMQ STOMP adapter are more than the five ones above. For example, if you use destination type /temp-queue/routingKey , it will creates transient queues bound to the direct exchange. A transient queue will be automatically deleted once it receives a message. It can be used to implement RPC (remote procedure call), a variant of request-reply scenario. In RPC scenario, requester creates a transient queue to listen for reply as it sends a request. The queue will be automatically deleted once it receives the reply. You can also add your own exchanges in your vhost and incorporate them in STOMP destination, such as /exchange/user-added-exchange/routingKey . It will create an auto-named queue bound to user-added-exchange by the routingKey. This feature significantly extends RoboMQ STOMP adapter's capacity. Although we have talked so much about how our STOMP message destinations are lightweight but powerful, there's still things it can't do. For example, if you want to bind one queue with a non-default exchange and let multiple consumers subscribe the queue, you would have to ask for help from the AMQP protocol.","title":"Message destinations"},{"location":"STOMP/#stomp-use-cases","text":"We will provide examples of one-to-one scenario in five languages, including Python, Node.js, PHP, Java and C. In the examples, STOMP producer will first ask user for the quantity of messages, then publish the certain number of test messages to a particular destination through STOMP broker. STOMP consumer will subscribe the same destination and print the message body as it receives messages. All examples have implemented automatic reconnecting, which is crucial in real production. The example code provided bellow could be the short version, it might have omitted some advanced details. For full version code, please go to our SDK repository on GitHub. Follow the Message destinations section and you will be able to switch it to other scenario by changing only the destination argument. Before testing the example code, replace hostname, yourvhost, username and password with the real variables in your network environment. Always run consumer first to create the exchange and queue for producer to send messages to.","title":"STOMP use cases"},{"location":"STOMP/#python","text":"","title":"Python"},{"location":"STOMP/#prerequisite","text":"The Python library we use for this example can be found at https://pypi.python.org/pypi/stompest/ . Its GitHub repository is at https://github.com/nikipore/stompest . It supports STOMP version 1.0, 1.1 and 1.2. You can install it through sudo pip install stompest . Finally, import this library in your program. from stompest.config import StompConfig from stompest.protocol import StompSpec from stompest.sync import Stomp The full documentation of this library is at https://nikipore.github.io/stompest/ .","title":"Prerequisite"},{"location":"STOMP/#producer","text":"The first thing we need to do is to establish a connection with RoboMQ broker. In STOMP, username is called login and password is called passcode; vhost is passed in the host header of CONNECT(STOMP) frame. Set the outgoing heartbeat to 60000 milliseconds, so that client will confirm the connectivity with broker; but disable the incoming heartbeat because RoboMQ broker won't send heartbeat to client. Notice that stompest library reverses the order of outgoing and incoming heartbeats. client = Stomp(StompConfig(\"tcp://\" + server + \":\" + port, login = login, passcode = passcode, version = \"1.2\")) client.connect(versions = [\"1.2\"], host = vhost, heartBeats = (0, 60000)) After that, producer can send messages to a particular destination. In this example, it is a queue bound to the default exchange, but it can be replaced by other types of destinations to perform the corresponding messaging. The Message destinations section elaborates it. client.send(destination, body = message, headers = {\"content-type\": \"text/plain\"}, receipt = None) At last, producer will disconnect with the RoboMQ broker. client.disconnect()","title":"Producer"},{"location":"STOMP/#consumer","text":"The first step is the same as producer, consumer needs to connect to RoboMQ broker. Next step is to subscribe a destination, so that consumer knows where to listen to. Once it receives a message from the destination, it will print the message body. If you set \"ack\": \"auto\" , you don't need client.ack(frame) . The \"id\" must be different for multiple subscriptions because client.receiveFrame() receives messages from any subscription and client needs to distinguish them by subscription ID. subscription = client.subscribe(destination, {\"ack\": \"client\", \"id\": \"0\"}) while True: frame = client.receiveFrame() print frame.body client.ack(frame) When you no longer need it, you can also unsubscribe a destination with its unique token. client.unsubscribe(subscription)","title":"Consumer"},{"location":"STOMP/#putting-it-together","text":"producer.py import time from stompest.config import StompConfig from stompest.sync import Stomp server = \"hostname\" port = \"61613\" vhost = \"yourvhost\" login = \"username\" passcode = \"password\" destination = \"/queue/test\" #There're more options other than /queue/... try: client = Stomp(StompConfig(\"tcp://\" + server + \":\" + port, login = login, passcode = passcode, version = \"1.2\")) client.connect(versions = [\"1.2\"], host = vhost, heartBeats = (0, 60000)) #CONNECT msgNum = int(input(\"Quantity of test messages: \")) for i in range(msgNum): message = \"test msg \" + str(i + 1) client.send(destination, body = message, headers = {\"content-type\": \"text/plain\"}, receipt = None) #SEND time.sleep(1) client.disconnect() #DISCONNECT except Exception, e: print e consumer.py import time from stompest.config import StompConfig from stompest.sync import Stomp server = \"hostname\" port = \"61613\" vhost = \"yourvhost\" login = \"username\" passcode = \"password\" destination = \"/queue/test\" #There're more options other than /queue/... while True: try: client = Stomp(StompConfig(\"tcp://\" + server + \":\" + port, login = login, passcode = passcode, version = \"1.2\")) client.connect(versions = [\"1.2\"], host = vhost, heartBeats = (0, 60000)) #CONNECT subscription = client.subscribe(destination, {\"ack\": \"client\", \"id\": \"0\"}) #SUBSCRIBE while True: frame = client.receiveFrame() try: print frame.body client.ack(frame) #ACK except: print \"Error: Can't handle message received, NACKing\" client.nack(frame) #NACK except Exception, e: #reconnect on exception print \"Exception handled, reconnecting...\\nDetail:\\n%s\" % e try: client.disconnect() except: pass time.sleep(5)","title":"Putting it together"},{"location":"STOMP/#nodejs","text":"","title":"Node.js"},{"location":"STOMP/#prerequisite_1","text":"The Node.js library we use for this example can be found at https://github.com/jmesnil/stomp-websocket . It supports STOMP version 1.0 and 1.1. You can install the library through sudo npm install stompjs . Finally, require this library in your program. var Stomp = require(\"stompjs\"); The full documentation of this library is at https://jmesnil.net/stomp-websocket/doc/ .","title":"Prerequisite"},{"location":"STOMP/#producer_1","text":"The first thing we need to do is to establish a connection with RoboMQ broker. In STOMP, username is called login and password is called passcode; vhost is passed in the host header of CONNECT(STOMP) frame. Set the outgoing heartbeat to 60000 milliseconds, so that client will confirm the connectivity with broker; but disable the incoming heartbeat because RoboMQ broker won't send heartbeat to client. var client = Stomp.overTCP(server, port); client.heartbeat.outgoing = 60000; client.heartbeat.incoming = 0; client.connect(login, passcode, success_callback, fail_callback, vhost); After that, producer can send messages to a particular destination. In this example, it is a queue bound to the default exchange, but it can be replaced by other types of destinations to perform the corresponding messaging. The Message destinations section elaborates it. client.send(destination, {\"content-type\": \"text/plain\"}, message); At last, producer will disconnect with the RoboMQ broker. client.disconnect(callback);","title":"Producer"},{"location":"STOMP/#consumer_1","text":"The first step is the same as producer, consumer needs to connect to RoboMQ broker. Next step is to subscribe a destination, so that consumer knows where to listen to. Once it receives a message from the destination, it will call the callback function to print the message body. If you set ack: \"auto\" , you don't need message.ack(); . client.subscribe(destination, function(message) { console.log(message.body); message.ack(); }, {ack: \"client\"}); When you no longer need it, you can also unsubscribe a destination with its unique token. If so, you need to save the token when you subscribe. var subscription = client.subscribe(...); subscription.unsubscribe();","title":"Consumer"},{"location":"STOMP/#putting-it-together_1","text":"producer.js var Stomp = require(\"stompjs\"); var server = \"hostname\"; var port = 61613; //It takes either string or int argument var login = \"username\"; var passcode = \"password\"; var vhost = \"yourvhost\"; var destination = \"/queue/test\"; //There're more options other than /queue/... var client = Stomp.overTCP(server, port); client.heartbeat.outgoing = 60000; client.heartbeat.incoming = 0; client.connect(login, passcode , function() { process.stdout.write(\"Quantity of test messages: \"); process.stdin.on(\"data\", function (msgNum) { for(var i = 1; i <= msgNum; i++){ var message = \"test msg \" + i; client.send(destination, {\"content-type\": \"text/plain\"}, message); } client.disconnect(function() { process.exit(0); }); }); } //callback function of connection failure , function(ex) { console.log(ex); process.exit(-1); } , vhost); consumer.js var Stomp = require(\"stompjs\"); var domain = require(\"domain\"); var server = \"hostname\"; var port = 61613; //It takes either string or int argument var login = \"username\"; var passcode = \"password\"; var vhost = \"yourvhost\"; var destination = \"/queue/test\"; //There're more options other than /queue/... //use domain module to handle reconnecting var client = null; var dom = domain.create(); dom.on(\"error\", consume); dom.run(consume); function consume() { client = Stomp.overTCP(server, port); client.heartbeat.outgoing = 60000; client.heartbeat.incoming = 0; client.connect(login, passcode , function() { //the callback for subscribe() function is actually the callback on message client.subscribe(destination, function(message) { try { console.log(message.body); message.ack(); } catch(ex) { console.log(\"Error: Can't handle message received, NACKing\"); message.nack(); } }, {ack: \"client\"}); //if ack:\"auto\", no need to ack in code } //callback function of connection failure , function(ex) { console.log(\"Exception handled, reconnecting...\\nDetail:\\n\" + ex); client.disconnect(function() {setTimeout(consume, 5000);}); } , vhost); }","title":"Putting it together"},{"location":"STOMP/#php","text":"","title":"PHP"},{"location":"STOMP/#prerequisite_2","text":"The PHP library we use for this example can be found at https://php.net/manual/en/book.stomp.php . It supports STOMP version 1.0 and 1.1. This library depends on OpenSSL, if you want to use STOMP over SSL. In that case, first ensure that your have OpenSSL installed. Download the library from http://pecl.php.net/package/stomp and uncompress the tarball, enter stomp-x.x.x/ and install it by phpize ./configure make sudo make install Now you should see stomp.so in your php shared library directory, e.g /usr/lib/php5/20121212/ . Finally, edit your php.ini . In Dynamic Extensions section, add one line extension=stomp.so . You may see more installation approaches at https://php.net/manual/en/stomp.setup.php . Notice: this library is different with php5-stomp extension, do not mix them up.","title":"Prerequisite"},{"location":"STOMP/#producer_2","text":"The first thing we need to do is to establish a connection with RoboMQ broker. In STOMP, username is called login and password is called passcode; vhost is passed in the host header of CONNECT(STOMP) frame. Set the outgoing heartbeat to 60000 milliseconds, so that client will confirm the connectivity with broker; but disable the incoming heartbeat because RoboMQ broker won't send heartbeat to client. $client = new Stomp(\"tcp://\".$server.\":\".$port, $login, $passcode, array(\"host\" => $vhost, \"accept-version\" => \"1.0,1.1\", \"heart-beat\" => \"60000,0\")); After that, producer can send messages to a particular destination. In this example, it is a queue bound to the default exchange, but it can be replaced by other types of destinations to perform the corresponding messaging. The Message destinations section elaborates it. $client->send($destination, $message, array(\"content-type\" => \"text/plain\")); At last, producer will disconnect with the RoboMQ broker. This library contains disconnect function in client class's destructor. unset($client);","title":"Producer"},{"location":"STOMP/#consumer_2","text":"The first step is the same as producer, consumer needs to connect to RoboMQ broker. Next step is to subscribe a destination, so that consumer knows where to listen to. Once it receives a message from the destination, it will print the message body. If you set \"ack\"=>\"auto\" , you don't need $client->ack($frame); . $client->subscribe($destination, array(\"ack\" => \"client\")); while(true) { if ($frame = $client->readFrame()) { echo $frame->body.PHP_EOL; $client->ack($frame); } } When you no longer need it, you can also unsubscribe a destination. $client->unsubscribe($destination);","title":"Consumer"},{"location":"STOMP/#putting-it-together_2","text":"producer.php <?php $server = \"hostname\"; $port = \"61613\"; $vhost = \"yourvhost\"; $login = \"username\"; $passcode = \"password\"; $destination = \"/queue/test\"; //There're more options other than /queue/... try { $client = new Stomp(\"tcp://\".$server.\":\".$port, $login, $passcode, array(\"host\" => $vhost, \"accept-version\" => \"1.0,1.1\", \"heart-beat\" => \"60000,0\")); echo \"Quantity of test messages: \"; $msgNum = rtrim(fgets(STDIN), PHP_EOL); for ($i = 1; $i <= $msgNum; $i++) { $message = \"test msg \".$i; $client->send($destination, $message, array(\"content-type\" => \"text/plain\")); sleep(1); } unset($client); } catch (StompException $e) { die($e->getMessage()); } ?> consumer.php <?php $server = \"hostname\"; $port = \"61613\"; $vhost = \"yourvhost\"; $login = \"username\"; $passcode = \"password\"; $destination = \"/queue/test\"; //There're more options other than /queue/... while (true) { try { $client = new Stomp(\"tcp://\".$server.\":\".$port, $login, $passcode, array(\"host\" => $vhost, \"accept-version\" => \"1.0,1.1\", \"heart-beat\" => \"60000,0\")); $client->subscribe($destination, array(\"ack\" => \"client\")); //if \"ack\"=>\"auto\", no need to ack in code while (true) { if ($frame = $client->readFrame()) { try { echo $frame->body.PHP_EOL; $client->ack($frame); } catch (Exception $e) { echo \"Error: Can't handle message received, NACKing\"; $client->nack($frame); } } } } catch (StompException $e) { echo \"Exception handled, reconnecting...\\nDetail:\\n\".$e->getMessage().PHP_EOL; unset($client); sleep(5); } } ?>","title":"Putting it together"},{"location":"STOMP/#ruby","text":"","title":"Ruby"},{"location":"STOMP/#prerequisite_3","text":"The Ruby gem we use for this example can be found at https://rubygems.org/gems/stomp . Its GitHub repository is at https://github.com/stompgem/stomp . It supports STOMP version 1.0, 1.1 and 1.2. You can install it through gem install stomp . Finally, require this gem in your program. require 'stomp' The full documentation of this library is at https://www.rubydoc.info/github/stompgem/stomp/index .","title":"Prerequisite"},{"location":"STOMP/#producer_3","text":"The first thing we need to do is to establish a connection with RoboMQ broker. In STOMP, username is called login and password is called passcode; vhost is passed in the host header of CONNECT(STOMP) frame. Set the outgoing heartbeat to 60000 milliseconds, so that client will confirm the connectivity with broker; but disable the incoming heartbeat because RoboMQ broker won't send heartbeat to client. hash = { :hosts => [ {:login => login, :passcode => passcode, :host => server, :port => port}, ], :connect_headers => {\"host\" => vhost, \"accept-version\" => \"1.2\", \"heart-beat\" => \"60000,0\"} } connection = Stomp::Connection.new(hash) After that, producer can send messages to a particular destination. In this example, it is a queue bound to the default exchange, but it can be replaced by other types of destinations to perform the corresponding messaging. The Message destinations section elaborates it. connection.publish(destination, message, headers = {\"content-type\" => \"text/plain\"}) At last, producer will disconnect with the RoboMQ broker. connection.disconnect","title":"Producer"},{"location":"STOMP/#consumer_3","text":"The first step is the same as producer, consumer needs to connect to RoboMQ broker. Next step is to subscribe a destination, so that consumer knows where to listen to. Once it receives a message from the destination, it will print the message body. If you set \"ack\": \"auto\" , you don't need connection.ack(message_id) . The \"id\" must be different for multiple subscriptions because connection.receive receives messages from any subscription and client needs to distinguish them by subscription ID. subscription = connection.subscribe(destination, {\"ack\" => \"client-individual\", \"id\" => \"0\"}) while msg = connection.receive puts msg.body # ack current message connection.ack(msg.headers['message-id']) end When you no longer need it, you can also unsubscribe a destination with its unique token. connection.unsubscribe(subscription)","title":"Consumer"},{"location":"STOMP/#putting-it-together_3","text":"producer.rb require 'stomp' # connection options server = \"hostname\" port = \"61613\" vhost = \"yourvhost\" login = \"username\" passcode = \"password\" destination = \"/queue/test\" print \"Quantity of test messages: \" msgNum = gets.to_i # stomp gem connect hash hash = { :hosts => [ {:login => login, :passcode => passcode, :host => server, :port => port}, ], :connect_headers => {\"host\" => vhost, \"accept-version\" => \"1.2\", \"heart-beat\" => \"60000,0\"} } begin # connect connection = Stomp::Connection.new(hash) # send messages (1..msgNum).each do |counter| message = \"test msg #{counter}\" connection.publish(destination, message, headers = {\"content-type\" => \"text/plain\"}) sleep 1 end # disconnect connection.disconnect end consumer.rb require 'stomp' # connection options server = \"hostname\" port = \"61613\" vhost = \"yourvhost\" login = \"username\" passcode = \"password\" destination = \"/queue/test\" # stomp gem connect hash hash = { :hosts => [ {:login => login, :passcode => passcode, :host => server, :port => port}, ], :connect_headers => {\"host\" => vhost, \"accept-version\" => \"1.2\", \"heart-beat\" => \"60000,0\", \"content-type\" => \"text/plain\"} } loop do begin # connect connection = Stomp::Connection.new(hash) # subscribe connection.subscribe(destination, {\"ack\" => \"client-individual\", \"id\" => \"0\"}) while msg = connection.receive puts msg.body # ack current message connection.ack(msg.headers['message-id']) end rescue => e puts \"Exception handled, reconnecting...\\nDetail:\\n#{e.message}\" sleep 5 end end","title":"Putting it together"},{"location":"STOMP/#java","text":"","title":"Java"},{"location":"STOMP/#prerequisite_4","text":"The Java library we use for this example can be found at https://github.com/robomq/Gozirra . It supports STOMP version 1.0. You may clone the repository by git clone https://github.com/robomq/Gozirra.git . Import this library in your program import net.ser1.stomp.*; and compile your source code along with gozirra-robomq.jar. For example, javac -cp \".:./gozirra-robomq.jar\" Producer.java Consumer.java Run the producer and consumer classes. For example, java -cp \".:./gozirra-robomq.jar\" Consumer java -cp \".:./gozirra-robomq.jar\" Producer Of course, you can eventually compress your producer and consumer classes into jar files. Java7+ is required to compile with this library.","title":"Prerequisite"},{"location":"STOMP/#producer_4","text":"The first thing we need to do is to establish a connection with RoboMQ broker. In STOMP, username is called login and password is called passcode; vhost is passed in the host header of CONNECT(STOMP) frame. The library will automatically set the outgoing heartbeat to 60000 milliseconds and disable the incoming heartbeat, i.e. set it to 0. client = new Client(server, port, login, passcode, vhost); After that, producer can send messages to a particular destination. The third parameter of send() function is message headers. In this example, it is a queue bound to the default exchange, but it can be replaced by other types of destinations to perform the corresponding messaging. The Message destinations section elaborates it. HashMap headers = new HashMap(); headers.put(\"content-type\", \"text/plain\"); client.send(destination, message, headers); At last, producer will disconnect with the RoboMQ broker. client.disconnect();","title":"Producer"},{"location":"STOMP/#consumer_4","text":"The first step is the same as producer, consumer needs to connect to RoboMQ broker. Next step is to subscribe a destination, so that consumer knows where to listen to. Once it receives a message from the destination, it will call the overridden function message() to print the message body. client.subscribe(destination, new Listener() { public void message( Map headers, String body ) { System.out.println(body); } }); When you no longer need it, you can also unsubscribe a destination. client.unsubscribe(destination);","title":"Consumer"},{"location":"STOMP/#putting-it-together_4","text":"Producer.java import net.ser1.stomp.*; import java.util.HashMap; import java.util.Scanner; class Producer { private Client client; private String server = \"hostname\"; private int port = 61613; private String vhost = \"yourvhost\"; private String destination = \"/queue/test\"; //There're more options other than /queue/... private String login = \"username\"; private String passcode = \"password\"; private void produce() { try { client = new Client(server, port, login, passcode, vhost); System.out.print(\"Quantity of test messages: \"); Scanner scanner = new Scanner(System.in); int msgNum = scanner.nextInt(); HashMap headers = new HashMap(); headers.put(\"content-type\", \"text/plain\"); for (int i = 0; i < msgNum; i ++) { String message = \"test msg \" + Integer.toString(i + 1); client.send(destination, message, null); Thread.sleep(1000); } client.disconnect(); } catch(Exception e) { System.out.println(e); System.exit(-1); } } public static void main(String[] args) { Producer p = new Producer(); p.produce(); } } Consumer.java import net.ser1.stomp.*; import java.util.Map; class Consumer { private Client client; private String server = \"hostname\"; private int port = 61613; private String vhost = \"yourvhost\"; private String destination = \"/queue/test\"; //There're more options other than /queue/... private String login = \"username\"; private String passcode = \"password\"; private void consume() { while (true) { try { client = new Client(server, port, login, passcode, vhost); client.subscribe(destination, new Listener() { /** * This method is the overridden callback on receiving messages. * @ It is event-driven. You don't call it in your code. * @ It prints the message body on console. * @ There're other callback functions provided by this library. */ public void message(Map headers, String body) { System.out.println(body); } }); client.addErrorListener(new Listener() { public void message(Map header, String body) { System.out.printf(\"Exception handled, reconnecting...\\nDetail:\\n%s\\n\", body); //after connected, disconnect on error try { client.disconnect(); } catch(Exception e) {} } }); while (true) { //after connected, reconnect on connection lost if (!client.isSockConnected()) { break; } Thread.sleep(2000); //check interval must be short enough } } catch(Exception e) { //when initializing connection, reconnect on exception System.out.printf(\"Exception handled, reconnecting...\\nDetail:\\n%s\\n\", e); try { Thread.sleep(5000); } catch(Exception es) {} } } } public static void main(String[] args) { Consumer c = new Consumer(); c.consume(); } }","title":"Putting it together"},{"location":"STOMP/#go","text":"","title":"Go"},{"location":"STOMP/#prerequisite_5","text":"The Go library we use for this example can be found at https://github.com/go-stomp/stomp/ . It supports STOMP version 1.0, 1.1 and 1.2. You can install it through go get github.com/go-stomp/stomp . Finally, import this library in your program. import \"github.com/go-stomp/stomp\" The full documentation of this library is at https://godoc.org/github.com/go-stomp/stomp .","title":"Prerequisite"},{"location":"STOMP/#producer_5","text":"The first thing we need to do is to establish a connection with RoboMQ broker. In STOMP, username is called login and password is called passcode; vhost is passed in the host header of CONNECT(STOMP) frame. Set the outgoing heartbeat to 60000 milliseconds, so that client will confirm the connectivity with broker; but disable the incoming heartbeat because RoboMQ broker won't send heartbeat to client. client, err := stomp.Dial(\"tcp\", net.JoinHostPort(server, port), stomp.ConnOpt.Login(login, passcode), stomp.ConnOpt.Host(vhost), stomp.ConnOpt.AcceptVersion(stomp.V12), stomp.ConnOpt.HeartBeat(60 * time.Second, 0 * time.Second)) After that, producer can send messages to a particular destination. In this example, it is a queue bound to the default exchange, but it can be replaced by other types of destinations to perform the corresponding messaging. The Message destinations section elaborates it. You can also set custom headers with the message. client.Send(destination, \"text/plain\", []byte(message), stomp.SendOpt.Header(\"key\", \"value\")) At last, producer will disconnect with the RoboMQ broker. client.Disconnect()","title":"Producer"},{"location":"STOMP/#consumer_5","text":"The first step is the same as producer, consumer needs to connect to RoboMQ broker. Next step is to subscribe a destination, so that consumer knows where to listen to. Once it receives a message from the destination, it will print the message body. If you set AckAuto , you don't need client.Ack(msg) . sub, err := client.Subscribe(destination, stomp.AckClient) for { msg := <-sub.C fmt.Println(string(msg.Body)) client.Ack(msg) } When you no longer need it, you can also unsubscribe a destination with its unique token. sub.Unsubscribe()","title":"Consumer"},{"location":"STOMP/#putting-it-together_5","text":"producer.go package main import ( \"fmt\" \"github.com/go-stomp/stomp\" \"net\" \"os\" \"time\" ) var server = \"hostname\" var port = \"61613\" var vhost = \"yourvhost\" var login = \"username\" var passcode = \"password\" var destination = \"/queue/test\" // There're more options other than /queue/... func main() { // Connect to broker client, err := stomp.Dial(\"tcp\", net.JoinHostPort(server, port), stomp.ConnOpt.Login(login, passcode), stomp.ConnOpt.Host(vhost), stomp.ConnOpt.AcceptVersion(stomp.V12), stomp.ConnOpt.HeartBeat(60*time.Second, 0*time.Second)) if err != nil { fmt.Printf(\"Failed to connect, err: %v\\n\", err) os.Exit(1) } var msgNum int fmt.Print(\"Quantity of test messages: \") fmt.Scanf(\"%d\", &msgNum) for i := 0; i < msgNum; i++ { message := fmt.Sprintf(\"test msg %d\", i+1) err = client.Send(destination, \"text/plain\", []byte(message), stomp.SendOpt.Header(\"key\", \"value\")) if err != nil { fmt.Printf(\"Failed to publish, err: %v\\n\", err) os.Exit(1) } time.Sleep(time.Second) } client.Disconnect() } consumer.go package main import ( \"fmt\" \"github.com/go-stomp/stomp\" \"net\" \"time\" ) var server = \"hostname\" var port = \"61613\" var vhost = \"yourvhost\" var login = \"username\" var passcode = \"password\" var destination = \"/queue/test\" // There're more options other than /queue/... func main() { // Infinite loop to auto-reconnect on failure Loop: for { fmt.Println(\"Starting in 5 seconds...\") time.Sleep(5 * time.Second) // Connect to broker client, err := stomp.Dial(\"tcp\", net.JoinHostPort(server, port), stomp.ConnOpt.Login(login, passcode), stomp.ConnOpt.Host(vhost), stomp.ConnOpt.AcceptVersion(stomp.V12), stomp.ConnOpt.HeartBeat(60*time.Second, 0*time.Second)) if err != nil { fmt.Printf(\"Failed to connect, err: %v\\n\", err) continue Loop } // Subscribe to queue with client acknowledgement sub, err := client.Subscribe(destination, stomp.AckClient) if err != nil { fmt.Printf(\"Failed to subscribe, err: %v\\n\", err) continue Loop } fmt.Println(\"Started consuming messages.\") for { msg := <-sub.C if msg.Err != nil { fmt.Printf(\"Can't handle message received, NACKing... Error: %v\\n\", msg.Err) // Unacknowledge the message err = client.Nack(msg) if err != nil { fmt.Printf(\"Failed to NACK, err: %v\\n\", err) break } } fmt.Println(string(msg.Body)) // Acknowledge the message err = client.Ack(msg) if err != nil { fmt.Printf(\"Failed to ACK, err: %v\\n\", err) break } } } }","title":"Putting it together"},{"location":"STOMP/#c","text":"","title":"C"},{"location":"STOMP/#prerequisite_6","text":"The C library we use for this example can be found at https://github.com/evgenido/stomp . It supports STOMP version 1.0, 1.1 and 1.2. You may clone it by git clone https://github.com/evgenido/stomp.git . Extract the library source code from /src/ and place it in your project directory. Include /path/to/stomp.h in your code, depending on where you place the library. For example, if your project structure is ./producer.c ./consumer.c ./stomp/frame.c ./stomp/frame.h ./stomp/hdr.c ./stomp/hdr.h ./stomp/stomp.c ./stomp/stomp.h Include this library in your program, for example #include \"./stomp/stomp.h\" and compile it by gcc -o producer producer.c stomp/* gcc -o consumer consumer.c stomp/*","title":"Prerequisite"},{"location":"STOMP/#producer_6","text":"The first thing we need to do is to establish a connection with RoboMQ broker. Using this library, you always construct the headers before sending a STOMP frame. In STOMP, username is called login and password is called passcode. Set the outgoing heartbeat to 60000 milliseconds, so that client will confirm the connectivity with broker; but disable the incoming heartbeat because RoboMQ broker won't send heartbeat to client. struct ctx client; stomp_session_t *session; session = stomp_session_new(&client); struct stomp_hdr conn_hdrs[] = { {\"login\", login}, {\"passcode\", passcode}, {\"vhost\", vhost}, {\"accept-version\", \"1.0,1.1,1.2\"}, {\"heart-beat\", \"60000,0\"}, }; err = stomp_connect(session, server, port, sizeof(conn_hdrs)/sizeof(struct stomp_hdr), conn_hdrs); After that, producer can send messages to a particular destination. In this example, it is a queue bound to the default exchange, but it cae an be replaced by other types of destinations to perform the corresponding messaging. The Message destinations section elaborates it. Notice that length of the message char array, content-length in headers and last argument of stomp_send() must be identical. char body[20] = \"test message\"; struct stomp_hdr send_hdrs[] = { {\"destination\", destination}, {\"content-type\", \"text/plain\"}, {\"content-length\", \"20\"}, }; err = stomp_send(session, sizeof(send_hdrs)/sizeof(struct stomp_hdr), send_hdrs, body, 20); When all messages have been sent, producer will disconnect with the RoboMQ broker. This example just force disconnect, but you could use receipt attribute in headers to gracefully disconnect. struct stomp_hdr disconn_hdrs[] = { }; err = stomp_disconnect(session, sizeof(disconn_hdrs)/sizeof(struct stomp_hdr), disconn_hdrs); Finally, to start running the whole process above, you have to call stomp_run() before the end of your program. The process won't stop until stomp_disconnect() is called. This is a special feature of this C library, most STOMP libraries don't need it. err = stomp_run(session); To cleanly close the client, you still need to free the session and exit at the very end. stomp_session_free(session); exit(EXIT_SUCCESS);","title":"Producer"},{"location":"STOMP/#consumer_6","text":"The first step is the same as producer, consumer needs to connect to RoboMQ broker. Then you need to set a few callback functions. They play an significant role in this library. For example, callback on message and error. static void _message(stomp_session_t *s, void *ctx, void *session_ctx) { struct stomp_ctx_message *e = ctx; fprintf(stdout, \"%s\\n\", (const char *)e->body); } static void _error(stomp_session_t *session, void *ctx, void *session_ctx) { struct stomp_ctx_error *e = ctx; dump_hdrs(e->hdrc, e->hdrs); fprintf(stderr, \"Exception handled, reconnecting...\\nDetail:\\n%s\\n\", (const char *)e->body); struct stomp_hdr disconn_hdrs[] = { }; stomp_disconnect(session, sizeof(disconn_hdrs)/sizeof(struct stomp_hdr), disconn_hdrs); } stomp_callback_set(session, SCB_ERROR, _error); stomp_callback_set(session, SCB_MESSAGE, _message); Subsequently, subscribe a destination, so that consumer knows where to listen to. Once it receives a message from the destination, it will call _message() function to print the message body. If you set \"ack\": \"client\" in headers, you need to add stomp_ack() or stomp_nack() in _message() function. The id attribute in headers and the subscription token will be used when unsubscribe the destination. By the way, you can also see how to handle error using this library in the following code. struct stomp_hdr sub_hdrs[] = { {\"destination\", destination}, {\"ack\", \"auto\"}, {\"id\", \"0\"}, }; err = stomp_subscribe(session, sizeof(sub_hdrs)/sizeof(struct stomp_hdr), sub_hdrs); if (err<0) { perror(\"stomp\"); stomp_session_free(session); } else { subscription = err; } When you no longer need it, you can also unsubscribe a destination by the subscription ID and token. struct stomp_hdr unsub_hdrs[] = { {\"id\", \"0\"}, }; err = stomp_unsubscribe(session, subscription, sizeof(unsub_hdrs)/sizeof(struct stomp_hdr), unsub_hdrs); Finally, always remember to call stomp_run() at the end of your program; otherwise, nothing mentioned above will be actually executed. This functions is the driving force behind the client. Because this consumer example never calls stomp_disconnect() function, so it will be running forever after stomp_run() .","title":"Consumer"},{"location":"STOMP/#putting-it-together_6","text":"producer.c #include <stdlib.h> #include <stdio.h> #include <string.h> #include \"./stomp/stomp.h\" //depends on where you place the library struct ctx { const char *destination; }; /** * This is the method to print headers. */ static void dump_hdrs(int hdrc, const struct stomp_hdr *hdrs) { int i; for (i=0; i < hdrc; i++) { fprintf(stdout, \"%s:%s\\n\", hdrs[i].key, hdrs[i].val); } } /** * This is the callback method on error. * @It prints the error information. */ static void _error(stomp_session_t *session, void *ctx, void *session_ctx) { struct stomp_ctx_error *e = ctx; dump_hdrs(e->hdrc, e->hdrs); fprintf(stderr, \"%s\\n\", (const char *)e->body); } /** * This is the main method which creates and runs producer instance. * @Exceptions on connection and publish error. */ int main(int argc, char *argv[]) { char* server = \"hostname\"; char* port = \"61613\"; char* login = \"username\"; char* passcode = \"password\"; char* vhost = \"yourvhost\"; char* destination = \"/queue/test\"; //There're more options other than /queue/... int err; struct ctx client; stomp_session_t *session; session = stomp_session_new(&client); if (!session) { perror(\"stomp\"); exit(EXIT_FAILURE); } stomp_callback_set(session, SCB_ERROR, _error); struct stomp_hdr conn_hdrs[] = { {\"login\", login}, {\"passcode\", passcode}, {\"vhost\", vhost}, {\"accept-version\", \"1.0,1.1,1.2\"}, {\"heart-beat\", \"60000,0\"}, }; err = stomp_connect(session, server, port, sizeof(conn_hdrs)/sizeof(struct stomp_hdr), conn_hdrs); if (err) { perror(\"stomp\"); stomp_session_free(session); exit(EXIT_FAILURE); } struct stomp_hdr send_hdrs[] = { {\"destination\", destination}, {\"content-type\", \"text/plain\"}, {\"content-length\", \"20\"}, }; int msgNum, i; char body[20]; printf(\"Quantity of test messages: \"); scanf(\"%d\", &msgNum); for(i = 1; i <= msgNum; i++) { sprintf(body, \"test msg %d\", i); do { //in case sending failed, keep retrying err = stomp_send(session, sizeof(send_hdrs)/sizeof(struct stomp_hdr), send_hdrs, body, 20); sleep(1); } while(err); } struct stomp_hdr disconn_hdrs[] = { }; //could use receipt to gracefully disconnect err = stomp_disconnect(session, sizeof(disconn_hdrs)/sizeof(struct stomp_hdr), disconn_hdrs); if (err) { perror(\"stomp\"); stomp_session_free(session); exit(EXIT_FAILURE); } err = stomp_run(session); //necessary to actually run the process, stop when stomp_disconnect() called if (err) { perror(\"stomp\"); stomp_session_free(session); exit(EXIT_FAILURE); } stomp_session_free(session); exit(EXIT_SUCCESS); return 0; } consumer.c #include <stdlib.h> #include <stdio.h> #include <string.h> #include \"./stomp/stomp.h\" //depends on where you place the library struct ctx { const char *destination; }; /** * This is the method to print headers. */ static void dump_hdrs(int hdrc, const struct stomp_hdr *hdrs) { int i; for (i=0; i < hdrc; i++) { fprintf(stdout, \"%s:%s\\n\", hdrs[i].key, hdrs[i].val); } } /** * This is the callback method on receiving message. * @It prints the message body. */ static void _message(stomp_session_t *s, void *ctx, void *session_ctx) { struct stomp_ctx_message *e = ctx; fprintf(stdout, \"%s\\n\", (const char *)e->body); } /** * This is the callback method on error. * @It prints the error information and disconnect. */ static void _error(stomp_session_t *session, void *ctx, void *session_ctx) { struct stomp_ctx_error *e = ctx; dump_hdrs(e->hdrc, e->hdrs); fprintf(stderr, \"Exception handled, reconnecting...\\nDetail:\\n%s\\n\", (const char *)e->body); //disconnect for clean reconnecting later struct stomp_hdr disconn_hdrs[] = { }; stomp_disconnect(session, sizeof(disconn_hdrs)/sizeof(struct stomp_hdr), disconn_hdrs); } /** * This is the main method which creates and sets consumer instance. * @Exceptions on connection and subscription error. */ int main(int argc, char *argv[]) { char* server = \"hostname\"; char* port = \"61613\"; char* login = \"username\"; char* passcode = \"password\"; char* vhost = \"yourvhost\"; char* destination = \"/queue/test\"; //There're more options other than /queue/... int err; int subscription; struct ctx client; stomp_session_t *session; while (1) { session = stomp_session_new(&client); if (!session) { perror(\"stomp\"); } else { stomp_callback_set(session, SCB_ERROR, _error); stomp_callback_set(session, SCB_MESSAGE, _message); struct stomp_hdr conn_hdrs[] = { {\"login\", login}, {\"passcode\", passcode}, {\"vhost\", vhost}, {\"accept-version\", \"1.0,1.1,1.2\"}, {\"heart-beat\", \"60000,0\"}, }; err = stomp_connect(session, server, port, sizeof(conn_hdrs)/sizeof(struct stomp_hdr), conn_hdrs); if (err) { perror(\"stomp\"); stomp_session_free(session); } else { struct stomp_hdr sub_hdrs[] = { {\"destination\", destination}, {\"ack\", \"auto\"}, //could set \"ack\" header to \"client\" and manually stomp_ack() / stomp_nack() {\"id\", \"0\"}, }; err = stomp_subscribe(session, sizeof(sub_hdrs)/sizeof(struct stomp_hdr), sub_hdrs); if (err<0) { perror(\"stomp\"); stomp_session_free(session); } else { subscription = err; //if success, return sub token for unsubscribing later err = stomp_run(session); //necessary to actually run the process, stop when stomp_disconnect() called if (err) { perror(\"stomp\"); stomp_session_free(session); } } } } sleep(5); } return 0; }","title":"Putting it together"},{"location":"Salesforce_Connector/","text":"Salesforce Connector One of the many platform with which RoboMQ is able to provide a connector is the popular customer relationship management platform, Salesforce. Salesforce has been part of our suite of connectors and adapters called \u201c ThingsConnect \u201d since the early days of our product. With this growing suite of adapter and connectors, RoboMQ is truly an Internet of Things (IoT) middleware platform that can connect any device to any application. Salesforce.com is one representative platform, where the devices and device networks can create cases to engage support and field operations teams to react to the issues and events of interest. IoT (Internet of Things) devices integrating with Salesforce.com and its workflowmanagement components will not only be valuable for reacting to the problem but they can also create new business opportunities by providing meaningful business information. This is really the essence of Internet of Things by making devices and sensors a.k.a. \u201cthings\u201d become other players in addition to people, systems and processes Using RoboMQ Salesforce connector, a customer\u2019s device or sensor can integrate Salesforce.com into its device management and diagnostics flow. This makes sense for an organizations using Salesforce.com where cases are typically used to engage technical support and triage teams to react to an issue or an incident. Another common use case is to receive and integrate the information from sensors or \u201cthings\u201d into the business workflows in Salesforce.com. This could be a powerful paradigm in a world where device and beacons with local intelligence are becoming a commonplace. Fig 1: Schematics of the Salesforce connector The RoboMQ Salesforce connector creates a seamless integration between the devices and Salesforce.com. Based on the context, the identity, and the nature of the information from the devices and sensors, the connector can be configured to create cases for a particular division or the group within an organization. This association is configurable and highly flexible including the mapping of the data elements from the device to the case being created. Why use a connector to Salesforce? Yes, you can create cases manually from the \u201cCases\u201d tab in the Salesforce.com graphical user interface. But this means someone has to become aware of the issue and has to act upon it. This is not only prone to mistakes but valuable time is lost before someone can look into the issue. And hello\u2026 why are we investing into the devices and sensors in the first place? To make processes faster, reduce cost and get things done cheaper using cheap microprocessors vs. costly human resources. Right? And that\u2019s where the value comes in \u2013 RoboMQ Salesforce connector offers tremendous efficiency in having the ability to create cases automatically within a customer\u2019s existing workflow. In addition, as a core feature of RoboMQ, it ensures the guaranteed and reliable delivery of the information through its robust and scalable IoT middleware infrastructure. With businesses, small to large and local to global, increasingly relying on sensors and devices to collect information from the environment and making decisions upon it, the need to build a network of intelligent, self-healing and proactive \u201cthings\u201d is a paramount one!! To learn more about the many other connectors that RoboMQ offerers check back on our connectors page! If you have any other questions please reach out to us as, sales@robomq.io and we would love to help.","title":"Salesforce"},{"location":"Salesforce_Connector/#salesforce-connector","text":"One of the many platform with which RoboMQ is able to provide a connector is the popular customer relationship management platform, Salesforce. Salesforce has been part of our suite of connectors and adapters called \u201c ThingsConnect \u201d since the early days of our product. With this growing suite of adapter and connectors, RoboMQ is truly an Internet of Things (IoT) middleware platform that can connect any device to any application. Salesforce.com is one representative platform, where the devices and device networks can create cases to engage support and field operations teams to react to the issues and events of interest. IoT (Internet of Things) devices integrating with Salesforce.com and its workflowmanagement components will not only be valuable for reacting to the problem but they can also create new business opportunities by providing meaningful business information. This is really the essence of Internet of Things by making devices and sensors a.k.a. \u201cthings\u201d become other players in addition to people, systems and processes Using RoboMQ Salesforce connector, a customer\u2019s device or sensor can integrate Salesforce.com into its device management and diagnostics flow. This makes sense for an organizations using Salesforce.com where cases are typically used to engage technical support and triage teams to react to an issue or an incident. Another common use case is to receive and integrate the information from sensors or \u201cthings\u201d into the business workflows in Salesforce.com. This could be a powerful paradigm in a world where device and beacons with local intelligence are becoming a commonplace. Fig 1: Schematics of the Salesforce connector The RoboMQ Salesforce connector creates a seamless integration between the devices and Salesforce.com. Based on the context, the identity, and the nature of the information from the devices and sensors, the connector can be configured to create cases for a particular division or the group within an organization. This association is configurable and highly flexible including the mapping of the data elements from the device to the case being created. Why use a connector to Salesforce? Yes, you can create cases manually from the \u201cCases\u201d tab in the Salesforce.com graphical user interface. But this means someone has to become aware of the issue and has to act upon it. This is not only prone to mistakes but valuable time is lost before someone can look into the issue. And hello\u2026 why are we investing into the devices and sensors in the first place? To make processes faster, reduce cost and get things done cheaper using cheap microprocessors vs. costly human resources. Right? And that\u2019s where the value comes in \u2013 RoboMQ Salesforce connector offers tremendous efficiency in having the ability to create cases automatically within a customer\u2019s existing workflow. In addition, as a core feature of RoboMQ, it ensures the guaranteed and reliable delivery of the information through its robust and scalable IoT middleware infrastructure. With businesses, small to large and local to global, increasingly relying on sensors and devices to collect information from the environment and making decisions upon it, the need to build a network of intelligent, self-healing and proactive \u201cthings\u201d is a paramount one!! To learn more about the many other connectors that RoboMQ offerers check back on our connectors page! If you have any other questions please reach out to us as, sales@robomq.io and we would love to help.","title":"Salesforce Connector"},{"location":"WebSTOMP/","text":"Introduction Before reading this chapter, we assume that you already know STOMP protocol. If not, please go through at least the first two sections of STOMP chapter in User Guide and refer to the Full documentation of STOMP when necessary. RoboMQ supports WebSTOMP, which is a simple bridge exposing the STOMP protocol 1.0 and 1.1 over emulated HTML5 WebSockets. Its port is 15674 , SSL port is 15673 . The main intention of WebSTOMP is to make it possible to use RoboMQ from web browsers. Therefore, RoboMQ WebSTOMP adapter is rather simple. It just takes the STOMP protocol, as provided by RoboMQ STOMP adapter and exposes it using a SockJS server. SockJS is a WebSockets poly-fill that provides a WebSocket-like JavaScript object in any browser. It will therefore work in older browsers that don't have native WebSocket support, as well as in new browsers that are behind WebSocket-unfriendly proxies. WebSTOMP use case We will provide example of WebSTOMP in JavaScript that is embedded in HTML. In the example, WebSTOMP producer will first connect to RoboMQ with inputted information from Web page, then publish inputted text to the inputted message destination. WebSTOMP consumer will also first connect then subscribe the inputted message destination and print the message topic and payload as it receives messages. The example code provided bellow could be the short version, it might have omitted some advanced details. For full version code, please go to our SDK repository on GitHub. Follow the Message destinations section in STOMP chapter and you will be able to switch among all the scenarios by changing only the message destination. This could also be a tutorial tool for STOMP novices to familiarize themselves with STOMP and WebSTOMP. Prerequisite The JavaScript library we use for this example is the same as we use for STOMP Node.js example. It can be found at https://github.com/jmesnil/stomp-websocket It supports STOMP version 1.0 and 1.1. Download stomp.js from https://raw.githubusercontent.com/jmesnil/stomp-websocket/master/lib/stomp.js and place it in your project directory. Finally, source stomp.js and https://cdn.sockjs.org/sockjs-0.3.min.js in your Web page. The full documentation of this library is at https://jmesnil.net/stomp-websocket/doc/ . Producer Step 1 is to establish a connection with RoboMQ broker. In constructor of SockJS, protocol can be \"http\" or \"https\", they use different ports. In connect() function, third parameter is callback function on connect, fourth is callback function on error. Set the outgoing heartbeat to 60000 milliseconds, so that client will confirm the connectivity with broker; but disable the incoming heartbeat because RoboMQ broker won't send heartbeat to client. var webSock = new SockJS(protocol + \"://\" + host + \":\" + port + \"/stomp\"); client = Stomp.over(webSock); client.heartbeat.outgoing = 60000; client.heartbeat.incoming = 0; client.connect(username, password, onConnect, onError, vhost); Step 2 is to send inputted messages to the inputted destination. The second parameter is message headers. It's not used in this example. client.send(destination, {}, message); Consumer Step 1 is the same as producer, consumer needs to connect to RoboMQ broker. Step 2 is to subscribe the inputted destination, so that consumer knows where to listen to. Once it receives a message from the destination, it will call the callback function to print the topic and payload of the message. subscription = client.subscribe(destination, onMessage, {ack: \"auto\"}); function onMessage(message) { //on page, print \"Destiantion: \" + message.headers[\"destination\"] + \", Message: \" + message.body } When page unloads, consumer will unsubscribe the destination by its token and disconnect with the RoboMQ broker. subscription.unsubscribe(); client.disconnect(); Putting it together producer.html <!DOCTYPE html> <html> <head> <title>producer</title> </head> <body onunload=\"close()\"> <h3>Step 1:</h3> <form name=\"connForm\" action=\"JavaScript:connect()\"> protocol:<br><input type=\"radio\" name=\"protocol\" value=\"http\" checked>http &nbsp;<input type=\"radio\" name=\"protocol\" value=\"https\">https<br> host:<br><input type=\"text\" name=\"host\" value=\"trial.robomq.io\"><br> port:<br><input type=\"text\" name=\"port\" value=\"15674\"><br> vhost:<br><input type=\"text\" name=\"vhost\" value=\"\"><br> username:<br><input type=\"text\" name=\"username\" value=\"\"><br> password:<br><input type=\"text\" name=\"password\" value=\"\"><br><br> <input type=\"submit\" value=\"connect\"> </form> <br><h3>Step 2:</h3> <form name=\"pubForm\" action=\"JavaScript:publish()\"> destination:<br><input type=\"text\" name=\"destination\" value=\"/queue/test\"><br> message:<br><input type=\"text\" name=\"message\" value=\"Hello World!\"><br><br> <input type=\"submit\" value=\"publish\"> </form> </body> <script src=\"http://cdn.sockjs.org/sockjs-0.3.min.js\"></script> <script src=\"stomp.js\"></script> <!--download stomp.js from https://raw.githubusercontent.com/jmesnil/stomp-websocket/master/lib/stomp.js--> <!--change src to file's actual path; don't directly source this GitHub link--> <script> var client = null; function connect() { if (client != null && client.connected) { client.disconnect(); } var connInfo = document.forms[\"connForm\"]; var webSock = new SockJS(connInfo[\"protocol\"].value + \"://\" + connInfo[\"host\"].value + \":\" + connInfo[\"port\"].value + \"/stomp\"); client = Stomp.over(webSock); client.heartbeat.outgoing = 60000; client.heartbeat.incoming = 0; client.connect(connInfo[\"username\"].value, connInfo[\"password\"].value, onConnect, onError, connInfo[\"vhost\"].value); } function onConnect() { alert(\"Connected to broker!\"); } function publish() { if (client == null || !client.connected) { alert(\"Please connect first!\"); return; } var pubInfo = document.forms[\"pubForm\"]; client.send(pubInfo[\"destination\"].value, {}, pubInfo[\"message\"].value); } function onError(error) { alert(error); } function close() { client.disconnect(); } </script> </html> consumer.html <!DOCTYPE html> <html> <head> <title>consumer</title> </head> <body onunload=\"close()\"> <h3>Step 1:</h3> <form name=\"connForm\" action=\"JavaScript:connect()\"> protocol:<br><input type=\"radio\" name=\"protocol\" value=\"http\" checked>http &nbsp;<input type=\"radio\" name=\"protocol\" value=\"https\">https<br> host:<br><input type=\"text\" name=\"host\" value=\"trial.robomq.io\"><br> port:<br><input type=\"text\" name=\"port\" value=\"15674\"><br> vhost:<br><input type=\"text\" name=\"vhost\" value=\"\"><br> username:<br><input type=\"text\" name=\"username\" value=\"\"><br> password:<br><input type=\"text\" name=\"password\" value=\"\"><br><br> <input type=\"submit\" value=\"connect\"> </form> <br><h3>Step 2:</h3> <form name=\"subForm\" action=\"JavaScript:subscribe()\"> destination:<br><input type=\"text\" name=\"destination\" value=\"/queue/test\"><br><br> <input type=\"submit\" value=\"subscribe\"> </form> <br><h3 id=\"msgArea\">Received:</h3><br> </body> <script src=\"http://cdn.sockjs.org/sockjs-0.3.min.js\"></script> <script src=\"stomp.js\"></script> <!--download stomp.js from https://raw.githubusercontent.com/jmesnil/stomp-websocket/master/lib/stomp.js--> <!--change src to file's actual path; don't directly source this GitHub link--> <script> var client = null; var subscription = null; function connect() { if (client != null && client.connected) { client.disconnect(); } var connInfo = document.forms[\"connForm\"]; var webSock = new SockJS(connInfo[\"protocol\"].value + \"://\" + connInfo[\"host\"].value + \":\" + connInfo[\"port\"].value + \"/stomp\"); client = Stomp.over(webSock); client.heartbeat.outgoing = 60000; client.heartbeat.incoming = 0; client.connect(connInfo[\"username\"].value, connInfo[\"password\"].value, onConnect, onError, connInfo[\"vhost\"].value); } function onConnect() { alert(\"Connected to broker!\"); } function subscribe() { if (client == null || !client.connected) { alert(\"Please connect first!\"); return; } if (subscription != null) { subscription.unsubscribe(); } var subInfo = document.forms[\"subForm\"]; subscription = client.subscribe(subInfo[\"destination\"].value, onMessage, {ack: \"auto\"}); alert(\"Subscription ID: \" + subscription[\"id\"]); } function onMessage(message) { var newMsg = document.createElement(\"div\"); newMsg.appendChild(document.createTextNode(\"Destiantion: \" + message.headers[\"destination\"] + \", Message: \" + message.body)); newMsg.appendChild(document.createElement(\"br\")); document.body.insertBefore(newMsg, document.getElementById(\"msgArea\").nextSibling); } function onError(error) { alert(error); subscription = null; } function close() { subscription.unsubscribe(); client.disconnect(); } </script> </html>","title":"WebSTOMP"},{"location":"WebSTOMP/#introduction","text":"Before reading this chapter, we assume that you already know STOMP protocol. If not, please go through at least the first two sections of STOMP chapter in User Guide and refer to the Full documentation of STOMP when necessary. RoboMQ supports WebSTOMP, which is a simple bridge exposing the STOMP protocol 1.0 and 1.1 over emulated HTML5 WebSockets. Its port is 15674 , SSL port is 15673 . The main intention of WebSTOMP is to make it possible to use RoboMQ from web browsers. Therefore, RoboMQ WebSTOMP adapter is rather simple. It just takes the STOMP protocol, as provided by RoboMQ STOMP adapter and exposes it using a SockJS server. SockJS is a WebSockets poly-fill that provides a WebSocket-like JavaScript object in any browser. It will therefore work in older browsers that don't have native WebSocket support, as well as in new browsers that are behind WebSocket-unfriendly proxies.","title":"Introduction"},{"location":"WebSTOMP/#webstomp-use-case","text":"We will provide example of WebSTOMP in JavaScript that is embedded in HTML. In the example, WebSTOMP producer will first connect to RoboMQ with inputted information from Web page, then publish inputted text to the inputted message destination. WebSTOMP consumer will also first connect then subscribe the inputted message destination and print the message topic and payload as it receives messages. The example code provided bellow could be the short version, it might have omitted some advanced details. For full version code, please go to our SDK repository on GitHub. Follow the Message destinations section in STOMP chapter and you will be able to switch among all the scenarios by changing only the message destination. This could also be a tutorial tool for STOMP novices to familiarize themselves with STOMP and WebSTOMP.","title":"WebSTOMP use case"},{"location":"WebSTOMP/#prerequisite","text":"The JavaScript library we use for this example is the same as we use for STOMP Node.js example. It can be found at https://github.com/jmesnil/stomp-websocket It supports STOMP version 1.0 and 1.1. Download stomp.js from https://raw.githubusercontent.com/jmesnil/stomp-websocket/master/lib/stomp.js and place it in your project directory. Finally, source stomp.js and https://cdn.sockjs.org/sockjs-0.3.min.js in your Web page. The full documentation of this library is at https://jmesnil.net/stomp-websocket/doc/ .","title":"Prerequisite"},{"location":"WebSTOMP/#producer","text":"Step 1 is to establish a connection with RoboMQ broker. In constructor of SockJS, protocol can be \"http\" or \"https\", they use different ports. In connect() function, third parameter is callback function on connect, fourth is callback function on error. Set the outgoing heartbeat to 60000 milliseconds, so that client will confirm the connectivity with broker; but disable the incoming heartbeat because RoboMQ broker won't send heartbeat to client. var webSock = new SockJS(protocol + \"://\" + host + \":\" + port + \"/stomp\"); client = Stomp.over(webSock); client.heartbeat.outgoing = 60000; client.heartbeat.incoming = 0; client.connect(username, password, onConnect, onError, vhost); Step 2 is to send inputted messages to the inputted destination. The second parameter is message headers. It's not used in this example. client.send(destination, {}, message);","title":"Producer"},{"location":"WebSTOMP/#consumer","text":"Step 1 is the same as producer, consumer needs to connect to RoboMQ broker. Step 2 is to subscribe the inputted destination, so that consumer knows where to listen to. Once it receives a message from the destination, it will call the callback function to print the topic and payload of the message. subscription = client.subscribe(destination, onMessage, {ack: \"auto\"}); function onMessage(message) { //on page, print \"Destiantion: \" + message.headers[\"destination\"] + \", Message: \" + message.body } When page unloads, consumer will unsubscribe the destination by its token and disconnect with the RoboMQ broker. subscription.unsubscribe(); client.disconnect();","title":"Consumer"},{"location":"WebSTOMP/#putting-it-together","text":"producer.html <!DOCTYPE html> <html> <head> <title>producer</title> </head> <body onunload=\"close()\"> <h3>Step 1:</h3> <form name=\"connForm\" action=\"JavaScript:connect()\"> protocol:<br><input type=\"radio\" name=\"protocol\" value=\"http\" checked>http &nbsp;<input type=\"radio\" name=\"protocol\" value=\"https\">https<br> host:<br><input type=\"text\" name=\"host\" value=\"trial.robomq.io\"><br> port:<br><input type=\"text\" name=\"port\" value=\"15674\"><br> vhost:<br><input type=\"text\" name=\"vhost\" value=\"\"><br> username:<br><input type=\"text\" name=\"username\" value=\"\"><br> password:<br><input type=\"text\" name=\"password\" value=\"\"><br><br> <input type=\"submit\" value=\"connect\"> </form> <br><h3>Step 2:</h3> <form name=\"pubForm\" action=\"JavaScript:publish()\"> destination:<br><input type=\"text\" name=\"destination\" value=\"/queue/test\"><br> message:<br><input type=\"text\" name=\"message\" value=\"Hello World!\"><br><br> <input type=\"submit\" value=\"publish\"> </form> </body> <script src=\"http://cdn.sockjs.org/sockjs-0.3.min.js\"></script> <script src=\"stomp.js\"></script> <!--download stomp.js from https://raw.githubusercontent.com/jmesnil/stomp-websocket/master/lib/stomp.js--> <!--change src to file's actual path; don't directly source this GitHub link--> <script> var client = null; function connect() { if (client != null && client.connected) { client.disconnect(); } var connInfo = document.forms[\"connForm\"]; var webSock = new SockJS(connInfo[\"protocol\"].value + \"://\" + connInfo[\"host\"].value + \":\" + connInfo[\"port\"].value + \"/stomp\"); client = Stomp.over(webSock); client.heartbeat.outgoing = 60000; client.heartbeat.incoming = 0; client.connect(connInfo[\"username\"].value, connInfo[\"password\"].value, onConnect, onError, connInfo[\"vhost\"].value); } function onConnect() { alert(\"Connected to broker!\"); } function publish() { if (client == null || !client.connected) { alert(\"Please connect first!\"); return; } var pubInfo = document.forms[\"pubForm\"]; client.send(pubInfo[\"destination\"].value, {}, pubInfo[\"message\"].value); } function onError(error) { alert(error); } function close() { client.disconnect(); } </script> </html> consumer.html <!DOCTYPE html> <html> <head> <title>consumer</title> </head> <body onunload=\"close()\"> <h3>Step 1:</h3> <form name=\"connForm\" action=\"JavaScript:connect()\"> protocol:<br><input type=\"radio\" name=\"protocol\" value=\"http\" checked>http &nbsp;<input type=\"radio\" name=\"protocol\" value=\"https\">https<br> host:<br><input type=\"text\" name=\"host\" value=\"trial.robomq.io\"><br> port:<br><input type=\"text\" name=\"port\" value=\"15674\"><br> vhost:<br><input type=\"text\" name=\"vhost\" value=\"\"><br> username:<br><input type=\"text\" name=\"username\" value=\"\"><br> password:<br><input type=\"text\" name=\"password\" value=\"\"><br><br> <input type=\"submit\" value=\"connect\"> </form> <br><h3>Step 2:</h3> <form name=\"subForm\" action=\"JavaScript:subscribe()\"> destination:<br><input type=\"text\" name=\"destination\" value=\"/queue/test\"><br><br> <input type=\"submit\" value=\"subscribe\"> </form> <br><h3 id=\"msgArea\">Received:</h3><br> </body> <script src=\"http://cdn.sockjs.org/sockjs-0.3.min.js\"></script> <script src=\"stomp.js\"></script> <!--download stomp.js from https://raw.githubusercontent.com/jmesnil/stomp-websocket/master/lib/stomp.js--> <!--change src to file's actual path; don't directly source this GitHub link--> <script> var client = null; var subscription = null; function connect() { if (client != null && client.connected) { client.disconnect(); } var connInfo = document.forms[\"connForm\"]; var webSock = new SockJS(connInfo[\"protocol\"].value + \"://\" + connInfo[\"host\"].value + \":\" + connInfo[\"port\"].value + \"/stomp\"); client = Stomp.over(webSock); client.heartbeat.outgoing = 60000; client.heartbeat.incoming = 0; client.connect(connInfo[\"username\"].value, connInfo[\"password\"].value, onConnect, onError, connInfo[\"vhost\"].value); } function onConnect() { alert(\"Connected to broker!\"); } function subscribe() { if (client == null || !client.connected) { alert(\"Please connect first!\"); return; } if (subscription != null) { subscription.unsubscribe(); } var subInfo = document.forms[\"subForm\"]; subscription = client.subscribe(subInfo[\"destination\"].value, onMessage, {ack: \"auto\"}); alert(\"Subscription ID: \" + subscription[\"id\"]); } function onMessage(message) { var newMsg = document.createElement(\"div\"); newMsg.appendChild(document.createTextNode(\"Destiantion: \" + message.headers[\"destination\"] + \", Message: \" + message.body)); newMsg.appendChild(document.createElement(\"br\")); document.body.insertBefore(newMsg, document.getElementById(\"msgArea\").nextSibling); } function onError(error) { alert(error); subscription = null; } function close() { subscription.unsubscribe(); client.disconnect(); } </script> </html>","title":"Putting it together"},{"location":"Workday_Connector/","text":"Workday \u00ae to Active Directory (AD) Integration Powered by RoboMQ Workday \u00ae is a leading enterprise Software-as-a-Service (SaaS) application provider for human resource, finance, and Enterprise Resource Planning (ERP) teams. Compared to traditional on-premise Human Capital Management (HCM) and finance applications, Workday \u00ae is often recognized for its quick implementation and ease of use , which makes the platform attractive to citizen integrators and line of business users. With Workday\u2019s \u00ae Human Capital Management (HCM), HR teams can perform an array of functions to manage the full lifecycle of an employee \u2013 from recruiting, talent management, workforce planning, expense management, and more. Microsoft Active Directory and Azure Active Directory , also referred to as AD, are on-premise and cloud hosted solutions, respectively, to manage users, roles, and computers and devices on a corporate network. AD allows network admins to create and manage domains, users, security groups, organization units and more. Companies leverage AD to organize a large number of users into logical groups and subgroups to provide Role-Based Access Control (RBAC) across the organization implementing job-specific or need-to-know basis privilege. Benefits Improved \u201cFirst day at Job\u201d experience Prevent Security and Reputation risk with role-based access control Real time sync between HRIS, Active Directory or Azure AD RoboMQ's Workday \u00ae Connector For many organizations, the process to get employees onboarded efficiently is a challenge. There tends to be a lot of moving parts behind the scenes to ensure employees have access to the tools and technologies needed to hit the ground running. System administrators are also often overloaded with related service desk tickets. Creating and/or updating user identities and assigning role-based access to employees can be tedious and costly work for them. The Workday \u00ae to AD Integration powered by RoboMQ is one of our popular integration solutions that streamlines creation and updating of user identities in AD including and provisioning and assigning role based access to third party systems like Salesforce, ServiceNow, ERP, databases and others.. What once would take an average of two (2) hours or more of a system admin\u2019s time to onboard, update critical employee lifecycle events, send out welcome or termination emails, create or delete accounts in various enterprise systems could now be fully automated with RoboMQ integration solution. As a full featured leading integration platform, RoboMQ provides two integration paths to achieve this functional need. Workday \u00ae extract file-based Integration Integration using Workday \u00ae APIs You could choose either of the two approaches based on your Workday setup or preferences. Workday \u00ae extract file-based integration to AD The Workday \u00ae file extract-based integration approach is a pretty straightforward process. Using this integration approach, scheduled extracts are setup to run on Workday \u00ae on a periodic basis. These scheduled extracts can be setup to automatically run for new employees being hired, terminated employees, and other employee lifecycle event that need to update Active Directory (AD) such as employee role, location or reporting structure changes. The output format of these scheduled extract is typically CSV (Comma Separated Values). These extracts are sent automatically to RoboMQ for processing. Once the scheduled extracts are received on RoboMQ cloud, it is processed in near-real time to make updates to on-premise AD, Azure AD or cloud hosted AD like Microsoft AD on AWS. Below is a detailed view of how this integration solution can manage the employee lifecycle including role-based access: Fig 1: Detailed view of managing employee lifecycle and role-based access Here\u2019s a breakdown of how this process typically works during the employee onboarding: When a new employee starts working at any company location, their information is entered into the company\u2019s Workday \u00ae HRIS system. Workday \u00ae sends this information as an extract to RoboMQ For new employees, RoboMQ creates user identity in Active Directory or Azure AD and provisions their access into enterprise applications based on their role or security groups ensuring that each employee has a single and unique account across all systems with associated access levels. RoboMQ automatically generates a random password for new employee along with default attributes and account control settings. A welcome email or other on-boarding emails are sent to the responsible office manager/s or helpdesk based on job role and location. These emails can be customized and branded to the organization needs. For existing employees, RoboMQ updates account settings, attributes, change of roles (e.g. promotions, transfer, etc.), or change of status (i.e. long-term leave, termination, or re-hire) in sync with Workday \u00ae HRIS. In addition to the Workday \u00ae to AD or Azure AD integration, additional downstream application connectors can be added to this workflow to update user account or access in third party systems. For example, some customers choose to accounts created in Salesforce, Office 365 or other enterprise systems. Managing user accounts or licenses in downstream systems has additional cost savings by making sure terminated employee do not have licenses assigned to them. More than the license cost, there is the safety mechanism in place so that terminated employee do not walk away with access to privileged CRM, operations or ERP systems. For more information or to set up a discussion on this integration solution, schedule an appointment with a RoboMQ integration solution specialist today! Workday \u00ae to AD API and Data Integration Approach Using Connect iPaaS Connect iPaaS is the no-code citizen integrator approach to API and data integration between leading SaaS, EPR, CRM and operations applications on cloud or on-premise. Using simple, easy and intuitive drag-and-drop capabilities, users of Connect can create integration workflows that streamline and automate business processes in minutes with absolutely no coding! Workday \u00ae , Active Directory (AD) and Azure AD are one of the many application connectors available on the Connect iPaaS. End user can integrate APIs from Workday \u00ae to onboard new employees by creating user identities in AD or Azure AD using data mapping and workflow definition. Additional functionality can be added to the integration workflows such as creating a service desk ticket in ServiceNow, creating an account in Salesforce or Microsoft Dynamics CRM or adding an entry in QuickBooks. The main difference between this approach is that API calls are being made to perform data integrations based on specific events, versus files being sent to make updates in near real-time using a managed file transfer (MFT) mechanism. Let\u2019s go over the process of setting up this integration on Connect iPaaS. In this example, we will integrate Workday \u00ae to AD with ServiceNow as an additional connector. We start with the \u201cDesign\u201d dashboard on Connect iPaaS where you have access to hundreds of APIs from leading SaaS, CRM, ERP and enterprise applications and databases. Fig 2: Connect iPaaS Design Dashboard Below images shows the workflow setup for employee onboarding from Workday \u00ae to AD. The left side panel shows the sequence API integrations with first node, Workday \u00ae , being the trigger event. This node receives API call when a new employee is hired in Workday \u00ae . Workday \u00ae is the trigger node while Active Directory and ServiceNow are the action nodes connected to the trigger node. Fig 3: Design dashboard with the workflow set up to streamline employee onboarding Now we go in the details of the Active Directory action node that is triggered in response to new employee hiring in Workday \u00ae . Below image shows that a new user will be created in a specified Organization Unit for the new employee. Fig 4: Create New User in Active Directory action being taken within Active Directory As we mentioned above, an additional ServiceNow API node is added to this workflow which will create a ServiceNow incident to notify a new hire to helpdesk. This incident can be used as a trigger to complete employee on-boarding checklist in service desk which may involve allocating laptop, mobile or other workplace setup activity. Fig 5: An incident is created in ServiceNow to notify helpdesk of a new hire As you see in the image above, you can perform data mapping from Workday \u00ae fields of the employee to required data fields is the action nodes, in this case being ServiceNow. Connect iPaaS provides advanced data mapping and transformation capabilities for business or non-technical users. You can use Microsoft Excel style function that you are very much at ease to perform desired data mappings and transformations. To start using Connect iPaaS, simply sign up at https://trial.robomq.io/connect/ . Or for more information using this integration approach, schedule an appointment with a RoboMQ integration solution specialist today! This integration provides a fabulous \u201cfirst day at job\u201d experience to new hires which can improve employee satisfaction, loyalty and retention. The automated management of role-based access ensures that the right people have access to right information at right time. Managing the termination of access makes sure there are no compliance, security or reputation risks by someone walking away with access to sensitive privileged information. In summary, the Workday \u00ae to AD integration powered by RoboMQ enables your IT and HR teams to focus on more strategic business priorities. This integration provides significant cost savings on HR and already burdened system admin resources. Once this solution is implemented, new employees will have access to the accounts and applications needed from day one, and updates to their profile in your Active Directory will happen in near real-time. This integration provides a fabulous \u201cfirst day at job\u201d experience to new hires which can improve employee satisfaction, loyalty and retention. The automated management of role-based access ensures that the right people have access to right information at right time. Managing the termination of access makes sure there are no compliance, security or reputation risks by someone walking away with access to sensitive privileged information. Experience the transformational power of our Workday \u00ae to AD integration powered by RoboMQ for your enterprise. Schedule a call with an integration specialist today . We are not affiliated, associated, authorized, endorsed by, or in any way officially connected with Workday or any of its affiliates. The name Workday is a registered trademark of Workday. The use of the Workday trademark is for identification and reference purposes only and does not imply any association with Workday or any of its affiliates.","title":"Workday<sup>&reg;</sup> to AD"},{"location":"Workday_Connector/#workday-to-active-directory-ad-integration-powered-by-robomq","text":"Workday \u00ae is a leading enterprise Software-as-a-Service (SaaS) application provider for human resource, finance, and Enterprise Resource Planning (ERP) teams. Compared to traditional on-premise Human Capital Management (HCM) and finance applications, Workday \u00ae is often recognized for its quick implementation and ease of use , which makes the platform attractive to citizen integrators and line of business users. With Workday\u2019s \u00ae Human Capital Management (HCM), HR teams can perform an array of functions to manage the full lifecycle of an employee \u2013 from recruiting, talent management, workforce planning, expense management, and more. Microsoft Active Directory and Azure Active Directory , also referred to as AD, are on-premise and cloud hosted solutions, respectively, to manage users, roles, and computers and devices on a corporate network. AD allows network admins to create and manage domains, users, security groups, organization units and more. Companies leverage AD to organize a large number of users into logical groups and subgroups to provide Role-Based Access Control (RBAC) across the organization implementing job-specific or need-to-know basis privilege.","title":"Workday&reg; to Active Directory (AD) Integration Powered by RoboMQ"},{"location":"Workday_Connector/#benefits","text":"Improved \u201cFirst day at Job\u201d experience Prevent Security and Reputation risk with role-based access control Real time sync between HRIS, Active Directory or Azure AD","title":"Benefits"},{"location":"Workday_Connector/#robomqs-workday-connector","text":"For many organizations, the process to get employees onboarded efficiently is a challenge. There tends to be a lot of moving parts behind the scenes to ensure employees have access to the tools and technologies needed to hit the ground running. System administrators are also often overloaded with related service desk tickets. Creating and/or updating user identities and assigning role-based access to employees can be tedious and costly work for them. The Workday \u00ae to AD Integration powered by RoboMQ is one of our popular integration solutions that streamlines creation and updating of user identities in AD including and provisioning and assigning role based access to third party systems like Salesforce, ServiceNow, ERP, databases and others.. What once would take an average of two (2) hours or more of a system admin\u2019s time to onboard, update critical employee lifecycle events, send out welcome or termination emails, create or delete accounts in various enterprise systems could now be fully automated with RoboMQ integration solution. As a full featured leading integration platform, RoboMQ provides two integration paths to achieve this functional need. Workday \u00ae extract file-based Integration Integration using Workday \u00ae APIs You could choose either of the two approaches based on your Workday setup or preferences.","title":"RoboMQ's Workday&reg; Connector"},{"location":"Workday_Connector/#workday-extract-file-based-integration-to-ad","text":"The Workday \u00ae file extract-based integration approach is a pretty straightforward process. Using this integration approach, scheduled extracts are setup to run on Workday \u00ae on a periodic basis. These scheduled extracts can be setup to automatically run for new employees being hired, terminated employees, and other employee lifecycle event that need to update Active Directory (AD) such as employee role, location or reporting structure changes. The output format of these scheduled extract is typically CSV (Comma Separated Values). These extracts are sent automatically to RoboMQ for processing. Once the scheduled extracts are received on RoboMQ cloud, it is processed in near-real time to make updates to on-premise AD, Azure AD or cloud hosted AD like Microsoft AD on AWS. Below is a detailed view of how this integration solution can manage the employee lifecycle including role-based access: Fig 1: Detailed view of managing employee lifecycle and role-based access Here\u2019s a breakdown of how this process typically works during the employee onboarding: When a new employee starts working at any company location, their information is entered into the company\u2019s Workday \u00ae HRIS system. Workday \u00ae sends this information as an extract to RoboMQ For new employees, RoboMQ creates user identity in Active Directory or Azure AD and provisions their access into enterprise applications based on their role or security groups ensuring that each employee has a single and unique account across all systems with associated access levels. RoboMQ automatically generates a random password for new employee along with default attributes and account control settings. A welcome email or other on-boarding emails are sent to the responsible office manager/s or helpdesk based on job role and location. These emails can be customized and branded to the organization needs. For existing employees, RoboMQ updates account settings, attributes, change of roles (e.g. promotions, transfer, etc.), or change of status (i.e. long-term leave, termination, or re-hire) in sync with Workday \u00ae HRIS. In addition to the Workday \u00ae to AD or Azure AD integration, additional downstream application connectors can be added to this workflow to update user account or access in third party systems. For example, some customers choose to accounts created in Salesforce, Office 365 or other enterprise systems. Managing user accounts or licenses in downstream systems has additional cost savings by making sure terminated employee do not have licenses assigned to them. More than the license cost, there is the safety mechanism in place so that terminated employee do not walk away with access to privileged CRM, operations or ERP systems. For more information or to set up a discussion on this integration solution, schedule an appointment with a RoboMQ integration solution specialist today!","title":"Workday&reg; extract file-based integration to AD"},{"location":"Workday_Connector/#workday-to-ad-api-and-data-integration-approach-using-connect-ipaas","text":"Connect iPaaS is the no-code citizen integrator approach to API and data integration between leading SaaS, EPR, CRM and operations applications on cloud or on-premise. Using simple, easy and intuitive drag-and-drop capabilities, users of Connect can create integration workflows that streamline and automate business processes in minutes with absolutely no coding! Workday \u00ae , Active Directory (AD) and Azure AD are one of the many application connectors available on the Connect iPaaS. End user can integrate APIs from Workday \u00ae to onboard new employees by creating user identities in AD or Azure AD using data mapping and workflow definition. Additional functionality can be added to the integration workflows such as creating a service desk ticket in ServiceNow, creating an account in Salesforce or Microsoft Dynamics CRM or adding an entry in QuickBooks. The main difference between this approach is that API calls are being made to perform data integrations based on specific events, versus files being sent to make updates in near real-time using a managed file transfer (MFT) mechanism. Let\u2019s go over the process of setting up this integration on Connect iPaaS. In this example, we will integrate Workday \u00ae to AD with ServiceNow as an additional connector. We start with the \u201cDesign\u201d dashboard on Connect iPaaS where you have access to hundreds of APIs from leading SaaS, CRM, ERP and enterprise applications and databases. Fig 2: Connect iPaaS Design Dashboard Below images shows the workflow setup for employee onboarding from Workday \u00ae to AD. The left side panel shows the sequence API integrations with first node, Workday \u00ae , being the trigger event. This node receives API call when a new employee is hired in Workday \u00ae . Workday \u00ae is the trigger node while Active Directory and ServiceNow are the action nodes connected to the trigger node. Fig 3: Design dashboard with the workflow set up to streamline employee onboarding Now we go in the details of the Active Directory action node that is triggered in response to new employee hiring in Workday \u00ae . Below image shows that a new user will be created in a specified Organization Unit for the new employee. Fig 4: Create New User in Active Directory action being taken within Active Directory As we mentioned above, an additional ServiceNow API node is added to this workflow which will create a ServiceNow incident to notify a new hire to helpdesk. This incident can be used as a trigger to complete employee on-boarding checklist in service desk which may involve allocating laptop, mobile or other workplace setup activity. Fig 5: An incident is created in ServiceNow to notify helpdesk of a new hire As you see in the image above, you can perform data mapping from Workday \u00ae fields of the employee to required data fields is the action nodes, in this case being ServiceNow. Connect iPaaS provides advanced data mapping and transformation capabilities for business or non-technical users. You can use Microsoft Excel style function that you are very much at ease to perform desired data mappings and transformations. To start using Connect iPaaS, simply sign up at https://trial.robomq.io/connect/ . Or for more information using this integration approach, schedule an appointment with a RoboMQ integration solution specialist today! This integration provides a fabulous \u201cfirst day at job\u201d experience to new hires which can improve employee satisfaction, loyalty and retention. The automated management of role-based access ensures that the right people have access to right information at right time. Managing the termination of access makes sure there are no compliance, security or reputation risks by someone walking away with access to sensitive privileged information. In summary, the Workday \u00ae to AD integration powered by RoboMQ enables your IT and HR teams to focus on more strategic business priorities. This integration provides significant cost savings on HR and already burdened system admin resources. Once this solution is implemented, new employees will have access to the accounts and applications needed from day one, and updates to their profile in your Active Directory will happen in near real-time. This integration provides a fabulous \u201cfirst day at job\u201d experience to new hires which can improve employee satisfaction, loyalty and retention. The automated management of role-based access ensures that the right people have access to right information at right time. Managing the termination of access makes sure there are no compliance, security or reputation risks by someone walking away with access to sensitive privileged information. Experience the transformational power of our Workday \u00ae to AD integration powered by RoboMQ for your enterprise. Schedule a call with an integration specialist today . We are not affiliated, associated, authorized, endorsed by, or in any way officially connected with Workday or any of its affiliates. The name Workday is a registered trademark of Workday. The use of the Workday trademark is for identification and reference purposes only and does not imply any association with Workday or any of its affiliates.","title":"Workday&reg; to AD API and Data Integration Approach Using Connect iPaaS"},{"location":"about/","text":"About RoboMQ RoboMQ enables integration among devices, sensors and applications using open standard based technologies and protocols. Its Message Queue as a Service hub is a cloud based SaaS (Software as a Service) subscription product, which is also offered with enterprise hosting option. Its data integration hub enables companies to connect their products to the cloud and the enterprise systems using virtually any communication channel (e.g. cellular networks, the Internet, WiFi, or satellite). License The SDK available on GitHub , example code and code snippets referred in this documentation are 100% free and open source. The SDK is developed under the Apache 2.0 license , allowing it to be used in both open and proprietary projects. Copyright (c) 2014-2015 RoboMQ . Contact Email: info@robomq.io Address: 8260 Greensboro Dr. Ste. A-32, McLean, VA 22102","title":"About"},{"location":"about/#about-robomq","text":"RoboMQ enables integration among devices, sensors and applications using open standard based technologies and protocols. Its Message Queue as a Service hub is a cloud based SaaS (Software as a Service) subscription product, which is also offered with enterprise hosting option. Its data integration hub enables companies to connect their products to the cloud and the enterprise systems using virtually any communication channel (e.g. cellular networks, the Internet, WiFi, or satellite).","title":"About RoboMQ"},{"location":"about/#license","text":"The SDK available on GitHub , example code and code snippets referred in this documentation are 100% free and open source. The SDK is developed under the Apache 2.0 license , allowing it to be used in both open and proprietary projects. Copyright (c) 2014-2015 RoboMQ .","title":"License"},{"location":"about/#contact","text":"Email: info@robomq.io Address: 8260 Greensboro Dr. Ste. A-32, McLean, VA 22102","title":"Contact"},{"location":"applicationIntegration/","text":"Advantages of Application Integration using Message Queues Message Oriented Middleware (MOM) have long been used for application integration and creating Enterprise Service Bus for developing scalable and decoupled applications. RoboMQ < platform is built with the AMQP broker at the core. The particular implementation of the AMQP broker used is RoboMQ . RoboMQ thus provides all the capabilities and feature sets of the RabbitMQ platform with integrated management, dashboards, and analytics in a Software as a Service (SaaS) package. There are certain distinct advantages of using Message Queues for application integration. Decoupled applications The applications developed using Message Queues are decouple by design. What it means is that your order submission application is not hard wired to your order processor and the order processor application is not hard wired to the shipping application, in atypical order management application example. All of these applications are working together by sending discreet messages to each other. By virtue of decoupling, you can: Add more functionality and applications in the system without changing the existing code Modify any part of the application without affecting other Add more instances of a part of application to handle load. If there is a order rush but order processing takes longer time, you can add more order processor to handle increased load Try different message delivery topologies to achieve complex process orchestration and grow the system organically Note : Refer to this excellent book on Integration Design patterns to learn and build complex messaging applications Enterprise Integration Patterns Scalable systems Applications and systems built using Message Queue based hub are scalable by design. Additional worker processes can be added to the different part of the system to handle increased load. This elastic scaling allows quick and dynamic handling of the bottleneck applications Sophisticated integration patterns Message queues allow building applications using variety of Message delivery patterns and their combination. Basic message delivery patterns are : Direct - one to one message delivery from producers to consumers Topic or Fanout - deliver one message to all interested consumers Request-Reply - two way request reply communication Content based Routing - delivering message based on routing Work Queues - round robin delivery of messages to multiple worker processes SDK containing example code for these use cases can be found at RoboMQ SDK Guaranteed Delivery Message Queue based integration hub ensures guaranteed delivery of the message and critical information. Unlike synchronous point to point communication where recipient needs to available and be on-line, Message Queues deliver message when the recipient is available. In addition, messages can be durable or persistent which will survive any catastrophic failure of the messaging system itself. Deliver any type of content - text, JSON, binary, image or any arbitrary type Message Queue based integration system do not enforce any data format or type of content. Any type of media or content can be delivered using Message Queues. The producer and consumer of the message can decide and process any kind of the messages. To learn more details about the benefits of message queues built on AMQP protocol, refer to AMQP website Learn about RabbitMQ and the details of its implementation of AMQP, read more at RabbitMQ website","title":"Application integration"},{"location":"applicationIntegration/#advantages-of-application-integration-using-message-queues","text":"Message Oriented Middleware (MOM) have long been used for application integration and creating Enterprise Service Bus for developing scalable and decoupled applications. RoboMQ < platform is built with the AMQP broker at the core. The particular implementation of the AMQP broker used is RoboMQ . RoboMQ thus provides all the capabilities and feature sets of the RabbitMQ platform with integrated management, dashboards, and analytics in a Software as a Service (SaaS) package. There are certain distinct advantages of using Message Queues for application integration.","title":"Advantages of Application Integration using Message Queues"},{"location":"applicationIntegration/#decoupled-applications","text":"The applications developed using Message Queues are decouple by design. What it means is that your order submission application is not hard wired to your order processor and the order processor application is not hard wired to the shipping application, in atypical order management application example. All of these applications are working together by sending discreet messages to each other. By virtue of decoupling, you can: Add more functionality and applications in the system without changing the existing code Modify any part of the application without affecting other Add more instances of a part of application to handle load. If there is a order rush but order processing takes longer time, you can add more order processor to handle increased load Try different message delivery topologies to achieve complex process orchestration and grow the system organically Note : Refer to this excellent book on Integration Design patterns to learn and build complex messaging applications Enterprise Integration Patterns","title":"Decoupled applications"},{"location":"applicationIntegration/#scalable-systems","text":"Applications and systems built using Message Queue based hub are scalable by design. Additional worker processes can be added to the different part of the system to handle increased load. This elastic scaling allows quick and dynamic handling of the bottleneck applications","title":"Scalable systems"},{"location":"applicationIntegration/#sophisticated-integration-patterns","text":"Message queues allow building applications using variety of Message delivery patterns and their combination. Basic message delivery patterns are : Direct - one to one message delivery from producers to consumers Topic or Fanout - deliver one message to all interested consumers Request-Reply - two way request reply communication Content based Routing - delivering message based on routing Work Queues - round robin delivery of messages to multiple worker processes SDK containing example code for these use cases can be found at RoboMQ SDK","title":"Sophisticated integration patterns"},{"location":"applicationIntegration/#guaranteed-delivery","text":"Message Queue based integration hub ensures guaranteed delivery of the message and critical information. Unlike synchronous point to point communication where recipient needs to available and be on-line, Message Queues deliver message when the recipient is available. In addition, messages can be durable or persistent which will survive any catastrophic failure of the messaging system itself.","title":"Guaranteed Delivery"},{"location":"applicationIntegration/#deliver-any-type-of-content-text-json-binary-image-or-any-arbitrary-type","text":"Message Queue based integration system do not enforce any data format or type of content. Any type of media or content can be delivered using Message Queues. The producer and consumer of the message can decide and process any kind of the messages. To learn more details about the benefits of message queues built on AMQP protocol, refer to AMQP website Learn about RabbitMQ and the details of its implementation of AMQP, read more at RabbitMQ website","title":"Deliver any type of content - text, JSON, binary, image or any arbitrary type"},{"location":"broadcast/","text":"Broadcast (Publish/Subscribe) For broadcast messaging, a producer sends messages to fan-out exchange that are broadcast to all queues bound to that exchange. As soon as a consumer subscribes to the queue, messages will be delivered to that consumer Browse the chapter of AMQP Introduction first if you're new to AMQP. Python Prerequisites Python client AMQP library The Python library we use for this example can be found at https://github.com/pika/pika . You can install it through sudo pip install pika . Finally, import this library in your program. import pika The full documentation of this library is at https://pika.readthedocs.org/en/0.9.14/ . pika library is not thread safe. Do not use a connection or channel across threads. Producer The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. credentials = pika.PlainCredentials(username, password) connection = pika.BlockingConnection(pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60)) channel = connection.channel() Then producer can publish messages to a fanout exchange where routing key is useless. It will assign a blank string to routing key in publish function. Delivery mode = 1 means it's a non-persistent message. properties = pika.spec.BasicProperties(content_type = \"text/plain\", delivery_mode = 1) channel.basic_publish(exchange = exchangeName, routing_key = \"\", body = \"Hello World!\", properties = properties) At last, producer will disconnect with the RoboMQ broker. connection.close() Consumer The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a fanout exchange, a queue, and bind the queue to the exchange with any routing key (we use an empty key in this example). The routing key is useless in fanout exchange. Auto-delete means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. Exclusive means no other consumer can consume the queue when this one is consuming it. channel.exchange_declare(exchange = exchangeName, exchange_type = \"fanout\", auto_delete = True) channel.queue_declare(queue = queueName, exclusive = True, auto_delete = True) channel.queue_bind(exchange = exchangeName, queue = queueName, routing_key = None) Finally, consumer can consume messages from the queue. The no_ack parameter indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, no_ack equals to true, so producer does not explicitly acknowledge received messages. The start_consuming() function will be blocking the process until stop_consuming() is invoked or exception happens. channel.basic_consume(consumer_callback = onMessage, queue = queueName, no_ack = True) channel.start_consuming() When messages are received, a callback function onMessage() will be invoked to print the message content. def onMessage(channel, method, properties, body): print body Putting it all together producer.py import pika server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" exchangeName = \"testEx\" try: #connect credentials = pika.PlainCredentials(username, password) connection = pika.BlockingConnection(pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60)) channel = connection.channel() #send message #for fanout type exchange, routing key is useless properties = pika.spec.BasicProperties(content_type = \"text/plain\", delivery_mode = 1) channel.basic_publish(exchange = exchangeName, routing_key = \"\", body = \"Hello World!\", properties = properties) #disconnect connection.close() except Exception, e: print e consumer.py import pika import time server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" exchangeName = \"testEx\" queueName = \"testQ1\" #callback funtion on receiving messages def onMessage(channel, method, properties, body): print body while True: try: #connect credentials = pika.PlainCredentials(username, password) connection = pika.BlockingConnection(pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60)) channel = connection.channel() #declare exchange and queue, bind them and consume messages #for fanout type exchange, routing key is useless channel.exchange_declare(exchange = exchangeName, exchange_type = \"fanout\", auto_delete = True) channel.queue_declare(queue = queueName, exclusive = True, auto_delete = True) channel.queue_bind(exchange = exchangeName, queue = queueName, routing_key = None) channel.basic_consume(consumer_callback = onMessage, queue = queueName, no_ack = True) channel.start_consuming() except Exception, e: #reconnect on exception print \"Exception handled, reconnecting...\\nDetail:\\n%s\" % e try: connection.close() except: pass time.sleep(5) Node.js Prerequisites Node.js client AMQP library The Node.js library we use for this example can be found at https://github.com/squaremo/amqp.node . You can install the library through sudo npm install amqplib . Finally, require this library in your program. var amqp = require(\"amqplib\"); The full documentation of this library is at https://www.squaremobius.net/amqp.node/doc/channel_api.html . Producer The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. As shown in the code, this library provides chainable callback API in the form of .then(callback) . For the default vhost \"/\", you will need to insert \"%2f\" (its hexadecimal ASCII code) to the AMQP URI, instead of \"/\" itself. producer = amqp.connect(\"amqp://\" + username + \":\" + password + \"@\" + server + \":\" + port + \"/\" + vhost + \"?heartbeat=60\"); producer.then(function(conn) { return conn.createConfirmChannel().then(successCallback); }).then(null, failureCallback); Then producer can publish messages to a fanout exchange where routing key is useless. It will assign a blank string to routing key in publish function. Delivery mode = 1 means it's a non-persistent message. ch.publish(exchangeName, \"\", content = new Buffer(\"Hello World!\"), options = {contentType: \"text/plain\", deliveryMode: 1}, callback); At last, producer will disconnect with the RoboMQ broker. conn.close(); Consumer The same as producer, consumer needs to first connect to RoboMQ broker. The difference is that consumer uses conn.createChannel() function, while producer uses conn.createConfirmChannel() because the latter one is only useful for publish confirm. Then consumer will declare a fanout exchange, a queue, and bind the queue to the exchange with any routing key (we use an empty key in this example). The routing key is useless in fanout exchange. Durable means the exchange or queue will survive possible broker failover. It's false in this example. Auto-delete means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. Exclusive means no other consumer can consume the queue when this one is consuming it. ch.assertExchange(exchangeName, \"fanout\", {durable: false, autoDelete: true}); ch.assertQueue(queueName, {durable: false, autoDelete: true, exclusive: true}); ch.bindQueue(queueName, exchangeName, \"\"); Finally, consumer can consume messages from the queue. The noAck option indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, noAck is true, so producer does not explicitly acknowledge received messages. The second parameter of consume() function is the callback on receiving messages. In this example, when messages are received, the callback function will be invoked to print the message content. ch.consume(queueName, function(message) { console.log(message.content.toString()); }, {noAck: true}); Putting it all together producer.js var amqp = require(\"amqplib\"); var server = \"hostname\"; var port = \"5672\"; var vhost = \"yourvhost\"; //for \"/\" vhost, use \"%2f\" instead var username = \"username\"; var password = \"password\"; var exchangeName = \"testEx\"; producer = amqp.connect(\"amqp://\" + username + \":\" + password + \"@\" + server + \":\" + port + \"/\" + vhost + \"?heartbeat=60\"); producer.then(function(conn) { return conn.createConfirmChannel().then(function(ch) { //for fanout type exchange, routing key is useless ch.publish(exchangeName, \"\", content = new Buffer(\"Hello World!\"), options = {contentType: \"text/plain\", deliveryMode: 1}, function(err, ok) { if (err != null) { console.error(\"Error: failed to send message\\n\" + err); } conn.close(); }); }); }).then(null, function(err) { console.error(err); }); consumer.js var amqp = require(\"amqplib\"); var domain = require(\"domain\"); var server = \"hostname\"; var port = \"5672\"; var vhost = \"yourvhost\"; //for \"/\" vhost, use \"%2f\" instead var username = \"username\"; var password = \"password\"; var exchangeName = \"testEx\"; var queueName = \"testQ1\"; //use domain module to handle reconnecting var consumer = null; var dom = domain.create(); dom.on(\"error\", relisten); dom.run(listen); function listen() { consumer = amqp.connect(\"amqp://\" + username + \":\" + password + \"@\" + server + \":\" + port + \"/\" + vhost + \"?heartbeat=60\"); consumer.then(function(conn) { return conn.createChannel().then(function(ch) { ch.assertExchange(exchangeName, \"fanout\", {durable: false, autoDelete: true}); ch.assertQueue(queueName, {durable: false, autoDelete: true, exclusive: true}); //for fanout type exchange, routing key is useless ch.bindQueue(queueName, exchangeName, \"\"); ch.consume(queueName, function(message) { //callback funtion on receiving messages console.log(message.content.toString()); }, {noAck: true}); }); }).then(null, function(err) { console.error(\"Exception handled, reconnecting...\\nDetail:\\n\" + err); setTimeout(listen, 5000); }); } function relisten() { consumer.then(function(conn) { conn.close(); }); setTimeout(listen, 5000); } PHP Prerequisite PHP client AMQP library The PHP library we use for this example can be found at https://github.com/videlalvaro/php-amqplib . It uses composer to install in a few steps. Add a composer.json file to your project: { \"require\": { \"videlalvaro/php-amqplib\": \"2.2.*\" } } Download the latest composer in the same path: curl -sS https://getcomposer.org/installer | php Install the library through composer: ./composer.phar install Finally, require this library in your program and use the classes. require_once __DIR__ . '/../vendor/autoload.php'; //directory of library folder use PhpAmqpLib\\Connection\\AMQPConnection; use PhpAmqpLib\\Message\\AMQPMessage; Producer The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. $connection = new AMQPConnection($server, $port, $username, $password, $vhost, $heartbeat = 60); $channel = $connection->channel(); Then producer can publish messages to a fanout exchange where routing key is useless. It will assign a blank string to routing key in publish function. Delivery mode = 1 means it's a non-persistent message. $message = new AMQPMessage(\"Hello World!\", array(\"content_type\" => \"text/plain\", \"delivery_mode\" => 1)); $channel->basic_publish($message, $exchangeName, $routing_key = \"\"); At last, producer will disconnect with the RoboMQ broker. $connection->close(); Consumer The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a fanout exchange, a queue, and bind the queue to the exchange with any routing key (we use an empty key in this example). The routing key is useless in fanout exchange. Auto-delete means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. Exclusive means no other consumer can consume the queue when this one is consuming it. $channel->exchange_declare($exchangeName, $type = \"fanout\", false, false, $auto_delete = true); $channel->queue_declare($queueName, false, false, $exclusive = true, $auto_delete = true); $channel->queue_bind($queueName, $exchangeName, $routing_key = \"\"); Finally, consumer can consume messages from the queue. The no_ack parameter indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, no_ack equals to true, so producer does not explicitly acknowledge received messages. The while loop will be blocking the process and listening for messages until exception happens. $channel->basic_consume($queueName, \"\", false, $no_ack = true, false, false, $callback = $onMessage); while(count($channel->callbacks)) { $channel->wait(); } When messages are received, a callback function will be invoked to print the message content. $onMessage = function ($message) { echo $message->body.PHP_EOL; }; Putting it together producer.php <?php require_once __DIR__ . '/../vendor/autoload.php'; //directory of library folder use PhpAmqpLib\\Connection\\AMQPConnection; use PhpAmqpLib\\Message\\AMQPMessage; $server = \"hostname\"; $port = 5672; $vhost = \"yourvhost\"; $username = \"username\"; $password = \"password\"; $exchangeName = \"testEx\"; try { //connect $connection = new AMQPConnection($server, $port, $username, $password, $vhost, $heartbeat = 60); $channel = $connection->channel(); //send message //for fanout type exchange, routing key is useless $message = new AMQPMessage(\"Hello World!\", array(\"content_type\" => \"text/plain\", \"delivery_mode\" => 1)); $channel->basic_publish($message, $exchangeName, $routing_key = \"\"); //disconnect $connection->close(); } catch(Exception $e) { echo $e.PHP_EOL; } ?> consumer.php <?php require_once __DIR__.\"/../vendor/autoload.php\"; //directory of library folder use PhpAmqpLib\\Connection\\AMQPConnection; $server = \"hostname\"; $port = 5672; $vhost = \"yourvhost\"; $username = \"username\"; $password = \"password\"; $exchangeName = \"testEx\"; $queueName = \"testQ1\"; //callback funtion on receiving messages $onMessage = function ($message) { echo $message->body.PHP_EOL; }; while (true) { try { //connect $connection = new AMQPConnection($server, $port, $username, $password, $vhost, $heartbeat = 60); $channel = $connection->channel(); //declare exchange and queue, bind them and consume messages //for fanout type exchange, routing key is useless $channel->exchange_declare($exchangeName, $type = \"fanout\", false, false, $auto_delete = true); $channel->queue_declare($queueName, false, false, $exclusive = true, $auto_delete = true); $channel->queue_bind($queueName, $exchangeName, $routing_key = \"\"); $channel->basic_consume($queueName, \"\", false, $no_ack = true, false, false, $callback = $onMessage); //start consuming while(count($channel->callbacks)) { $channel->wait(); } } catch(Exception $e) { //reconnect on exception echo \"Exception handled, reconnecting...\\nDetail:\\n\".$e.PHP_EOL; if ($connection != null) { try { $connection->close(); } catch (Exception $e1) {} } sleep(5); } } ?> Ruby Prerequisites Ruby client AMQP library The Ruby library we use for this example can be found at http://rubybunny.info/ . With Ruby version >= 2.0, you can install it through sudo gem install bunny . Finally, import this library in your program. require \"bunny\" The full documentation of this library is at http://rubybunny.info/articles/guides.html . We recommend combining the documentation with the source code of this library when you use it because some of the documentation out there is not being updated timely from our observation. Producer The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. Although the library provides a connection property named recover_from_connection_close , we discourage you to use it. The reason will be explained in the Consumer section. connection = Bunny.new(:host => server, :port => port, :vhost => vhost, :user => username, :pass => password, :heartbeat => 60, :recover_from_connection_close => false) connection.start channel = connection.create_channel Then producer can publish messages to a fanout exchange where routing key is useless. Delivery mode = 1 means it's a non-persistent message. exchange = channel.fanout(exchangeName, :auto_delete => true) exchange.publish(\"Hello World!\", :content_type => \"text/plain\", :delivery_mode => 1) At last, producer will disconnect with the RoboMQ broker. connection.close Consumer The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a fanout exchange, a queue, and bind the queue to the exchange without any routing key since routing key is useless in fanout exchange. Auto-delete means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. Exclusive means no other consumer can consume the queue when this one is consuming it. exchange = channel.fanout(exchangeName, :auto_delete => true) queue = channel.queue(queueName, :exclusive => true, :auto_delete => true) queue.bind(exchange) After that, consumer can consume messages from the queue. The manual_ack parameter indicates if consumer needs to manually send acknowledgment back to broker when it has received the message. In this example, manual_ack equals to false, so producer does not manually acknowledge received messages. The subscribe() function is followed by a callback which will be invoked to print the message payload on receiving a message. queue.subscribe(:block => false, :manual_ack => false) do |delivery_info, metadata, payload| puts payload end As we mentioned in the Producer section, recover_from_connection_close is set to false when connecting to RoboMQ broker. It matters for consumers because recover_from_connection_close will only recover the connection, it won't recreate exchange and queue in case they are gone. Therefore, a more robust approach is letting your code handle reconnecting on its own and keep checking the existence of the subscribed queue. while true raise \"Lost the subscribed queue %s\" % queueName unless connection.queue_exists?(queueName) sleep 1 end Putting it all together producer.rb require \"bunny\" server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" exchangeName = \"testEx\" begin #connect connection = Bunny.new(:host => server, :port => port, :vhost => vhost, :user => username, :pass => password, :heartbeat => 60, :recover_from_connection_close => false) connection.start channel = connection.create_channel #send message #for fanout type exchange, routing key is useless exchange = channel.fanout(exchangeName, :auto_delete => true) exchange.publish(\"Hello World!\", :content_type => \"text/plain\", :delivery_mode => 1) #disconnect connection.close rescue Exception => e puts e end consumer.rb require \"bunny\" server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" exchangeName = \"testEx\" queueName = \"testQ1\" while true begin #connect, disable auto-reconnect so as to manually reconnect connection = Bunny.new(:host => server, :port => port, :vhost => vhost, :user => username, :pass => password, :heartbeat => 60, :recover_from_connection_close => false) connection.start channel = connection.create_channel #declare exchange and queue, bind them and consume messages #for fanout type exchange, routing key is useless exchange = channel.fanout(exchangeName, :auto_delete => true) queue = channel.queue(queueName, :exclusive => true, :auto_delete => true) queue.bind(exchange) queue.subscribe(:block => false, :manual_ack => false) do |delivery_info, metadata, payload| puts payload end #keep checking the existence of the subscribed queue while true raise \"Lost the subscribed queue %s\" % queueName unless connection.queue_exists?(queueName) sleep 1 end rescue Exception => e #reconnect on exception puts \"Exception handled, reconnecting...\\nDetail:\\n%s\" % e #blindly clean old connection begin connection.close end sleep 5 end end Java Prerequisites Java client AMQP library The Java library we use for this example can be found at https://www.rabbitmq.com/java-client.html . Download the library jar file, then import this library in your program import com.rabbitmq.client.*; and compile your source code with the jar file. For example, javac -cp \".:./rabbitmq-client.jar\" Producer.java Consumer.java Run the producer and consumer classes. For example, java -cp \".:./rabbitmq-client.jar\" Consumer java -cp \".:./rabbitmq-client.jar\" Producer Of course, you can eventually compress your producer and consumer classes into jar files. Producer The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. ConnectionFactory factory = new ConnectionFactory(); factory.setHost(server); factory.setPort(port); factory.setVirtualHost(vhost); factory.setUsername(username); factory.setPassword(password); factory.setRequestedHeartbeat(60); connection = factory.newConnection(); channel = connection.createChannel(); Then producer can publish messages to a fanout exchange where routing key is useless. It will assign a blank string to routing key in publish function. String message = \"Hello World!\"; channel.basicPublish(exchangeName, \"\", MessageProperties.TEXT_PLAIN, message.getBytes()); At last, producer will disconnect with the RoboMQ broker. connection.close(); Consumer The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a fanout exchange, a queue, and bind the queue to the exchange with any routing key (we use an empty key in this example). The routing key is useless in fanout exchange. The fourth parameter of exchangeDeclare() and queueDeclare() are auto-delete. That means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. The third parameter of queueDeclare() is exclusive. That means no other consumer can consume the queue when this one is consuming it. channel.exchangeDeclare(exchangeName, \"fanout\", false, true, false, null); channel.queueDeclare(queueName, false, true, true, null); channel.queueBind(queueName, exchangeName, \"\", null); Finally, consumer can consume messages from the queue. The second parameter of basicConsume() function no-ack indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, no-ack equals to true, so producer does not explicitly acknowledge received messages. The while loop will be blocking the process and listening for messages until exception happens. When messages are received, it will print the message content. QueueingConsumer qc = new QueueingConsumer(channel); channel.basicConsume(queueName, true, qc); while (true) { QueueingConsumer.Delivery delivery = qc.nextDelivery(); String message = new String(delivery.getBody()); System.out.println(message); } Putting it all together Producer.java import com.rabbitmq.client.ConnectionFactory; import com.rabbitmq.client.Connection; import com.rabbitmq.client.Channel; import com.rabbitmq.client.MessageProperties; public class Producer { private Connection connection; private Channel channel; private static String server = \"hostname\"; private static int port = 5672; private static String vhost = \"yourvhost\"; private static String username = \"username\"; private static String password = \"password\"; private static String exchangeName = \"testEx\"; private void produce() { try { //connect ConnectionFactory factory = new ConnectionFactory(); factory.setHost(server); factory.setPort(port); factory.setVirtualHost(vhost); factory.setUsername(username); factory.setPassword(password); factory.setRequestedHeartbeat(60); connection = factory.newConnection(); channel = connection.createChannel(); //send message String message = \"Hello World!\"; //for fanout type exchange, routing key is useless channel.basicPublish(exchangeName, \"\", MessageProperties.TEXT_PLAIN, message.getBytes()); //disconnect connection.close(); } catch(Exception e) { System.out.println(e); System.exit(-1); } } public static void main(String[] args) { Producer p = new Producer(); p.produce(); } } Consumer.java import com.rabbitmq.client.ConnectionFactory; import com.rabbitmq.client.Connection; import com.rabbitmq.client.Channel; import com.rabbitmq.client.QueueingConsumer; public class Consumer { private Connection connection; private Channel channel; private static String server = \"hostname\"; private static int port = 5672; private static String vhost = \"yourvhost\"; private static String username = \"username\"; private static String password = \"password\"; private static String exchangeName = \"testEx\"; private static String queueName = \"testQ1\"; private void consume() { while (true) { try { //connect ConnectionFactory factory = new ConnectionFactory(); factory.setHost(server); factory.setPort(port); factory.setVirtualHost(vhost); factory.setUsername(username); factory.setPassword(password); factory.setRequestedHeartbeat(60); connection = factory.newConnection(); channel = connection.createChannel(); //declare exchange and queue, bind them and consume messages channel.exchangeDeclare(exchangeName, \"fanout\", false, true, false, null); channel.queueDeclare(queueName, false, true, true, null); //for fanout type exchange, routing key is useless channel.queueBind(queueName, exchangeName, \"\", null); QueueingConsumer qc = new QueueingConsumer(channel); channel.basicConsume(queueName, true, qc); while (true) { QueueingConsumer.Delivery delivery = qc.nextDelivery(); String message = new String(delivery.getBody()); System.out.println(message); } } catch(Exception e) { //reconnect on exception System.out.printf(\"Exception handled, reconnecting...\\nDetail:\\n%s\\n\", e); try { connection.close(); } catch (Exception e1) {} try { Thread.sleep(5000); } catch(Exception e2) {} } } } public static void main(String[] args) { Consumer c = new Consumer(); c.consume(); } } Go Prerequisites Go client AMQP library The Go library we use for this example can be found at https://github.com/streadway/amqp . You can install it through go get github.com/streadway/amqp . Finally, import this library in your program. import \"github.com/streadway/amqp\" The full documentation of this library is at https://godoc.org/github.com/streadway/amqp . Producer The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. connection, err := amqp.DialConfig(fmt.Sprintf(\"amqp://%s:%s@%s:%d/%s\", username, password, server, port, vhost), amqp.Config{Heartbeat: 60 * time.Second}) channel, err := connection.Channel() Then producer can publish messages to a fanout exchange where routing key is useless. It will assign a blank string to routing key in publish function. Delivery mode = 1 means it's a non-persistent message. err = channel.Publish(exchangeName, \"\", false, false, amqp.Publishing{ContentType: \"text/plain\", DeliveryMode: 1, Body: []byte(\"Hello World!\")}) At last, producer will disconnect with the RoboMQ broker. connection.Close() Consumer The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a fanout exchange, a queue, and bind the queue to the exchange with any routing key (we use an empty key in this example). The routing key is useless in fanout exchange. Durable means the exchange or queue will survive possible broker failover. It's false in this example. Auto-delete means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. Exclusive means no other consumer can consume the queue when this one is consuming it. // audo-delete = true err = channel.ExchangeDeclare(exchangeName, \"fanout\", false, true, false, false, nil) // durable = false; auto-delete = true; exclusive = true queue, err := channel.QueueDeclare(queueName, false, true, true, false, nil) err = channel.QueueBind(queueName, \"\", exchangeName, false, nil) Finally, consumer can consume messages from the queue. Consumer-tag can be later used to Cancel() this consumer when it's no longer needed. Auto-ack parameter indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, auto-ack equals to true, so producer does not explicitly acknowledge received messages. // consumer-tag = \"consumer\"; auto-ack = true messageChan, err := channel.Consume(queue.Name, \"consumer\", true, true, false, false, nil) Note a message channel is returned by the Consume() function. Incoming messages will be received through that channel. Channel in Golang is a typed conduit through which you can send and receive values. Sends and receives block until the other side is ready. for message := range messageChan { fmt.Println(string(message.Body)) } Putting it all together producer.go package main import ( \"fmt\" \"github.com/streadway/amqp\" \"os\" \"time\" ) var server = \"hostname\" var port = 5672 var vhost = \"yourvhost\" var username = \"username\" var password = \"password\" var exchangeName = \"testEx\" func main() { connection, err := amqp.DialConfig(fmt.Sprintf(\"amqp://%s:%s@%s:%d/%s\", username, password, server, port, vhost), amqp.Config{Heartbeat: 60 * time.Second}) if err != nil { fmt.Printf(\"Failed to connect, err: %v\\n\", err) os.Exit(1) } defer connection.Close() channel, err := connection.Channel() if err != nil { fmt.Printf(\"Failed to create channel, err: %v\\n\", err) os.Exit(1) } defer channel.Close() err = channel.Publish( exchangeName, // exchange // for fanout type exchange, routing key is useless \"\", // routing key false, // mandatory false, // immediate amqp.Publishing{ ContentType: \"text/plain\", DeliveryMode: 1, Body: []byte(\"Hello World!\"), }) if err != nil { fmt.Printf(\"Failed to publish message, err: %v\\n\", err) os.Exit(1) } } consumer.go package main import ( \"fmt\" \"github.com/streadway/amqp\" \"time\" ) var server = \"hostname\" var port = 5672 var vhost = \"yourvhost\" var username = \"username\" var password = \"password\" var exchangeName = \"testEx\" var queueName = \"testQ1\" func main() { // Infinite loop to auto-reconnect on failure Loop: for { fmt.Println(\"Starting in 5 seconds...\") time.Sleep(5 * time.Second) connection, err := amqp.DialConfig(fmt.Sprintf(\"amqp://%s:%s@%s:%d/%s\", username, password, server, port, vhost), amqp.Config{Heartbeat: 60 * time.Second}) if err != nil { fmt.Printf(\"Failed to connect, err: %v\\n\", err) continue Loop } defer connection.Close() channel, err := connection.Channel() if err != nil { fmt.Printf(\"Failed to create channel, err: %v\\n\", err) continue Loop } defer channel.Close() err = channel.ExchangeDeclare( exchangeName, // name \"fanout\", // type false, // durable true, // audo-delete false, // internal false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to declare exchange, err: %v\\n\", err) continue Loop } queue, err := channel.QueueDeclare( queueName, // name false, // durable true, // auto-delete true, // exclusive false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to declare queue, err: %v\\n\", err) continue Loop } err = channel.QueueBind( queueName, // queue // for fanout type exchange, routing key is useless \"\", // key exchangeName, // exchange false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to bind queue with exchange, err: %v\\n\", err) continue Loop } messageChan, err := channel.Consume( queue.Name, // queue \"consumer\", // consumer tag true, // auto-ack true, // exclusive false, // no-local false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to consume messages, err: %v\\n\", err) continue Loop } fmt.Println(\"Started consuming messages.\") for message := range messageChan { fmt.Println(string(message.Body)) } } } C Prerequisites C client AMQP library robomq.io is built on AMQP, an open, general-purpose protocol for messaging. There are a number of clients for AMQP in many different languages. However, we'll choose a simple C-language AMQP client library written for use with v2.0+ of the RabbitMQ broker. https://github.com/alanxz/rabbitmq-c/tree/master/librabbitmq You can copy librabbitmq subfolder from latest release located here on GitHub: https://github.com/alanxz/rabbitmq-c https://github.com/alanxz/rabbitmq-c Alternatively, thanks to Subversion support in GitHub, you can use svn export directly: svn export https://github.com/alanxz/rabbitmq-c/trunk/librabbitmq Copy the librabbitmq package into your working directory: cp librabbitmq ./ Also copy all source files and Makefile from RoboMQ SDK at https://github.com/robomq/robomq.io/tree/master/sdk/AMQP/C into the same directory. Now your working directory should have the content as bellow: broadcast config.h librabbitmq Makefile one-to-one request-reply routing-key topic Use the Makefile to compile under a Linux terminal. Run make type={sub-directory} to compile the producer and consumer under the sub-directory. Before compiling the next sub-directory, run make clean to clean up the compiled files. Note that these examples provide a simple client implementation to get started but does not go into detailed description of all flags passed into the AMQP methods. A complete reference to RabbitMQ's implementaton of version 0-9-1 of the AMQP specification can be found in this guide. https://www.rabbitmq.com/amqp-0-9-1-reference.html Producer For broadcast messaging, the producer should publish messages to the the fanout type exchange that broadcasts all the messages it receives to all the queues bound to it. Therefore, routing_key is not required in this example. amqp_basic_properties_t props; props._flags = AMQP_BASIC_CONTENT_TYPE_FLAG | AMQP_BASIC_DELIVERY_MODE_FLAG; props.content_type = amqp_cstring_bytes(\"text/plain\"); props.delivery_mode = 1; /* non-persistent delivery mode */ amqp_boolean_t mandatory = 0; amqp_boolean_t immediate = 0; char exchange_name[] = \"fanout-exchange\"; char routing_key[] = \"\"; int result; // Sending message result = amqp_basic_publish(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(routing_key), mandatory, immediate, &props, amqp_cstring_bytes(\"Hello\")); Consumer Then the consumer should create an exchange and subscribe to a queue. This exchange will be defined similarly to the one-to-one example, however, the fanout exchange type is specified below as exchange_type and binding_key is not required. amqp_bytes_t queue; amqp_channel_t channel = 1; amqp_boolean_t passive = 0; amqp_boolean_t durable = 0; amqp_boolean_t exclusive = 0; amqp_boolean_t auto_delete = 1; amqp_boolean_t internal = 0; char exchange_name[] = \"fanout-exchange\"; char exchange_type[] = \"fanout\"; char queue_name[] = \"hello-queue\"; char binding_key[] = \"\"; // Declaring exchange amqp_exchange_declare(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(exchange_type), passive, durable, auto_delete, internal, amqp_empty_table); // Declaring queue amqp_queue_declare_ok_t *r = amqp_queue_declare(conn, channel, amqp_cstring_bytes(queue_name), passive, durable, exclusive, auto_delete, amqp_empty_table); queue = amqp_bytes_malloc_dup(r->queue); // Binding to queue amqp_queue_bind(conn, channel, queue, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(binding_key), amqp_empty_table); At this point, consumer should start consuming messages broadcast from the fanout exchange type. Putting it all together The full code below includes some basic AMQP error handling for consumer that is useful when declaring exchanges and queues. In addition, main receiver loop attempts to reconnect upon network connection failure. producer.c #include <stdlib.h> #include <stdio.h> #include <string.h> #include <amqp_tcp_socket.h> #include <amqp.h> #include <amqp_framing.h> amqp_connection_state_t mqconnect() { amqp_connection_state_t conn = amqp_new_connection(); amqp_socket_t *socket = NULL; char hostname[] = \"localhost\"; // RoboMQ hostname int port = 5672; //default char user[] = \"guest\"; // RoboMQ username char password[] = \"guest\"; // RoboMQ password char vhost[] = \"/\"; // RoboMQ account vhost amqp_channel_t channel = 1; int channel_max = 0; int frame_max = 131072; int heartbeat = 60; int status = 0; // Opening socket socket = amqp_tcp_socket_new(conn); status = amqp_socket_open(socket, hostname, port); if (status) { printf(\"Error opening TCP socket, status = %d, exiting.\", status); } amqp_login(conn, vhost, channel_max, frame_max, heartbeat, AMQP_SASL_METHOD_PLAIN, user, password); amqp_channel_open(conn, channel); return conn; } int main(int argc, char const *const *argv) { amqp_connection_state_t conn; amqp_channel_t channel = 1; amqp_basic_properties_t props; props._flags = AMQP_BASIC_CONTENT_TYPE_FLAG | AMQP_BASIC_DELIVERY_MODE_FLAG; props.content_type = amqp_cstring_bytes(\"text/plain\"); props.delivery_mode = 1; /* non-persistent delivery mode */ amqp_boolean_t mandatory = 0; amqp_boolean_t immediate = 0; char exchange_name[] = \"fanout-exchange\"; char routing_key[] = \"\"; char *msg_body = \"Hello\\n\"; int result; conn = mqconnect(); // Sending message result = amqp_basic_publish(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(routing_key), mandatory, immediate, &props, amqp_cstring_bytes(msg_body)); // Closing connection amqp_connection_close(conn, AMQP_REPLY_SUCCESS); amqp_destroy_connection(conn); return 0; } consumer.c #include <stdlib.h> #include <stdio.h> #include <string.h> #include <amqp_tcp_socket.h> #include <amqp.h> #include <amqp_framing.h> amqp_connection_state_t mqconnect() { amqp_connection_state_t conn = amqp_new_connection(); amqp_socket_t *socket = NULL; char hostname[] = \"localhost\"; // RoboMQ hostname int port = 5672; //default char user[] = \"guest\"; // RoboMQ username char password[] = \"guest\"; // RoboMQ password char vhost[] = \"/\"; // RoboMQ account vhost amqp_channel_t channel = 1; amqp_rpc_reply_t reply; int channel_max = 0; int frame_max = 131072; int heartbeat = 60; int status = 0; // Opening socket socket = amqp_tcp_socket_new(conn); status = amqp_socket_open(socket, hostname, port); if (status) { printf(\"Error opening TCP socket, status = %d\\n\", status); } reply = amqp_login(conn, vhost, channel_max, frame_max, heartbeat, AMQP_SASL_METHOD_PLAIN, user, password); if(reply.reply_type != AMQP_RESPONSE_NORMAL) { fprintf(stderr, \"%s: server connection reply code: %d\\n\", \"Error logging in\", reply.reply_type); } amqp_channel_open(conn, channel); return conn; } amqp_bytes_t mqdeclare(amqp_connection_state_t conn, const char *exchange_name, const char *queue_name) { amqp_bytes_t queue; amqp_channel_t channel = 1; amqp_boolean_t passive = 0; amqp_boolean_t durable = 0; amqp_boolean_t exclusive = 0; amqp_boolean_t auto_delete = 1; amqp_boolean_t internal = 0; char exchange_type[] = \"fanout\"; char binding_key[] = \"\"; amqp_rpc_reply_t reply; // Declaring exchange amqp_exchange_declare(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(exchange_type), passive, durable, auto_delete, internal, amqp_empty_table); reply = amqp_get_rpc_reply(conn); if(reply.reply_type != AMQP_RESPONSE_NORMAL) { amqp_connection_close_t *m = (amqp_connection_close_t *) reply.reply.decoded; if(NULL != m) { fprintf(stderr, \"%s: server connection error %d, message: %.*s\\n\", \"Error declaring exchange\", m->reply_code, (int) m->reply_text.len, (char *) m->reply_text.bytes); } } // Declaring queue amqp_queue_declare_ok_t *r = amqp_queue_declare(conn, channel, amqp_cstring_bytes(queue_name), passive, durable, exclusive, auto_delete, amqp_empty_table); reply = amqp_get_rpc_reply(conn); if(reply.reply_type != AMQP_RESPONSE_NORMAL) { fprintf(stderr, \"%s: server connection reply code: %d\\n\", \"Error declaring queue\", reply.reply_type); } else { queue = amqp_bytes_malloc_dup(r->queue); // Binding to queue amqp_queue_bind(conn, channel, queue, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(binding_key), amqp_empty_table); } return queue; } int main(int argc, char const *const *argv) { amqp_connection_state_t conn; amqp_bytes_t queue; amqp_channel_t channel = 1; amqp_boolean_t no_local = 0; amqp_boolean_t no_ack = 1; amqp_boolean_t exclusive = 0; char exchange_name[] = \"fanout-exchange\"; const char *queue_name; int retry_time = 5; // retry time in seconds if(argc < 2) { printf(\"Syntax error:\\n\" \"Usage: mqlisten <queue_name>\\n\"); exit(-1); } queue_name = (char *)argv[1]; conn = mqconnect(); queue = mqdeclare(conn, &exchange_name[0], &queue_name[0]); // Consuming the message amqp_basic_consume(conn, channel, queue, amqp_empty_bytes, no_local, no_ack, exclusive, amqp_empty_table); while (1) { amqp_rpc_reply_t result; amqp_envelope_t envelope; amqp_maybe_release_buffers(conn); result = amqp_consume_message(conn, &envelope, NULL, 0); if (AMQP_RESPONSE_NORMAL != result.reply_type) { printf(\"Consumer AMQP failure occurred, response code = %d, retrying in %d seconds...\\n\", result.reply_type, retry_time); // Closing current connection before reconnecting amqp_connection_close(conn, AMQP_CONNECTION_FORCED); amqp_destroy_connection(conn); // Reconnecting on exception conn = mqconnect(); queue = mqdeclare(conn, &exchange_name[0], &queue_name[0]); amqp_basic_consume(conn, channel, queue, amqp_empty_bytes, no_local, no_ack, exclusive, amqp_empty_table); sleep(retry_time); } else { printf(\"Received message size: %d\\nbody: %s\\n\", (int)envelope.message.body.len, (char *)envelope.message.body.bytes); amqp_destroy_envelope(&envelope); } } return 0; }","title":"Broadcast (publish/subscribe)"},{"location":"broadcast/#broadcast-publishsubscribe","text":"For broadcast messaging, a producer sends messages to fan-out exchange that are broadcast to all queues bound to that exchange. As soon as a consumer subscribes to the queue, messages will be delivered to that consumer Browse the chapter of AMQP Introduction first if you're new to AMQP.","title":"Broadcast (Publish/Subscribe)"},{"location":"broadcast/#python","text":"","title":"Python"},{"location":"broadcast/#prerequisites","text":"Python client AMQP library The Python library we use for this example can be found at https://github.com/pika/pika . You can install it through sudo pip install pika . Finally, import this library in your program. import pika The full documentation of this library is at https://pika.readthedocs.org/en/0.9.14/ . pika library is not thread safe. Do not use a connection or channel across threads.","title":"Prerequisites"},{"location":"broadcast/#producer","text":"The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. credentials = pika.PlainCredentials(username, password) connection = pika.BlockingConnection(pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60)) channel = connection.channel() Then producer can publish messages to a fanout exchange where routing key is useless. It will assign a blank string to routing key in publish function. Delivery mode = 1 means it's a non-persistent message. properties = pika.spec.BasicProperties(content_type = \"text/plain\", delivery_mode = 1) channel.basic_publish(exchange = exchangeName, routing_key = \"\", body = \"Hello World!\", properties = properties) At last, producer will disconnect with the RoboMQ broker. connection.close()","title":"Producer"},{"location":"broadcast/#consumer","text":"The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a fanout exchange, a queue, and bind the queue to the exchange with any routing key (we use an empty key in this example). The routing key is useless in fanout exchange. Auto-delete means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. Exclusive means no other consumer can consume the queue when this one is consuming it. channel.exchange_declare(exchange = exchangeName, exchange_type = \"fanout\", auto_delete = True) channel.queue_declare(queue = queueName, exclusive = True, auto_delete = True) channel.queue_bind(exchange = exchangeName, queue = queueName, routing_key = None) Finally, consumer can consume messages from the queue. The no_ack parameter indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, no_ack equals to true, so producer does not explicitly acknowledge received messages. The start_consuming() function will be blocking the process until stop_consuming() is invoked or exception happens. channel.basic_consume(consumer_callback = onMessage, queue = queueName, no_ack = True) channel.start_consuming() When messages are received, a callback function onMessage() will be invoked to print the message content. def onMessage(channel, method, properties, body): print body","title":"Consumer"},{"location":"broadcast/#putting-it-all-together","text":"producer.py import pika server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" exchangeName = \"testEx\" try: #connect credentials = pika.PlainCredentials(username, password) connection = pika.BlockingConnection(pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60)) channel = connection.channel() #send message #for fanout type exchange, routing key is useless properties = pika.spec.BasicProperties(content_type = \"text/plain\", delivery_mode = 1) channel.basic_publish(exchange = exchangeName, routing_key = \"\", body = \"Hello World!\", properties = properties) #disconnect connection.close() except Exception, e: print e consumer.py import pika import time server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" exchangeName = \"testEx\" queueName = \"testQ1\" #callback funtion on receiving messages def onMessage(channel, method, properties, body): print body while True: try: #connect credentials = pika.PlainCredentials(username, password) connection = pika.BlockingConnection(pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60)) channel = connection.channel() #declare exchange and queue, bind them and consume messages #for fanout type exchange, routing key is useless channel.exchange_declare(exchange = exchangeName, exchange_type = \"fanout\", auto_delete = True) channel.queue_declare(queue = queueName, exclusive = True, auto_delete = True) channel.queue_bind(exchange = exchangeName, queue = queueName, routing_key = None) channel.basic_consume(consumer_callback = onMessage, queue = queueName, no_ack = True) channel.start_consuming() except Exception, e: #reconnect on exception print \"Exception handled, reconnecting...\\nDetail:\\n%s\" % e try: connection.close() except: pass time.sleep(5)","title":"Putting it all together"},{"location":"broadcast/#nodejs","text":"","title":"Node.js"},{"location":"broadcast/#prerequisites_1","text":"Node.js client AMQP library The Node.js library we use for this example can be found at https://github.com/squaremo/amqp.node . You can install the library through sudo npm install amqplib . Finally, require this library in your program. var amqp = require(\"amqplib\"); The full documentation of this library is at https://www.squaremobius.net/amqp.node/doc/channel_api.html .","title":"Prerequisites"},{"location":"broadcast/#producer_1","text":"The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. As shown in the code, this library provides chainable callback API in the form of .then(callback) . For the default vhost \"/\", you will need to insert \"%2f\" (its hexadecimal ASCII code) to the AMQP URI, instead of \"/\" itself. producer = amqp.connect(\"amqp://\" + username + \":\" + password + \"@\" + server + \":\" + port + \"/\" + vhost + \"?heartbeat=60\"); producer.then(function(conn) { return conn.createConfirmChannel().then(successCallback); }).then(null, failureCallback); Then producer can publish messages to a fanout exchange where routing key is useless. It will assign a blank string to routing key in publish function. Delivery mode = 1 means it's a non-persistent message. ch.publish(exchangeName, \"\", content = new Buffer(\"Hello World!\"), options = {contentType: \"text/plain\", deliveryMode: 1}, callback); At last, producer will disconnect with the RoboMQ broker. conn.close();","title":"Producer"},{"location":"broadcast/#consumer_1","text":"The same as producer, consumer needs to first connect to RoboMQ broker. The difference is that consumer uses conn.createChannel() function, while producer uses conn.createConfirmChannel() because the latter one is only useful for publish confirm. Then consumer will declare a fanout exchange, a queue, and bind the queue to the exchange with any routing key (we use an empty key in this example). The routing key is useless in fanout exchange. Durable means the exchange or queue will survive possible broker failover. It's false in this example. Auto-delete means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. Exclusive means no other consumer can consume the queue when this one is consuming it. ch.assertExchange(exchangeName, \"fanout\", {durable: false, autoDelete: true}); ch.assertQueue(queueName, {durable: false, autoDelete: true, exclusive: true}); ch.bindQueue(queueName, exchangeName, \"\"); Finally, consumer can consume messages from the queue. The noAck option indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, noAck is true, so producer does not explicitly acknowledge received messages. The second parameter of consume() function is the callback on receiving messages. In this example, when messages are received, the callback function will be invoked to print the message content. ch.consume(queueName, function(message) { console.log(message.content.toString()); }, {noAck: true});","title":"Consumer"},{"location":"broadcast/#putting-it-all-together_1","text":"producer.js var amqp = require(\"amqplib\"); var server = \"hostname\"; var port = \"5672\"; var vhost = \"yourvhost\"; //for \"/\" vhost, use \"%2f\" instead var username = \"username\"; var password = \"password\"; var exchangeName = \"testEx\"; producer = amqp.connect(\"amqp://\" + username + \":\" + password + \"@\" + server + \":\" + port + \"/\" + vhost + \"?heartbeat=60\"); producer.then(function(conn) { return conn.createConfirmChannel().then(function(ch) { //for fanout type exchange, routing key is useless ch.publish(exchangeName, \"\", content = new Buffer(\"Hello World!\"), options = {contentType: \"text/plain\", deliveryMode: 1}, function(err, ok) { if (err != null) { console.error(\"Error: failed to send message\\n\" + err); } conn.close(); }); }); }).then(null, function(err) { console.error(err); }); consumer.js var amqp = require(\"amqplib\"); var domain = require(\"domain\"); var server = \"hostname\"; var port = \"5672\"; var vhost = \"yourvhost\"; //for \"/\" vhost, use \"%2f\" instead var username = \"username\"; var password = \"password\"; var exchangeName = \"testEx\"; var queueName = \"testQ1\"; //use domain module to handle reconnecting var consumer = null; var dom = domain.create(); dom.on(\"error\", relisten); dom.run(listen); function listen() { consumer = amqp.connect(\"amqp://\" + username + \":\" + password + \"@\" + server + \":\" + port + \"/\" + vhost + \"?heartbeat=60\"); consumer.then(function(conn) { return conn.createChannel().then(function(ch) { ch.assertExchange(exchangeName, \"fanout\", {durable: false, autoDelete: true}); ch.assertQueue(queueName, {durable: false, autoDelete: true, exclusive: true}); //for fanout type exchange, routing key is useless ch.bindQueue(queueName, exchangeName, \"\"); ch.consume(queueName, function(message) { //callback funtion on receiving messages console.log(message.content.toString()); }, {noAck: true}); }); }).then(null, function(err) { console.error(\"Exception handled, reconnecting...\\nDetail:\\n\" + err); setTimeout(listen, 5000); }); } function relisten() { consumer.then(function(conn) { conn.close(); }); setTimeout(listen, 5000); }","title":"Putting it all together"},{"location":"broadcast/#php","text":"","title":"PHP"},{"location":"broadcast/#prerequisite","text":"PHP client AMQP library The PHP library we use for this example can be found at https://github.com/videlalvaro/php-amqplib . It uses composer to install in a few steps. Add a composer.json file to your project: { \"require\": { \"videlalvaro/php-amqplib\": \"2.2.*\" } } Download the latest composer in the same path: curl -sS https://getcomposer.org/installer | php Install the library through composer: ./composer.phar install Finally, require this library in your program and use the classes. require_once __DIR__ . '/../vendor/autoload.php'; //directory of library folder use PhpAmqpLib\\Connection\\AMQPConnection; use PhpAmqpLib\\Message\\AMQPMessage;","title":"Prerequisite"},{"location":"broadcast/#producer_2","text":"The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. $connection = new AMQPConnection($server, $port, $username, $password, $vhost, $heartbeat = 60); $channel = $connection->channel(); Then producer can publish messages to a fanout exchange where routing key is useless. It will assign a blank string to routing key in publish function. Delivery mode = 1 means it's a non-persistent message. $message = new AMQPMessage(\"Hello World!\", array(\"content_type\" => \"text/plain\", \"delivery_mode\" => 1)); $channel->basic_publish($message, $exchangeName, $routing_key = \"\"); At last, producer will disconnect with the RoboMQ broker. $connection->close();","title":"Producer"},{"location":"broadcast/#consumer_2","text":"The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a fanout exchange, a queue, and bind the queue to the exchange with any routing key (we use an empty key in this example). The routing key is useless in fanout exchange. Auto-delete means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. Exclusive means no other consumer can consume the queue when this one is consuming it. $channel->exchange_declare($exchangeName, $type = \"fanout\", false, false, $auto_delete = true); $channel->queue_declare($queueName, false, false, $exclusive = true, $auto_delete = true); $channel->queue_bind($queueName, $exchangeName, $routing_key = \"\"); Finally, consumer can consume messages from the queue. The no_ack parameter indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, no_ack equals to true, so producer does not explicitly acknowledge received messages. The while loop will be blocking the process and listening for messages until exception happens. $channel->basic_consume($queueName, \"\", false, $no_ack = true, false, false, $callback = $onMessage); while(count($channel->callbacks)) { $channel->wait(); } When messages are received, a callback function will be invoked to print the message content. $onMessage = function ($message) { echo $message->body.PHP_EOL; };","title":"Consumer"},{"location":"broadcast/#putting-it-together","text":"producer.php <?php require_once __DIR__ . '/../vendor/autoload.php'; //directory of library folder use PhpAmqpLib\\Connection\\AMQPConnection; use PhpAmqpLib\\Message\\AMQPMessage; $server = \"hostname\"; $port = 5672; $vhost = \"yourvhost\"; $username = \"username\"; $password = \"password\"; $exchangeName = \"testEx\"; try { //connect $connection = new AMQPConnection($server, $port, $username, $password, $vhost, $heartbeat = 60); $channel = $connection->channel(); //send message //for fanout type exchange, routing key is useless $message = new AMQPMessage(\"Hello World!\", array(\"content_type\" => \"text/plain\", \"delivery_mode\" => 1)); $channel->basic_publish($message, $exchangeName, $routing_key = \"\"); //disconnect $connection->close(); } catch(Exception $e) { echo $e.PHP_EOL; } ?> consumer.php <?php require_once __DIR__.\"/../vendor/autoload.php\"; //directory of library folder use PhpAmqpLib\\Connection\\AMQPConnection; $server = \"hostname\"; $port = 5672; $vhost = \"yourvhost\"; $username = \"username\"; $password = \"password\"; $exchangeName = \"testEx\"; $queueName = \"testQ1\"; //callback funtion on receiving messages $onMessage = function ($message) { echo $message->body.PHP_EOL; }; while (true) { try { //connect $connection = new AMQPConnection($server, $port, $username, $password, $vhost, $heartbeat = 60); $channel = $connection->channel(); //declare exchange and queue, bind them and consume messages //for fanout type exchange, routing key is useless $channel->exchange_declare($exchangeName, $type = \"fanout\", false, false, $auto_delete = true); $channel->queue_declare($queueName, false, false, $exclusive = true, $auto_delete = true); $channel->queue_bind($queueName, $exchangeName, $routing_key = \"\"); $channel->basic_consume($queueName, \"\", false, $no_ack = true, false, false, $callback = $onMessage); //start consuming while(count($channel->callbacks)) { $channel->wait(); } } catch(Exception $e) { //reconnect on exception echo \"Exception handled, reconnecting...\\nDetail:\\n\".$e.PHP_EOL; if ($connection != null) { try { $connection->close(); } catch (Exception $e1) {} } sleep(5); } } ?>","title":"Putting it together"},{"location":"broadcast/#ruby","text":"","title":"Ruby"},{"location":"broadcast/#prerequisites_2","text":"Ruby client AMQP library The Ruby library we use for this example can be found at http://rubybunny.info/ . With Ruby version >= 2.0, you can install it through sudo gem install bunny . Finally, import this library in your program. require \"bunny\" The full documentation of this library is at http://rubybunny.info/articles/guides.html . We recommend combining the documentation with the source code of this library when you use it because some of the documentation out there is not being updated timely from our observation.","title":"Prerequisites"},{"location":"broadcast/#producer_3","text":"The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. Although the library provides a connection property named recover_from_connection_close , we discourage you to use it. The reason will be explained in the Consumer section. connection = Bunny.new(:host => server, :port => port, :vhost => vhost, :user => username, :pass => password, :heartbeat => 60, :recover_from_connection_close => false) connection.start channel = connection.create_channel Then producer can publish messages to a fanout exchange where routing key is useless. Delivery mode = 1 means it's a non-persistent message. exchange = channel.fanout(exchangeName, :auto_delete => true) exchange.publish(\"Hello World!\", :content_type => \"text/plain\", :delivery_mode => 1) At last, producer will disconnect with the RoboMQ broker. connection.close","title":"Producer"},{"location":"broadcast/#consumer_3","text":"The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a fanout exchange, a queue, and bind the queue to the exchange without any routing key since routing key is useless in fanout exchange. Auto-delete means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. Exclusive means no other consumer can consume the queue when this one is consuming it. exchange = channel.fanout(exchangeName, :auto_delete => true) queue = channel.queue(queueName, :exclusive => true, :auto_delete => true) queue.bind(exchange) After that, consumer can consume messages from the queue. The manual_ack parameter indicates if consumer needs to manually send acknowledgment back to broker when it has received the message. In this example, manual_ack equals to false, so producer does not manually acknowledge received messages. The subscribe() function is followed by a callback which will be invoked to print the message payload on receiving a message. queue.subscribe(:block => false, :manual_ack => false) do |delivery_info, metadata, payload| puts payload end As we mentioned in the Producer section, recover_from_connection_close is set to false when connecting to RoboMQ broker. It matters for consumers because recover_from_connection_close will only recover the connection, it won't recreate exchange and queue in case they are gone. Therefore, a more robust approach is letting your code handle reconnecting on its own and keep checking the existence of the subscribed queue. while true raise \"Lost the subscribed queue %s\" % queueName unless connection.queue_exists?(queueName) sleep 1 end","title":"Consumer"},{"location":"broadcast/#putting-it-all-together_2","text":"producer.rb require \"bunny\" server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" exchangeName = \"testEx\" begin #connect connection = Bunny.new(:host => server, :port => port, :vhost => vhost, :user => username, :pass => password, :heartbeat => 60, :recover_from_connection_close => false) connection.start channel = connection.create_channel #send message #for fanout type exchange, routing key is useless exchange = channel.fanout(exchangeName, :auto_delete => true) exchange.publish(\"Hello World!\", :content_type => \"text/plain\", :delivery_mode => 1) #disconnect connection.close rescue Exception => e puts e end consumer.rb require \"bunny\" server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" exchangeName = \"testEx\" queueName = \"testQ1\" while true begin #connect, disable auto-reconnect so as to manually reconnect connection = Bunny.new(:host => server, :port => port, :vhost => vhost, :user => username, :pass => password, :heartbeat => 60, :recover_from_connection_close => false) connection.start channel = connection.create_channel #declare exchange and queue, bind them and consume messages #for fanout type exchange, routing key is useless exchange = channel.fanout(exchangeName, :auto_delete => true) queue = channel.queue(queueName, :exclusive => true, :auto_delete => true) queue.bind(exchange) queue.subscribe(:block => false, :manual_ack => false) do |delivery_info, metadata, payload| puts payload end #keep checking the existence of the subscribed queue while true raise \"Lost the subscribed queue %s\" % queueName unless connection.queue_exists?(queueName) sleep 1 end rescue Exception => e #reconnect on exception puts \"Exception handled, reconnecting...\\nDetail:\\n%s\" % e #blindly clean old connection begin connection.close end sleep 5 end end","title":"Putting it all together"},{"location":"broadcast/#java","text":"","title":"Java"},{"location":"broadcast/#prerequisites_3","text":"Java client AMQP library The Java library we use for this example can be found at https://www.rabbitmq.com/java-client.html . Download the library jar file, then import this library in your program import com.rabbitmq.client.*; and compile your source code with the jar file. For example, javac -cp \".:./rabbitmq-client.jar\" Producer.java Consumer.java Run the producer and consumer classes. For example, java -cp \".:./rabbitmq-client.jar\" Consumer java -cp \".:./rabbitmq-client.jar\" Producer Of course, you can eventually compress your producer and consumer classes into jar files.","title":"Prerequisites"},{"location":"broadcast/#producer_4","text":"The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. ConnectionFactory factory = new ConnectionFactory(); factory.setHost(server); factory.setPort(port); factory.setVirtualHost(vhost); factory.setUsername(username); factory.setPassword(password); factory.setRequestedHeartbeat(60); connection = factory.newConnection(); channel = connection.createChannel(); Then producer can publish messages to a fanout exchange where routing key is useless. It will assign a blank string to routing key in publish function. String message = \"Hello World!\"; channel.basicPublish(exchangeName, \"\", MessageProperties.TEXT_PLAIN, message.getBytes()); At last, producer will disconnect with the RoboMQ broker. connection.close();","title":"Producer"},{"location":"broadcast/#consumer_4","text":"The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a fanout exchange, a queue, and bind the queue to the exchange with any routing key (we use an empty key in this example). The routing key is useless in fanout exchange. The fourth parameter of exchangeDeclare() and queueDeclare() are auto-delete. That means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. The third parameter of queueDeclare() is exclusive. That means no other consumer can consume the queue when this one is consuming it. channel.exchangeDeclare(exchangeName, \"fanout\", false, true, false, null); channel.queueDeclare(queueName, false, true, true, null); channel.queueBind(queueName, exchangeName, \"\", null); Finally, consumer can consume messages from the queue. The second parameter of basicConsume() function no-ack indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, no-ack equals to true, so producer does not explicitly acknowledge received messages. The while loop will be blocking the process and listening for messages until exception happens. When messages are received, it will print the message content. QueueingConsumer qc = new QueueingConsumer(channel); channel.basicConsume(queueName, true, qc); while (true) { QueueingConsumer.Delivery delivery = qc.nextDelivery(); String message = new String(delivery.getBody()); System.out.println(message); }","title":"Consumer"},{"location":"broadcast/#putting-it-all-together_3","text":"Producer.java import com.rabbitmq.client.ConnectionFactory; import com.rabbitmq.client.Connection; import com.rabbitmq.client.Channel; import com.rabbitmq.client.MessageProperties; public class Producer { private Connection connection; private Channel channel; private static String server = \"hostname\"; private static int port = 5672; private static String vhost = \"yourvhost\"; private static String username = \"username\"; private static String password = \"password\"; private static String exchangeName = \"testEx\"; private void produce() { try { //connect ConnectionFactory factory = new ConnectionFactory(); factory.setHost(server); factory.setPort(port); factory.setVirtualHost(vhost); factory.setUsername(username); factory.setPassword(password); factory.setRequestedHeartbeat(60); connection = factory.newConnection(); channel = connection.createChannel(); //send message String message = \"Hello World!\"; //for fanout type exchange, routing key is useless channel.basicPublish(exchangeName, \"\", MessageProperties.TEXT_PLAIN, message.getBytes()); //disconnect connection.close(); } catch(Exception e) { System.out.println(e); System.exit(-1); } } public static void main(String[] args) { Producer p = new Producer(); p.produce(); } } Consumer.java import com.rabbitmq.client.ConnectionFactory; import com.rabbitmq.client.Connection; import com.rabbitmq.client.Channel; import com.rabbitmq.client.QueueingConsumer; public class Consumer { private Connection connection; private Channel channel; private static String server = \"hostname\"; private static int port = 5672; private static String vhost = \"yourvhost\"; private static String username = \"username\"; private static String password = \"password\"; private static String exchangeName = \"testEx\"; private static String queueName = \"testQ1\"; private void consume() { while (true) { try { //connect ConnectionFactory factory = new ConnectionFactory(); factory.setHost(server); factory.setPort(port); factory.setVirtualHost(vhost); factory.setUsername(username); factory.setPassword(password); factory.setRequestedHeartbeat(60); connection = factory.newConnection(); channel = connection.createChannel(); //declare exchange and queue, bind them and consume messages channel.exchangeDeclare(exchangeName, \"fanout\", false, true, false, null); channel.queueDeclare(queueName, false, true, true, null); //for fanout type exchange, routing key is useless channel.queueBind(queueName, exchangeName, \"\", null); QueueingConsumer qc = new QueueingConsumer(channel); channel.basicConsume(queueName, true, qc); while (true) { QueueingConsumer.Delivery delivery = qc.nextDelivery(); String message = new String(delivery.getBody()); System.out.println(message); } } catch(Exception e) { //reconnect on exception System.out.printf(\"Exception handled, reconnecting...\\nDetail:\\n%s\\n\", e); try { connection.close(); } catch (Exception e1) {} try { Thread.sleep(5000); } catch(Exception e2) {} } } } public static void main(String[] args) { Consumer c = new Consumer(); c.consume(); } }","title":"Putting it all together"},{"location":"broadcast/#go","text":"","title":"Go"},{"location":"broadcast/#prerequisites_4","text":"Go client AMQP library The Go library we use for this example can be found at https://github.com/streadway/amqp . You can install it through go get github.com/streadway/amqp . Finally, import this library in your program. import \"github.com/streadway/amqp\" The full documentation of this library is at https://godoc.org/github.com/streadway/amqp .","title":"Prerequisites"},{"location":"broadcast/#producer_5","text":"The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. connection, err := amqp.DialConfig(fmt.Sprintf(\"amqp://%s:%s@%s:%d/%s\", username, password, server, port, vhost), amqp.Config{Heartbeat: 60 * time.Second}) channel, err := connection.Channel() Then producer can publish messages to a fanout exchange where routing key is useless. It will assign a blank string to routing key in publish function. Delivery mode = 1 means it's a non-persistent message. err = channel.Publish(exchangeName, \"\", false, false, amqp.Publishing{ContentType: \"text/plain\", DeliveryMode: 1, Body: []byte(\"Hello World!\")}) At last, producer will disconnect with the RoboMQ broker. connection.Close()","title":"Producer"},{"location":"broadcast/#consumer_5","text":"The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a fanout exchange, a queue, and bind the queue to the exchange with any routing key (we use an empty key in this example). The routing key is useless in fanout exchange. Durable means the exchange or queue will survive possible broker failover. It's false in this example. Auto-delete means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. Exclusive means no other consumer can consume the queue when this one is consuming it. // audo-delete = true err = channel.ExchangeDeclare(exchangeName, \"fanout\", false, true, false, false, nil) // durable = false; auto-delete = true; exclusive = true queue, err := channel.QueueDeclare(queueName, false, true, true, false, nil) err = channel.QueueBind(queueName, \"\", exchangeName, false, nil) Finally, consumer can consume messages from the queue. Consumer-tag can be later used to Cancel() this consumer when it's no longer needed. Auto-ack parameter indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, auto-ack equals to true, so producer does not explicitly acknowledge received messages. // consumer-tag = \"consumer\"; auto-ack = true messageChan, err := channel.Consume(queue.Name, \"consumer\", true, true, false, false, nil) Note a message channel is returned by the Consume() function. Incoming messages will be received through that channel. Channel in Golang is a typed conduit through which you can send and receive values. Sends and receives block until the other side is ready. for message := range messageChan { fmt.Println(string(message.Body)) }","title":"Consumer"},{"location":"broadcast/#putting-it-all-together_4","text":"producer.go package main import ( \"fmt\" \"github.com/streadway/amqp\" \"os\" \"time\" ) var server = \"hostname\" var port = 5672 var vhost = \"yourvhost\" var username = \"username\" var password = \"password\" var exchangeName = \"testEx\" func main() { connection, err := amqp.DialConfig(fmt.Sprintf(\"amqp://%s:%s@%s:%d/%s\", username, password, server, port, vhost), amqp.Config{Heartbeat: 60 * time.Second}) if err != nil { fmt.Printf(\"Failed to connect, err: %v\\n\", err) os.Exit(1) } defer connection.Close() channel, err := connection.Channel() if err != nil { fmt.Printf(\"Failed to create channel, err: %v\\n\", err) os.Exit(1) } defer channel.Close() err = channel.Publish( exchangeName, // exchange // for fanout type exchange, routing key is useless \"\", // routing key false, // mandatory false, // immediate amqp.Publishing{ ContentType: \"text/plain\", DeliveryMode: 1, Body: []byte(\"Hello World!\"), }) if err != nil { fmt.Printf(\"Failed to publish message, err: %v\\n\", err) os.Exit(1) } } consumer.go package main import ( \"fmt\" \"github.com/streadway/amqp\" \"time\" ) var server = \"hostname\" var port = 5672 var vhost = \"yourvhost\" var username = \"username\" var password = \"password\" var exchangeName = \"testEx\" var queueName = \"testQ1\" func main() { // Infinite loop to auto-reconnect on failure Loop: for { fmt.Println(\"Starting in 5 seconds...\") time.Sleep(5 * time.Second) connection, err := amqp.DialConfig(fmt.Sprintf(\"amqp://%s:%s@%s:%d/%s\", username, password, server, port, vhost), amqp.Config{Heartbeat: 60 * time.Second}) if err != nil { fmt.Printf(\"Failed to connect, err: %v\\n\", err) continue Loop } defer connection.Close() channel, err := connection.Channel() if err != nil { fmt.Printf(\"Failed to create channel, err: %v\\n\", err) continue Loop } defer channel.Close() err = channel.ExchangeDeclare( exchangeName, // name \"fanout\", // type false, // durable true, // audo-delete false, // internal false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to declare exchange, err: %v\\n\", err) continue Loop } queue, err := channel.QueueDeclare( queueName, // name false, // durable true, // auto-delete true, // exclusive false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to declare queue, err: %v\\n\", err) continue Loop } err = channel.QueueBind( queueName, // queue // for fanout type exchange, routing key is useless \"\", // key exchangeName, // exchange false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to bind queue with exchange, err: %v\\n\", err) continue Loop } messageChan, err := channel.Consume( queue.Name, // queue \"consumer\", // consumer tag true, // auto-ack true, // exclusive false, // no-local false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to consume messages, err: %v\\n\", err) continue Loop } fmt.Println(\"Started consuming messages.\") for message := range messageChan { fmt.Println(string(message.Body)) } } }","title":"Putting it all together"},{"location":"broadcast/#c","text":"","title":"C"},{"location":"broadcast/#prerequisites_5","text":"C client AMQP library robomq.io is built on AMQP, an open, general-purpose protocol for messaging. There are a number of clients for AMQP in many different languages. However, we'll choose a simple C-language AMQP client library written for use with v2.0+ of the RabbitMQ broker. https://github.com/alanxz/rabbitmq-c/tree/master/librabbitmq You can copy librabbitmq subfolder from latest release located here on GitHub: https://github.com/alanxz/rabbitmq-c https://github.com/alanxz/rabbitmq-c Alternatively, thanks to Subversion support in GitHub, you can use svn export directly: svn export https://github.com/alanxz/rabbitmq-c/trunk/librabbitmq Copy the librabbitmq package into your working directory: cp librabbitmq ./ Also copy all source files and Makefile from RoboMQ SDK at https://github.com/robomq/robomq.io/tree/master/sdk/AMQP/C into the same directory. Now your working directory should have the content as bellow: broadcast config.h librabbitmq Makefile one-to-one request-reply routing-key topic Use the Makefile to compile under a Linux terminal. Run make type={sub-directory} to compile the producer and consumer under the sub-directory. Before compiling the next sub-directory, run make clean to clean up the compiled files. Note that these examples provide a simple client implementation to get started but does not go into detailed description of all flags passed into the AMQP methods. A complete reference to RabbitMQ's implementaton of version 0-9-1 of the AMQP specification can be found in this guide. https://www.rabbitmq.com/amqp-0-9-1-reference.html","title":"Prerequisites"},{"location":"broadcast/#producer_6","text":"For broadcast messaging, the producer should publish messages to the the fanout type exchange that broadcasts all the messages it receives to all the queues bound to it. Therefore, routing_key is not required in this example. amqp_basic_properties_t props; props._flags = AMQP_BASIC_CONTENT_TYPE_FLAG | AMQP_BASIC_DELIVERY_MODE_FLAG; props.content_type = amqp_cstring_bytes(\"text/plain\"); props.delivery_mode = 1; /* non-persistent delivery mode */ amqp_boolean_t mandatory = 0; amqp_boolean_t immediate = 0; char exchange_name[] = \"fanout-exchange\"; char routing_key[] = \"\"; int result; // Sending message result = amqp_basic_publish(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(routing_key), mandatory, immediate, &props, amqp_cstring_bytes(\"Hello\"));","title":"Producer"},{"location":"broadcast/#consumer_6","text":"Then the consumer should create an exchange and subscribe to a queue. This exchange will be defined similarly to the one-to-one example, however, the fanout exchange type is specified below as exchange_type and binding_key is not required. amqp_bytes_t queue; amqp_channel_t channel = 1; amqp_boolean_t passive = 0; amqp_boolean_t durable = 0; amqp_boolean_t exclusive = 0; amqp_boolean_t auto_delete = 1; amqp_boolean_t internal = 0; char exchange_name[] = \"fanout-exchange\"; char exchange_type[] = \"fanout\"; char queue_name[] = \"hello-queue\"; char binding_key[] = \"\"; // Declaring exchange amqp_exchange_declare(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(exchange_type), passive, durable, auto_delete, internal, amqp_empty_table); // Declaring queue amqp_queue_declare_ok_t *r = amqp_queue_declare(conn, channel, amqp_cstring_bytes(queue_name), passive, durable, exclusive, auto_delete, amqp_empty_table); queue = amqp_bytes_malloc_dup(r->queue); // Binding to queue amqp_queue_bind(conn, channel, queue, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(binding_key), amqp_empty_table); At this point, consumer should start consuming messages broadcast from the fanout exchange type.","title":"Consumer"},{"location":"broadcast/#putting-it-all-together_5","text":"The full code below includes some basic AMQP error handling for consumer that is useful when declaring exchanges and queues. In addition, main receiver loop attempts to reconnect upon network connection failure. producer.c #include <stdlib.h> #include <stdio.h> #include <string.h> #include <amqp_tcp_socket.h> #include <amqp.h> #include <amqp_framing.h> amqp_connection_state_t mqconnect() { amqp_connection_state_t conn = amqp_new_connection(); amqp_socket_t *socket = NULL; char hostname[] = \"localhost\"; // RoboMQ hostname int port = 5672; //default char user[] = \"guest\"; // RoboMQ username char password[] = \"guest\"; // RoboMQ password char vhost[] = \"/\"; // RoboMQ account vhost amqp_channel_t channel = 1; int channel_max = 0; int frame_max = 131072; int heartbeat = 60; int status = 0; // Opening socket socket = amqp_tcp_socket_new(conn); status = amqp_socket_open(socket, hostname, port); if (status) { printf(\"Error opening TCP socket, status = %d, exiting.\", status); } amqp_login(conn, vhost, channel_max, frame_max, heartbeat, AMQP_SASL_METHOD_PLAIN, user, password); amqp_channel_open(conn, channel); return conn; } int main(int argc, char const *const *argv) { amqp_connection_state_t conn; amqp_channel_t channel = 1; amqp_basic_properties_t props; props._flags = AMQP_BASIC_CONTENT_TYPE_FLAG | AMQP_BASIC_DELIVERY_MODE_FLAG; props.content_type = amqp_cstring_bytes(\"text/plain\"); props.delivery_mode = 1; /* non-persistent delivery mode */ amqp_boolean_t mandatory = 0; amqp_boolean_t immediate = 0; char exchange_name[] = \"fanout-exchange\"; char routing_key[] = \"\"; char *msg_body = \"Hello\\n\"; int result; conn = mqconnect(); // Sending message result = amqp_basic_publish(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(routing_key), mandatory, immediate, &props, amqp_cstring_bytes(msg_body)); // Closing connection amqp_connection_close(conn, AMQP_REPLY_SUCCESS); amqp_destroy_connection(conn); return 0; } consumer.c #include <stdlib.h> #include <stdio.h> #include <string.h> #include <amqp_tcp_socket.h> #include <amqp.h> #include <amqp_framing.h> amqp_connection_state_t mqconnect() { amqp_connection_state_t conn = amqp_new_connection(); amqp_socket_t *socket = NULL; char hostname[] = \"localhost\"; // RoboMQ hostname int port = 5672; //default char user[] = \"guest\"; // RoboMQ username char password[] = \"guest\"; // RoboMQ password char vhost[] = \"/\"; // RoboMQ account vhost amqp_channel_t channel = 1; amqp_rpc_reply_t reply; int channel_max = 0; int frame_max = 131072; int heartbeat = 60; int status = 0; // Opening socket socket = amqp_tcp_socket_new(conn); status = amqp_socket_open(socket, hostname, port); if (status) { printf(\"Error opening TCP socket, status = %d\\n\", status); } reply = amqp_login(conn, vhost, channel_max, frame_max, heartbeat, AMQP_SASL_METHOD_PLAIN, user, password); if(reply.reply_type != AMQP_RESPONSE_NORMAL) { fprintf(stderr, \"%s: server connection reply code: %d\\n\", \"Error logging in\", reply.reply_type); } amqp_channel_open(conn, channel); return conn; } amqp_bytes_t mqdeclare(amqp_connection_state_t conn, const char *exchange_name, const char *queue_name) { amqp_bytes_t queue; amqp_channel_t channel = 1; amqp_boolean_t passive = 0; amqp_boolean_t durable = 0; amqp_boolean_t exclusive = 0; amqp_boolean_t auto_delete = 1; amqp_boolean_t internal = 0; char exchange_type[] = \"fanout\"; char binding_key[] = \"\"; amqp_rpc_reply_t reply; // Declaring exchange amqp_exchange_declare(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(exchange_type), passive, durable, auto_delete, internal, amqp_empty_table); reply = amqp_get_rpc_reply(conn); if(reply.reply_type != AMQP_RESPONSE_NORMAL) { amqp_connection_close_t *m = (amqp_connection_close_t *) reply.reply.decoded; if(NULL != m) { fprintf(stderr, \"%s: server connection error %d, message: %.*s\\n\", \"Error declaring exchange\", m->reply_code, (int) m->reply_text.len, (char *) m->reply_text.bytes); } } // Declaring queue amqp_queue_declare_ok_t *r = amqp_queue_declare(conn, channel, amqp_cstring_bytes(queue_name), passive, durable, exclusive, auto_delete, amqp_empty_table); reply = amqp_get_rpc_reply(conn); if(reply.reply_type != AMQP_RESPONSE_NORMAL) { fprintf(stderr, \"%s: server connection reply code: %d\\n\", \"Error declaring queue\", reply.reply_type); } else { queue = amqp_bytes_malloc_dup(r->queue); // Binding to queue amqp_queue_bind(conn, channel, queue, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(binding_key), amqp_empty_table); } return queue; } int main(int argc, char const *const *argv) { amqp_connection_state_t conn; amqp_bytes_t queue; amqp_channel_t channel = 1; amqp_boolean_t no_local = 0; amqp_boolean_t no_ack = 1; amqp_boolean_t exclusive = 0; char exchange_name[] = \"fanout-exchange\"; const char *queue_name; int retry_time = 5; // retry time in seconds if(argc < 2) { printf(\"Syntax error:\\n\" \"Usage: mqlisten <queue_name>\\n\"); exit(-1); } queue_name = (char *)argv[1]; conn = mqconnect(); queue = mqdeclare(conn, &exchange_name[0], &queue_name[0]); // Consuming the message amqp_basic_consume(conn, channel, queue, amqp_empty_bytes, no_local, no_ack, exclusive, amqp_empty_table); while (1) { amqp_rpc_reply_t result; amqp_envelope_t envelope; amqp_maybe_release_buffers(conn); result = amqp_consume_message(conn, &envelope, NULL, 0); if (AMQP_RESPONSE_NORMAL != result.reply_type) { printf(\"Consumer AMQP failure occurred, response code = %d, retrying in %d seconds...\\n\", result.reply_type, retry_time); // Closing current connection before reconnecting amqp_connection_close(conn, AMQP_CONNECTION_FORCED); amqp_destroy_connection(conn); // Reconnecting on exception conn = mqconnect(); queue = mqdeclare(conn, &exchange_name[0], &queue_name[0]); amqp_basic_consume(conn, channel, queue, amqp_empty_bytes, no_local, no_ack, exclusive, amqp_empty_table); sleep(retry_time); } else { printf(\"Received message size: %d\\nbody: %s\\n\", (int)envelope.message.body.len, (char *)envelope.message.body.bytes); amqp_destroy_envelope(&envelope); } } return 0; }","title":"Putting it all together"},{"location":"connectors/","text":"Salesforce Connector This section introduces you to the Salesforce Connector providing an interface between client devices/sensors and an customer's existing Salesforce workflow. The connector utilizes the RoboMQ to ensure the guaranteed and reliable delivery of case information. Overview: A Salesforce customer may have one or more users/divisions within their organization. Therefore, connector can be configured to create cases for more than one division or group within the organization based on the nature of the information or defect from the device or sensor. The connector is designed to integrate seamlessly into the customer's existing management or diagnostics workflow in Salesforce.com allowing case creation to be automated. This offers tremendous efficiency in reducing cost and valuable time without human intervention required to act upon and manually create each case. Startup Authentication Process: Before the connector can start processing any case requests, an access token must be provided by the Salesforce authentication server. The connector requests authorization on behalf on tenant providing username and password, then server verifies credentials and responds with access token. The connector obtains the access token and submits with all subsequent requests. If invalid user credentials are provided or other error prevents token from being issued, the user cannot authorize the connector to access Salesforce API in this flow. Connector Operation: The Salesforce connector currently supports Salesforce Case Create requests. Devices/sensors issue case requests messages over AMQP through the RoboMQ broker. The connector identifies the source of the incoming message, determines the destination Salesforce user/division, and creates a case record associated with their account. The incoming AMQP playload consists of all elements necessary to create and assign a case (i.e. subject, description, contact name, etc.). Mapping of the data elements from the device to the case attributes is configuration driven. Configuration: The connector configuration mapping is a JSON formatted file requiring definition of 2 sections, \"tenant\" and \"divisions\" as follows: Tenant section: Salesforce client Id and secret for remote API access, AMQP connection parameters and credentials. Divisions section: Salesforce user/division credentials Default case record attributes AMQP exchange, queue, and/or routing key. Prerequisite: Requires Python 2.7 and above. Install simple-salesforce REST API client. Create dead letter queue in your vhost with the script deadLetterQueue.py provided by RoboMQ . Get the help session for detailed usage. python deadLetterQueue.py -? Execution: The Connector is intended for installation/execution either on the customer's enterprise platform or hosted on a supported cloud platform. Starting it simply requires specifying the configuration mapping file as shown in example below: python SFconnector.py -i config.json Database Connector This section introduces you to the DB Connector providing an API between your client applications/devices and back-end database. RoboMQ has built a DBConnector module in Python. It consists of an interface between AMQP broker and backend database supporting these transactions: SQL Read & AMQP Publish AMQP Get & SQL Write AMQP Subscribe & SQL Write Overview: DBConnector is easily installed, configured, and executes on client's enterprise platform, so there is no risk of insecure access to database. DBConnector is configured to use one logical database. All SQL CRUD transactions are supported within the database. On the AMQP side, DBConnector will publish to a destination exchange and get messages from a source queue. Each Read & Publish transaction consists of one AMQP message per database record (row). Each Get & Write transaction consists of one or multiple write statements (insert or update) per AMQP message. Database records can be translated to/from AMQP message in either delimited text or JSON / XML format. You can specify any delimiter if using delimited text. If the destination exchange, source exchange & queue does not exist, DBConnector will create them with the default arguments. All the methods of DBConnector returns True, False or None, which respectively indicates success, failure or empty result. Empty result happens when the source queue is empty or read query returns 0 rows. Messages that fail during processing (i.e. invalid content, database transaction failure, etc.) will be \"dead lettered\". You can find them in the dead letter queue and deal with them later. DBConnector handles all possible exceptions to prevent your invoker process from being interrupted. It will print the error or warning and write log if you have enabled logging. Configuration: The configuration file is written in JSON format. It consists of 3 major sections, \"database\", \"broker\" and \"format\". Database section: access information of the database, query statement or template. Broker section: AMQP connection parameters and credentials, message source and destination. Format section: whether message is delimited text, JSON or XML, if delimited, specify the delimiter. Prerequisite: Requires Python 2.7 and above. Install pypyodbc module. Install ODBC driver for the chosen database. Execution: After that, three major methods you'll invoke are selectNSend() , receiveNInsert() and subscribeNInsert() . selectNSend() executes a read query in database and publish each row of the result as a message to the destination exchange. receiveNInsert() gets a message from the source queue, from which extracts the values and write one record or multiple records into the database. subscribeNInsert() follows the same work flow as receiveNInsert() , except for it listens on a queue and keeps consuming messages as they come in. Putting it together, the whole example script for subscribeNInsert() would be, import os from thingsConnect.sql import DBConnector print \"1. load config from DBConnector.config\" dbc = DBConnector(os.path.dirname(os.path.realpath(__file__)) + \"/DBConnector.config\") print \"2. subscribe & insert, started listening\" dbc.subscribeNInsert()","title":"Connectors"},{"location":"connectors/#salesforce-connector","text":"This section introduces you to the Salesforce Connector providing an interface between client devices/sensors and an customer's existing Salesforce workflow. The connector utilizes the RoboMQ to ensure the guaranteed and reliable delivery of case information. Overview: A Salesforce customer may have one or more users/divisions within their organization. Therefore, connector can be configured to create cases for more than one division or group within the organization based on the nature of the information or defect from the device or sensor. The connector is designed to integrate seamlessly into the customer's existing management or diagnostics workflow in Salesforce.com allowing case creation to be automated. This offers tremendous efficiency in reducing cost and valuable time without human intervention required to act upon and manually create each case. Startup Authentication Process: Before the connector can start processing any case requests, an access token must be provided by the Salesforce authentication server. The connector requests authorization on behalf on tenant providing username and password, then server verifies credentials and responds with access token. The connector obtains the access token and submits with all subsequent requests. If invalid user credentials are provided or other error prevents token from being issued, the user cannot authorize the connector to access Salesforce API in this flow. Connector Operation: The Salesforce connector currently supports Salesforce Case Create requests. Devices/sensors issue case requests messages over AMQP through the RoboMQ broker. The connector identifies the source of the incoming message, determines the destination Salesforce user/division, and creates a case record associated with their account. The incoming AMQP playload consists of all elements necessary to create and assign a case (i.e. subject, description, contact name, etc.). Mapping of the data elements from the device to the case attributes is configuration driven. Configuration: The connector configuration mapping is a JSON formatted file requiring definition of 2 sections, \"tenant\" and \"divisions\" as follows: Tenant section: Salesforce client Id and secret for remote API access, AMQP connection parameters and credentials. Divisions section: Salesforce user/division credentials Default case record attributes AMQP exchange, queue, and/or routing key. Prerequisite: Requires Python 2.7 and above. Install simple-salesforce REST API client. Create dead letter queue in your vhost with the script deadLetterQueue.py provided by RoboMQ . Get the help session for detailed usage. python deadLetterQueue.py -? Execution: The Connector is intended for installation/execution either on the customer's enterprise platform or hosted on a supported cloud platform. Starting it simply requires specifying the configuration mapping file as shown in example below: python SFconnector.py -i config.json","title":"Salesforce Connector"},{"location":"connectors/#database-connector","text":"This section introduces you to the DB Connector providing an API between your client applications/devices and back-end database. RoboMQ has built a DBConnector module in Python. It consists of an interface between AMQP broker and backend database supporting these transactions: SQL Read & AMQP Publish AMQP Get & SQL Write AMQP Subscribe & SQL Write Overview: DBConnector is easily installed, configured, and executes on client's enterprise platform, so there is no risk of insecure access to database. DBConnector is configured to use one logical database. All SQL CRUD transactions are supported within the database. On the AMQP side, DBConnector will publish to a destination exchange and get messages from a source queue. Each Read & Publish transaction consists of one AMQP message per database record (row). Each Get & Write transaction consists of one or multiple write statements (insert or update) per AMQP message. Database records can be translated to/from AMQP message in either delimited text or JSON / XML format. You can specify any delimiter if using delimited text. If the destination exchange, source exchange & queue does not exist, DBConnector will create them with the default arguments. All the methods of DBConnector returns True, False or None, which respectively indicates success, failure or empty result. Empty result happens when the source queue is empty or read query returns 0 rows. Messages that fail during processing (i.e. invalid content, database transaction failure, etc.) will be \"dead lettered\". You can find them in the dead letter queue and deal with them later. DBConnector handles all possible exceptions to prevent your invoker process from being interrupted. It will print the error or warning and write log if you have enabled logging. Configuration: The configuration file is written in JSON format. It consists of 3 major sections, \"database\", \"broker\" and \"format\". Database section: access information of the database, query statement or template. Broker section: AMQP connection parameters and credentials, message source and destination. Format section: whether message is delimited text, JSON or XML, if delimited, specify the delimiter. Prerequisite: Requires Python 2.7 and above. Install pypyodbc module. Install ODBC driver for the chosen database. Execution: After that, three major methods you'll invoke are selectNSend() , receiveNInsert() and subscribeNInsert() . selectNSend() executes a read query in database and publish each row of the result as a message to the destination exchange. receiveNInsert() gets a message from the source queue, from which extracts the values and write one record or multiple records into the database. subscribeNInsert() follows the same work flow as receiveNInsert() , except for it listens on a queue and keeps consuming messages as they come in. Putting it together, the whole example script for subscribeNInsert() would be, import os from thingsConnect.sql import DBConnector print \"1. load config from DBConnector.config\" dbc = DBConnector(os.path.dirname(os.path.realpath(__file__)) + \"/DBConnector.config\") print \"2. subscribe & insert, started listening\" dbc.subscribeNInsert()","title":"Database Connector"},{"location":"creatingNewApplication/","text":"Sign up for RoboMQ This guide covers the basics of creating messaging applications using RoboMQ . You need to have the RoboMQ service account created before proceeding with client application development - please see the Getting Started . First application in under 10 lines! AMQP client Now we are going to build our first AMQP application. Prerequisite The Python library we use for this example can be found at https://github.com/pika/pika . You can install it through sudo pip install pika . Finally, import this library in your program. import pika The full documentation of this library is at https://pika.readthedocs.org/en/0.9.14/ . Producer The first thing we need to do is to establish a connection with RoboMQ broker. connection = pika.BlockingConnection(pika.ConnectionParameters(host = hostname, port = 5672, virtual_host = yourvhost, credentials = pika.PlainCredentials(username, password))) channel = connection.channel() Then producer can publish messages to the direct exchange where messages will be delivered to queues whose routing key matches. channel.basic_publish(exchange = \"amq.direct\", routing_key = \"test\", body = \"Hello World!\", properties = None) At last, producer will disconnect with the RoboMQ broker. connection.close() Consumer The first step is the same as producer, consumer needs to connect to RoboMQ broker. Then consumer will declare a queue, and bind the queue to the direct exchange with a routing key. The routing key decides what messages will the queue receive. channel.queue_declare(queue = \"testQ\") channel.queue_bind(exchange = \"amq.direct\", queue = \"testQ\", routing_key = \"test\") Finally, consumer can consume messages from the queue. channel.basic_consume(consumer_callback = onMessage, queue = \"testQ\", no_ack = True) channel.start_consuming() When messages are received, a callback function onMessage() will be invoked to print the message content. def onMessage(channel, method, properties, body): print body Putting it together Before testing the example code, replace hostname, yourvhost, username and password with the real variables in your network environment. producer.py import pika connection = pika.BlockingConnection(pika.ConnectionParameters(host = hostname, port = 5672, virtual_host = yourvhost, credentials = pika.PlainCredentials(username, password))) channel = connection.channel() channel.basic_publish(exchange = \"amq.direct\", routing_key = \"test\", body = \"Hello World!\", properties = None) connection.close() consumer.py import pika def onMessage(channel, method, properties, body): print body connection = pika.BlockingConnection(pika.ConnectionParameters(host = hostname, port = 5672, virtual_host = yourvhost, credentials = pika.PlainCredentials(username, password))) channel = connection.channel() channel.queue_declare(queue = \"testQ\") channel.queue_bind(exchange = \"amq.direct\", queue = \"testQ\", routing_key = \"test\") channel.basic_consume(consumer_callback = onMessage, queue = \"testQ\", no_ack = True) channel.start_consuming() MQTT client Now we are going to build our first MQTT application. Prerequisites The Python library we use for this example can be found at https://eclipse.org/paho/clients/python/ . Its source code is at https://git.eclipse.org/c/paho/org.eclipse.paho.mqtt.python.git/ . You can install it through sudo pip install paho-mqtt . Finally, import this library in your program. import paho.mqtt.client as mqtt The full documentation of this library is at https://pypi.python.org/pypi/paho-mqtt . This library is built on the basis of a C++ library mosquitto. The documentation of mosquitto is at http://mosquitto.org . Producer The first thing we need to do is to establish a connection with RoboMQ broker and start looping then. RoboMQ allows you to specify vhost along with username. See Vhost specification section for the detail. Many MQTT libraries, including this one, require network looping to complete and maintain the connection with broker. There could be several loop functions for you to choose. If none of them are called, incoming network data will not be processed and outgoing network data may not be sent in a timely fashion. client = mqtt.Client() client.username_pw_set(yourvhost + \":\" + username, password) client.connect(hostname, 1883) client.loop_start() After that, producer can send messages to a particular topic. In this example, the topic is \"test\"; It lets user input the message to send. message = raw_input(\"Input message to send: \") client.publish(topic = \"test\", payload = message) At last, producer will stop looping and disconnect with the RoboMQ broker. client.loop_stop() client.disconnect() Consumer The same as producer, consumer needs to connect to RoboMQ broker and start looping. The difference is consumer loops forever. client.loop_forever() After connecting, consumer will subscribe a topic, so that consumer knows where to listen to. client.subscribe(\"test\") Once it receives a message from the queue bound by the topic, it will call the callback function onMessage() to print the topic and message payload. def onMessage(client, userdata, message): print(\"Topic: \" + message.topic + \", Message: \" + message.payload) The callback functions should be preset before connecting to RoboMQ broker. client.on_message = onMessage Putting it all together Before testing the example code, replace hostname, yourvhost, username and password with the real variables in your network environment. producer.py import sys, paho.mqtt.client as mqtt client = mqtt.Client() client.username_pw_set(yourvhost + \":\" + username, password) client.connect(hostname, 1883) client.loop_start() message = raw_input(\"Input message to send: \") client.publish(topic = \"test\", payload = message) client.loop_stop() client.disconnect() consumer.py import sys, paho.mqtt.client as mqtt def onMessage(client, userdata, message): print(\"Topic: \" + message.topic + \", Message: \" + message.payload) client = mqtt.Client() client.username_pw_set(yourvhost + \":\" + username, password) client.on_message = onMessage client.connect(hostname, 1883) client.subscribe(\"test\") client.loop_forever() STOMP client Now we are going to build our first STOMP application. Prerequisite The Python library we use for this example can be found at https://pypi.python.org/pypi/stompest/ . Its GitHub repository is at https://github.com/nikipore/stompest . It supports STOMP version 1.0, 1.1 and 1.2. You can install it through sudo pip install stompest . The full documentation of this library is at http://nikipore.github.io/stompest/ . Producer The first thing we need to do is to establish a connection with RoboMQ broker. In STOMP, username is called login and password is called passcode. client = Stomp(StompConfig(\"tcp://\" + hostname + \":61613\", login = username, passcode = password, version = \"1.2\")) client.connect(versions = [\"1.2\"], host = yourvhost) After that, producer can send messages to a particular destination. In this example, it is a queue bound to the default exchange, but it can be replaced by other types of destinations to perform the corresponding messaging. The Message destinations section in STOMP chapter elaborates it. client.send(destination = \"/queue/test\", body = \"Hello World!\", headers = None) At last, producer will disconnect with the RoboMQ broker. client.disconnect() Consumer The first step is the same as producer, consumer needs to connect to RoboMQ broker. Next step is to subscribe a destination, so that consumer knows where to listen to. Once it receives a message from the destination, it will print the message body. subscription = client.subscribe(\"/queue/test\", {StompSpec.ACK_HEADER: StompSpec.ACK_AUTO, StompSpec.ID_HEADER: '0'}) while True: frame = client.receiveFrame() print frame.body Putting it together Before testing the example code, replace hostname, yourvhost, username and password with the real variables in your network environment. producer.py import sys from stompest.config import StompConfig from stompest.sync import Stomp client = Stomp(StompConfig(\"tcp://\" + hostname + \":61613\", login = username, passcode = password, version = \"1.2\")) client.connect(versions = [\"1.2\"], host = yourvhost) client.send(destination = \"/queue/test\", body = \"Hello World!\", headers = None) client.disconnect() consumer.py import sys from stompest.config import StompConfig from stompest.protocol import StompSpec from stompest.sync import Stomp client = Stomp(StompConfig(\"tcp://\" + hostname + \":61613\", login = username, passcode = password, version = \"1.2\")) client.connect(versions = [\"1.2\"], host = yourvhost) subscription = client.subscribe(\"/queue/test\", {StompSpec.ACK_HEADER: StompSpec.ACK_AUTO, StompSpec.ID_HEADER: '0'}) while True: frame = client.receiveFrame() print frame.body","title":"Creating a new application"},{"location":"creatingNewApplication/#sign-up-for-robomq","text":"This guide covers the basics of creating messaging applications using RoboMQ . You need to have the RoboMQ service account created before proceeding with client application development - please see the Getting Started .","title":"Sign up for RoboMQ"},{"location":"creatingNewApplication/#first-application-in-under-10-lines","text":"","title":"First application in under 10 lines!"},{"location":"creatingNewApplication/#amqp-client","text":"Now we are going to build our first AMQP application.","title":"AMQP client"},{"location":"creatingNewApplication/#prerequisite","text":"The Python library we use for this example can be found at https://github.com/pika/pika . You can install it through sudo pip install pika . Finally, import this library in your program. import pika The full documentation of this library is at https://pika.readthedocs.org/en/0.9.14/ .","title":"Prerequisite"},{"location":"creatingNewApplication/#producer","text":"The first thing we need to do is to establish a connection with RoboMQ broker. connection = pika.BlockingConnection(pika.ConnectionParameters(host = hostname, port = 5672, virtual_host = yourvhost, credentials = pika.PlainCredentials(username, password))) channel = connection.channel() Then producer can publish messages to the direct exchange where messages will be delivered to queues whose routing key matches. channel.basic_publish(exchange = \"amq.direct\", routing_key = \"test\", body = \"Hello World!\", properties = None) At last, producer will disconnect with the RoboMQ broker. connection.close()","title":"Producer"},{"location":"creatingNewApplication/#consumer","text":"The first step is the same as producer, consumer needs to connect to RoboMQ broker. Then consumer will declare a queue, and bind the queue to the direct exchange with a routing key. The routing key decides what messages will the queue receive. channel.queue_declare(queue = \"testQ\") channel.queue_bind(exchange = \"amq.direct\", queue = \"testQ\", routing_key = \"test\") Finally, consumer can consume messages from the queue. channel.basic_consume(consumer_callback = onMessage, queue = \"testQ\", no_ack = True) channel.start_consuming() When messages are received, a callback function onMessage() will be invoked to print the message content. def onMessage(channel, method, properties, body): print body","title":"Consumer"},{"location":"creatingNewApplication/#putting-it-together","text":"Before testing the example code, replace hostname, yourvhost, username and password with the real variables in your network environment. producer.py import pika connection = pika.BlockingConnection(pika.ConnectionParameters(host = hostname, port = 5672, virtual_host = yourvhost, credentials = pika.PlainCredentials(username, password))) channel = connection.channel() channel.basic_publish(exchange = \"amq.direct\", routing_key = \"test\", body = \"Hello World!\", properties = None) connection.close() consumer.py import pika def onMessage(channel, method, properties, body): print body connection = pika.BlockingConnection(pika.ConnectionParameters(host = hostname, port = 5672, virtual_host = yourvhost, credentials = pika.PlainCredentials(username, password))) channel = connection.channel() channel.queue_declare(queue = \"testQ\") channel.queue_bind(exchange = \"amq.direct\", queue = \"testQ\", routing_key = \"test\") channel.basic_consume(consumer_callback = onMessage, queue = \"testQ\", no_ack = True) channel.start_consuming()","title":"Putting it together"},{"location":"creatingNewApplication/#mqtt-client","text":"Now we are going to build our first MQTT application.","title":"MQTT client"},{"location":"creatingNewApplication/#prerequisites","text":"The Python library we use for this example can be found at https://eclipse.org/paho/clients/python/ . Its source code is at https://git.eclipse.org/c/paho/org.eclipse.paho.mqtt.python.git/ . You can install it through sudo pip install paho-mqtt . Finally, import this library in your program. import paho.mqtt.client as mqtt The full documentation of this library is at https://pypi.python.org/pypi/paho-mqtt . This library is built on the basis of a C++ library mosquitto. The documentation of mosquitto is at http://mosquitto.org .","title":"Prerequisites"},{"location":"creatingNewApplication/#producer_1","text":"The first thing we need to do is to establish a connection with RoboMQ broker and start looping then. RoboMQ allows you to specify vhost along with username. See Vhost specification section for the detail. Many MQTT libraries, including this one, require network looping to complete and maintain the connection with broker. There could be several loop functions for you to choose. If none of them are called, incoming network data will not be processed and outgoing network data may not be sent in a timely fashion. client = mqtt.Client() client.username_pw_set(yourvhost + \":\" + username, password) client.connect(hostname, 1883) client.loop_start() After that, producer can send messages to a particular topic. In this example, the topic is \"test\"; It lets user input the message to send. message = raw_input(\"Input message to send: \") client.publish(topic = \"test\", payload = message) At last, producer will stop looping and disconnect with the RoboMQ broker. client.loop_stop() client.disconnect()","title":"Producer"},{"location":"creatingNewApplication/#consumer_1","text":"The same as producer, consumer needs to connect to RoboMQ broker and start looping. The difference is consumer loops forever. client.loop_forever() After connecting, consumer will subscribe a topic, so that consumer knows where to listen to. client.subscribe(\"test\") Once it receives a message from the queue bound by the topic, it will call the callback function onMessage() to print the topic and message payload. def onMessage(client, userdata, message): print(\"Topic: \" + message.topic + \", Message: \" + message.payload) The callback functions should be preset before connecting to RoboMQ broker. client.on_message = onMessage","title":"Consumer"},{"location":"creatingNewApplication/#putting-it-all-together","text":"Before testing the example code, replace hostname, yourvhost, username and password with the real variables in your network environment. producer.py import sys, paho.mqtt.client as mqtt client = mqtt.Client() client.username_pw_set(yourvhost + \":\" + username, password) client.connect(hostname, 1883) client.loop_start() message = raw_input(\"Input message to send: \") client.publish(topic = \"test\", payload = message) client.loop_stop() client.disconnect() consumer.py import sys, paho.mqtt.client as mqtt def onMessage(client, userdata, message): print(\"Topic: \" + message.topic + \", Message: \" + message.payload) client = mqtt.Client() client.username_pw_set(yourvhost + \":\" + username, password) client.on_message = onMessage client.connect(hostname, 1883) client.subscribe(\"test\") client.loop_forever()","title":"Putting it all together"},{"location":"creatingNewApplication/#stomp-client","text":"Now we are going to build our first STOMP application.","title":"STOMP client"},{"location":"creatingNewApplication/#prerequisite_1","text":"The Python library we use for this example can be found at https://pypi.python.org/pypi/stompest/ . Its GitHub repository is at https://github.com/nikipore/stompest . It supports STOMP version 1.0, 1.1 and 1.2. You can install it through sudo pip install stompest . The full documentation of this library is at http://nikipore.github.io/stompest/ .","title":"Prerequisite"},{"location":"creatingNewApplication/#producer_2","text":"The first thing we need to do is to establish a connection with RoboMQ broker. In STOMP, username is called login and password is called passcode. client = Stomp(StompConfig(\"tcp://\" + hostname + \":61613\", login = username, passcode = password, version = \"1.2\")) client.connect(versions = [\"1.2\"], host = yourvhost) After that, producer can send messages to a particular destination. In this example, it is a queue bound to the default exchange, but it can be replaced by other types of destinations to perform the corresponding messaging. The Message destinations section in STOMP chapter elaborates it. client.send(destination = \"/queue/test\", body = \"Hello World!\", headers = None) At last, producer will disconnect with the RoboMQ broker. client.disconnect()","title":"Producer"},{"location":"creatingNewApplication/#consumer_2","text":"The first step is the same as producer, consumer needs to connect to RoboMQ broker. Next step is to subscribe a destination, so that consumer knows where to listen to. Once it receives a message from the destination, it will print the message body. subscription = client.subscribe(\"/queue/test\", {StompSpec.ACK_HEADER: StompSpec.ACK_AUTO, StompSpec.ID_HEADER: '0'}) while True: frame = client.receiveFrame() print frame.body","title":"Consumer"},{"location":"creatingNewApplication/#putting-it-together_1","text":"Before testing the example code, replace hostname, yourvhost, username and password with the real variables in your network environment. producer.py import sys from stompest.config import StompConfig from stompest.sync import Stomp client = Stomp(StompConfig(\"tcp://\" + hostname + \":61613\", login = username, passcode = password, version = \"1.2\")) client.connect(versions = [\"1.2\"], host = yourvhost) client.send(destination = \"/queue/test\", body = \"Hello World!\", headers = None) client.disconnect() consumer.py import sys from stompest.config import StompConfig from stompest.protocol import StompSpec from stompest.sync import Stomp client = Stomp(StompConfig(\"tcp://\" + hostname + \":61613\", login = username, passcode = password, version = \"1.2\")) client.connect(versions = [\"1.2\"], host = yourvhost) subscription = client.subscribe(\"/queue/test\", {StompSpec.ACK_HEADER: StompSpec.ACK_AUTO, StompSpec.ID_HEADER: '0'}) while True: frame = client.receiveFrame() print frame.body","title":"Putting it together"},{"location":"deviceIntegration/","text":"IoT and M2M Integration Devices, sensors and systems connecting together are driving the next generation of applications creating the Internet of Things (IoT). RoboMQ provides an open standard based platform to connect your devices and sensors to the back-end applications, systems, processes and people to build the nest big thing. You can work with message queue protocols like MQTT ( MQ for Telemetry), AMQP (Advanced Message Queue Protocol) and STOMP ( Simple Text Oriented Messaging Protocol) while using RoboMQ . The protocols supported by RoboMQ can run on very small footprint devices using a choice among languages that are supported by device OS and profile. Common choices of devices include Raspberry Pi, Audrino, Beaglebone and mBed based platforms. The most basic requirement is the support for running one languages and network connectivity. You should however be cognizant of the device footprint when choosing the message queue protocol. For the example case, we have chosen Raspberry Pi device running a small Linux kernel (a variant of Debian Linux) and Python programming language. Raspberry Pi as an example device The Raspberry Pi is a credit-card sized micro-computer that plugs into your TV and a keyboard. It is a capable little computer which can be used in electronics projects. In this guide you will be introduced how to use raspberry pi to acquire information from real-world via sensors and other electrical components, and then integrate raspberry pi into RoboMQ as data producer. Getting raspberry pi ready There may be some steps to do when you have all the devices and materials. For example you need to install a system into the micro-SD card which your raspberry pi will be boot from. For detailed instructions on how to setup a raspberry pi, please go to the official raspberry pi document page. Raspberry Pi Documentation Prerequisite Raspberry Pi Although any model of raspberry pi will work, we recommend the newest version. In this documentation we will use the model raspberry pi B+ for the example. You can buy a raspberry pi from their official site: raspberry products Input device For raspberry B+ there are 4 USB ports on the board. You can plug in a USB keyboard and mouse to control your raspberry pi. Power source A typical Android cellphone charger is good for raspberry pi. Monitor(optional) Raspberry Pi has an HDMI port for display. It may be easier and more comfortable for you to work with your raspberry pi directly on it's own system GUI. But if you do not, there is still no problem because you can also use you laptop to ssh the raspberry and control it in the terminal. For tutorial how to ssh a raspberry you can refer to Adafruit Learning System: https://learn.adafruit.com/adafruits-raspberry-pi-lesson-6-using-ssh Sensors: Raspberry pi is compatible with a lot of sensors. In our documentation we are going to show 3 sensors for demonstration: DHT11 humidity & temperature sensor, PIR motion sensor and light sensor. You can get these sensors from online shopping sites (Amazon, ebay, etc). Breadboard and jumper wires These are used to connect sensors to the raspberry pi. You can also get these from online shopping sites. Python This is the language we recommend for raspberry pi-sensor programming. As it's handy, simple, and is supported by raspberry pi. Python 2.7.3 or above is preferred. Raspberry Pi and sensors With raspberry pi we can easily develop some sensor programs. In this part we are going to show 3 examples: PIR motion sensor, DHT11 humidity & temperature sensor, and light sensor. Before integrating these sensors into RoboMQ , we would try them locally on your raspberry. You can see how them work in your raspberry pi LXTerminal. For details about how to set up and run the sensors with raspberry pi, please go to the Adafruit Learning System . DHT11 humidity & temperature sensor https://learn.adafruit.com/downloads/pdf/dht-humidity-sensing-on-raspberry-pi-with-gdocs-logging.pdf Light sensor https://learn.adafruit.com/basic-resistor-sensor-reading-on-raspberry-pi/basic-photocell-reading PIR motion sensor https://learn.adafruit.com/adafruits-raspberry-pi-lesson-12-sensing-movement/overview https://learn.adafruit.com/adafruits-raspberry-pi-lesson-12-sensing-movement/overview Integrate Raspberry Pi with RoboMQ After you have finished setting it up and testing it locally, you may start to think: Why would I do this? What can I do with this in real world? Okay, let's imagine a scenario. You are an employee in a water & sewer utility company. You need a system to monitor your water wells. You need temperature, humidity, luminance, and intruder detection real-time data to be read as it happens and, for some, at a defined interval. And for the convenience of management and ability to take immediate actions, you need all the data to be visible in your control center. As an smart engineer, you have already developed the sensor data collecting programs, as discussed in sections above, by working with raspberry pi and sensors locally. What you need now is to add some simple code to send the data read from the sensors via RoboMQ broker to RoboMQ dashboard application so that you can easily open the dashboard and view data charts. For sending data, the main job is to create a producer module, then call its send method in your raspberry pi sensor programs. Follow the next section to build this application. You will find it easy, handy and fun !!! RoboMQ has now enhanced and packaged the sensorProducer module introduced bellow. You may either directly use our package or build the module yourself following the next section. The Python pip package is available at https://s3.amazonaws.com/public.robomq/packages/sensorProducer.tar.gz . Read our blog at http://robomq.blogspot.com/2015/05/device-to-dashboard-real-time-analytics.html for specific use guide. Messaging with AMQP Create Producer First, launch your raspberry pi and create a file named \"producer.py\", then paste the following code into the file: import sys, os, json, pika stationID = \"well1\" coordinate = [-89, 64] server = \"hostname\" port = \"5672\" vhost = \"waterSupply\" username = \"username\" password = \"password\" topic = \"sensors\" parameters = pika.URLParameters(\"amqp://\" + username + \":\" + password + \"@\" + server + \":\" + port + \"/\" + vhost) def connect(): try: connection = pika.BlockingConnection(parameters) channel = connection.channel() return channel except: print \"Error: Failed to connect broker\" channel = connect() #connect to broker #publish message def send(msgJson): global channel msgJson[\"stationID\"] = stationID msgJson[\"coordinate\"] = coordinate properties = pika.BasicProperties(content_type = \"application/json\", delivery_mode = 1) try: channel.basic_publish(\"amq.topic\", topic, json.dumps(msgJson, ensure_ascii=False), properties) except: print \"Error: Failed to send message\" channel = connect() #reconnect to broker It will be the producer module that you are going to import in your raspberry pi-sensor codes to send messages to RoboMQ . As you can see, the producer module contains 2 methods. First is the connect() method that is in charge of establishing connection to the RoboMQ broker. It will automatically reconnect on exception too. Another method is send() which publishes messages through RoboMQ to worker consumers running on RoboMQ server. (You always have the option to build your own worker consumers to handle messages sent by yourself). In any of your sensor programs, just call send() function to send the data collection to RoboMQ broker. A message should be a JSON object containing key-value pairs. Now we are all set for the producer module, after this we are going add a few lines in the sensor programs. Edit Sensor Programs In this part we are going to combine the DHT11 sensor and the Light sensor into one program, just for clean-wise. Edit your DHT11 sensor and Light sensor program as bellow: import RPi.GPIO as gpio import Adafruit_DHT import time import os import sys import producer DEBUG = 1 gpio.setmode(gpio.BCM) htsensor = Adafruit_DHT.DHT11 htpin = 4 lpin=21 while True: humidity, temperature = Adafruit_DHT.read_retry(htsensor, htpin) if humidity is not None and temperature is not None: temperature = temperature * 9 / 5 + 32 print 'Temp={0:0.1f}*F Humid={1:0.1f}%'.format(temperature, humidity) else: print 'Failed to get reading. Try again!' reading = 0 gpio.setup(lpin, gpio.OUT) gpio.output(lpin, gpio.LOW) time.sleep(1) gpio.setup(lpin, gpio.IN) while (gpio.input(lpin) == gpio.LOW): reading += 1 luminance = 100 - reading print ('Luminance='), luminance message = {\"time\": time.time() * 1000} message[\"temperature\"] = temperature message[\"humidity\"] = humidity message[\"luminance\"] = luminance try: producer.send(message) except: print \"Error: failed to send data through producer\" time.sleep(30) #interval And then edit your PIR motion sensor as bellow: import RPi.GPIO as gpio import time import producer gpio.setmode(gpio.BOARD) mpin = 31 gpio.setup(mpin,gpio.IN) while True: gpio.wait_for_edge(mpin, gpio.RISING) print('Intruder detected') message = {\"time\": time.time() * 1000} message[\"intruder\"] = 1 try: producer.send(message) except: print \"Error: failed to send data through producer\" gpio.remove_event_detect(mpin) gpio.wait_for_edge(mpin, gpio.FALLING) print('Intruder left or froze') message = {\"time\": time.time() * 1000} message[\"intruder\"] = 0 try: producer.send(message) except: print \"Error: failed to send data through producer\" gpio.remove_event_detect(mpin) Now all your data will be sent via RoboMQ broker to the our dashboard application. The only thing you need to accomplish is just open your dashboard in a Web browser. Messaging with MQTT In the example above we implemented sending message by creating a producer module in AMQP protocol and call its send() function in the sensor program. However there are more than one way we can build a producer as RoboMQ supports multiple protocols. Now we are going to show you one more example how to send messages using the MQTT protocol. You only need to change the producer module. Modify the \"producer.py\" as bellow: import sys, os, json import paho.mqtt.client as mqtt stationID = \"well1\" coordinate = [-89, 64] server = \"hostname\" port = 1883 vhost = \"waterSupply\" username = \"username\" password = \"password\" topic = \"sensors\" def connect(): try: client = mqtt.Client(client_id=\"\", clean_session=True, userdata=None, protocol=\"MQTTv31\") client.username_pw_set(vhost + \":\" + username, password) client.connect(server, port, keepalive=60, bind_address=\"\") client.loop_start() #start network loop return client except: print \"Error: Failed to connect broker\" def reconnect(): global client if (client): client.loop_stop() #stop the current loop before reconnecting client.disconnect() client = connect() client = connect() #connect to broker #publish message def send(msgJson): global client msgJson[\"stationID\"] = stationID msgJson[\"coordinate\"] = coordinate try: result = client.publish(topic, payload=str(json.dumps(msgJson, ensure_ascii=False)), qos=1, retain=False) if (result[0] == 4): reconnect() #reconnect to broker except: print \"Error: Failed to send message\" reconnect() #reconnect to broker Since the difference is limited in the producer module, there is no need to modify the sensor programs. Messaging with STOMP For STOMP producer module, no change is required for sensor programs either, only change your \"producer.py\" as bellow: import sys, os, json from stompest.config import StompConfig from stompest.sync import Stomp stationID = \"well1\" coordinate = [-89, 64] server = \"hostname\" port = \"61613\" vhost = \"waterSupply\" username = \"username\" password = \"password\" topic = \"sensors\" def connect(): try: client = Stomp(StompConfig(\"tcp://\" + server + \":\" + port, login = username, passcode = password, version = \"1.2\")) client.connect(host = vhost) return client except: print \"Error: Failed to connect broker\" client = connect() #connect to broker #publish message def send(msgJson): global client msgJson[\"stationID\"] = stationID msgJson[\"coordinate\"] = coordinate try: client.send(\"/topic/\" + topic, json.dumps(msgJson, ensure_ascii=False), {\"content-type\": \"application/json\"}) except: print \"Error: Failed to send message\" client = connect() #reconnect to broker","title":"IoT and M2M integration"},{"location":"deviceIntegration/#iot-and-m2m-integration","text":"Devices, sensors and systems connecting together are driving the next generation of applications creating the Internet of Things (IoT). RoboMQ provides an open standard based platform to connect your devices and sensors to the back-end applications, systems, processes and people to build the nest big thing. You can work with message queue protocols like MQTT ( MQ for Telemetry), AMQP (Advanced Message Queue Protocol) and STOMP ( Simple Text Oriented Messaging Protocol) while using RoboMQ . The protocols supported by RoboMQ can run on very small footprint devices using a choice among languages that are supported by device OS and profile. Common choices of devices include Raspberry Pi, Audrino, Beaglebone and mBed based platforms. The most basic requirement is the support for running one languages and network connectivity. You should however be cognizant of the device footprint when choosing the message queue protocol. For the example case, we have chosen Raspberry Pi device running a small Linux kernel (a variant of Debian Linux) and Python programming language.","title":"IoT and M2M Integration"},{"location":"deviceIntegration/#raspberry-pi-as-an-example-device","text":"The Raspberry Pi is a credit-card sized micro-computer that plugs into your TV and a keyboard. It is a capable little computer which can be used in electronics projects. In this guide you will be introduced how to use raspberry pi to acquire information from real-world via sensors and other electrical components, and then integrate raspberry pi into RoboMQ as data producer.","title":"Raspberry Pi as an example device"},{"location":"deviceIntegration/#getting-raspberry-pi-ready","text":"There may be some steps to do when you have all the devices and materials. For example you need to install a system into the micro-SD card which your raspberry pi will be boot from. For detailed instructions on how to setup a raspberry pi, please go to the official raspberry pi document page. Raspberry Pi Documentation","title":"Getting raspberry pi ready"},{"location":"deviceIntegration/#prerequisite","text":"","title":"Prerequisite"},{"location":"deviceIntegration/#raspberry-pi","text":"Although any model of raspberry pi will work, we recommend the newest version. In this documentation we will use the model raspberry pi B+ for the example. You can buy a raspberry pi from their official site: raspberry products","title":"Raspberry Pi"},{"location":"deviceIntegration/#input-device","text":"For raspberry B+ there are 4 USB ports on the board. You can plug in a USB keyboard and mouse to control your raspberry pi.","title":"Input device"},{"location":"deviceIntegration/#power-source","text":"A typical Android cellphone charger is good for raspberry pi.","title":"Power source"},{"location":"deviceIntegration/#monitoroptional","text":"Raspberry Pi has an HDMI port for display. It may be easier and more comfortable for you to work with your raspberry pi directly on it's own system GUI. But if you do not, there is still no problem because you can also use you laptop to ssh the raspberry and control it in the terminal. For tutorial how to ssh a raspberry you can refer to Adafruit Learning System: https://learn.adafruit.com/adafruits-raspberry-pi-lesson-6-using-ssh","title":"Monitor(optional)"},{"location":"deviceIntegration/#sensors","text":"Raspberry pi is compatible with a lot of sensors. In our documentation we are going to show 3 sensors for demonstration: DHT11 humidity & temperature sensor, PIR motion sensor and light sensor. You can get these sensors from online shopping sites (Amazon, ebay, etc).","title":"Sensors:"},{"location":"deviceIntegration/#breadboard-and-jumper-wires","text":"These are used to connect sensors to the raspberry pi. You can also get these from online shopping sites.","title":"Breadboard and jumper wires"},{"location":"deviceIntegration/#python","text":"This is the language we recommend for raspberry pi-sensor programming. As it's handy, simple, and is supported by raspberry pi. Python 2.7.3 or above is preferred.","title":"Python"},{"location":"deviceIntegration/#raspberry-pi-and-sensors","text":"With raspberry pi we can easily develop some sensor programs. In this part we are going to show 3 examples: PIR motion sensor, DHT11 humidity & temperature sensor, and light sensor. Before integrating these sensors into RoboMQ , we would try them locally on your raspberry. You can see how them work in your raspberry pi LXTerminal. For details about how to set up and run the sensors with raspberry pi, please go to the Adafruit Learning System .","title":"Raspberry Pi and sensors"},{"location":"deviceIntegration/#dht11-humidity-temperature-sensor","text":"https://learn.adafruit.com/downloads/pdf/dht-humidity-sensing-on-raspberry-pi-with-gdocs-logging.pdf","title":"DHT11 humidity &amp; temperature sensor"},{"location":"deviceIntegration/#light-sensor","text":"https://learn.adafruit.com/basic-resistor-sensor-reading-on-raspberry-pi/basic-photocell-reading","title":"Light sensor"},{"location":"deviceIntegration/#pir-motion-sensor","text":"https://learn.adafruit.com/adafruits-raspberry-pi-lesson-12-sensing-movement/overview https://learn.adafruit.com/adafruits-raspberry-pi-lesson-12-sensing-movement/overview","title":"PIR motion sensor"},{"location":"deviceIntegration/#integrate-raspberry-pi-with-robomq","text":"After you have finished setting it up and testing it locally, you may start to think: Why would I do this? What can I do with this in real world? Okay, let's imagine a scenario. You are an employee in a water & sewer utility company. You need a system to monitor your water wells. You need temperature, humidity, luminance, and intruder detection real-time data to be read as it happens and, for some, at a defined interval. And for the convenience of management and ability to take immediate actions, you need all the data to be visible in your control center. As an smart engineer, you have already developed the sensor data collecting programs, as discussed in sections above, by working with raspberry pi and sensors locally. What you need now is to add some simple code to send the data read from the sensors via RoboMQ broker to RoboMQ dashboard application so that you can easily open the dashboard and view data charts. For sending data, the main job is to create a producer module, then call its send method in your raspberry pi sensor programs. Follow the next section to build this application. You will find it easy, handy and fun !!! RoboMQ has now enhanced and packaged the sensorProducer module introduced bellow. You may either directly use our package or build the module yourself following the next section. The Python pip package is available at https://s3.amazonaws.com/public.robomq/packages/sensorProducer.tar.gz . Read our blog at http://robomq.blogspot.com/2015/05/device-to-dashboard-real-time-analytics.html for specific use guide.","title":"Integrate Raspberry Pi with RoboMQ"},{"location":"deviceIntegration/#messaging-with-amqp","text":"","title":"Messaging with AMQP"},{"location":"deviceIntegration/#create-producer","text":"First, launch your raspberry pi and create a file named \"producer.py\", then paste the following code into the file: import sys, os, json, pika stationID = \"well1\" coordinate = [-89, 64] server = \"hostname\" port = \"5672\" vhost = \"waterSupply\" username = \"username\" password = \"password\" topic = \"sensors\" parameters = pika.URLParameters(\"amqp://\" + username + \":\" + password + \"@\" + server + \":\" + port + \"/\" + vhost) def connect(): try: connection = pika.BlockingConnection(parameters) channel = connection.channel() return channel except: print \"Error: Failed to connect broker\" channel = connect() #connect to broker #publish message def send(msgJson): global channel msgJson[\"stationID\"] = stationID msgJson[\"coordinate\"] = coordinate properties = pika.BasicProperties(content_type = \"application/json\", delivery_mode = 1) try: channel.basic_publish(\"amq.topic\", topic, json.dumps(msgJson, ensure_ascii=False), properties) except: print \"Error: Failed to send message\" channel = connect() #reconnect to broker It will be the producer module that you are going to import in your raspberry pi-sensor codes to send messages to RoboMQ . As you can see, the producer module contains 2 methods. First is the connect() method that is in charge of establishing connection to the RoboMQ broker. It will automatically reconnect on exception too. Another method is send() which publishes messages through RoboMQ to worker consumers running on RoboMQ server. (You always have the option to build your own worker consumers to handle messages sent by yourself). In any of your sensor programs, just call send() function to send the data collection to RoboMQ broker. A message should be a JSON object containing key-value pairs. Now we are all set for the producer module, after this we are going add a few lines in the sensor programs.","title":"Create Producer"},{"location":"deviceIntegration/#edit-sensor-programs","text":"In this part we are going to combine the DHT11 sensor and the Light sensor into one program, just for clean-wise. Edit your DHT11 sensor and Light sensor program as bellow: import RPi.GPIO as gpio import Adafruit_DHT import time import os import sys import producer DEBUG = 1 gpio.setmode(gpio.BCM) htsensor = Adafruit_DHT.DHT11 htpin = 4 lpin=21 while True: humidity, temperature = Adafruit_DHT.read_retry(htsensor, htpin) if humidity is not None and temperature is not None: temperature = temperature * 9 / 5 + 32 print 'Temp={0:0.1f}*F Humid={1:0.1f}%'.format(temperature, humidity) else: print 'Failed to get reading. Try again!' reading = 0 gpio.setup(lpin, gpio.OUT) gpio.output(lpin, gpio.LOW) time.sleep(1) gpio.setup(lpin, gpio.IN) while (gpio.input(lpin) == gpio.LOW): reading += 1 luminance = 100 - reading print ('Luminance='), luminance message = {\"time\": time.time() * 1000} message[\"temperature\"] = temperature message[\"humidity\"] = humidity message[\"luminance\"] = luminance try: producer.send(message) except: print \"Error: failed to send data through producer\" time.sleep(30) #interval And then edit your PIR motion sensor as bellow: import RPi.GPIO as gpio import time import producer gpio.setmode(gpio.BOARD) mpin = 31 gpio.setup(mpin,gpio.IN) while True: gpio.wait_for_edge(mpin, gpio.RISING) print('Intruder detected') message = {\"time\": time.time() * 1000} message[\"intruder\"] = 1 try: producer.send(message) except: print \"Error: failed to send data through producer\" gpio.remove_event_detect(mpin) gpio.wait_for_edge(mpin, gpio.FALLING) print('Intruder left or froze') message = {\"time\": time.time() * 1000} message[\"intruder\"] = 0 try: producer.send(message) except: print \"Error: failed to send data through producer\" gpio.remove_event_detect(mpin) Now all your data will be sent via RoboMQ broker to the our dashboard application. The only thing you need to accomplish is just open your dashboard in a Web browser.","title":"Edit Sensor Programs"},{"location":"deviceIntegration/#messaging-with-mqtt","text":"In the example above we implemented sending message by creating a producer module in AMQP protocol and call its send() function in the sensor program. However there are more than one way we can build a producer as RoboMQ supports multiple protocols. Now we are going to show you one more example how to send messages using the MQTT protocol. You only need to change the producer module. Modify the \"producer.py\" as bellow: import sys, os, json import paho.mqtt.client as mqtt stationID = \"well1\" coordinate = [-89, 64] server = \"hostname\" port = 1883 vhost = \"waterSupply\" username = \"username\" password = \"password\" topic = \"sensors\" def connect(): try: client = mqtt.Client(client_id=\"\", clean_session=True, userdata=None, protocol=\"MQTTv31\") client.username_pw_set(vhost + \":\" + username, password) client.connect(server, port, keepalive=60, bind_address=\"\") client.loop_start() #start network loop return client except: print \"Error: Failed to connect broker\" def reconnect(): global client if (client): client.loop_stop() #stop the current loop before reconnecting client.disconnect() client = connect() client = connect() #connect to broker #publish message def send(msgJson): global client msgJson[\"stationID\"] = stationID msgJson[\"coordinate\"] = coordinate try: result = client.publish(topic, payload=str(json.dumps(msgJson, ensure_ascii=False)), qos=1, retain=False) if (result[0] == 4): reconnect() #reconnect to broker except: print \"Error: Failed to send message\" reconnect() #reconnect to broker Since the difference is limited in the producer module, there is no need to modify the sensor programs.","title":"Messaging with MQTT"},{"location":"deviceIntegration/#messaging-with-stomp","text":"For STOMP producer module, no change is required for sensor programs either, only change your \"producer.py\" as bellow: import sys, os, json from stompest.config import StompConfig from stompest.sync import Stomp stationID = \"well1\" coordinate = [-89, 64] server = \"hostname\" port = \"61613\" vhost = \"waterSupply\" username = \"username\" password = \"password\" topic = \"sensors\" def connect(): try: client = Stomp(StompConfig(\"tcp://\" + server + \":\" + port, login = username, passcode = password, version = \"1.2\")) client.connect(host = vhost) return client except: print \"Error: Failed to connect broker\" client = connect() #connect to broker #publish message def send(msgJson): global client msgJson[\"stationID\"] = stationID msgJson[\"coordinate\"] = coordinate try: client.send(\"/topic/\" + topic, json.dumps(msgJson, ensure_ascii=False), {\"content-type\": \"application/json\"}) except: print \"Error: Failed to send message\" client = connect() #reconnect to broker","title":"Messaging with STOMP"},{"location":"gettingStarted/","text":"Getting started Getting started with RoboMQ extremely simple and easy - just sign up for a free trial or if you are ready, contact us to get started on one of the subscription plans. Free Trial To sign up for the free trial of RoboMQ , click on Free Trial link. Provide some basic information and some one from RoboMQ team will reach out to you with information to get you started. With the free trial - You do not need to provide any credit card or payment information You get shared tenancy in a full feature cluster supporting all features except analytics and data driven alert platforms which is based on the content of your data Maximum five (5) concurrent connections to allow you to develop your applications. Subscription plans If you are ready to get started with a paid subscription , reach out to us on our website at Contact us and we will be happy to get you started and setup in couple of hours. There are following subscription options available: Shared tenancy - Shared tenancy on the cloud with your secure virtual host. Available in multiple pricing options of varying size and support levels. Dedicated cluster on the cloud - Dedicated tenancy in the cloud with your private RoboMQ clusters. Clusters are built and priced to the required capacity. Enterprise hosted option provides RoboMQ infrastructure hosted on your private cloud or data center as a managed service. After you sign up Once you sign up for the Free trial or one of the subscription plans, you get access to the full feature set of the RoboMQ SaaS offering. Following sections explain how to access the components and get started with building your first application. We will illustrate these steps below for a fictional customer named 'nova' with vhost name or tenant ID 'nova'. Administrative access to your tenant Upon sign up, a administrative user and credential token is created for your virtual host on RoboMQ cluster. Administrative user : the user name is same as the vhost or the customer tenant name, which for this example is nova Credential - administrative credential is a secure token that will be sent over the registered email. This token is one time token generated using TOTP (Time-Based One-Time Password Algorithm) IETF RFC 6238 . Every time the token is reset a new token is created. Figure : Login credential for RoboMQ Management console Creating additional users and access grants Additional users can be created with specific passwords or token. Tokens are recommended for security and get be generated for the users using TOTP (Time-Based One-Time Password Algorithm). As part of the initial setup, we provide following three users which are sufficient to get the application integration going for most needs. vhostRead - The 'vhost' is the customer specific tenant ID. For the example case, the user name will be 'novaRead'. This user has read only access to message, and queues. This user can be used to receive/get messages and act as consumer in the messaging parlance. vhostWrite - The 'vhost' is the customer specific tenant ID. For the example case, the user name will be 'novaWrite'. This user has write only access to message, and queues. This user can be used to send/publish messages and act as producer in the messaging parlance. vhostRW - The 'vhost' is the customer specific tenant ID. For the example case, the user name will be 'novaRW'. This user has write and read access to message, and queues. This user can be used to send/publish as well as receive/get messages and act as both producer and consumer in the messaging parlance. *Note: All three above users do not have administrative, management access to the tenant. These users do not have rights to access RoboMQ management console. * Monitoring real time activity of your tenant using Management Console The real time activities of your tenant can be monitored using the Management Console. The management console provides real time information up to 10 minutes of past activity including messaging activity, connections, channels, exchanges, queues and users. For longer horizon messaging traffic activity including visual graphs, RoboMQ Messaging Dashboard should be used. Figure : Monitoring real time activity using RoboMQ Management Console Messaging Dashboard RoboMQ messaging dashboard provides specialized visual graphs and charts giving you a single pane of glass, capturing all the messaging activity for your tenant. The following key messaging activity parameters are tracked in the dashboard: 1. Exchanges 2. Connections 3. Channels 4. Queues 5. Consumers 6. Messages delivered 7. Message Delivery Rate 8. Messages Delivered - Get 9. Messages Delivery Rate - Get 9. Messages Delivered - consume 10. Messages Delivery Rate - Consume 11. Messages Acknowledged 12. Message Acknowledge Rate 13. Messages Redelivered 14. Messages Redelivery Rate 15. Messages Published 16. Message Publish Rate 17. Bytes Received 18. Byte Receive Rate 19. Byte Sent 20. Byte Send Rate The Messaging dashboard provides historical information for up to 15 days of the messaging activity on your tenant. Figure : Messaging Dashboard Analytics and data driven alerts One of the core strength of the RoboMQ platform is the expandability. Based on the expandability, we have provided the IoT Analytics Application . This platforms consume the messages in parallel and provides analytics on it. This functionality is specific use case driven and the some customization is needed to generate required analytics. Figure : Analytics based on message content Another example of the expandable nature of the RoboMQ platform is the data driven alerts . It consumes the messages and acts on the message content evaluating them against threshold configuration. When the message content hits these threshold values , a custom alert, email or a phone call can be made to react to this situation. This functionality is also use case specific and needs configuration. Writing your first application By now you should be familiar with your tenant and all set to start writing your first application using RoboMQ. Follow the sample code and the tutorial in the next section to start sending and receiving messages in less than 10 lines of code from your devices, sensors and applications !!!! Technical support Whenever you feel challenged to debug your client program or have technical advice to RoboMQ , we are ready to solve your problem as soon as possible 7/24. You can report a issue on our GitHub or directly contact us through Email info@robomq.io .","title":"Getting started"},{"location":"gettingStarted/#getting-started","text":"Getting started with RoboMQ extremely simple and easy - just sign up for a free trial or if you are ready, contact us to get started on one of the subscription plans.","title":"Getting started"},{"location":"gettingStarted/#free-trial","text":"To sign up for the free trial of RoboMQ , click on Free Trial link. Provide some basic information and some one from RoboMQ team will reach out to you with information to get you started. With the free trial - You do not need to provide any credit card or payment information You get shared tenancy in a full feature cluster supporting all features except analytics and data driven alert platforms which is based on the content of your data Maximum five (5) concurrent connections to allow you to develop your applications.","title":"Free Trial"},{"location":"gettingStarted/#subscription-plans","text":"If you are ready to get started with a paid subscription , reach out to us on our website at Contact us and we will be happy to get you started and setup in couple of hours. There are following subscription options available: Shared tenancy - Shared tenancy on the cloud with your secure virtual host. Available in multiple pricing options of varying size and support levels. Dedicated cluster on the cloud - Dedicated tenancy in the cloud with your private RoboMQ clusters. Clusters are built and priced to the required capacity. Enterprise hosted option provides RoboMQ infrastructure hosted on your private cloud or data center as a managed service.","title":"Subscription plans"},{"location":"gettingStarted/#after-you-sign-up","text":"Once you sign up for the Free trial or one of the subscription plans, you get access to the full feature set of the RoboMQ SaaS offering. Following sections explain how to access the components and get started with building your first application. We will illustrate these steps below for a fictional customer named 'nova' with vhost name or tenant ID 'nova'.","title":"After you sign up"},{"location":"gettingStarted/#administrative-access-to-your-tenant","text":"Upon sign up, a administrative user and credential token is created for your virtual host on RoboMQ cluster. Administrative user : the user name is same as the vhost or the customer tenant name, which for this example is nova Credential - administrative credential is a secure token that will be sent over the registered email. This token is one time token generated using TOTP (Time-Based One-Time Password Algorithm) IETF RFC 6238 . Every time the token is reset a new token is created. Figure : Login credential for RoboMQ Management console","title":"Administrative access to your tenant"},{"location":"gettingStarted/#creating-additional-users-and-access-grants","text":"Additional users can be created with specific passwords or token. Tokens are recommended for security and get be generated for the users using TOTP (Time-Based One-Time Password Algorithm). As part of the initial setup, we provide following three users which are sufficient to get the application integration going for most needs. vhostRead - The 'vhost' is the customer specific tenant ID. For the example case, the user name will be 'novaRead'. This user has read only access to message, and queues. This user can be used to receive/get messages and act as consumer in the messaging parlance. vhostWrite - The 'vhost' is the customer specific tenant ID. For the example case, the user name will be 'novaWrite'. This user has write only access to message, and queues. This user can be used to send/publish messages and act as producer in the messaging parlance. vhostRW - The 'vhost' is the customer specific tenant ID. For the example case, the user name will be 'novaRW'. This user has write and read access to message, and queues. This user can be used to send/publish as well as receive/get messages and act as both producer and consumer in the messaging parlance. *Note: All three above users do not have administrative, management access to the tenant. These users do not have rights to access RoboMQ management console. *","title":"Creating additional users and access grants"},{"location":"gettingStarted/#monitoring-real-time-activity-of-your-tenant-using-management-console","text":"The real time activities of your tenant can be monitored using the Management Console. The management console provides real time information up to 10 minutes of past activity including messaging activity, connections, channels, exchanges, queues and users. For longer horizon messaging traffic activity including visual graphs, RoboMQ Messaging Dashboard should be used. Figure : Monitoring real time activity using RoboMQ Management Console","title":"Monitoring real time activity of your tenant using Management Console"},{"location":"gettingStarted/#messaging-dashboard","text":"RoboMQ messaging dashboard provides specialized visual graphs and charts giving you a single pane of glass, capturing all the messaging activity for your tenant. The following key messaging activity parameters are tracked in the dashboard: 1. Exchanges 2. Connections 3. Channels 4. Queues 5. Consumers 6. Messages delivered 7. Message Delivery Rate 8. Messages Delivered - Get 9. Messages Delivery Rate - Get 9. Messages Delivered - consume 10. Messages Delivery Rate - Consume 11. Messages Acknowledged 12. Message Acknowledge Rate 13. Messages Redelivered 14. Messages Redelivery Rate 15. Messages Published 16. Message Publish Rate 17. Bytes Received 18. Byte Receive Rate 19. Byte Sent 20. Byte Send Rate The Messaging dashboard provides historical information for up to 15 days of the messaging activity on your tenant. Figure : Messaging Dashboard","title":"Messaging Dashboard"},{"location":"gettingStarted/#analytics-and-data-driven-alerts","text":"One of the core strength of the RoboMQ platform is the expandability. Based on the expandability, we have provided the IoT Analytics Application . This platforms consume the messages in parallel and provides analytics on it. This functionality is specific use case driven and the some customization is needed to generate required analytics. Figure : Analytics based on message content Another example of the expandable nature of the RoboMQ platform is the data driven alerts . It consumes the messages and acts on the message content evaluating them against threshold configuration. When the message content hits these threshold values , a custom alert, email or a phone call can be made to react to this situation. This functionality is also use case specific and needs configuration.","title":"Analytics and data driven alerts"},{"location":"gettingStarted/#writing-your-first-application","text":"By now you should be familiar with your tenant and all set to start writing your first application using RoboMQ. Follow the sample code and the tutorial in the next section to start sending and receiving messages in less than 10 lines of code from your devices, sensors and applications !!!!","title":"Writing your first application"},{"location":"gettingStarted/#technical-support","text":"Whenever you feel challenged to debug your client program or have technical advice to RoboMQ , we are ready to solve your problem as soon as possible 7/24. You can report a issue on our GitHub or directly contact us through Email info@robomq.io .","title":"Technical support"},{"location":"managed_file_transfer/","text":"Managed File Transfer Managed File Transfer (MFT) is a reliable and guaranteed delivery file transfer service with all the management, error handling and recovery features built in for a secure and encrypted file transfer. It supports managed file transfer across any of the file transfer protocols (be it FTP, SFTP, FTP over SSL etc..) and various file systems (Windows, Linux/Unix, mid range systems, S3, Object Stores, Cloud Storage etc.). The file transfer is secure and encrypted and tracked through the transfer and in-transit processing providing a reliable enterprise grade MFT platform for managing the secure transfer of data from source location to one or more destinations through public, private and hybrid network. Introduction Setup and configuration Work Flow Error Handling, alerts and monitoring Introduction RoboMQ MFT service allows you to transfer files between file systems using variety of file transfer protocols. The Managed File Transfer platform is built on the strength of RoboMQ Message Oriented Middleware(MOM)providing guarantee delivery reliable data transfer. It utilizes the RoboMQ broker for receiving and tracking events identifying each steps of transfer and in-transit transformation. In addition to regular MFT functionality, you get following silent advantages while using RoboMQ. Support for all file transfer protocols End to end tracking for the file transfers and transformations Ability to break files into messages and integrating the data with APIa. This approach offers integration with non-file based APIs and systems Microservices based approach for data transformation, enrichments and validation Robust error handling, monitoring, alerts and Error Analytics Setup and configuration The MFT service needs to talk to your RoboMQ tenant, therefore you will need to provide your vhost or tenant ID , username , password and your preference for secure transfer over ssl . To transfer files from one location to another, MFT service requires access to four folders, let's call them upload , inbound , outbound and destination (you can use any name you want): \u251c\u2500\u2500 destination \u2502 \u251c\u2500\u2500 archive \u2502 \u2514\u2500\u2500 error \u251c\u2500\u2500 inbound \u2502 \u251c\u2500\u2500 archive \u2502 \u2514\u2500\u2500 error \u251c\u2500\u2500 outbound \u2502 \u251c\u2500\u2500 archive \u2502 \u2514\u2500\u2500 error \u2514\u2500\u2500 upload \u251c\u2500\u2500 archive \u2514\u2500\u2500 error Those folders don't need to be under the same directory. Actually they can and often do reside on different servers, file systems or S3 buckets . Note that you will need to provide credential of the accounts for accessing those file systems and make sure those accounts have read and write permissions on the above specific folders. In case that you need some files under those folders but don't want them to be transferred, you can configure a filter to ignore files with names that match a certain pattern. At this point, the MFT service configured and is ready to work. Work Flow The following picture depicts a typical MFT file transfer flow. Fig 1: High level schematic of a file transfer flow MFT has a file listener, it scans the upload folder on a configurable interval. Once a expected file detected, it will be copied to one or more inbound folders (multiple MFT services can work together in case the file needs to be duplicated and processed at multiple destinations). If file requires specific validation or transformation, an optional MFT Microservice can perform transformation, validation or data enrichment on the file in the inbound folder. After successfully processing the file, this component moves file to outbound folder. Finally another MFT Microservice will pick it up from outbound folder and put it into destination . Note that just like with any integration with RoboMQ there could be a whole chain of Microservices performing variety of functions including transformation, validation, data enrichment or application of any business logic while file is in transit from source to the destination. At each step of the processing, the original successfully processed files are archived in corresponding archive folder. Error Handling, alerts and monitoring Upon any failure at any point, the current file will be moved to corresponding error folder. At this point RoboMQ error handling process kicks in which is robust and has multiple options for tactical as well as strategic handling of error case. An error message (includes file information) will be sent to an error queue and an notification message (describes what is the error and how it happened) will be sent to an notification queue. A SMS, an email or a phone call could be triggered to the operations team or the responsible party based on setup of the severity rules and notification mechanism A ticket or a case can be created in any of the case management platform being used like serviceNow, Jira, Salesforce or any other All the errors are saved into a real-time database which provides a analytical dashboard view of the errors for long term trends, root cause analysis and corrective actions Fig 1: Error Analytics dashboard for analysis and corrective actions","title":"Managed File Transfer"},{"location":"managed_file_transfer/#managed-file-transfer","text":"Managed File Transfer (MFT) is a reliable and guaranteed delivery file transfer service with all the management, error handling and recovery features built in for a secure and encrypted file transfer. It supports managed file transfer across any of the file transfer protocols (be it FTP, SFTP, FTP over SSL etc..) and various file systems (Windows, Linux/Unix, mid range systems, S3, Object Stores, Cloud Storage etc.). The file transfer is secure and encrypted and tracked through the transfer and in-transit processing providing a reliable enterprise grade MFT platform for managing the secure transfer of data from source location to one or more destinations through public, private and hybrid network. Introduction Setup and configuration Work Flow Error Handling, alerts and monitoring","title":"Managed File Transfer"},{"location":"managed_file_transfer/#introduction","text":"RoboMQ MFT service allows you to transfer files between file systems using variety of file transfer protocols. The Managed File Transfer platform is built on the strength of RoboMQ Message Oriented Middleware(MOM)providing guarantee delivery reliable data transfer. It utilizes the RoboMQ broker for receiving and tracking events identifying each steps of transfer and in-transit transformation. In addition to regular MFT functionality, you get following silent advantages while using RoboMQ. Support for all file transfer protocols End to end tracking for the file transfers and transformations Ability to break files into messages and integrating the data with APIa. This approach offers integration with non-file based APIs and systems Microservices based approach for data transformation, enrichments and validation Robust error handling, monitoring, alerts and Error Analytics","title":"Introduction"},{"location":"managed_file_transfer/#setup-and-configuration","text":"The MFT service needs to talk to your RoboMQ tenant, therefore you will need to provide your vhost or tenant ID , username , password and your preference for secure transfer over ssl . To transfer files from one location to another, MFT service requires access to four folders, let's call them upload , inbound , outbound and destination (you can use any name you want): \u251c\u2500\u2500 destination \u2502 \u251c\u2500\u2500 archive \u2502 \u2514\u2500\u2500 error \u251c\u2500\u2500 inbound \u2502 \u251c\u2500\u2500 archive \u2502 \u2514\u2500\u2500 error \u251c\u2500\u2500 outbound \u2502 \u251c\u2500\u2500 archive \u2502 \u2514\u2500\u2500 error \u2514\u2500\u2500 upload \u251c\u2500\u2500 archive \u2514\u2500\u2500 error Those folders don't need to be under the same directory. Actually they can and often do reside on different servers, file systems or S3 buckets . Note that you will need to provide credential of the accounts for accessing those file systems and make sure those accounts have read and write permissions on the above specific folders. In case that you need some files under those folders but don't want them to be transferred, you can configure a filter to ignore files with names that match a certain pattern. At this point, the MFT service configured and is ready to work.","title":"Setup and configuration"},{"location":"managed_file_transfer/#work-flow","text":"The following picture depicts a typical MFT file transfer flow. Fig 1: High level schematic of a file transfer flow MFT has a file listener, it scans the upload folder on a configurable interval. Once a expected file detected, it will be copied to one or more inbound folders (multiple MFT services can work together in case the file needs to be duplicated and processed at multiple destinations). If file requires specific validation or transformation, an optional MFT Microservice can perform transformation, validation or data enrichment on the file in the inbound folder. After successfully processing the file, this component moves file to outbound folder. Finally another MFT Microservice will pick it up from outbound folder and put it into destination . Note that just like with any integration with RoboMQ there could be a whole chain of Microservices performing variety of functions including transformation, validation, data enrichment or application of any business logic while file is in transit from source to the destination. At each step of the processing, the original successfully processed files are archived in corresponding archive folder.","title":"Work Flow"},{"location":"managed_file_transfer/#error-handling-alerts-and-monitoring","text":"Upon any failure at any point, the current file will be moved to corresponding error folder. At this point RoboMQ error handling process kicks in which is robust and has multiple options for tactical as well as strategic handling of error case. An error message (includes file information) will be sent to an error queue and an notification message (describes what is the error and how it happened) will be sent to an notification queue. A SMS, an email or a phone call could be triggered to the operations team or the responsible party based on setup of the severity rules and notification mechanism A ticket or a case can be created in any of the case management platform being used like serviceNow, Jira, Salesforce or any other All the errors are saved into a real-time database which provides a analytical dashboard view of the errors for long term trends, root cause analysis and corrective actions Fig 1: Error Analytics dashboard for analysis and corrective actions","title":"Error Handling, alerts and monitoring"},{"location":"one-one/","text":"One to One (Direct) For one to one messaging, a producer sends messages to specified queue. A consumer receives messages from that queue. To ensure message is not lost, message acknowledgments can be sent back to producer to confirm a particular message has been received. Browse the chapter of AMQP Introduction first if you're new to AMQP. Python Prerequisites Python client AMQP library The Python library we use for this example can be found at https://github.com/pika/pika . You can install it through sudo pip install pika . Finally, import this library in your program. import pika The full documentation of this library is at https://pika.readthedocs.org/en/0.9.14/ . pika library is not thread safe. Do not use a connection or channel across threads. Producer The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. credentials = pika.PlainCredentials(username, password) connection = pika.BlockingConnection(pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60)) channel = connection.channel() Then producer can publish messages to the default exchange where queue name itself is the routing key. It will assign a blank string to exchange parameter in publish function to use the default exchange. Delivery mode = 1 means it's a non-persistent message. properties = pika.spec.BasicProperties(content_type = \"text/plain\", delivery_mode = 1) channel.basic_publish(exchange = \"\", routing_key = routingKey, body = \"Hello World!\", properties = properties) At last, producer will disconnect with the RoboMQ broker. connection.close() Consumer The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a queue. By default, the queue will be bound to the default exchange with the same binding key as its name. Auto-delete means after all consumers have finished consuming it, the queue will be deleted by broker. channel.queue_declare(queue = queueName, auto_delete = True) Finally, consumer can consume messages from the queue. The no_ack parameter indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, no_ack equals to true, so producer does not explicitly acknowledge received messages. The start_consuming() function will be blocking the process until stop_consuming() is invoked or exception happens. channel.basic_consume(consumer_callback = onMessage, queue = queueName, no_ack = True) channel.start_consuming() When messages are received, a callback function onMessage() will be invoked to print the message content. def onMessage(channel, method, properties, body): print body Putting it all together producer.py import pika server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" routingKey = \"testQ\" try: #connect credentials = pika.PlainCredentials(username, password) connection = pika.BlockingConnection(pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60)) channel = connection.channel() #send message #assigning blank string to exchange is to use the default exchange, where queue name is the routing key properties = pika.spec.BasicProperties(content_type = \"text/plain\", delivery_mode = 1) channel.basic_publish(exchange = \"\", routing_key = routingKey, body = \"Hello World!\", properties = properties) #disconnect connection.close() except Exception, e: print e consumer.py import pika import time server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" queueName = \"testQ\" #callback funtion on receiving messages def onMessage(channel, method, properties, body): print body while True: try: #connect credentials = pika.PlainCredentials(username, password) connection = pika.BlockingConnection(pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60)) channel = connection.channel() #declare queue and consume messages #one-to-one messaging uses the default exchange, where queue name is the routing key channel.queue_declare(queue = queueName, auto_delete = True) channel.basic_consume(consumer_callback = onMessage, queue = queueName, no_ack = True) channel.start_consuming() except Exception, e: #reconnect on exception print \"Exception handled, reconnecting...\\nDetail:\\n%s\" % e try: connection.close() except: pass time.sleep(5) Node.js Prerequisites Node.js client AMQP library The Node.js library we use for this example can be found at https://github.com/squaremo/amqp.node . You can install the library through sudo npm install amqplib . Finally, require this library in your program. var amqp = require(\"amqplib\"); The full documentation of this library is at https://www.squaremobius.net/amqp.node/doc/channel_api.html . Producer The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. As shown in the code, this library provides chainable callback API in the form of .then(callback) . For the default vhost \"/\", you will need to insert \"%2f\" (its hexadecimal ASCII code) to the AMQP URI, instead of \"/\" itself. producer = amqp.connect(\"amqp://\" + username + \":\" + password + \"@\" + server + \":\" + port + \"/\" + vhost + \"?heartbeat=60\"); producer.then(function(conn) { return conn.createConfirmChannel().then(successCallback); }).then(null, failureCallback); Then producer can publish messages to the default exchange where queue name itself is the routing key. It will assign a blank string to exchange parameter in publish function to use the default exchange. Delivery mode = 1 means it's a non-persistent message. ch.publish(\"\", routingKey, content = new Buffer(\"Hello World!\"), options = {contentType: \"text/plain\", deliveryMode: 1}, callback); At last, producer will disconnect with the RoboMQ broker. conn.close(); Consumer The same as producer, consumer needs to first connect to RoboMQ broker. The difference is that consumer uses conn.createChannel() function, while producer uses conn.createConfirmChannel() because the latter one is only useful for publish confirm. Then consumer will declare a queue. By default, the queue will be bound to the default exchange with the same binding key as its name. Durable means the queue will survive possible broker failover. It's false in this example. Auto-delete means after all consumers have finished consuming it, the queue will be deleted by broker. Exclusive means no other consumer can consume the queue when this one is consuming it. It's false in this example. ch.assertQueue(queueName, {durable: false, autoDelete: true, exclusive: false}); Finally, consumer can consume messages from the queue. The noAck option indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, noAck is true, so producer does not explicitly acknowledge received messages. The second parameter of consume() function is the callback on receiving messages. In this example, when messages are received, the callback function will be invoked to print the message content. ch.consume(queueName, function(message) { console.log(message.content.toString()); }, {noAck: true}); Putting it all together producer.js var amqp = require(\"amqplib\"); var server = \"hostname\"; var port = \"5672\"; var vhost = \"yourvhost\"; //for \"/\" vhost, use \"%2f\" instead var username = \"username\"; var password = \"password\"; var routingKey = \"testQ\"; producer = amqp.connect(\"amqp://\" + username + \":\" + password + \"@\" + server + \":\" + port + \"/\" + vhost + \"?heartbeat=60\"); producer.then(function(conn) { return conn.createConfirmChannel().then(function(ch) { //assigning blank string to exchange is to use the default exchange, where queue name is the routing key ch.publish(\"\", routingKey, content = new Buffer(\"Hello World!\"), options = {contentType: \"text/plain\", deliveryMode: 1}, function(err, ok) { if (err != null) { console.error(\"Error: failed to send message\\n\" + err); } conn.close(); }); }); }).then(null, function(err) { console.error(err); }); consumer.js var amqp = require(\"amqplib\"); var domain = require(\"domain\"); var server = \"hostname\"; var port = \"5672\"; var vhost = \"yourvhost\"; //for \"/\" vhost, use \"%2f\" instead var username = \"username\"; var password = \"password\"; var queueName = \"testQ\"; //use domain module to handle reconnecting var consumer = null; var dom = domain.create(); dom.on(\"error\", relisten); dom.run(listen); function listen() { consumer = amqp.connect(\"amqp://\" + username + \":\" + password + \"@\" + server + \":\" + port + \"/\" + vhost + \"?heartbeat=60\"); consumer.then(function(conn) { return conn.createChannel().then(function(ch) { //one-to-one messaging uses the default exchange, where queue name is the routing key ch.assertQueue(queueName, {durable: false, autoDelete: true, exclusive: false}); ch.consume(queueName, function(message) { //callback funtion on receiving messages console.log(message.content.toString()); }, {noAck: true}); }); }).then(null, function(err) { console.error(\"Exception handled, reconnecting...\\nDetail:\\n\" + err); setTimeout(listen, 5000); }); } function relisten() { consumer.then(function(conn) { conn.close(); }); setTimeout(listen, 5000); } PHP Prerequisite PHP client AMQP library The PHP library we use for this example can be found at https://github.com/videlalvaro/php-amqplib . It uses composer to install in a few steps. Add a composer.json file to your project: { \"require\": { \"videlalvaro/php-amqplib\": \"2.2.*\" } } Download the latest composer in the same path: curl -sS https://getcomposer.org/installer | php Install the library through composer: ./composer.phar install Finally, require this library in your program and use the classes. require_once __DIR__ . '/../vendor/autoload.php'; //directory of library folder use PhpAmqpLib\\Connection\\AMQPConnection; use PhpAmqpLib\\Message\\AMQPMessage; Producer The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. $connection = new AMQPConnection($server, $port, $username, $password, $vhost, $heartbeat = 60); $channel = $connection->channel(); Then producer can publish messages to the default exchange where queue name itself is the routing key. It will assign a blank string to exchange parameter in publish function to use the default exchange. Delivery mode = 1 means it's a non-persistent message. $message = new AMQPMessage(\"Hello World!\", array(\"content_type\" => \"text/plain\", \"delivery_mode\" => 1)); $channel->basic_publish($message, $exchange = \"\", $routingKey); At last, producer will disconnect with the RoboMQ broker. $connection->close(); Consumer The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a queue. By default, the queue will be bound to the default exchange with the same binding key as its name. Auto-delete means after all consumers have finished consuming it, the queue will be deleted by broker. $channel->queue_declare($queueName, false, false, false, $auto_delete = true); Finally, consumer can consume messages from the queue. The no_ack parameter indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, no_ack equals to true, so producer does not explicitly acknowledge received messages. The while loop will be blocking the process and listening for messages until exception happens. $channel->basic_consume($queueName, \"\", false, $no_ack = true, false, false, $callback = $onMessage); while(count($channel->callbacks)) { $channel->wait(); } When messages are received, a callback function will be invoked to print the message content. $onMessage = function ($message) { echo $message->body.PHP_EOL; }; Putting it together producer.php <?php require_once __DIR__ . '/../vendor/autoload.php'; //directory of library folder use PhpAmqpLib\\Connection\\AMQPConnection; use PhpAmqpLib\\Message\\AMQPMessage; $server = \"hostname\"; $port = 5672; $vhost = \"yourvhost\"; $username = \"username\"; $password = \"password\"; $routingKey = \"testQ\"; try { //connect $connection = new AMQPConnection($server, $port, $username, $password, $vhost, $heartbeat = 60); $channel = $connection->channel(); //send message //assigning blank string to exchange is to use the default exchange, where queue name is the routing key $message = new AMQPMessage(\"Hello World!\", array(\"content_type\" => \"text/plain\", \"delivery_mode\" => 1)); $channel->basic_publish($message, $exchange = \"\", $routingKey); //disconnect $connection->close(); } catch(Exception $e) { echo $e.PHP_EOL; } ?> consumer.php <?php require_once __DIR__.\"/../vendor/autoload.php\"; //directory of library folder use PhpAmqpLib\\Connection\\AMQPConnection; $server = \"hostname\"; $port = 5672; $vhost = \"yourvhost\"; $username = \"username\"; $password = \"password\"; $queueName = \"testQ\"; //callback funtion on receiving messages $onMessage = function ($message) { echo $message->body.PHP_EOL; }; while (true) { try { //connect $connection = new AMQPConnection($server, $port, $username, $password, $vhost, $heartbeat = 60); $channel = $connection->channel(); //declare queue and consume messages //one-to-one messaging uses the default exchange, where queue name is the routing key $channel->queue_declare($queueName, false, false, false, $auto_delete = true); $channel->basic_consume($queueName, \"\", false, $no_ack = true, false, false, $callback = $onMessage); //start consuming while(count($channel->callbacks)) { $channel->wait(); } } catch(Exception $e) { //reconnect on exception echo \"Exception handled, reconnecting...\\nDetail:\\n\".$e.PHP_EOL; if ($connection != null) { try { $connection->close(); } catch (Exception $e1) {} } sleep(5); } } ?> Ruby Prerequisites Ruby client AMQP library The Ruby library we use for this example can be found at http://rubybunny.info/ . With Ruby version >= 2.0, you can install it through sudo gem install bunny . Finally, import this library in your program. require \"bunny\" The full documentation of this library is at http://rubybunny.info/articles/guides.html . We recommend combining the documentation with the source code of this library when you use it because some of the documentation out there is not being updated timely from our observation. Producer The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. Although the library provides a connection property named recover_from_connection_close , we discourage you to use it. The reason will be explained in the Consumer section. connection = Bunny.new(:host => server, :port => port, :vhost => vhost, :user => username, :pass => password, :heartbeat => 60, :recover_from_connection_close => false) connection.start channel = connection.create_channel Then producer can publish messages to the default exchange where queue name itself is the routing key. Delivery mode = 1 means it's a non-persistent message. exchange = channel.default_exchange exchange.publish(\"Hello World!\", :routing_key => routingKey, :content_type => \"text/plain\", :delivery_mode => 1) At last, producer will disconnect with the RoboMQ broker. connection.close Consumer The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a queue. By default, the queue will be bound to the default exchange with the same binding key as its name. Auto-delete means after all consumers have finished consuming it, the queue will be deleted by broker. queue = channel.queue(queueName, :auto_delete => true) After that, consumer can consume messages from the queue. The manual_ack parameter indicates if consumer needs to manually send acknowledgment back to broker when it has received the message. In this example, manual_ack equals to false, so producer does not manually acknowledge received messages. The subscribe() function is followed by a callback which will be invoked to print the message payload on receiving a message. queue.subscribe(:block => false, :manual_ack => false) do |delivery_info, metadata, payload| puts payload end As we mentioned in the Producer section, recover_from_connection_close is set to false when connecting to RoboMQ broker. It matters for consumers because recover_from_connection_close will only recover the connection, it won't recreate exchange and queue in case they are gone. Therefore, a more robust approach is letting your code handle reconnecting on its own and keep checking the existence of the subscribed queue. while true raise \"Lost the subscribed queue %s\" % queueName unless connection.queue_exists?(queueName) sleep 1 end Putting it all together producer.rb require \"bunny\" server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" routingKey = \"testQ\" begin #connect connection = Bunny.new(:host => server, :port => port, :vhost => vhost, :user => username, :pass => password, :heartbeat => 60, :recover_from_connection_close => false) connection.start channel = connection.create_channel #send message #assigning blank string to exchange is to use the default exchange, where queue name is the routing key exchange = channel.default_exchange exchange.publish(\"Hello World!\", :routing_key => routingKey, :content_type => \"text/plain\", :delivery_mode => 1) #disconnect connection.close rescue Exception => e puts e end consumer.rb require \"bunny\" server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" queueName = \"testQ\" while true begin #connect, disable auto-reconnect so as to manually reconnect connection = Bunny.new(:host => server, :port => port, :vhost => vhost, :user => username, :pass => password, :heartbeat => 60, :recover_from_connection_close => false) connection.start channel = connection.create_channel #declare queue and consume messages #one-to-one messaging uses the default exchange, where queue name is the routing key queue = channel.queue(queueName, :auto_delete => true) queue.subscribe(:block => false, :manual_ack => false) do |delivery_info, metadata, payload| puts payload end #keep checking the existence of the subscribed queue while true raise \"Lost the subscribed queue %s\" % queueName unless connection.queue_exists?(queueName) sleep 1 end rescue Exception => e #reconnect on exception puts \"Exception handled, reconnecting...\\nDetail:\\n%s\" % e #blindly clean old connection begin connection.close end sleep 5 end end Java Prerequisites Java client AMQP library The Java library we use for this example can be found at https://www.rabbitmq.com/java-client.html . Download the library jar file, then import this library in your program import com.rabbitmq.client.*; and compile your source code with the jar file. For example, javac -cp \".:./rabbitmq-client.jar\" Producer.java Consumer.java Run the producer and consumer classes. For example, java -cp \".:./rabbitmq-client.jar\" Consumer java -cp \".:./rabbitmq-client.jar\" Producer Of course, you can eventually compress your producer and consumer classes into jar files. Producer The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. ConnectionFactory factory = new ConnectionFactory(); factory.setHost(server); factory.setPort(port); factory.setVirtualHost(vhost); factory.setUsername(username); factory.setPassword(password); factory.setRequestedHeartbeat(60); connection = factory.newConnection(); channel = connection.createChannel(); Then producer can publish messages to the default exchange where queue name itself is the routing key. It will assign a blank string to exchange parameter in publish function to use the default exchange. String message = \"Hello World!\"; channel.basicPublish(\"\", routingKey, MessageProperties.TEXT_PLAIN, message.getBytes()); At last, producer will disconnect with the RoboMQ broker. connection.close(); Consumer The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a queue. By default, the queue will be bound to the default exchange with the same binding key as its name. The fourth parameter auto-delete is true. That means after all consumers have finished consuming it, the queue will be deleted by broker. channel.queueDeclare(queueName, false, false, true, null); Finally, consumer can consume messages from the queue. The second parameter of basicConsume() function no-ack indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, no-ack equals to true, so producer does not explicitly acknowledge received messages. The while loop will be blocking the process and listening for messages until exception happens. When messages are received, it will print the message content. QueueingConsumer qc = new QueueingConsumer(channel); channel.basicConsume(queueName, true, qc); while (true) { QueueingConsumer.Delivery delivery = qc.nextDelivery(); String message = new String(delivery.getBody()); System.out.println(message); } Putting it all together Producer.java import com.rabbitmq.client.ConnectionFactory; import com.rabbitmq.client.Connection; import com.rabbitmq.client.Channel; import com.rabbitmq.client.MessageProperties; public class Producer { private Connection connection; private Channel channel; private static String server = \"hostname\"; private static int port = 5672; private static String vhost = \"yourvhost\"; private static String username = \"username\"; private static String password = \"password\"; private static String routingKey = \"testQ\"; private void produce() { try { //connect ConnectionFactory factory = new ConnectionFactory(); factory.setHost(server); factory.setPort(port); factory.setVirtualHost(vhost); factory.setUsername(username); factory.setPassword(password); factory.setRequestedHeartbeat(60); connection = factory.newConnection(); channel = connection.createChannel(); //send message String message = \"Hello World!\"; //assigning blank string to exchange is to use the default exchange, where queue name is the routing key channel.basicPublish(\"\", routingKey, MessageProperties.TEXT_PLAIN, message.getBytes()); //disconnect connection.close(); } catch(Exception e) { System.out.println(e); System.exit(-1); } } public static void main(String[] args) { Producer p = new Producer(); p.produce(); } } Consumer.java import com.rabbitmq.client.ConnectionFactory; import com.rabbitmq.client.Connection; import com.rabbitmq.client.Channel; import com.rabbitmq.client.QueueingConsumer; public class Consumer { private Connection connection; private Channel channel; private static String server = \"hostname\"; private static int port = 5672; private static String vhost = \"yourvhost\"; private static String username = \"username\"; private static String password = \"password\"; private static String queueName = \"testQ\"; private void consume() { while (true) { try { //connect ConnectionFactory factory = new ConnectionFactory(); factory.setHost(server); factory.setPort(port); factory.setVirtualHost(vhost); factory.setUsername(username); factory.setPassword(password); factory.setRequestedHeartbeat(60); connection = factory.newConnection(); channel = connection.createChannel(); //declare queue and consume messages //one-to-one messaging uses the default exchange, where queue name is the routing key channel.queueDeclare(queueName, false, false, true, null); QueueingConsumer qc = new QueueingConsumer(channel); channel.basicConsume(queueName, true, qc); while (true) { QueueingConsumer.Delivery delivery = qc.nextDelivery(); String message = new String(delivery.getBody()); System.out.println(message); } } catch(Exception e) { //reconnect on exception System.out.printf(\"Exception handled, reconnecting...\\nDetail:\\n%s\\n\", e); try { connection.close(); } catch (Exception e1) {} try { Thread.sleep(5000); } catch(Exception e2) {} } } } public static void main(String[] args) { Consumer c = new Consumer(); c.consume(); } } Go Prerequisites Go client AMQP library The Go library we use for this example can be found at https://github.com/streadway/amqp . You can install it through go get github.com/streadway/amqp . Finally, import this library in your program. import \"github.com/streadway/amqp\" The full documentation of this library is at https://godoc.org/github.com/streadway/amqp . Producer The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. connection, err := amqp.DialConfig(fmt.Sprintf(\"amqp://%s:%s@%s:%d/%s\", username, password, server, port, vhost), amqp.Config{Heartbeat: 60 * time.Second}) channel, err := connection.Channel() Then producer can publish messages to the default exchange where queue name itself is the routing key. It will assign a blank string to exchange parameter in publish function to use the default exchange. Delivery mode = 1 means it's a non-persistent message. err = channel.Publish(\"\", routingKey, false, false, amqp.Publishing{ContentType: \"text/plain\", DeliveryMode: 1, Body: []byte(\"Hello World!\")}) At last, producer will disconnect with the RoboMQ broker. connection.Close() Consumer The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a queue. By default, the queue will be bound to the default exchange with the same binding key as its name. Durable means the exchange or queue will survive possible broker failover. It's false in this example. Auto-delete means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. Exclusive means no other consumer can consume the queue when this one is consuming it. // durable = false; auto-delete = true; exclusive = false queue, err := channel.QueueDeclare(queueName, false, true, false, false, nil) Finally, consumer can consume messages from the queue. Consumer-tag can be later used to Cancel() this consumer when it's no longer needed. Auto-ack parameter indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, auto-ack equals to true, so producer does not explicitly acknowledge received messages. // consumer-tag = \"consumer\"; auto-ack = true messageChan, err := channel.Consume(queue.Name, \"consumer\", true, false, false, false, nil) Note a message channel is returned by the Consume() function. Incoming messages will be received through that channel. Channel in Golang is a typed conduit through which you can send and receive values. Sends and receives block until the other side is ready. for message := range messageChan { fmt.Println(string(message.Body)) } Putting it all together producer.go package main import ( \"fmt\" \"github.com/streadway/amqp\" \"os\" \"time\" ) var server = \"hostname\" var port = 5672 var vhost = \"yourvhost\" var username = \"username\" var password = \"password\" var routingKey = \"testQ\" func main() { connection, err := amqp.DialConfig(fmt.Sprintf(\"amqp://%s:%s@%s:%d/%s\", username, password, server, port, vhost), amqp.Config{Heartbeat: 60 * time.Second}) if err != nil { fmt.Printf(\"Failed to connect, err: %v\\n\", err) os.Exit(1) } defer connection.Close() channel, err := connection.Channel() if err != nil { fmt.Printf(\"Failed to create channel, err: %v\\n\", err) os.Exit(1) } defer channel.Close() err = channel.Publish( // assigning blank string to exchange is to use the default exchange, where queue name is the routing key \"\", // exchange routingKey, // routing key false, // mandatory false, // immediate amqp.Publishing{ ContentType: \"text/plain\", DeliveryMode: 1, Body: []byte(\"Hello World!\"), }) if err != nil { fmt.Printf(\"Failed to publish message, err: %v\\n\", err) os.Exit(1) } } consumer.go package main import ( \"fmt\" \"github.com/streadway/amqp\" \"time\" ) var server = \"hostname\" var port = 5672 var vhost = \"yourvhost\" var username = \"username\" var password = \"password\" var queueName = \"testQ\" func main() { // Infinite loop to auto-reconnect on failure Loop: for { fmt.Println(\"Starting in 5 seconds...\") time.Sleep(5 * time.Second) connection, err := amqp.DialConfig(fmt.Sprintf(\"amqp://%s:%s@%s:%d/%s\", username, password, server, port, vhost), amqp.Config{Heartbeat: 60 * time.Second}) if err != nil { fmt.Printf(\"Failed to connect, err: %v\\n\", err) continue Loop } defer connection.Close() channel, err := connection.Channel() if err != nil { fmt.Printf(\"Failed to create channel, err: %v\\n\", err) continue Loop } defer channel.Close() // one-to-one messaging uses the default exchange, where queue name is the routing key queue, err := channel.QueueDeclare( queueName, // name false, // durable true, // auto-delete false, // exclusive false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to declare queue, err: %v\\n\", err) continue Loop } messageChan, err := channel.Consume( queue.Name, // queue \"consumer\", // consumer tag true, // auto-ack false, // exclusive false, // no-local false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to consume messages, err: %v\\n\", err) continue Loop } fmt.Println(\"Started consuming messages.\") for message := range messageChan { fmt.Println(string(message.Body)) } } } C Prerequisites C client AMQP library robomq.io is built on AMQP, an open, general-purpose protocol for messaging. There are a number of clients for AMQP in many different languages. However, we'll choose a simple C-language AMQP client library written for use with v2.0+ of the RabbitMQ broker. https://github.com/alanxz/rabbitmq-c/tree/master/librabbitmq You can copy librabbitmq subfolder from latest release located here on GitHub: https://github.com/alanxz/rabbitmq-c Alternatively, thanks to Subversion support in GitHub, you can use svn export directly: svn export https://github.com/alanxz/rabbitmq-c/trunk/librabbitmq Copy the librabbitmq package into your working directory: cp librabbitmq ./ Also copy all source files and Makefile from RoboMQ SDK at https://github.com/robomq/robomq.io/tree/master/sdk/AMQP/C into the same directory. Now your working directory should have the content as bellow: broadcast config.h librabbitmq Makefile one-to-one request-reply routing-key topic Use the Makefile to compile under a Linux terminal. Run make type={sub-directory} to compile the producer and consumer under the sub-directory. Before compiling the next sub-directory, run make clean to clean up the compiled files. Note that these examples provide a simple client implementation to get started but does not go into detailed description of all flags passed into the AMQP methods. A complete reference to RabbitMQ's implementaton of version 0-9-1 of the AMQP specification can be found in this guide. https://www.rabbitmq.com/amqp-0-9-1-reference.html Producer First, producer should initialize a connection to the RoboMQ server. amqp_connection_state_t conn = amqp_new_connection(); amqp_socket_t *socket = NULL; char hostname[] = \"hostname\"; // RoboMQ hostname int port = 5672; //default char user[] = \"username\"; // RoboMQ username char password[] = \"password\"; // RoboMQ password char vhost[] = \"vhost\"; // RoboMQ account vhost amqp_channel_t channel = 1; int channel_max = 0; int frame_max = 131072; int heartbeat = 60; int status = 0; // Opening socket socket = amqp_tcp_socket_new(conn); status = amqp_socket_open(socket, hostname, port); if (status) { printf(\"Error opening TCP socket, status = %d, exiting.\", status); } amqp_login(conn, vhost, channel_max, frame_max, heartbeat, AMQP_SASL_METHOD_PLAIN, user, password); amqp_channel_open(conn, channel); Then, producer should publish messages to the specified exchange attached with routing key. If not specified, that routing key is the queue name. Based on that routing key, messages will be sent through the exchange and distributed to the right queue. amqp_basic_properties_t props; props._flags = AMQP_BASIC_CONTENT_TYPE_FLAG | AMQP_BASIC_DELIVERY_MODE_FLAG; props.content_type = amqp_cstring_bytes(\"text/plain\"); props.delivery_mode = 1; /* non-persistent delivery mode */ amqp_boolean_t mandatory = 0; amqp_boolean_t immediate = 0; char exchange_name[] = \"hello-exchange\"; char routing_key[] = \"hola\"; int result; // Sending message result = amqp_basic_publish(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(routing_key), mandatory, immediate, &props, amqp_cstring_bytes(\"Hello\")); Finally, after all messaged are produced, producer should terminate this connection. amqp_channel_close(conn, channel, AMQP_REPLY_SUCCESS); amqp_connection_close(conn, AMQP_REPLY_SUCCESS); amqp_destroy_connection(conn); Consumer First, consumer should initialize connection to the RoboMQ server. amqp_connection_state_t conn = amqp_new_connection(); amqp_socket_t *socket = NULL; char hostname[] = \"hostname\"; // RoboMQ hostname int port = 5672; //default char user[] = \"username\"; // RoboMQ username char password[] = \"password\"; // RoboMQ password char vhost[] = \"vhost\"; // RoboMQ account vhost amqp_channel_t channel = 1; int channel_max = 0; int frame_max = 131072; int heartbeat = 60; int status = 0; // Opening socket socket = amqp_tcp_socket_new(conn); status = amqp_socket_open(socket, hostname, port); if (status) { printf(\"Error opening TCP socket, status = %d, exiting.\", status); } amqp_login(conn, vhost, channel_max, frame_max, heartbeat, AMQP_SASL_METHOD_PLAIN, user, password); amqp_channel_open(conn, channel); Then consumer should create a queue and subscribe to a queue. This queue will work as a mailbox where all messages published to it will be stored until they are consumed. The direct exchange type is specified below in exchange_type definition. amqp_bytes_t queue; amqp_channel_t channel = 1; amqp_boolean_t passive = 0; amqp_boolean_t durable = 0; amqp_boolean_t exclusive = 0; amqp_boolean_t auto_delete = 1; amqp_boolean_t internal = 0; char exchange_name[] = \"hello-exchange\"; char exchange_type[] = \"direct\"; char queue_name[] = \"hello-queue\"; char binding_key[] = \"hola\"; // Declaring exchange amqp_exchange_declare(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(exchange_type), passive, durable, auto_delete, internal, amqp_empty_table); if(amqp_get_rpc_reply(conn).reply_type != AMQP_RESPONSE_NORMAL) { printf(\"Error declaring exchange: %d\\n\", amqp_get_rpc_reply(conn)); exit(1); } // Declaring queue amqp_queue_declare_ok_t *r = amqp_queue_declare(conn, channel, amqp_cstring_bytes(queue_name), passive, durable, exclusive, auto_delete, amqp_empty_table); if(amqp_get_rpc_reply(conn).reply_type != AMQP_RESPONSE_NORMAL) { printf(\"Error declaring queue: %d\\n\", amqp_get_rpc_reply(conn)); exit(1); } queue = amqp_bytes_malloc_dup(r->queue); // Binding to queue amqp_queue_bind(conn, channel, queue, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(binding_key), amqp_empty_table); Note that all the queues declared without specific binding key use the queue name as the default binding key. At this point, consumer should start consuming messages. The no_ack parameter indicates whether consumer will automatically send acknowledgment back to broker. For this example, producer does not explicitly acknowledge received messages. Therefore, we set no_ack attribute value as true. Then, consumer should receive messages and implement any desired processing on message contents. amqp_boolean_t no_local = 0; amqp_boolean_t no_ack = 1; amqp_boolean_t exclusive = 0; amqp_frame_t frame; // Consuming the message amqp_basic_consume(conn, channel, queue, amqp_empty_bytes, no_local, no_ack, exclusive, amqp_empty_table); amqp_rpc_reply_t result; amqp_envelope_t envelope; amqp_maybe_release_buffers(conn); result = amqp_consume_message(conn, &envelope, NULL, 0); if (AMQP_RESPONSE_NORMAL == result.reply_type) { printf(\"Received message size: %d\\nbody: %s\\n\", (int)envelope.message.body.len, (char *)envelope.message.body.bytes); amqp_destroy_envelope(&envelope); } Putting it all together The full code below includes some basic AMQP error handling for consumer that is useful when declaring exchanges and queues. In addition, main receiver loop attempts to reconnect upon network connection failure. producer.c #include <stdlib.h> #include <stdio.h> #include <string.h> #include <amqp_tcp_socket.h> #include <amqp.h> #include <amqp_framing.h> amqp_connection_state_t mqconnect() { amqp_connection_state_t conn = amqp_new_connection(); amqp_socket_t *socket = NULL; char hostname[] = \"localhost\"; // RoboMQ hostname int port = 5672; //default char user[] = \"guest\"; // RoboMQ username char password[] = \"guest\"; // RoboMQ password char vhost[] = \"/\"; // RoboMQ account vhost amqp_channel_t channel = 1; int channel_max = 0; int frame_max = 131072; int heartbeat = 60; int status = 0; // Opening socket socket = amqp_tcp_socket_new(conn); status = amqp_socket_open(socket, hostname, port); if (status) { printf(\"Error opening TCP socket, status = %d, exiting.\", status); } amqp_login(conn, vhost, channel_max, frame_max, heartbeat, AMQP_SASL_METHOD_PLAIN, user, password); amqp_channel_open(conn, channel); return conn; } int main(int argc, char const *const *argv) { amqp_connection_state_t conn; amqp_channel_t channel = 1; amqp_basic_properties_t props; props._flags = AMQP_BASIC_CONTENT_TYPE_FLAG | AMQP_BASIC_DELIVERY_MODE_FLAG; props.content_type = amqp_cstring_bytes(\"text/plain\"); props.delivery_mode = 1; /* non-persistent delivery mode */ amqp_boolean_t mandatory = 0; amqp_boolean_t immediate = 0; char exchange_name[] = \"hello-exchange\"; char routing_key[] = \"hola\"; char *msg_body = \"Hello\\n\"; int result; conn = mqconnect(); // Sending message result = amqp_basic_publish(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(routing_key), mandatory, immediate, &props, amqp_cstring_bytes(msg_body)); if (AMQP_RESPONSE_NONE != result) { printf(\"Producer AMQP failure occurred, response code = %d\\n\", result); } // Closing connection amqp_connection_close(conn, AMQP_REPLY_SUCCESS); amqp_destroy_connection(conn); return 0; } consumer.c #include <stdlib.h> #include <stdio.h> #include <string.h> #include <amqp_tcp_socket.h> #include <amqp.h> #include <amqp_framing.h> amqp_connection_state_t mqconnect() { amqp_connection_state_t conn = amqp_new_connection(); amqp_socket_t *socket = NULL; char hostname[] = \"localhost\"; // RoboMQ hostname int port = 5672; //default char user[] = \"guest\"; // RoboMQ username char password[] = \"guest\"; // RoboMQ password char vhost[] = \"/\"; // RoboMQ account vhost amqp_channel_t channel = 1; amqp_rpc_reply_t reply; int channel_max = 0; int frame_max = 131072; int heartbeat = 60; int status = 0; // Opening socket socket = amqp_tcp_socket_new(conn); status = amqp_socket_open(socket, hostname, port); if (status) { printf(\"Error opening TCP socket, status = %d\\n\", status); } reply = amqp_login(conn, vhost, channel_max, frame_max, heartbeat, AMQP_SASL_METHOD_PLAIN, user, password); if(reply.reply_type != AMQP_RESPONSE_NORMAL) { fprintf(stderr, \"%s: server connection reply code: %d\\n\", \"Error logging in\", reply.reply_type); } amqp_channel_open(conn, channel); return conn; } amqp_bytes_t mqdeclare(amqp_connection_state_t conn, const char *exchange_name, const char *queue_name) { amqp_bytes_t queue; amqp_channel_t channel = 1; amqp_boolean_t passive = 0; amqp_boolean_t durable = 0; amqp_boolean_t exclusive = 0; amqp_boolean_t auto_delete = 1; amqp_boolean_t internal = 0; char exchange_type[] = \"direct\"; char binding_key[] = \"hola\"; amqp_rpc_reply_t reply; // Declaring exchange amqp_exchange_declare(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(exchange_type), passive, durable, auto_delete, internal, amqp_empty_table); reply = amqp_get_rpc_reply(conn); if(reply.reply_type != AMQP_RESPONSE_NORMAL) { amqp_connection_close_t *m = (amqp_connection_close_t *) reply.reply.decoded; if(NULL != m) { fprintf(stderr, \"%s: server connection error %d, message: %.*s\\n\", \"Error declaring exchange\", m->reply_code, (int) m->reply_text.len, (char *) m->reply_text.bytes); } } // Declaring queue amqp_queue_declare_ok_t *r = amqp_queue_declare(conn, channel, amqp_cstring_bytes(queue_name), passive, durable, exclusive, auto_delete, amqp_empty_table); reply = amqp_get_rpc_reply(conn); if(reply.reply_type != AMQP_RESPONSE_NORMAL) { fprintf(stderr, \"%s: server connection reply code: %d\\n\", \"Error declaring queue\", reply.reply_type); } else { queue = amqp_bytes_malloc_dup(r->queue); // Binding to queue amqp_queue_bind(conn, channel, queue, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(binding_key), amqp_empty_table); } return queue; } int main(int argc, char const *const *argv) { amqp_connection_state_t conn; amqp_bytes_t queue; amqp_channel_t channel = 1; amqp_boolean_t no_local = 0; amqp_boolean_t no_ack = 1; amqp_boolean_t exclusive = 0; char exchange_name[] = \"hello-exchange\"; char queue_name[] = \"hello-queue\"; int retry_time = 5; // retry time in seconds conn = mqconnect(); queue = mqdeclare(conn, &exchange_name[0], &queue_name[0]); // Consuming the message amqp_basic_consume(conn, channel, queue, amqp_empty_bytes, no_local, no_ack, exclusive, amqp_empty_table); while (1) { amqp_rpc_reply_t result; amqp_envelope_t envelope; amqp_maybe_release_buffers(conn); result = amqp_consume_message(conn, &envelope, NULL, 0); if (AMQP_RESPONSE_NORMAL != result.reply_type) { printf(\"Consumer AMQP failure occurred, response code = %d, retrying in %d seconds...\\n\", result.reply_type, retry_time); // Closing current connection before reconnecting amqp_connection_close(conn, AMQP_CONNECTION_FORCED); amqp_destroy_connection(conn); // Reconnecting on exception conn = mqconnect(); queue = mqdeclare(conn, &exchange_name[0], &queue_name[0]); amqp_basic_consume(conn, channel, queue, amqp_empty_bytes, no_local, no_ack, exclusive, amqp_empty_table); sleep(retry_time); } else { printf(\"Received message size: %d\\nbody: %s\\n\", (int)envelope.message.body.len, (char *)envelope.message.body.bytes); amqp_destroy_envelope(&envelope); } } return 0; }","title":"One to one (direct) messaging"},{"location":"one-one/#one-to-one-direct","text":"For one to one messaging, a producer sends messages to specified queue. A consumer receives messages from that queue. To ensure message is not lost, message acknowledgments can be sent back to producer to confirm a particular message has been received. Browse the chapter of AMQP Introduction first if you're new to AMQP.","title":"One to One (Direct)"},{"location":"one-one/#python","text":"","title":"Python"},{"location":"one-one/#prerequisites","text":"Python client AMQP library The Python library we use for this example can be found at https://github.com/pika/pika . You can install it through sudo pip install pika . Finally, import this library in your program. import pika The full documentation of this library is at https://pika.readthedocs.org/en/0.9.14/ . pika library is not thread safe. Do not use a connection or channel across threads.","title":"Prerequisites"},{"location":"one-one/#producer","text":"The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. credentials = pika.PlainCredentials(username, password) connection = pika.BlockingConnection(pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60)) channel = connection.channel() Then producer can publish messages to the default exchange where queue name itself is the routing key. It will assign a blank string to exchange parameter in publish function to use the default exchange. Delivery mode = 1 means it's a non-persistent message. properties = pika.spec.BasicProperties(content_type = \"text/plain\", delivery_mode = 1) channel.basic_publish(exchange = \"\", routing_key = routingKey, body = \"Hello World!\", properties = properties) At last, producer will disconnect with the RoboMQ broker. connection.close()","title":"Producer"},{"location":"one-one/#consumer","text":"The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a queue. By default, the queue will be bound to the default exchange with the same binding key as its name. Auto-delete means after all consumers have finished consuming it, the queue will be deleted by broker. channel.queue_declare(queue = queueName, auto_delete = True) Finally, consumer can consume messages from the queue. The no_ack parameter indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, no_ack equals to true, so producer does not explicitly acknowledge received messages. The start_consuming() function will be blocking the process until stop_consuming() is invoked or exception happens. channel.basic_consume(consumer_callback = onMessage, queue = queueName, no_ack = True) channel.start_consuming() When messages are received, a callback function onMessage() will be invoked to print the message content. def onMessage(channel, method, properties, body): print body","title":"Consumer"},{"location":"one-one/#putting-it-all-together","text":"producer.py import pika server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" routingKey = \"testQ\" try: #connect credentials = pika.PlainCredentials(username, password) connection = pika.BlockingConnection(pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60)) channel = connection.channel() #send message #assigning blank string to exchange is to use the default exchange, where queue name is the routing key properties = pika.spec.BasicProperties(content_type = \"text/plain\", delivery_mode = 1) channel.basic_publish(exchange = \"\", routing_key = routingKey, body = \"Hello World!\", properties = properties) #disconnect connection.close() except Exception, e: print e consumer.py import pika import time server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" queueName = \"testQ\" #callback funtion on receiving messages def onMessage(channel, method, properties, body): print body while True: try: #connect credentials = pika.PlainCredentials(username, password) connection = pika.BlockingConnection(pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60)) channel = connection.channel() #declare queue and consume messages #one-to-one messaging uses the default exchange, where queue name is the routing key channel.queue_declare(queue = queueName, auto_delete = True) channel.basic_consume(consumer_callback = onMessage, queue = queueName, no_ack = True) channel.start_consuming() except Exception, e: #reconnect on exception print \"Exception handled, reconnecting...\\nDetail:\\n%s\" % e try: connection.close() except: pass time.sleep(5)","title":"Putting it all together"},{"location":"one-one/#nodejs","text":"","title":"Node.js"},{"location":"one-one/#prerequisites_1","text":"Node.js client AMQP library The Node.js library we use for this example can be found at https://github.com/squaremo/amqp.node . You can install the library through sudo npm install amqplib . Finally, require this library in your program. var amqp = require(\"amqplib\"); The full documentation of this library is at https://www.squaremobius.net/amqp.node/doc/channel_api.html .","title":"Prerequisites"},{"location":"one-one/#producer_1","text":"The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. As shown in the code, this library provides chainable callback API in the form of .then(callback) . For the default vhost \"/\", you will need to insert \"%2f\" (its hexadecimal ASCII code) to the AMQP URI, instead of \"/\" itself. producer = amqp.connect(\"amqp://\" + username + \":\" + password + \"@\" + server + \":\" + port + \"/\" + vhost + \"?heartbeat=60\"); producer.then(function(conn) { return conn.createConfirmChannel().then(successCallback); }).then(null, failureCallback); Then producer can publish messages to the default exchange where queue name itself is the routing key. It will assign a blank string to exchange parameter in publish function to use the default exchange. Delivery mode = 1 means it's a non-persistent message. ch.publish(\"\", routingKey, content = new Buffer(\"Hello World!\"), options = {contentType: \"text/plain\", deliveryMode: 1}, callback); At last, producer will disconnect with the RoboMQ broker. conn.close();","title":"Producer"},{"location":"one-one/#consumer_1","text":"The same as producer, consumer needs to first connect to RoboMQ broker. The difference is that consumer uses conn.createChannel() function, while producer uses conn.createConfirmChannel() because the latter one is only useful for publish confirm. Then consumer will declare a queue. By default, the queue will be bound to the default exchange with the same binding key as its name. Durable means the queue will survive possible broker failover. It's false in this example. Auto-delete means after all consumers have finished consuming it, the queue will be deleted by broker. Exclusive means no other consumer can consume the queue when this one is consuming it. It's false in this example. ch.assertQueue(queueName, {durable: false, autoDelete: true, exclusive: false}); Finally, consumer can consume messages from the queue. The noAck option indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, noAck is true, so producer does not explicitly acknowledge received messages. The second parameter of consume() function is the callback on receiving messages. In this example, when messages are received, the callback function will be invoked to print the message content. ch.consume(queueName, function(message) { console.log(message.content.toString()); }, {noAck: true});","title":"Consumer"},{"location":"one-one/#putting-it-all-together_1","text":"producer.js var amqp = require(\"amqplib\"); var server = \"hostname\"; var port = \"5672\"; var vhost = \"yourvhost\"; //for \"/\" vhost, use \"%2f\" instead var username = \"username\"; var password = \"password\"; var routingKey = \"testQ\"; producer = amqp.connect(\"amqp://\" + username + \":\" + password + \"@\" + server + \":\" + port + \"/\" + vhost + \"?heartbeat=60\"); producer.then(function(conn) { return conn.createConfirmChannel().then(function(ch) { //assigning blank string to exchange is to use the default exchange, where queue name is the routing key ch.publish(\"\", routingKey, content = new Buffer(\"Hello World!\"), options = {contentType: \"text/plain\", deliveryMode: 1}, function(err, ok) { if (err != null) { console.error(\"Error: failed to send message\\n\" + err); } conn.close(); }); }); }).then(null, function(err) { console.error(err); }); consumer.js var amqp = require(\"amqplib\"); var domain = require(\"domain\"); var server = \"hostname\"; var port = \"5672\"; var vhost = \"yourvhost\"; //for \"/\" vhost, use \"%2f\" instead var username = \"username\"; var password = \"password\"; var queueName = \"testQ\"; //use domain module to handle reconnecting var consumer = null; var dom = domain.create(); dom.on(\"error\", relisten); dom.run(listen); function listen() { consumer = amqp.connect(\"amqp://\" + username + \":\" + password + \"@\" + server + \":\" + port + \"/\" + vhost + \"?heartbeat=60\"); consumer.then(function(conn) { return conn.createChannel().then(function(ch) { //one-to-one messaging uses the default exchange, where queue name is the routing key ch.assertQueue(queueName, {durable: false, autoDelete: true, exclusive: false}); ch.consume(queueName, function(message) { //callback funtion on receiving messages console.log(message.content.toString()); }, {noAck: true}); }); }).then(null, function(err) { console.error(\"Exception handled, reconnecting...\\nDetail:\\n\" + err); setTimeout(listen, 5000); }); } function relisten() { consumer.then(function(conn) { conn.close(); }); setTimeout(listen, 5000); }","title":"Putting it all together"},{"location":"one-one/#php","text":"","title":"PHP"},{"location":"one-one/#prerequisite","text":"PHP client AMQP library The PHP library we use for this example can be found at https://github.com/videlalvaro/php-amqplib . It uses composer to install in a few steps. Add a composer.json file to your project: { \"require\": { \"videlalvaro/php-amqplib\": \"2.2.*\" } } Download the latest composer in the same path: curl -sS https://getcomposer.org/installer | php Install the library through composer: ./composer.phar install Finally, require this library in your program and use the classes. require_once __DIR__ . '/../vendor/autoload.php'; //directory of library folder use PhpAmqpLib\\Connection\\AMQPConnection; use PhpAmqpLib\\Message\\AMQPMessage;","title":"Prerequisite"},{"location":"one-one/#producer_2","text":"The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. $connection = new AMQPConnection($server, $port, $username, $password, $vhost, $heartbeat = 60); $channel = $connection->channel(); Then producer can publish messages to the default exchange where queue name itself is the routing key. It will assign a blank string to exchange parameter in publish function to use the default exchange. Delivery mode = 1 means it's a non-persistent message. $message = new AMQPMessage(\"Hello World!\", array(\"content_type\" => \"text/plain\", \"delivery_mode\" => 1)); $channel->basic_publish($message, $exchange = \"\", $routingKey); At last, producer will disconnect with the RoboMQ broker. $connection->close();","title":"Producer"},{"location":"one-one/#consumer_2","text":"The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a queue. By default, the queue will be bound to the default exchange with the same binding key as its name. Auto-delete means after all consumers have finished consuming it, the queue will be deleted by broker. $channel->queue_declare($queueName, false, false, false, $auto_delete = true); Finally, consumer can consume messages from the queue. The no_ack parameter indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, no_ack equals to true, so producer does not explicitly acknowledge received messages. The while loop will be blocking the process and listening for messages until exception happens. $channel->basic_consume($queueName, \"\", false, $no_ack = true, false, false, $callback = $onMessage); while(count($channel->callbacks)) { $channel->wait(); } When messages are received, a callback function will be invoked to print the message content. $onMessage = function ($message) { echo $message->body.PHP_EOL; };","title":"Consumer"},{"location":"one-one/#putting-it-together","text":"producer.php <?php require_once __DIR__ . '/../vendor/autoload.php'; //directory of library folder use PhpAmqpLib\\Connection\\AMQPConnection; use PhpAmqpLib\\Message\\AMQPMessage; $server = \"hostname\"; $port = 5672; $vhost = \"yourvhost\"; $username = \"username\"; $password = \"password\"; $routingKey = \"testQ\"; try { //connect $connection = new AMQPConnection($server, $port, $username, $password, $vhost, $heartbeat = 60); $channel = $connection->channel(); //send message //assigning blank string to exchange is to use the default exchange, where queue name is the routing key $message = new AMQPMessage(\"Hello World!\", array(\"content_type\" => \"text/plain\", \"delivery_mode\" => 1)); $channel->basic_publish($message, $exchange = \"\", $routingKey); //disconnect $connection->close(); } catch(Exception $e) { echo $e.PHP_EOL; } ?> consumer.php <?php require_once __DIR__.\"/../vendor/autoload.php\"; //directory of library folder use PhpAmqpLib\\Connection\\AMQPConnection; $server = \"hostname\"; $port = 5672; $vhost = \"yourvhost\"; $username = \"username\"; $password = \"password\"; $queueName = \"testQ\"; //callback funtion on receiving messages $onMessage = function ($message) { echo $message->body.PHP_EOL; }; while (true) { try { //connect $connection = new AMQPConnection($server, $port, $username, $password, $vhost, $heartbeat = 60); $channel = $connection->channel(); //declare queue and consume messages //one-to-one messaging uses the default exchange, where queue name is the routing key $channel->queue_declare($queueName, false, false, false, $auto_delete = true); $channel->basic_consume($queueName, \"\", false, $no_ack = true, false, false, $callback = $onMessage); //start consuming while(count($channel->callbacks)) { $channel->wait(); } } catch(Exception $e) { //reconnect on exception echo \"Exception handled, reconnecting...\\nDetail:\\n\".$e.PHP_EOL; if ($connection != null) { try { $connection->close(); } catch (Exception $e1) {} } sleep(5); } } ?>","title":"Putting it together"},{"location":"one-one/#ruby","text":"","title":"Ruby"},{"location":"one-one/#prerequisites_2","text":"Ruby client AMQP library The Ruby library we use for this example can be found at http://rubybunny.info/ . With Ruby version >= 2.0, you can install it through sudo gem install bunny . Finally, import this library in your program. require \"bunny\" The full documentation of this library is at http://rubybunny.info/articles/guides.html . We recommend combining the documentation with the source code of this library when you use it because some of the documentation out there is not being updated timely from our observation.","title":"Prerequisites"},{"location":"one-one/#producer_3","text":"The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. Although the library provides a connection property named recover_from_connection_close , we discourage you to use it. The reason will be explained in the Consumer section. connection = Bunny.new(:host => server, :port => port, :vhost => vhost, :user => username, :pass => password, :heartbeat => 60, :recover_from_connection_close => false) connection.start channel = connection.create_channel Then producer can publish messages to the default exchange where queue name itself is the routing key. Delivery mode = 1 means it's a non-persistent message. exchange = channel.default_exchange exchange.publish(\"Hello World!\", :routing_key => routingKey, :content_type => \"text/plain\", :delivery_mode => 1) At last, producer will disconnect with the RoboMQ broker. connection.close","title":"Producer"},{"location":"one-one/#consumer_3","text":"The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a queue. By default, the queue will be bound to the default exchange with the same binding key as its name. Auto-delete means after all consumers have finished consuming it, the queue will be deleted by broker. queue = channel.queue(queueName, :auto_delete => true) After that, consumer can consume messages from the queue. The manual_ack parameter indicates if consumer needs to manually send acknowledgment back to broker when it has received the message. In this example, manual_ack equals to false, so producer does not manually acknowledge received messages. The subscribe() function is followed by a callback which will be invoked to print the message payload on receiving a message. queue.subscribe(:block => false, :manual_ack => false) do |delivery_info, metadata, payload| puts payload end As we mentioned in the Producer section, recover_from_connection_close is set to false when connecting to RoboMQ broker. It matters for consumers because recover_from_connection_close will only recover the connection, it won't recreate exchange and queue in case they are gone. Therefore, a more robust approach is letting your code handle reconnecting on its own and keep checking the existence of the subscribed queue. while true raise \"Lost the subscribed queue %s\" % queueName unless connection.queue_exists?(queueName) sleep 1 end","title":"Consumer"},{"location":"one-one/#putting-it-all-together_2","text":"producer.rb require \"bunny\" server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" routingKey = \"testQ\" begin #connect connection = Bunny.new(:host => server, :port => port, :vhost => vhost, :user => username, :pass => password, :heartbeat => 60, :recover_from_connection_close => false) connection.start channel = connection.create_channel #send message #assigning blank string to exchange is to use the default exchange, where queue name is the routing key exchange = channel.default_exchange exchange.publish(\"Hello World!\", :routing_key => routingKey, :content_type => \"text/plain\", :delivery_mode => 1) #disconnect connection.close rescue Exception => e puts e end consumer.rb require \"bunny\" server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" queueName = \"testQ\" while true begin #connect, disable auto-reconnect so as to manually reconnect connection = Bunny.new(:host => server, :port => port, :vhost => vhost, :user => username, :pass => password, :heartbeat => 60, :recover_from_connection_close => false) connection.start channel = connection.create_channel #declare queue and consume messages #one-to-one messaging uses the default exchange, where queue name is the routing key queue = channel.queue(queueName, :auto_delete => true) queue.subscribe(:block => false, :manual_ack => false) do |delivery_info, metadata, payload| puts payload end #keep checking the existence of the subscribed queue while true raise \"Lost the subscribed queue %s\" % queueName unless connection.queue_exists?(queueName) sleep 1 end rescue Exception => e #reconnect on exception puts \"Exception handled, reconnecting...\\nDetail:\\n%s\" % e #blindly clean old connection begin connection.close end sleep 5 end end","title":"Putting it all together"},{"location":"one-one/#java","text":"","title":"Java"},{"location":"one-one/#prerequisites_3","text":"Java client AMQP library The Java library we use for this example can be found at https://www.rabbitmq.com/java-client.html . Download the library jar file, then import this library in your program import com.rabbitmq.client.*; and compile your source code with the jar file. For example, javac -cp \".:./rabbitmq-client.jar\" Producer.java Consumer.java Run the producer and consumer classes. For example, java -cp \".:./rabbitmq-client.jar\" Consumer java -cp \".:./rabbitmq-client.jar\" Producer Of course, you can eventually compress your producer and consumer classes into jar files.","title":"Prerequisites"},{"location":"one-one/#producer_4","text":"The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. ConnectionFactory factory = new ConnectionFactory(); factory.setHost(server); factory.setPort(port); factory.setVirtualHost(vhost); factory.setUsername(username); factory.setPassword(password); factory.setRequestedHeartbeat(60); connection = factory.newConnection(); channel = connection.createChannel(); Then producer can publish messages to the default exchange where queue name itself is the routing key. It will assign a blank string to exchange parameter in publish function to use the default exchange. String message = \"Hello World!\"; channel.basicPublish(\"\", routingKey, MessageProperties.TEXT_PLAIN, message.getBytes()); At last, producer will disconnect with the RoboMQ broker. connection.close();","title":"Producer"},{"location":"one-one/#consumer_4","text":"The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a queue. By default, the queue will be bound to the default exchange with the same binding key as its name. The fourth parameter auto-delete is true. That means after all consumers have finished consuming it, the queue will be deleted by broker. channel.queueDeclare(queueName, false, false, true, null); Finally, consumer can consume messages from the queue. The second parameter of basicConsume() function no-ack indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, no-ack equals to true, so producer does not explicitly acknowledge received messages. The while loop will be blocking the process and listening for messages until exception happens. When messages are received, it will print the message content. QueueingConsumer qc = new QueueingConsumer(channel); channel.basicConsume(queueName, true, qc); while (true) { QueueingConsumer.Delivery delivery = qc.nextDelivery(); String message = new String(delivery.getBody()); System.out.println(message); }","title":"Consumer"},{"location":"one-one/#putting-it-all-together_3","text":"Producer.java import com.rabbitmq.client.ConnectionFactory; import com.rabbitmq.client.Connection; import com.rabbitmq.client.Channel; import com.rabbitmq.client.MessageProperties; public class Producer { private Connection connection; private Channel channel; private static String server = \"hostname\"; private static int port = 5672; private static String vhost = \"yourvhost\"; private static String username = \"username\"; private static String password = \"password\"; private static String routingKey = \"testQ\"; private void produce() { try { //connect ConnectionFactory factory = new ConnectionFactory(); factory.setHost(server); factory.setPort(port); factory.setVirtualHost(vhost); factory.setUsername(username); factory.setPassword(password); factory.setRequestedHeartbeat(60); connection = factory.newConnection(); channel = connection.createChannel(); //send message String message = \"Hello World!\"; //assigning blank string to exchange is to use the default exchange, where queue name is the routing key channel.basicPublish(\"\", routingKey, MessageProperties.TEXT_PLAIN, message.getBytes()); //disconnect connection.close(); } catch(Exception e) { System.out.println(e); System.exit(-1); } } public static void main(String[] args) { Producer p = new Producer(); p.produce(); } } Consumer.java import com.rabbitmq.client.ConnectionFactory; import com.rabbitmq.client.Connection; import com.rabbitmq.client.Channel; import com.rabbitmq.client.QueueingConsumer; public class Consumer { private Connection connection; private Channel channel; private static String server = \"hostname\"; private static int port = 5672; private static String vhost = \"yourvhost\"; private static String username = \"username\"; private static String password = \"password\"; private static String queueName = \"testQ\"; private void consume() { while (true) { try { //connect ConnectionFactory factory = new ConnectionFactory(); factory.setHost(server); factory.setPort(port); factory.setVirtualHost(vhost); factory.setUsername(username); factory.setPassword(password); factory.setRequestedHeartbeat(60); connection = factory.newConnection(); channel = connection.createChannel(); //declare queue and consume messages //one-to-one messaging uses the default exchange, where queue name is the routing key channel.queueDeclare(queueName, false, false, true, null); QueueingConsumer qc = new QueueingConsumer(channel); channel.basicConsume(queueName, true, qc); while (true) { QueueingConsumer.Delivery delivery = qc.nextDelivery(); String message = new String(delivery.getBody()); System.out.println(message); } } catch(Exception e) { //reconnect on exception System.out.printf(\"Exception handled, reconnecting...\\nDetail:\\n%s\\n\", e); try { connection.close(); } catch (Exception e1) {} try { Thread.sleep(5000); } catch(Exception e2) {} } } } public static void main(String[] args) { Consumer c = new Consumer(); c.consume(); } }","title":"Putting it all together"},{"location":"one-one/#go","text":"","title":"Go"},{"location":"one-one/#prerequisites_4","text":"Go client AMQP library The Go library we use for this example can be found at https://github.com/streadway/amqp . You can install it through go get github.com/streadway/amqp . Finally, import this library in your program. import \"github.com/streadway/amqp\" The full documentation of this library is at https://godoc.org/github.com/streadway/amqp .","title":"Prerequisites"},{"location":"one-one/#producer_5","text":"The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. connection, err := amqp.DialConfig(fmt.Sprintf(\"amqp://%s:%s@%s:%d/%s\", username, password, server, port, vhost), amqp.Config{Heartbeat: 60 * time.Second}) channel, err := connection.Channel() Then producer can publish messages to the default exchange where queue name itself is the routing key. It will assign a blank string to exchange parameter in publish function to use the default exchange. Delivery mode = 1 means it's a non-persistent message. err = channel.Publish(\"\", routingKey, false, false, amqp.Publishing{ContentType: \"text/plain\", DeliveryMode: 1, Body: []byte(\"Hello World!\")}) At last, producer will disconnect with the RoboMQ broker. connection.Close()","title":"Producer"},{"location":"one-one/#consumer_5","text":"The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a queue. By default, the queue will be bound to the default exchange with the same binding key as its name. Durable means the exchange or queue will survive possible broker failover. It's false in this example. Auto-delete means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. Exclusive means no other consumer can consume the queue when this one is consuming it. // durable = false; auto-delete = true; exclusive = false queue, err := channel.QueueDeclare(queueName, false, true, false, false, nil) Finally, consumer can consume messages from the queue. Consumer-tag can be later used to Cancel() this consumer when it's no longer needed. Auto-ack parameter indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, auto-ack equals to true, so producer does not explicitly acknowledge received messages. // consumer-tag = \"consumer\"; auto-ack = true messageChan, err := channel.Consume(queue.Name, \"consumer\", true, false, false, false, nil) Note a message channel is returned by the Consume() function. Incoming messages will be received through that channel. Channel in Golang is a typed conduit through which you can send and receive values. Sends and receives block until the other side is ready. for message := range messageChan { fmt.Println(string(message.Body)) }","title":"Consumer"},{"location":"one-one/#putting-it-all-together_4","text":"producer.go package main import ( \"fmt\" \"github.com/streadway/amqp\" \"os\" \"time\" ) var server = \"hostname\" var port = 5672 var vhost = \"yourvhost\" var username = \"username\" var password = \"password\" var routingKey = \"testQ\" func main() { connection, err := amqp.DialConfig(fmt.Sprintf(\"amqp://%s:%s@%s:%d/%s\", username, password, server, port, vhost), amqp.Config{Heartbeat: 60 * time.Second}) if err != nil { fmt.Printf(\"Failed to connect, err: %v\\n\", err) os.Exit(1) } defer connection.Close() channel, err := connection.Channel() if err != nil { fmt.Printf(\"Failed to create channel, err: %v\\n\", err) os.Exit(1) } defer channel.Close() err = channel.Publish( // assigning blank string to exchange is to use the default exchange, where queue name is the routing key \"\", // exchange routingKey, // routing key false, // mandatory false, // immediate amqp.Publishing{ ContentType: \"text/plain\", DeliveryMode: 1, Body: []byte(\"Hello World!\"), }) if err != nil { fmt.Printf(\"Failed to publish message, err: %v\\n\", err) os.Exit(1) } } consumer.go package main import ( \"fmt\" \"github.com/streadway/amqp\" \"time\" ) var server = \"hostname\" var port = 5672 var vhost = \"yourvhost\" var username = \"username\" var password = \"password\" var queueName = \"testQ\" func main() { // Infinite loop to auto-reconnect on failure Loop: for { fmt.Println(\"Starting in 5 seconds...\") time.Sleep(5 * time.Second) connection, err := amqp.DialConfig(fmt.Sprintf(\"amqp://%s:%s@%s:%d/%s\", username, password, server, port, vhost), amqp.Config{Heartbeat: 60 * time.Second}) if err != nil { fmt.Printf(\"Failed to connect, err: %v\\n\", err) continue Loop } defer connection.Close() channel, err := connection.Channel() if err != nil { fmt.Printf(\"Failed to create channel, err: %v\\n\", err) continue Loop } defer channel.Close() // one-to-one messaging uses the default exchange, where queue name is the routing key queue, err := channel.QueueDeclare( queueName, // name false, // durable true, // auto-delete false, // exclusive false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to declare queue, err: %v\\n\", err) continue Loop } messageChan, err := channel.Consume( queue.Name, // queue \"consumer\", // consumer tag true, // auto-ack false, // exclusive false, // no-local false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to consume messages, err: %v\\n\", err) continue Loop } fmt.Println(\"Started consuming messages.\") for message := range messageChan { fmt.Println(string(message.Body)) } } }","title":"Putting it all together"},{"location":"one-one/#c","text":"","title":"C"},{"location":"one-one/#prerequisites_5","text":"C client AMQP library robomq.io is built on AMQP, an open, general-purpose protocol for messaging. There are a number of clients for AMQP in many different languages. However, we'll choose a simple C-language AMQP client library written for use with v2.0+ of the RabbitMQ broker. https://github.com/alanxz/rabbitmq-c/tree/master/librabbitmq You can copy librabbitmq subfolder from latest release located here on GitHub: https://github.com/alanxz/rabbitmq-c Alternatively, thanks to Subversion support in GitHub, you can use svn export directly: svn export https://github.com/alanxz/rabbitmq-c/trunk/librabbitmq Copy the librabbitmq package into your working directory: cp librabbitmq ./ Also copy all source files and Makefile from RoboMQ SDK at https://github.com/robomq/robomq.io/tree/master/sdk/AMQP/C into the same directory. Now your working directory should have the content as bellow: broadcast config.h librabbitmq Makefile one-to-one request-reply routing-key topic Use the Makefile to compile under a Linux terminal. Run make type={sub-directory} to compile the producer and consumer under the sub-directory. Before compiling the next sub-directory, run make clean to clean up the compiled files. Note that these examples provide a simple client implementation to get started but does not go into detailed description of all flags passed into the AMQP methods. A complete reference to RabbitMQ's implementaton of version 0-9-1 of the AMQP specification can be found in this guide. https://www.rabbitmq.com/amqp-0-9-1-reference.html","title":"Prerequisites"},{"location":"one-one/#producer_6","text":"First, producer should initialize a connection to the RoboMQ server. amqp_connection_state_t conn = amqp_new_connection(); amqp_socket_t *socket = NULL; char hostname[] = \"hostname\"; // RoboMQ hostname int port = 5672; //default char user[] = \"username\"; // RoboMQ username char password[] = \"password\"; // RoboMQ password char vhost[] = \"vhost\"; // RoboMQ account vhost amqp_channel_t channel = 1; int channel_max = 0; int frame_max = 131072; int heartbeat = 60; int status = 0; // Opening socket socket = amqp_tcp_socket_new(conn); status = amqp_socket_open(socket, hostname, port); if (status) { printf(\"Error opening TCP socket, status = %d, exiting.\", status); } amqp_login(conn, vhost, channel_max, frame_max, heartbeat, AMQP_SASL_METHOD_PLAIN, user, password); amqp_channel_open(conn, channel); Then, producer should publish messages to the specified exchange attached with routing key. If not specified, that routing key is the queue name. Based on that routing key, messages will be sent through the exchange and distributed to the right queue. amqp_basic_properties_t props; props._flags = AMQP_BASIC_CONTENT_TYPE_FLAG | AMQP_BASIC_DELIVERY_MODE_FLAG; props.content_type = amqp_cstring_bytes(\"text/plain\"); props.delivery_mode = 1; /* non-persistent delivery mode */ amqp_boolean_t mandatory = 0; amqp_boolean_t immediate = 0; char exchange_name[] = \"hello-exchange\"; char routing_key[] = \"hola\"; int result; // Sending message result = amqp_basic_publish(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(routing_key), mandatory, immediate, &props, amqp_cstring_bytes(\"Hello\")); Finally, after all messaged are produced, producer should terminate this connection. amqp_channel_close(conn, channel, AMQP_REPLY_SUCCESS); amqp_connection_close(conn, AMQP_REPLY_SUCCESS); amqp_destroy_connection(conn);","title":"Producer"},{"location":"one-one/#consumer_6","text":"First, consumer should initialize connection to the RoboMQ server. amqp_connection_state_t conn = amqp_new_connection(); amqp_socket_t *socket = NULL; char hostname[] = \"hostname\"; // RoboMQ hostname int port = 5672; //default char user[] = \"username\"; // RoboMQ username char password[] = \"password\"; // RoboMQ password char vhost[] = \"vhost\"; // RoboMQ account vhost amqp_channel_t channel = 1; int channel_max = 0; int frame_max = 131072; int heartbeat = 60; int status = 0; // Opening socket socket = amqp_tcp_socket_new(conn); status = amqp_socket_open(socket, hostname, port); if (status) { printf(\"Error opening TCP socket, status = %d, exiting.\", status); } amqp_login(conn, vhost, channel_max, frame_max, heartbeat, AMQP_SASL_METHOD_PLAIN, user, password); amqp_channel_open(conn, channel); Then consumer should create a queue and subscribe to a queue. This queue will work as a mailbox where all messages published to it will be stored until they are consumed. The direct exchange type is specified below in exchange_type definition. amqp_bytes_t queue; amqp_channel_t channel = 1; amqp_boolean_t passive = 0; amqp_boolean_t durable = 0; amqp_boolean_t exclusive = 0; amqp_boolean_t auto_delete = 1; amqp_boolean_t internal = 0; char exchange_name[] = \"hello-exchange\"; char exchange_type[] = \"direct\"; char queue_name[] = \"hello-queue\"; char binding_key[] = \"hola\"; // Declaring exchange amqp_exchange_declare(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(exchange_type), passive, durable, auto_delete, internal, amqp_empty_table); if(amqp_get_rpc_reply(conn).reply_type != AMQP_RESPONSE_NORMAL) { printf(\"Error declaring exchange: %d\\n\", amqp_get_rpc_reply(conn)); exit(1); } // Declaring queue amqp_queue_declare_ok_t *r = amqp_queue_declare(conn, channel, amqp_cstring_bytes(queue_name), passive, durable, exclusive, auto_delete, amqp_empty_table); if(amqp_get_rpc_reply(conn).reply_type != AMQP_RESPONSE_NORMAL) { printf(\"Error declaring queue: %d\\n\", amqp_get_rpc_reply(conn)); exit(1); } queue = amqp_bytes_malloc_dup(r->queue); // Binding to queue amqp_queue_bind(conn, channel, queue, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(binding_key), amqp_empty_table); Note that all the queues declared without specific binding key use the queue name as the default binding key. At this point, consumer should start consuming messages. The no_ack parameter indicates whether consumer will automatically send acknowledgment back to broker. For this example, producer does not explicitly acknowledge received messages. Therefore, we set no_ack attribute value as true. Then, consumer should receive messages and implement any desired processing on message contents. amqp_boolean_t no_local = 0; amqp_boolean_t no_ack = 1; amqp_boolean_t exclusive = 0; amqp_frame_t frame; // Consuming the message amqp_basic_consume(conn, channel, queue, amqp_empty_bytes, no_local, no_ack, exclusive, amqp_empty_table); amqp_rpc_reply_t result; amqp_envelope_t envelope; amqp_maybe_release_buffers(conn); result = amqp_consume_message(conn, &envelope, NULL, 0); if (AMQP_RESPONSE_NORMAL == result.reply_type) { printf(\"Received message size: %d\\nbody: %s\\n\", (int)envelope.message.body.len, (char *)envelope.message.body.bytes); amqp_destroy_envelope(&envelope); }","title":"Consumer"},{"location":"one-one/#putting-it-all-together_5","text":"The full code below includes some basic AMQP error handling for consumer that is useful when declaring exchanges and queues. In addition, main receiver loop attempts to reconnect upon network connection failure. producer.c #include <stdlib.h> #include <stdio.h> #include <string.h> #include <amqp_tcp_socket.h> #include <amqp.h> #include <amqp_framing.h> amqp_connection_state_t mqconnect() { amqp_connection_state_t conn = amqp_new_connection(); amqp_socket_t *socket = NULL; char hostname[] = \"localhost\"; // RoboMQ hostname int port = 5672; //default char user[] = \"guest\"; // RoboMQ username char password[] = \"guest\"; // RoboMQ password char vhost[] = \"/\"; // RoboMQ account vhost amqp_channel_t channel = 1; int channel_max = 0; int frame_max = 131072; int heartbeat = 60; int status = 0; // Opening socket socket = amqp_tcp_socket_new(conn); status = amqp_socket_open(socket, hostname, port); if (status) { printf(\"Error opening TCP socket, status = %d, exiting.\", status); } amqp_login(conn, vhost, channel_max, frame_max, heartbeat, AMQP_SASL_METHOD_PLAIN, user, password); amqp_channel_open(conn, channel); return conn; } int main(int argc, char const *const *argv) { amqp_connection_state_t conn; amqp_channel_t channel = 1; amqp_basic_properties_t props; props._flags = AMQP_BASIC_CONTENT_TYPE_FLAG | AMQP_BASIC_DELIVERY_MODE_FLAG; props.content_type = amqp_cstring_bytes(\"text/plain\"); props.delivery_mode = 1; /* non-persistent delivery mode */ amqp_boolean_t mandatory = 0; amqp_boolean_t immediate = 0; char exchange_name[] = \"hello-exchange\"; char routing_key[] = \"hola\"; char *msg_body = \"Hello\\n\"; int result; conn = mqconnect(); // Sending message result = amqp_basic_publish(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(routing_key), mandatory, immediate, &props, amqp_cstring_bytes(msg_body)); if (AMQP_RESPONSE_NONE != result) { printf(\"Producer AMQP failure occurred, response code = %d\\n\", result); } // Closing connection amqp_connection_close(conn, AMQP_REPLY_SUCCESS); amqp_destroy_connection(conn); return 0; } consumer.c #include <stdlib.h> #include <stdio.h> #include <string.h> #include <amqp_tcp_socket.h> #include <amqp.h> #include <amqp_framing.h> amqp_connection_state_t mqconnect() { amqp_connection_state_t conn = amqp_new_connection(); amqp_socket_t *socket = NULL; char hostname[] = \"localhost\"; // RoboMQ hostname int port = 5672; //default char user[] = \"guest\"; // RoboMQ username char password[] = \"guest\"; // RoboMQ password char vhost[] = \"/\"; // RoboMQ account vhost amqp_channel_t channel = 1; amqp_rpc_reply_t reply; int channel_max = 0; int frame_max = 131072; int heartbeat = 60; int status = 0; // Opening socket socket = amqp_tcp_socket_new(conn); status = amqp_socket_open(socket, hostname, port); if (status) { printf(\"Error opening TCP socket, status = %d\\n\", status); } reply = amqp_login(conn, vhost, channel_max, frame_max, heartbeat, AMQP_SASL_METHOD_PLAIN, user, password); if(reply.reply_type != AMQP_RESPONSE_NORMAL) { fprintf(stderr, \"%s: server connection reply code: %d\\n\", \"Error logging in\", reply.reply_type); } amqp_channel_open(conn, channel); return conn; } amqp_bytes_t mqdeclare(amqp_connection_state_t conn, const char *exchange_name, const char *queue_name) { amqp_bytes_t queue; amqp_channel_t channel = 1; amqp_boolean_t passive = 0; amqp_boolean_t durable = 0; amqp_boolean_t exclusive = 0; amqp_boolean_t auto_delete = 1; amqp_boolean_t internal = 0; char exchange_type[] = \"direct\"; char binding_key[] = \"hola\"; amqp_rpc_reply_t reply; // Declaring exchange amqp_exchange_declare(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(exchange_type), passive, durable, auto_delete, internal, amqp_empty_table); reply = amqp_get_rpc_reply(conn); if(reply.reply_type != AMQP_RESPONSE_NORMAL) { amqp_connection_close_t *m = (amqp_connection_close_t *) reply.reply.decoded; if(NULL != m) { fprintf(stderr, \"%s: server connection error %d, message: %.*s\\n\", \"Error declaring exchange\", m->reply_code, (int) m->reply_text.len, (char *) m->reply_text.bytes); } } // Declaring queue amqp_queue_declare_ok_t *r = amqp_queue_declare(conn, channel, amqp_cstring_bytes(queue_name), passive, durable, exclusive, auto_delete, amqp_empty_table); reply = amqp_get_rpc_reply(conn); if(reply.reply_type != AMQP_RESPONSE_NORMAL) { fprintf(stderr, \"%s: server connection reply code: %d\\n\", \"Error declaring queue\", reply.reply_type); } else { queue = amqp_bytes_malloc_dup(r->queue); // Binding to queue amqp_queue_bind(conn, channel, queue, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(binding_key), amqp_empty_table); } return queue; } int main(int argc, char const *const *argv) { amqp_connection_state_t conn; amqp_bytes_t queue; amqp_channel_t channel = 1; amqp_boolean_t no_local = 0; amqp_boolean_t no_ack = 1; amqp_boolean_t exclusive = 0; char exchange_name[] = \"hello-exchange\"; char queue_name[] = \"hello-queue\"; int retry_time = 5; // retry time in seconds conn = mqconnect(); queue = mqdeclare(conn, &exchange_name[0], &queue_name[0]); // Consuming the message amqp_basic_consume(conn, channel, queue, amqp_empty_bytes, no_local, no_ack, exclusive, amqp_empty_table); while (1) { amqp_rpc_reply_t result; amqp_envelope_t envelope; amqp_maybe_release_buffers(conn); result = amqp_consume_message(conn, &envelope, NULL, 0); if (AMQP_RESPONSE_NORMAL != result.reply_type) { printf(\"Consumer AMQP failure occurred, response code = %d, retrying in %d seconds...\\n\", result.reply_type, retry_time); // Closing current connection before reconnecting amqp_connection_close(conn, AMQP_CONNECTION_FORCED); amqp_destroy_connection(conn); // Reconnecting on exception conn = mqconnect(); queue = mqdeclare(conn, &exchange_name[0], &queue_name[0]); amqp_basic_consume(conn, channel, queue, amqp_empty_bytes, no_local, no_ack, exclusive, amqp_empty_table); sleep(retry_time); } else { printf(\"Received message size: %d\\nbody: %s\\n\", (int)envelope.message.body.len, (char *)envelope.message.body.bytes); amqp_destroy_envelope(&envelope); } } return 0; }","title":"Putting it all together"},{"location":"request-reply/","text":"Request - Reply This is a two-way message communication also using direct exchange but unlike the RPC pattern, the reply queue is bound to an exchange allowing more than one client to subscribe to and process the replies asynchronously. In addition any service application can process a request from any client. In this situation, both producer and consumer are capable of publishing and consuming messages. Browse the chapter of AMQP Introduction first if you're new to AMQP. Read the chapter of Key based message routing before reading this chapter. Python Prerequisites Python client AMQP library The Python library we use for this example can be found at https://github.com/pika/pika . You can install it through sudo pip install pika . Finally, import this library in your program. import pika The full documentation of this library is at https://pika.readthedocs.org/en/0.9.14/ . pika library is not thread safe. Do not use a connection or channel across threads. Producer The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. credentials = pika.PlainCredentials(username, password) connection = pika.BlockingConnection(pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60)) channel = connection.channel() Then producer will do what consumer does, listen on the replyQueue on its side. channel.queue_declare(queue = replyQueue, exclusive = True, auto_delete = True) channel.queue_bind(exchange = exchangeName, queue = replyQueue, routing_key = replyKey) channel.basic_consume(consumer_callback = onMessage, queue = replyQueue, no_ack = True) channel.start_consuming() After that producer can publish messages to the exchange through routing key of the requestQueue on consumer side. The message carries a reply-to property to indicate consumer where to reply to. It's the routing key of producer's replyQueue. properties = pika.spec.BasicProperties(content_type = \"text/plain\", delivery_mode = 1, reply_to = replyKey) channel.basic_publish(exchange = exchangeName, routing_key = requestKey, body = \"Hello World!\", properties = properties) Once producer has received the reply, the callback function will disconnect with the RoboMQ broker. def onMessage(channel, method, properties, body): print body channel.stop_consuming() connection.close() Consumer The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will listen on its requestQueue. channel.exchange_declare(exchange = exchangeName, exchange_type = \"direct\", auto_delete = True) channel.queue_declare(queue = requestQueue, exclusive = True, auto_delete = True) channel.queue_bind(exchange = exchangeName, queue = requestQueue, routing_key = requestKey) channel.basic_consume(consumer_callback = onMessage, queue = requestQueue, no_ack = False) channel.start_consuming() When requests are received, a callback function will be invoked to print the message content and reply according to the reply-to property of request message. This time, we have set no_ack to false. If reply succeeds, ACK the request message; otherwise, NACK it, so it will be re-queued. def onMessage(channel, method, properties, body): print body try: replyProp = pika.BasicProperties(content_type = \"text/plain\", delivery_mode = 1) channel.basic_publish(exchange = exchangeName, routing_key = properties.reply_to, properties = replyProp, body = \"Reply to %s\" % (body)) channel.basic_ack(delivery_tag = method.delivery_tag) except: channel.basic_nack(delivery_tag = method.delivery_tag) Putting it all together producer.py import pika import thread import time server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" exchangeName = \"testEx\" replyQueue = \"replyQ\" requestKey = \"request\" replyKey = \"reply\" #callback funtion on receiving reply messages def onMessage(channel, method, properties, body): print body #close connection once receives the reply channel.stop_consuming() connection.close() #listen for reply messages def listen(): channel.queue_declare(queue = replyQueue, exclusive = True, auto_delete = True) channel.queue_bind(exchange = exchangeName, queue = replyQueue, routing_key = replyKey) channel.basic_consume(consumer_callback = onMessage, queue = replyQueue, no_ack = True) channel.start_consuming() try: #connect credentials = pika.PlainCredentials(username, password) connection = pika.BlockingConnection(pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60)) channel = connection.channel() thread.start_new_thread(listen, ()) time.sleep(1) #give time for it to start consuming #send request message properties = pika.spec.BasicProperties(content_type = \"text/plain\", delivery_mode = 1, reply_to = replyKey) channel.basic_publish(exchange = exchangeName, routing_key = requestKey, body = \"Hello World!\", properties = properties) #block until receives reply message while connection.is_open: pass except Exception, e: print e consumer.py import pika import time server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" exchangeName = \"testEx\" requestQueue = \"requestQ\" requestKey = \"request\" #callback funtion on receiving request messages, reply to the reply_to header def onMessage(channel, method, properties, body): print body try: replyProp = pika.BasicProperties(content_type = \"text/plain\", delivery_mode = 1) channel.basic_publish(exchange = exchangeName, routing_key = properties.reply_to, properties = replyProp, body = \"Reply to %s\" % (body)) channel.basic_ack(delivery_tag = method.delivery_tag) except: channel.basic_nack(delivery_tag = method.delivery_tag) while True: try: #connect credentials = pika.PlainCredentials(username, password) connection = pika.BlockingConnection(pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60)) channel = connection.channel() #declare exchange and queue, bind them and consume messages channel.exchange_declare(exchange = exchangeName, exchange_type = \"direct\", auto_delete = True) channel.queue_declare(queue = requestQueue, exclusive = True, auto_delete = True) channel.queue_bind(exchange = exchangeName, queue = requestQueue, routing_key = requestKey) channel.basic_consume(consumer_callback = onMessage, queue = requestQueue, no_ack = False) channel.start_consuming() except Exception, e: #reconnect on exception print \"Exception handled, reconnecting...\\nDetail:\\n%s\" % e try: connection.close() except: pass time.sleep(5) Node.js Prerequisites Node.js client AMQP library The Node.js library we use for this example can be found at https://github.com/squaremo/amqp.node . You can install the library through sudo npm install amqplib . Finally, require this library in your program. var amqp = require(\"amqplib\"); The full documentation of this library is at https://www.squaremobius.net/amqp.node/doc/channel_api.html . Producer The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. producer = amqp.connect(\"amqp://\" + username + \":\" + password + \"@\" + server + \":\" + port + \"/\" + vhost + \"?heartbeat=60\"); producer.then(function(conn) { return conn.createConfirmChannel().then(successCallback); }).then(null, failureCallback); Then producer will do what consumer does, listen on the replyQueue on its side. Once producer has received the reply, it will disconnect with the RoboMQ broker. ch.assertQueue(replyQueue, {durable: false, autoDelete: true, exclusive: true}); ch.bindQueue(replyQueue, exchangeName, replyKey); ch.consume(replyQueue, function(message) { console.log(message.content.toString()); conn.close(); }, {noAck: true}); After that producer can publish messages to the exchange through routing key of the requestQueue on consumer side. The message carries a reply-to property to indicate consumer where to reply to. It's the routing key of producer's replyQueue. ch.publish(exchangeName, requestKey, content = new Buffer(\"Hello World!\"), options = {contentType: \"text/plain\", deliveryMode: 1, replyTo: replyKey}, callback); Consumer The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will listen on its requestQueue. When requests are received, a callback function will be invoked to print the message content and reply according to the reply-to property of request message. This time, we have set noAck to false. If reply succeeds, ACK the request message; otherwise, NACK it, so it will be re-queued. ch.assertExchange(exchangeName, \"direct\", {durable: false, autoDelete: true}); ch.assertQueue(requestQueue, {durable: false, autoDelete: true, exclusive: true}); ch.bindQueue(requestQueue, exchangeName, requestKey); ch.consume(requestQueue, function(message) { console.log(message.content.toString()); ch.publish(exchangeName, message.properties.replyTo, new Buffer(\"Reply to \" + message.content.toString()), options = {contentType: \"text/plain\", deliveryMode: 1}, function(err, ok) { if (err != null) { ch.nack(message); } else { ch.ack(message); } }); }, {noAck: false}); Putting it all together producer.js var amqp = require(\"amqplib\"); var server = \"hostname\"; var port = \"5672\"; var vhost = \"yourvhost\"; //for \"/\" vhost, use \"%2f\" instead var username = \"username\"; var password = \"password\"; var exchangeName = \"testEx\"; var replyQueue = \"replyQ\"; var requestKey = \"request\"; var replyKey = \"reply\"; producer = amqp.connect(\"amqp://\" + username + \":\" + password + \"@\" + server + \":\" + port + \"/\" + vhost + \"?heartbeat=60\"); producer.then(function(conn) { return conn.createChannel().then(function(ch) { //listen for reply messages ch.assertQueue(replyQueue, {durable: false, autoDelete: true, exclusive: true}); ch.bindQueue(replyQueue, exchangeName, replyKey); ch.consume(replyQueue, function(message) { //callback funtion on receiving reply messages console.log(message.content.toString()); //close connection once receives the reply conn.close(); }, {noAck: true}); //send the request message after 1 second setTimeout(function() { ch.publish(exchangeName, requestKey, content = new Buffer(\"Hello World!\"), options = {contentType: \"text/plain\", deliveryMode: 1, replyTo: replyKey}, function(err, ok) { if (err != null) { console.error(\"Error: failed to send message\\n\" + err); } }); }, 1000); }); }).then(null, function(err) { console.error(err); }); consumer.js var amqp = require(\"amqplib\"); var domain = require(\"domain\"); var server = \"hostname\"; var port = \"5672\"; var vhost = \"yourvhost\"; //for \"/\" vhost, use \"%2f\" instead var username = \"username\"; var password = \"password\"; var exchangeName = \"testEx\"; var requestQueue = \"requestQ\"; var requestKey = \"request\"; //use domain module to handle reconnecting var consumer = null; var dom = domain.create(); dom.on(\"error\", relisten); dom.run(listen); function listen() { consumer = amqp.connect(\"amqp://\" + username + \":\" + password + \"@\" + server + \":\" + port + \"/\" + vhost + \"?heartbeat=60\"); consumer.then(function(conn) { return conn.createChannel().then(function(ch) { ch.assertExchange(exchangeName, \"direct\", {durable: false, autoDelete: true}); ch.assertQueue(requestQueue, {durable: false, autoDelete: true, exclusive: true}); ch.bindQueue(requestQueue, exchangeName, requestKey); ch.consume(requestQueue, function(message) { //callback funtion on receiving messages, reply to the reply_to header console.log(message.content.toString()); ch.publish(exchangeName, message.properties.replyTo, new Buffer(\"Reply to \" + message.content.toString()), options = {contentType: \"text/plain\", deliveryMode: 1}, function(err, ok) { if (err != null) { ch.nack(message); } else { ch.ack(message); } }); }, {noAck: false}); }); }).then(null, function(err) { console.error(\"Exception handled, reconnecting...\\nDetail:\\n\" + err); setTimeout(listen, 5000); }); } function relisten() { consumer.then(function(conn) { conn.close(); }); setTimeout(listen, 5000); } PHP Prerequisite PHP client AMQP library The PHP library we use for this example can be found at https://github.com/videlalvaro/php-amqplib . It uses composer to install in a few steps. Add a composer.json file to your project: { \"require\": { \"videlalvaro/php-amqplib\": \"2.2.*\" } } Download the latest composer in the same path: curl -sS https://getcomposer.org/installer | php Install the library through composer: ./composer.phar install Finally, require this library in your program and use the classes. require_once __DIR__ . '/../vendor/autoload.php'; //directory of library folder use PhpAmqpLib\\Connection\\AMQPConnection; use PhpAmqpLib\\Message\\AMQPMessage; Producer The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. $connection = new AMQPConnection($server, $port, $username, $password, $vhost, $heartbeat = 60); $channel = $connection->channel(); Then producer will do what consumer does, listen on the replyQueue on its side. $channel->queue_declare($replyQueue, false, false, $exclusive = true, $auto_delete = true); $channel->queue_bind($replyQueue, $exchangeName, $replyKey); $consumerTag = $channel->basic_consume($replyQueue, \"\", false, $no_ack = true, false, false, $callback = $onMessage); After that producer can publish messages to the exchange through routing key of the requestQueue on consumer side. The message carries a reply-to property to indicate consumer where to reply to. It's the routing key of producer's replyQueue. $message = new AMQPMessage(\"Hello World!\", array(\"content_type\" => \"text/plain\", \"delivery_mode\" => 1, \"reply_to\" => $replyKey)); $channel->basic_publish($message, $exchangeName, $requestKey); Once producer has received the reply, the callback function will disconnect with the RoboMQ broker. $onMessage = function ($message) { echo $message->body.PHP_EOL; $channel->basic_cancel($consumerTag); }; Consumer The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will listen on its requestQueue. $channel->exchange_declare($exchangeName, $type = \"direct\", false, false, $auto_delete = true); $channel->queue_declare($requestQueue, false, false, $exclusive = true, $auto_delete = true); $channel->queue_bind($requestQueue, $exchangeName, $requestKey); $channel->basic_consume($requestQueue, \"\", false, $no_ack = false, false, false, $callback = $onMessage); When requests are received, a callback function will be invoked to print the message content and reply according to the reply-to property of request message. This time, we have set no_ack to false. If reply succeeds, ACK the request message; otherwise, NACK it, so it will be re-queued. $onMessage = function ($message) { echo $message->body.PHP_EOL; try { $replyMessage = new AMQPMessage(\"Reply to \".$message->body, array(\"content_type\" => \"text/plain\", \"delivery_mode\" => 1)); $channel->basic_publish($replyMessage, $exchangeName, $message->get(\"reply_to\")); $channel->basic_ack($message->delivery_info[\"delivery_tag\"]); } catch (Exception $e) { $channel->basic_nack($message->delivery_info[\"delivery_tag\"]); } }; Putting it together producer.php <?php require_once __DIR__ . '/../vendor/autoload.php'; //directory of library folder use PhpAmqpLib\\Connection\\AMQPConnection; use PhpAmqpLib\\Message\\AMQPMessage; $GLOBALS[\"channel\"] = $channel; $GLOBALS[\"consumerTag\"] = $consumerTag; $server = \"hostname\"; $port = 5672; $vhost = \"yourvhost\"; $username = \"username\"; $password = \"password\"; $exchangeName = \"testEx\"; $replyQueue = \"replyQ\"; $requestKey = \"request\"; $replyKey = \"reply\"; //callback funtion on receiving reply messages $onMessage = function ($message) { echo $message->body.PHP_EOL; //stop consuming once receives the reply $GLOBALS[\"channel\"]->basic_cancel($GLOBALS[\"consumerTag\"]); }; try { //connect $connection = new AMQPConnection($server, $port, $username, $password, $vhost, $heartbeat = 60); $channel = $connection->channel(); //listen for reply messages $channel->queue_declare($replyQueue, false, false, $exclusive = true, $auto_delete = true); $channel->queue_bind($replyQueue, $exchangeName, $replyKey); $consumerTag = $channel->basic_consume($replyQueue, \"\", false, $no_ack = true, false, false, $callback = $onMessage); //send request message $message = new AMQPMessage(\"Hello World!\", array(\"content_type\" => \"text/plain\", \"delivery_mode\" => 1, \"reply_to\" => $replyKey)); $channel->basic_publish($message, $exchangeName, $requestKey); //start consuming while(count($channel->callbacks)) { $channel->wait(); } //disconnect $connection->close(); } catch(Exception $e) { echo $e.PHP_EOL; } ?> consumer.php <?php require_once __DIR__.\"/../vendor/autoload.php\"; //directory of library folder use PhpAmqpLib\\Connection\\AMQPConnection; use PhpAmqpLib\\Message\\AMQPMessage; $GLOBALS[\"channel\"] = $channel; $GLOBALS[\"exchangeName\"] = $exchangeName; $server = \"hostname\"; $port = 5672; $vhost = \"yourvhost\"; $username = \"username\"; $password = \"password\"; $exchangeName = \"testEx\"; $requestQueue = \"requestQ\"; $requestKey = \"request\"; //callback funtion on receiving request messages, reply to the reply_to header $onMessage = function ($message) { echo $message->body.PHP_EOL; try { $replyMessage = new AMQPMessage(\"Reply to \".$message->body, array(\"content_type\" => \"text/plain\", \"delivery_mode\" => 1)); $GLOBALS[\"channel\"]->basic_publish($replyMessage, $GLOBALS[\"exchangeName\"], $message->get(\"reply_to\")); $GLOBALS[\"channel\"]->basic_ack($message->delivery_info[\"delivery_tag\"]); } catch (Exception $e) { $GLOBALS[\"channel\"]->basic_nack($message->delivery_info[\"delivery_tag\"]); } }; while (true) { try { //connect $connection = new AMQPConnection($server, $port, $username, $password, $vhost, $heartbeat = 60); $channel = $connection->channel(); //declare exchange and queue, bind them and consume messages $channel->exchange_declare($exchangeName, $type = \"direct\", false, false, $auto_delete = true); $channel->queue_declare($requestQueue, false, false, $exclusive = true, $auto_delete = true); $channel->queue_bind($requestQueue, $exchangeName, $requestKey); $channel->basic_consume($requestQueue, \"\", false, $no_ack = false, false, false, $callback = $onMessage); //start consuming while(count($channel->callbacks)) { $channel->wait(); } } catch(Exception $e) { //reconnect on exception echo \"Exception handled, reconnecting...\\nDetail:\\n\".$e.PHP_EOL; if ($connection != null) { try { $connection->close(); } catch (Exception $e1) {} } sleep(5); } } ?> Ruby Prerequisites Ruby client AMQP library The Ruby library we use for this example can be found at http://rubybunny.info/ . With Ruby version >= 2.0, you can install it through sudo gem install bunny . Finally, import this library in your program. require \"bunny\" The full documentation of this library is at http://rubybunny.info/articles/guides.html . We recommend combining the documentation with the source code of this library when you use it because some of the documentation out there is not being updated timely from our observation. Producer The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. Although the library provides a connection property named recover_from_connection_close , we discourage you to use it. The reason will be explained in the Consumer section. connection = Bunny.new(:host => server, :port => port, :vhost => vhost, :user => username, :pass => password, :heartbeat => 60, :recover_from_connection_close => false) connection.start channel = connection.create_channel Then producer will do what consumer does, listen on the replyQueue on its side. exchange = channel.direct(exchangeName, :auto_delete => true) queue = channel.queue(replyQueue, :exclusive => true, :auto_delete => true) queue.bind(exchange, :routing_key => replyKey) isReplied = false consumer = queue.subscribe(:block => false, :manual_ack => false) do |delivery_info, metadata, payload| puts payload isReplied = true end After that producer can publish messages to the exchange through routing key of the requestQueue on consumer side. The message carries a reply-to property to indicate consumer where to reply to. It's the routing key of producer's replyQueue. exchange.publish(\"Hello World!\", :routing_key => requestKey, :content_type => \"text/plain\", :delivery_mode => 1, :reply_to => replyKey) In this example, producer is blocked until it receives the reply, then it will disconnect with the RoboMQ broker. while !isReplied end cancel_ok = consumer.cancel connection.close Consumer The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will listen on its requestQueue. When requests are received, a callback function will be invoked to print the message content and reply according to the reply-to property of request message. This time, we have set manual_ack to true. If reply succeeds, ACK the request message; otherwise, NACK it, so it will be re-queued. As we mentioned in the Producer section, recover_from_connection_close is set to false when connecting to RoboMQ broker. It matters for consumers because recover_from_connection_close will only recover the connection, it won't recreate exchange and queue in case they are gone. Therefore, a more robust approach is letting your code handle reconnecting on its own and keep checking the existence of the subscribed queue. exchange = channel.direct(exchangeName, :auto_delete => true) queue = channel.queue(requestQueue, :exclusive => true, :auto_delete => true) queue.bind(exchange, :routing_key => requestKey) queue.subscribe(:block => false, :manual_ack => true) do |delivery_info, metadata, payload| puts payload #reply according to the reply_to header begin exchange.publish(\"Reply to %s\" % payload, :routing_key => metadata.reply_to, :content_type => \"text/plain\", :delivery_mode => 1) channel.basic_ack(delivery_info.delivery_tag, false) rescue channel.basic_nack(delivery_info.delivery_tag, false, false) end end #keep checking the existence of the subscribed queue while true raise \"Lost the subscribed queue %s\" % requestQueue unless connection.queue_exists?(requestQueue) sleep 1 end Putting it all together producer.rb require \"bunny\" server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" exchangeName = \"testEx\" replyQueue = \"replyQ\" requestKey = \"request\" replyKey = \"reply\" begin #connect connection = Bunny.new(:host => server, :port => port, :vhost => vhost, :user => username, :pass => password, :heartbeat => 60, :recover_from_connection_close => false) connection.start channel = connection.create_channel #listen for reply message exchange = channel.direct(exchangeName, :auto_delete => true) queue = channel.queue(replyQueue, :exclusive => true, :auto_delete => true) queue.bind(exchange, :routing_key => replyKey) isReplied = false consumer = queue.subscribe(:block => false, :manual_ack => false) do |delivery_info, metadata, payload| puts payload isReplied = true end #send request message exchange.publish(\"Hello World!\", :routing_key => requestKey, :content_type => \"text/plain\", :delivery_mode => 1, :reply_to => replyKey) #wait until receives the reply while !isReplied end #close connection once receives the reply cancel_ok = consumer.cancel connection.close rescue Exception => e puts e end consumer.rb require \"bunny\" server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" exchangeName = \"testEx\" requestQueue = \"requestQ\" requestKey = \"request\" while true begin #connect, disable auto-reconnect so as to manually reconnect connection = Bunny.new(:host => server, :port => port, :vhost => vhost, :user => username, :pass => password, :heartbeat => 60, :recover_from_connection_close => false) connection.start channel = connection.create_channel #declare exchange and queue, bind them and consume messages exchange = channel.direct(exchangeName, :auto_delete => true) queue = channel.queue(requestQueue, :exclusive => true, :auto_delete => true) queue.bind(exchange, :routing_key => requestKey) queue.subscribe(:block => false, :manual_ack => true) do |delivery_info, metadata, payload| puts payload #reply according to the reply_to header begin exchange.publish(\"Reply to %s\" % payload, :routing_key => metadata.reply_to, :content_type => \"text/plain\", :delivery_mode => 1) channel.basic_ack(delivery_info.delivery_tag, false) rescue channel.basic_nack(delivery_info.delivery_tag, false, false) end end #keep checking the existence of the subscribed queue while true raise \"Lost the subscribed queue %s\" % requestQueue unless connection.queue_exists?(requestQueue) sleep 1 end rescue Exception => e #reconnect on exception puts \"Exception handled, reconnecting...\\nDetail:\\n%s\" % e #blindly clean old connection begin connection.close end sleep 5 end end Java Prerequisites Java client AMQP library The Java library we use for this example can be found at https://www.rabbitmq.com/java-client.html . Download the library jar file, then import this library in your program import com.rabbitmq.client.*; and compile your source code with the jar file. For example, javac -cp \".:./rabbitmq-client.jar\" Producer.java Consumer.java Run the producer and consumer classes. For example, java -cp \".:./rabbitmq-client.jar\" Consumer java -cp \".:./rabbitmq-client.jar\" Producer Of course, you can eventually compress your producer and consumer classes into jar files. Producer The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. ConnectionFactory factory = new ConnectionFactory(); factory.setHost(server); factory.setPort(port); factory.setVirtualHost(vhost); factory.setUsername(username); factory.setPassword(password); factory.setRequestedHeartbeat(60); connection = factory.newConnection(); channel = connection.createChannel(); Then producer will do what consumer does, listen on the replyQueue on its side. String message = \"Hello World!\"; channel.queueDeclare(replyQueue, false, true, true, null); channel.queueBind(replyQueue, exchangeName, replyKey, null); QueueingConsumer qc = new QueueingConsumer(channel); channel.basicConsume(replyQueue, true, qc); After that producer can publish messages to the exchange through routing key of the requestQueue on consumer side. The message carries a reply-to property to indicate consumer where to reply to. It's the routing key of producer's replyQueue. BasicProperties properties = new BasicProperties.Builder(). contentType(\"text/plain\"). deliveryMode(1). replyTo(replyKey). build(); channel.basicPublish(exchangeName, requestKey, properties, message.getBytes()); Once producer has received the reply, the callback function will disconnect with the RoboMQ broker. QueueingConsumer.Delivery delivery = qc.nextDelivery(); String replyMessage = new String(delivery.getBody()); System.out.println(replyMessage); connection.close(); Consumer The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will listen on its requestQueue. channel.exchangeDeclare(exchangeName, \"direct\", false, true, false, null); channel.queueDeclare(requestQueue, false, true, true, null); channel.queueBind(requestQueue, exchangeName, requestKey, null); QueueingConsumer qc = new QueueingConsumer(channel); channel.basicConsume(requestQueue, false, qc); When requests are received, it will print the message content and reply according to the reply-to property of request message. This time, we have set no-ack to false in basicConsume() . If reply succeeds, ACK the request message; otherwise, NACK it, so it will be re-queued. while (true) { QueueingConsumer.Delivery delivery = qc.nextDelivery(); String message = new String(delivery.getBody()); System.out.println(message); //when receives messages, reply to the reply_to header String replyMessage = \"Reply to \" + message; BasicProperties properties = new BasicProperties.Builder(). contentType(\"text/plain\"). deliveryMode(1). build(); try { channel.basicPublish(exchangeName, delivery.getProperties().getReplyTo(), properties, replyMessage.getBytes()); channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); } catch(Exception e) { channel.basicNack(delivery.getEnvelope().getDeliveryTag(), false, false); } } Putting it all together Producer.java import com.rabbitmq.client.ConnectionFactory; import com.rabbitmq.client.Connection; import com.rabbitmq.client.Channel; import com.rabbitmq.client.QueueingConsumer; import com.rabbitmq.client.AMQP.BasicProperties; public class Producer { private Connection connection; private Channel channel; private static String server = \"hostname\"; private static int port = 5672; private static String vhost = \"yourvhost\"; private static String username = \"username\"; private static String password = \"password\"; private String exchangeName = \"testEx\"; private String replyQueue = \"replyQ\"; private String requestKey = \"request\"; private String replyKey = \"reply\"; private void produce() { try { //connect ConnectionFactory factory = new ConnectionFactory(); factory.setHost(server); factory.setPort(port); factory.setVirtualHost(vhost); factory.setUsername(username); factory.setPassword(password); factory.setRequestedHeartbeat(60); connection = factory.newConnection(); channel = connection.createChannel(); //listen for reply messages String message = \"Hello World!\"; channel.queueDeclare(replyQueue, false, true, true, null); channel.queueBind(replyQueue, exchangeName, replyKey, null); QueueingConsumer qc = new QueueingConsumer(channel); channel.basicConsume(replyQueue, true, qc); //send request message BasicProperties properties = new BasicProperties.Builder(). contentType(\"text/plain\"). deliveryMode(1). replyTo(replyKey). build(); channel.basicPublish(exchangeName, requestKey, properties, message.getBytes()); //receive the reply message QueueingConsumer.Delivery delivery = qc.nextDelivery(); String replyMessage = new String(delivery.getBody()); System.out.println(replyMessage); //disconnect connection.close(); } catch(Exception e) { System.out.println(e); System.exit(-1); } } public static void main(String[] args) { Producer p = new Producer(); p.produce(); } } Consumer.java import com.rabbitmq.client.ConnectionFactory; import com.rabbitmq.client.Connection; import com.rabbitmq.client.Channel; import com.rabbitmq.client.QueueingConsumer; import com.rabbitmq.client.AMQP.BasicProperties; public class Consumer { private Connection connection; private Channel channel; private static String server = \"hostname\"; private static int port = 5672; private static String vhost = \"yourvhost\"; private static String username = \"username\"; private static String password = \"password\"; private String exchangeName = \"testEx\"; private String requestQueue = \"requestQ\"; private String requestKey = \"request\"; private void consume() { while (true) { try { //connect ConnectionFactory factory = new ConnectionFactory(); factory.setHost(server); factory.setPort(port); factory.setVirtualHost(vhost); factory.setUsername(username); factory.setPassword(password); factory.setRequestedHeartbeat(60); connection = factory.newConnection(); channel = connection.createChannel(); //declare exchange and queue, bind them and consume messages channel.exchangeDeclare(exchangeName, \"direct\", false, true, false, null); channel.queueDeclare(requestQueue, false, true, true, null); channel.queueBind(requestQueue, exchangeName, requestKey, null); QueueingConsumer qc = new QueueingConsumer(channel); channel.basicConsume(requestQueue, false, qc); while (true) { QueueingConsumer.Delivery delivery = qc.nextDelivery(); String message = new String(delivery.getBody()); System.out.println(message); //when receives messages, reply to the reply_to header String replyMessage = \"Reply to \" + message; BasicProperties properties = new BasicProperties.Builder(). contentType(\"text/plain\"). deliveryMode(1). build(); try { channel.basicPublish(exchangeName, delivery.getProperties().getReplyTo(), properties, replyMessage.getBytes()); channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); } catch(Exception e) { channel.basicNack(delivery.getEnvelope().getDeliveryTag(), false, false); } } } catch(Exception e) { //reconnect on exception System.out.printf(\"Exception handled, reconnecting...\\nDetail:\\n%s\\n\", e); try { connection.close(); } catch (Exception e1) {} try { Thread.sleep(5000); } catch(Exception e2) {} } } } public static void main(String[] args) { Consumer c = new Consumer(); c.consume(); } } Go Prerequisites Go client AMQP library The Go library we use for this example can be found at https://github.com/streadway/amqp . You can install it through go get github.com/streadway/amqp . Finally, import this library in your program. import \"github.com/streadway/amqp\" The full documentation of this library is at https://godoc.org/github.com/streadway/amqp . Producer The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. connection, err := amqp.DialConfig(fmt.Sprintf(\"amqp://%s:%s@%s:%d/%s\", username, password, server, port, vhost), amqp.Config{Heartbeat: 60 * time.Second}) channel, err := connection.Channel() Then producer will do what consumer does, listen on the replyQueue on its side. queue, err := channel.QueueDeclare(replyQueue, false, true, true, false, nil) err = channel.QueueBind(replyQueue, replyKey, exchangeName, false, nil) messageChan, err := channel.Consume(queue.Name, \"replyConsumer\", true, true, false, false, nil) message := <-messageChan fmt.Println(string(message.Body)) After that producer can publish a message to the exchange through routing key of the requestQueue on consumer side. The message carries a reply-to property to indicate consumer where to reply to. It's the routing key of producer's replyQueue. err = channel.Publish(exchangeName, requestKey, false, false, amqp.Publishing{ContentType: \"text/plain\", DeliveryMode: 1, ReplyTo: replyKey, Body: []byte(\"Hello World!\")}) Producer should be blocked until it receives the reply before exiting. Consumer The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will listen on its requestQueue. err = channel.ExchangeDeclare(exchangeName, \"direct\", false, true, false, false, nil) queue, err := channel.QueueDeclare(requestQueue, false, true, true, false, nil) err = channel.QueueBind(requestQueue, requestKey, exchangeName, false, nil) messageChan, err := channel.Consume(queue.Name, \"requestConsumer\", false, true, false, false, nil) When requests are received, it will print the message content and reply according to the reply-to property of request message. Note that auto-ack has been set to false above. If reply succeeds, ACK the request message; otherwise, NACK it, so it will be re-queued. for message := range messageChan { fmt.Println(string(message.Body)) err = channel.Publish(exchangeName, message.ReplyTo, false, false, amqp.Publishing{ContentType: \"text/plain\", DeliveryMode: 1, Body: append([]byte(\"Reply to \"), message.Body...)}) if err != nil { err = message.Nack(false, true) } else { err = message.Ack(false) } } Putting it all together producer.go package main import ( \"fmt\" \"github.com/streadway/amqp\" \"os\" \"time\" ) var server = \"hostname\" var port = 5672 var vhost = \"yourvhost\" var username = \"username\" var password = \"password\" var exchangeName = \"testEx\" var replyQueue = \"replyQ\" var requestKey = \"request\" var replyKey = \"reply\" func main() { connection, err := amqp.DialConfig(fmt.Sprintf(\"amqp://%s:%s@%s:%d/%s\", username, password, server, port, vhost), amqp.Config{Heartbeat: 60 * time.Second}) if err != nil { fmt.Printf(\"Failed to connect, err: %v\\n\", err) os.Exit(1) } defer connection.Close() channel, err := connection.Channel() if err != nil { fmt.Printf(\"Failed to create channel, err: %v\\n\", err) os.Exit(1) } defer channel.Close() queue, err := channel.QueueDeclare( replyQueue, // name false, // durable true, // auto-delete true, // exclusive false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to declare reply queue, err: %v\\n\", err) os.Exit(1) } err = channel.QueueBind( replyQueue, // queue replyKey, // key exchangeName, // exchange false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to bind reply queue with exchange, err: %v\\n\", err) os.Exit(1) } messageChan, err := channel.Consume( queue.Name, // queue \"replyConsumer\", // consumer tag true, // auto-ack true, // exclusive false, // no-local false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to consume reply messages, err: %v\\n\", err) os.Exit(1) } // use a channel to communicate between goroutines gotReply := make(chan bool) // listen for reply message go func(messageChan <-chan amqp.Delivery, gotReply chan bool) { message := <-messageChan fmt.Println(string(message.Body)) // notify main goroutine it has got the reply gotReply <- true }(messageChan, gotReply) err = channel.Publish( exchangeName, // exchange requestKey, // routing key false, // mandatory false, // immediate amqp.Publishing{ ContentType: \"text/plain\", DeliveryMode: 1, ReplyTo: replyKey, Body: []byte(\"Hello World!\"), }) if err != nil { fmt.Printf(\"Failed to publish request message, err: %v\\n\", err) os.Exit(1) } // block until it has got the reply _ = <-gotReply } consumer.go package main import ( \"fmt\" \"github.com/streadway/amqp\" \"time\" ) var server = \"hostname\" var port = 5672 var vhost = \"yourvhost\" var username = \"username\" var password = \"password\" var exchangeName = \"testEx\" var requestQueue = \"requestQ\" var requestKey = \"request\" func main() { // Infinite loop to auto-reconnect on failure Loop: for { fmt.Println(\"Starting in 5 seconds...\") time.Sleep(5 * time.Second) connection, err := amqp.DialConfig(fmt.Sprintf(\"amqp://%s:%s@%s:%d/%s\", username, password, server, port, vhost), amqp.Config{Heartbeat: 60 * time.Second}) if err != nil { fmt.Printf(\"Failed to connect, err: %v\\n\", err) continue Loop } defer connection.Close() channel, err := connection.Channel() if err != nil { fmt.Printf(\"Failed to create channel, err: %v\\n\", err) continue Loop } defer channel.Close() err = channel.ExchangeDeclare( exchangeName, // name \"direct\", // type false, // durable true, // audo-delete false, // internal false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to declare exchange, err: %v\\n\", err) continue Loop } queue, err := channel.QueueDeclare( requestQueue, // name false, // durable true, // auto-delete true, // exclusive false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to declare request queue, err: %v\\n\", err) continue Loop } err = channel.QueueBind( requestQueue, // queue requestKey, // key exchangeName, // exchange false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to bind request queue with exchange, err: %v\\n\", err) continue Loop } messageChan, err := channel.Consume( queue.Name, // queue \"requestConsumer\", // consumer tag false, // auto-ack true, // exclusive false, // no-local false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to consume request messages, err: %v\\n\", err) continue Loop } fmt.Println(\"Started consuming messages.\") for message := range messageChan { fmt.Println(string(message.Body)) // on receiving request messages, reply to the reply_to header err = channel.Publish( exchangeName, // exchange message.ReplyTo, // routing key false, // mandatory false, // immediate amqp.Publishing{ ContentType: \"text/plain\", DeliveryMode: 1, Body: append([]byte(\"Reply to \"), message.Body...), }) if err != nil { fmt.Printf(\"Failed to publish reply message, err: %v\\n\", err) err = message.Nack( false, // multiple true, // requeued ) if err != nil { fmt.Printf(\"Failed to NACK request message, err: %v\\n\", err) break } } else { err = message.Ack( false, // multiple ) if err != nil { fmt.Printf(\"Failed to ACK request message, err: %v\\n\", err) break } } } } } C Prerequisites C client AMQP library Robomq.io is built on AMQP, an open, general-purpose protocol for messaging. There are a number of clients for AMQP in many different languages. However, we'll choose a simple C-language AMQP client library written for use with v2.0+ of the RabbitMQ broker. https://github.com/alanxz/rabbitmq-c/tree/master/librabbitmq You can copy librabbitmq subfolder from latest release located here on GitHub: https://github.com/alanxz/rabbitmq-c Alternatively, thanks to Subversion support in GitHub, you can use svn export directly: svn export https://github.com/alanxz/rabbitmq-c/trunk/librabbitmq Copy the librabbitmq package into your working directory: cp librabbitmq ./ Also copy all source files and Makefile from RoboMQ SDK at https://github.com/robomq/robomq.io/tree/master/sdk/AMQP/C into the same directory. Now your working directory should have the content as bellow: broadcast config.h librabbitmq Makefile one-to-one request-reply routing-key topic Use the Makefile to compile under a Linux terminal. Run make type={sub-directory} to compile the producer and consumer under the sub-directory. Before compiling the next sub-directory, run make clean to clean up the compiled files. Note that these examples provide a simple client implementation to get started but does not go into detailed description of all flags passed into the AMQP methods. A complete reference to RabbitMQ's implementaton of version 0-9-1 of the AMQP specification can be found in this guide. https://www.rabbitmq.com/amqp-0-9-1-reference.html Producer For request-reply messaging pattern, the producer also uses direct exchange, however, a the reply queue will be created and bound to an exchange allowing more than one consumer to subscribe to and send replies asynchronously. Therefore, after publishing a message, the producer will simply wait on a separate queue bound to with with key \"reply_key\" for replies sent by receiving consumer. char queue_name[] = \"reply-queue\"; char binding_key[] = \"reply_key\"; // Declaring exchange amqp_exchange_declare(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(exchange_type), passive, durable, auto_delete, internal, amqp_empty_table); // Declaring queue amqp_queue_declare_ok_t *r = amqp_queue_declare(conn, channel, amqp_cstring_bytes(queue_name), passive, durable, exclusive, auto_delete, amqp_empty_table); reply_queue = amqp_bytes_malloc_dup(r->queue); // Binding to queue amqp_queue_bind(conn, channel, reply_queue, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(binding_key), amqp_empty_table); // Now wait for the reply message amqp_basic_consume(conn, channel, reply_queue, amqp_empty_bytes, no_local, no_ack, exclusive, amqp_empty_table); while (1) { amqp_rpc_reply_t result; amqp_envelope_t envelope; amqp_maybe_release_buffers(conn); result = amqp_consume_message(conn, &envelope, NULL, 0); if (AMQP_RESPONSE_NORMAL == result.reply_type) { printf(\"Received reply message size: %d\\nbody: %s\\n\", (int)envelope.message.body.len, (char *)envelope.message.body.bytes); amqp_destroy_envelope(&envelope); } } Consumer This consumer after successfully receiving message from producer will simply send a reply with routing key \"reply_key\" indicating that exchange will deliver reply directly to the reply queue subscribed to by the producer. char routing_key[] = \"reply_key\"; result = amqp_consume_message(conn, &envelope, NULL, 0); if (AMQP_RESPONSE_NORMAL == result.reply_type) { // Now sending reply amqp_basic_publish(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(routing_key), 0, 0, &props, amqp_cstring_bytes(\"Hello back at you\")); amqp_destroy_envelope(&envelope); } At this point, consumer should start consuming messages. Putting it all together The full code below includes some basic AMQP error handling for consumer that is useful when declaring exchanges and queues. In addition, main receiver loop attempts to reconnect upon network connection failure. producer.c #include <stdlib.h> #include <stdio.h> #include <string.h> #include <amqp_tcp_socket.h> #include <amqp.h> #include <amqp_framing.h> amqp_connection_state_t mqconnect() { amqp_connection_state_t conn = amqp_new_connection(); amqp_socket_t *socket = NULL; char hostname[] = \"localhost\"; // RoboMQ hostname int port = 5672; //default char user[] = \"guest\"; // RoboMQ username char password[] = \"guest\"; // RoboMQ password char vhost[] = \"/\"; // RoboMQ account vhost amqp_channel_t channel = 1; int channel_max = 0; int frame_max = 131072; int heartbeat = 60; int status = 0; // Opening socket socket = amqp_tcp_socket_new(conn); status = amqp_socket_open(socket, hostname, port); if (status) { printf(\"Error opening TCP socket, status = %d, exiting.\", status); } amqp_login(conn, vhost, channel_max, frame_max, heartbeat, AMQP_SASL_METHOD_PLAIN, user, password); amqp_channel_open(conn, channel); return conn; } amqp_bytes_t mqdeclare(amqp_connection_state_t conn) { amqp_bytes_t queue; amqp_channel_t channel = 1; amqp_boolean_t passive = 0; amqp_boolean_t durable = 0; amqp_boolean_t exclusive = 0; amqp_boolean_t auto_delete = 1; amqp_boolean_t internal = 0; char exchange_name[] = \"hello-exchange\"; char exchange_type[] = \"direct\"; char queue_name[] = \"reply-queue\"; char binding_key[] = \"reply_key\"; amqp_rpc_reply_t reply; // Declaring exchange amqp_exchange_declare(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(exchange_type), passive, durable, auto_delete, internal, amqp_empty_table); reply = amqp_get_rpc_reply(conn); if(reply.reply_type != AMQP_RESPONSE_NORMAL) { amqp_connection_close_t *m = (amqp_connection_close_t *) reply.reply.decoded; fprintf(stderr, \"%s: server connection error %d, message: %.*s\\n\", \"Error declaring exchange\", m->reply_code, (int) m->reply_text.len, (char *) m->reply_text.bytes); exit(1); } // Declaring queue amqp_queue_declare_ok_t *r = amqp_queue_declare(conn, channel, amqp_cstring_bytes(queue_name), passive, durable, exclusive, auto_delete, amqp_empty_table); reply = amqp_get_rpc_reply(conn); if(reply.reply_type != AMQP_RESPONSE_NORMAL) { amqp_connection_close_t *m = (amqp_connection_close_t *) reply.reply.decoded; fprintf(stderr, \"%s: server connection error %d, message: %.*s\\n\", \"Error declaring queue\", m->reply_code, (int) m->reply_text.len, (char *) m->reply_text.bytes); exit(1); } queue = amqp_bytes_malloc_dup(r->queue); // Binding to queue amqp_queue_bind(conn, channel, queue, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(binding_key), amqp_empty_table); return queue; } int main(int argc, char const *const *argv) { amqp_connection_state_t conn; amqp_bytes_t reply_queue; amqp_channel_t channel = 1; amqp_basic_properties_t props; props._flags = AMQP_BASIC_CONTENT_TYPE_FLAG | AMQP_BASIC_DELIVERY_MODE_FLAG; props.content_type = amqp_cstring_bytes(\"text/plain\"); props.delivery_mode = 1; /* non-persistent delivery mode */ amqp_boolean_t mandatory = 0; amqp_boolean_t immediate = 0; amqp_boolean_t no_local = 0; amqp_boolean_t no_ack = 1; amqp_boolean_t exclusive = 0; char exchange_name[] = \"hello-exchange\"; char routing_key[] = \"request_key\"; char *msg_body = \"Hello\\n\"; int result; conn = mqconnect(); reply_queue = mqdeclare(conn); // Sending message result = amqp_basic_publish(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(routing_key), mandatory, immediate, &props, amqp_cstring_bytes(msg_body)); // Now wait for the reply message amqp_basic_consume(conn, channel, reply_queue, amqp_empty_bytes, no_local, no_ack, exclusive, amqp_empty_table); while (1) { amqp_rpc_reply_t result; amqp_envelope_t envelope; amqp_maybe_release_buffers(conn); result = amqp_consume_message(conn, &envelope, NULL, 0); if (AMQP_RESPONSE_NORMAL == result.reply_type) { printf(\"Received reply message size: %d\\nbody: %s\\n\", (int)envelope.message.body.len, (char *)envelope.message.body.bytes); amqp_destroy_envelope(&envelope); } } // Closing connection amqp_connection_close(conn, AMQP_REPLY_SUCCESS); amqp_destroy_connection(conn); return 0; } consumer.c #include <stdlib.h> #include <stdio.h> #include <string.h> #include <amqp_tcp_socket.h> #include <amqp.h> #include <amqp_framing.h> amqp_connection_state_t mqconnect() { amqp_connection_state_t conn = amqp_new_connection(); amqp_socket_t *socket = NULL; char hostname[] = \"localhost\"; // RoboMQ hostname int port = 5672; //default char user[] = \"guest\"; // RoboMQ username char password[] = \"guest\"; // RoboMQ password char vhost[] = \"/\"; // RoboMQ account vhost amqp_channel_t channel = 1; amqp_rpc_reply_t reply; int channel_max = 0; int frame_max = 131072; int heartbeat = 60; int status = 0; // Opening socket socket = amqp_tcp_socket_new(conn); status = amqp_socket_open(socket, hostname, port); if (status) { printf(\"Error opening TCP socket, status = %d\\n\", status); } reply = amqp_login(conn, vhost, channel_max, frame_max, heartbeat, AMQP_SASL_METHOD_PLAIN, user, password); if(reply.reply_type != AMQP_RESPONSE_NORMAL) { fprintf(stderr, \"%s: server connection reply code: %d\\n\", \"Error logging in\", reply.reply_type); } amqp_channel_open(conn, channel); return conn; } amqp_bytes_t mqdeclare(amqp_connection_state_t conn, const char *exchange_name, const char *queue_name) { amqp_bytes_t queue; amqp_channel_t channel = 1; amqp_boolean_t passive = 0; amqp_boolean_t durable = 0; amqp_boolean_t exclusive = 0; amqp_boolean_t auto_delete = 1; amqp_boolean_t internal = 0; char exchange_type[] = \"direct\"; char binding_key[] = \"request_key\"; amqp_rpc_reply_t reply; // Declaring exchange amqp_exchange_declare(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(exchange_type), passive, durable, auto_delete, internal, amqp_empty_table); reply = amqp_get_rpc_reply(conn); if(reply.reply_type != AMQP_RESPONSE_NORMAL) { amqp_connection_close_t *m = (amqp_connection_close_t *) reply.reply.decoded; if(NULL != m) { fprintf(stderr, \"%s: server connection error %d, message: %.*s\\n\", \"Error declaring exchange\", m->reply_code, (int) m->reply_text.len, (char *) m->reply_text.bytes); } } // Declaring queue amqp_queue_declare_ok_t *r = amqp_queue_declare(conn, channel, amqp_cstring_bytes(queue_name), passive, durable, exclusive, auto_delete, amqp_empty_table); reply = amqp_get_rpc_reply(conn); if(reply.reply_type != AMQP_RESPONSE_NORMAL) { fprintf(stderr, \"%s: server connection reply code: %d\\n\", \"Error declaring queue\", reply.reply_type); } else { queue = amqp_bytes_malloc_dup(r->queue); // Binding to queue amqp_queue_bind(conn, channel, queue, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(binding_key), amqp_empty_table); } return queue; } int main(int argc, char const *const *argv) { amqp_connection_state_t conn; amqp_bytes_t queue; amqp_channel_t channel = 1; amqp_boolean_t no_local = 0; amqp_boolean_t no_ack = 1; amqp_boolean_t exclusive = 0; char exchange_name[] = \"hello-exchange\"; char routing_key[] = \"reply_key\"; amqp_basic_properties_t props; props._flags = AMQP_BASIC_CONTENT_TYPE_FLAG | AMQP_BASIC_DELIVERY_MODE_FLAG; props.content_type = amqp_cstring_bytes(\"text/plain\"); props.delivery_mode = 1; /* non-persistent delivery mode */ char queue_name[] = \"hello-queue\"; int retry_time = 5; // retry time in seconds conn = mqconnect(); queue = mqdeclare(conn, &exchange_name[0], &queue_name[0]); // Consuming the message amqp_basic_consume(conn, channel, queue, amqp_empty_bytes, no_local, no_ack, exclusive, amqp_empty_table); while (1) { amqp_rpc_reply_t result; amqp_envelope_t envelope; amqp_maybe_release_buffers(conn); result = amqp_consume_message(conn, &envelope, NULL, 0); if (AMQP_RESPONSE_NORMAL != result.reply_type) { printf(\"Consumer AMQP failure occurred, response code = %d, retrying in %d seconds...\\n\", result.reply_type, retry_time); // Closing current connection before reconnecting amqp_connection_close(conn, AMQP_CONNECTION_FORCED); amqp_destroy_connection(conn); // Reconnecting on exception conn = mqconnect(); queue = mqdeclare(conn, &exchange_name[0], &queue_name[0]); amqp_basic_consume(conn, channel, queue, amqp_empty_bytes, no_local, no_ack, exclusive, amqp_empty_table); sleep(retry_time); } else { printf(\"Received message size: %d\\nbody: %s\\n\", (int)envelope.message.body.len, (char *)envelope.message.body.bytes); // Now sending reply amqp_basic_publish(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(routing_key), 0, 0, &props, amqp_cstring_bytes(\"Hello back at you\")); amqp_destroy_envelope(&envelope); } } return 0; }","title":"Request and reply"},{"location":"request-reply/#request-reply","text":"This is a two-way message communication also using direct exchange but unlike the RPC pattern, the reply queue is bound to an exchange allowing more than one client to subscribe to and process the replies asynchronously. In addition any service application can process a request from any client. In this situation, both producer and consumer are capable of publishing and consuming messages. Browse the chapter of AMQP Introduction first if you're new to AMQP. Read the chapter of Key based message routing before reading this chapter.","title":"Request - Reply"},{"location":"request-reply/#python","text":"","title":"Python"},{"location":"request-reply/#prerequisites","text":"Python client AMQP library The Python library we use for this example can be found at https://github.com/pika/pika . You can install it through sudo pip install pika . Finally, import this library in your program. import pika The full documentation of this library is at https://pika.readthedocs.org/en/0.9.14/ . pika library is not thread safe. Do not use a connection or channel across threads.","title":"Prerequisites"},{"location":"request-reply/#producer","text":"The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. credentials = pika.PlainCredentials(username, password) connection = pika.BlockingConnection(pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60)) channel = connection.channel() Then producer will do what consumer does, listen on the replyQueue on its side. channel.queue_declare(queue = replyQueue, exclusive = True, auto_delete = True) channel.queue_bind(exchange = exchangeName, queue = replyQueue, routing_key = replyKey) channel.basic_consume(consumer_callback = onMessage, queue = replyQueue, no_ack = True) channel.start_consuming() After that producer can publish messages to the exchange through routing key of the requestQueue on consumer side. The message carries a reply-to property to indicate consumer where to reply to. It's the routing key of producer's replyQueue. properties = pika.spec.BasicProperties(content_type = \"text/plain\", delivery_mode = 1, reply_to = replyKey) channel.basic_publish(exchange = exchangeName, routing_key = requestKey, body = \"Hello World!\", properties = properties) Once producer has received the reply, the callback function will disconnect with the RoboMQ broker. def onMessage(channel, method, properties, body): print body channel.stop_consuming() connection.close()","title":"Producer"},{"location":"request-reply/#consumer","text":"The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will listen on its requestQueue. channel.exchange_declare(exchange = exchangeName, exchange_type = \"direct\", auto_delete = True) channel.queue_declare(queue = requestQueue, exclusive = True, auto_delete = True) channel.queue_bind(exchange = exchangeName, queue = requestQueue, routing_key = requestKey) channel.basic_consume(consumer_callback = onMessage, queue = requestQueue, no_ack = False) channel.start_consuming() When requests are received, a callback function will be invoked to print the message content and reply according to the reply-to property of request message. This time, we have set no_ack to false. If reply succeeds, ACK the request message; otherwise, NACK it, so it will be re-queued. def onMessage(channel, method, properties, body): print body try: replyProp = pika.BasicProperties(content_type = \"text/plain\", delivery_mode = 1) channel.basic_publish(exchange = exchangeName, routing_key = properties.reply_to, properties = replyProp, body = \"Reply to %s\" % (body)) channel.basic_ack(delivery_tag = method.delivery_tag) except: channel.basic_nack(delivery_tag = method.delivery_tag)","title":"Consumer"},{"location":"request-reply/#putting-it-all-together","text":"producer.py import pika import thread import time server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" exchangeName = \"testEx\" replyQueue = \"replyQ\" requestKey = \"request\" replyKey = \"reply\" #callback funtion on receiving reply messages def onMessage(channel, method, properties, body): print body #close connection once receives the reply channel.stop_consuming() connection.close() #listen for reply messages def listen(): channel.queue_declare(queue = replyQueue, exclusive = True, auto_delete = True) channel.queue_bind(exchange = exchangeName, queue = replyQueue, routing_key = replyKey) channel.basic_consume(consumer_callback = onMessage, queue = replyQueue, no_ack = True) channel.start_consuming() try: #connect credentials = pika.PlainCredentials(username, password) connection = pika.BlockingConnection(pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60)) channel = connection.channel() thread.start_new_thread(listen, ()) time.sleep(1) #give time for it to start consuming #send request message properties = pika.spec.BasicProperties(content_type = \"text/plain\", delivery_mode = 1, reply_to = replyKey) channel.basic_publish(exchange = exchangeName, routing_key = requestKey, body = \"Hello World!\", properties = properties) #block until receives reply message while connection.is_open: pass except Exception, e: print e consumer.py import pika import time server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" exchangeName = \"testEx\" requestQueue = \"requestQ\" requestKey = \"request\" #callback funtion on receiving request messages, reply to the reply_to header def onMessage(channel, method, properties, body): print body try: replyProp = pika.BasicProperties(content_type = \"text/plain\", delivery_mode = 1) channel.basic_publish(exchange = exchangeName, routing_key = properties.reply_to, properties = replyProp, body = \"Reply to %s\" % (body)) channel.basic_ack(delivery_tag = method.delivery_tag) except: channel.basic_nack(delivery_tag = method.delivery_tag) while True: try: #connect credentials = pika.PlainCredentials(username, password) connection = pika.BlockingConnection(pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60)) channel = connection.channel() #declare exchange and queue, bind them and consume messages channel.exchange_declare(exchange = exchangeName, exchange_type = \"direct\", auto_delete = True) channel.queue_declare(queue = requestQueue, exclusive = True, auto_delete = True) channel.queue_bind(exchange = exchangeName, queue = requestQueue, routing_key = requestKey) channel.basic_consume(consumer_callback = onMessage, queue = requestQueue, no_ack = False) channel.start_consuming() except Exception, e: #reconnect on exception print \"Exception handled, reconnecting...\\nDetail:\\n%s\" % e try: connection.close() except: pass time.sleep(5)","title":"Putting it all together"},{"location":"request-reply/#nodejs","text":"","title":"Node.js"},{"location":"request-reply/#prerequisites_1","text":"Node.js client AMQP library The Node.js library we use for this example can be found at https://github.com/squaremo/amqp.node . You can install the library through sudo npm install amqplib . Finally, require this library in your program. var amqp = require(\"amqplib\"); The full documentation of this library is at https://www.squaremobius.net/amqp.node/doc/channel_api.html .","title":"Prerequisites"},{"location":"request-reply/#producer_1","text":"The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. producer = amqp.connect(\"amqp://\" + username + \":\" + password + \"@\" + server + \":\" + port + \"/\" + vhost + \"?heartbeat=60\"); producer.then(function(conn) { return conn.createConfirmChannel().then(successCallback); }).then(null, failureCallback); Then producer will do what consumer does, listen on the replyQueue on its side. Once producer has received the reply, it will disconnect with the RoboMQ broker. ch.assertQueue(replyQueue, {durable: false, autoDelete: true, exclusive: true}); ch.bindQueue(replyQueue, exchangeName, replyKey); ch.consume(replyQueue, function(message) { console.log(message.content.toString()); conn.close(); }, {noAck: true}); After that producer can publish messages to the exchange through routing key of the requestQueue on consumer side. The message carries a reply-to property to indicate consumer where to reply to. It's the routing key of producer's replyQueue. ch.publish(exchangeName, requestKey, content = new Buffer(\"Hello World!\"), options = {contentType: \"text/plain\", deliveryMode: 1, replyTo: replyKey}, callback);","title":"Producer"},{"location":"request-reply/#consumer_1","text":"The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will listen on its requestQueue. When requests are received, a callback function will be invoked to print the message content and reply according to the reply-to property of request message. This time, we have set noAck to false. If reply succeeds, ACK the request message; otherwise, NACK it, so it will be re-queued. ch.assertExchange(exchangeName, \"direct\", {durable: false, autoDelete: true}); ch.assertQueue(requestQueue, {durable: false, autoDelete: true, exclusive: true}); ch.bindQueue(requestQueue, exchangeName, requestKey); ch.consume(requestQueue, function(message) { console.log(message.content.toString()); ch.publish(exchangeName, message.properties.replyTo, new Buffer(\"Reply to \" + message.content.toString()), options = {contentType: \"text/plain\", deliveryMode: 1}, function(err, ok) { if (err != null) { ch.nack(message); } else { ch.ack(message); } }); }, {noAck: false});","title":"Consumer"},{"location":"request-reply/#putting-it-all-together_1","text":"producer.js var amqp = require(\"amqplib\"); var server = \"hostname\"; var port = \"5672\"; var vhost = \"yourvhost\"; //for \"/\" vhost, use \"%2f\" instead var username = \"username\"; var password = \"password\"; var exchangeName = \"testEx\"; var replyQueue = \"replyQ\"; var requestKey = \"request\"; var replyKey = \"reply\"; producer = amqp.connect(\"amqp://\" + username + \":\" + password + \"@\" + server + \":\" + port + \"/\" + vhost + \"?heartbeat=60\"); producer.then(function(conn) { return conn.createChannel().then(function(ch) { //listen for reply messages ch.assertQueue(replyQueue, {durable: false, autoDelete: true, exclusive: true}); ch.bindQueue(replyQueue, exchangeName, replyKey); ch.consume(replyQueue, function(message) { //callback funtion on receiving reply messages console.log(message.content.toString()); //close connection once receives the reply conn.close(); }, {noAck: true}); //send the request message after 1 second setTimeout(function() { ch.publish(exchangeName, requestKey, content = new Buffer(\"Hello World!\"), options = {contentType: \"text/plain\", deliveryMode: 1, replyTo: replyKey}, function(err, ok) { if (err != null) { console.error(\"Error: failed to send message\\n\" + err); } }); }, 1000); }); }).then(null, function(err) { console.error(err); }); consumer.js var amqp = require(\"amqplib\"); var domain = require(\"domain\"); var server = \"hostname\"; var port = \"5672\"; var vhost = \"yourvhost\"; //for \"/\" vhost, use \"%2f\" instead var username = \"username\"; var password = \"password\"; var exchangeName = \"testEx\"; var requestQueue = \"requestQ\"; var requestKey = \"request\"; //use domain module to handle reconnecting var consumer = null; var dom = domain.create(); dom.on(\"error\", relisten); dom.run(listen); function listen() { consumer = amqp.connect(\"amqp://\" + username + \":\" + password + \"@\" + server + \":\" + port + \"/\" + vhost + \"?heartbeat=60\"); consumer.then(function(conn) { return conn.createChannel().then(function(ch) { ch.assertExchange(exchangeName, \"direct\", {durable: false, autoDelete: true}); ch.assertQueue(requestQueue, {durable: false, autoDelete: true, exclusive: true}); ch.bindQueue(requestQueue, exchangeName, requestKey); ch.consume(requestQueue, function(message) { //callback funtion on receiving messages, reply to the reply_to header console.log(message.content.toString()); ch.publish(exchangeName, message.properties.replyTo, new Buffer(\"Reply to \" + message.content.toString()), options = {contentType: \"text/plain\", deliveryMode: 1}, function(err, ok) { if (err != null) { ch.nack(message); } else { ch.ack(message); } }); }, {noAck: false}); }); }).then(null, function(err) { console.error(\"Exception handled, reconnecting...\\nDetail:\\n\" + err); setTimeout(listen, 5000); }); } function relisten() { consumer.then(function(conn) { conn.close(); }); setTimeout(listen, 5000); }","title":"Putting it all together"},{"location":"request-reply/#php","text":"","title":"PHP"},{"location":"request-reply/#prerequisite","text":"PHP client AMQP library The PHP library we use for this example can be found at https://github.com/videlalvaro/php-amqplib . It uses composer to install in a few steps. Add a composer.json file to your project: { \"require\": { \"videlalvaro/php-amqplib\": \"2.2.*\" } } Download the latest composer in the same path: curl -sS https://getcomposer.org/installer | php Install the library through composer: ./composer.phar install Finally, require this library in your program and use the classes. require_once __DIR__ . '/../vendor/autoload.php'; //directory of library folder use PhpAmqpLib\\Connection\\AMQPConnection; use PhpAmqpLib\\Message\\AMQPMessage;","title":"Prerequisite"},{"location":"request-reply/#producer_2","text":"The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. $connection = new AMQPConnection($server, $port, $username, $password, $vhost, $heartbeat = 60); $channel = $connection->channel(); Then producer will do what consumer does, listen on the replyQueue on its side. $channel->queue_declare($replyQueue, false, false, $exclusive = true, $auto_delete = true); $channel->queue_bind($replyQueue, $exchangeName, $replyKey); $consumerTag = $channel->basic_consume($replyQueue, \"\", false, $no_ack = true, false, false, $callback = $onMessage); After that producer can publish messages to the exchange through routing key of the requestQueue on consumer side. The message carries a reply-to property to indicate consumer where to reply to. It's the routing key of producer's replyQueue. $message = new AMQPMessage(\"Hello World!\", array(\"content_type\" => \"text/plain\", \"delivery_mode\" => 1, \"reply_to\" => $replyKey)); $channel->basic_publish($message, $exchangeName, $requestKey); Once producer has received the reply, the callback function will disconnect with the RoboMQ broker. $onMessage = function ($message) { echo $message->body.PHP_EOL; $channel->basic_cancel($consumerTag); };","title":"Producer"},{"location":"request-reply/#consumer_2","text":"The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will listen on its requestQueue. $channel->exchange_declare($exchangeName, $type = \"direct\", false, false, $auto_delete = true); $channel->queue_declare($requestQueue, false, false, $exclusive = true, $auto_delete = true); $channel->queue_bind($requestQueue, $exchangeName, $requestKey); $channel->basic_consume($requestQueue, \"\", false, $no_ack = false, false, false, $callback = $onMessage); When requests are received, a callback function will be invoked to print the message content and reply according to the reply-to property of request message. This time, we have set no_ack to false. If reply succeeds, ACK the request message; otherwise, NACK it, so it will be re-queued. $onMessage = function ($message) { echo $message->body.PHP_EOL; try { $replyMessage = new AMQPMessage(\"Reply to \".$message->body, array(\"content_type\" => \"text/plain\", \"delivery_mode\" => 1)); $channel->basic_publish($replyMessage, $exchangeName, $message->get(\"reply_to\")); $channel->basic_ack($message->delivery_info[\"delivery_tag\"]); } catch (Exception $e) { $channel->basic_nack($message->delivery_info[\"delivery_tag\"]); } };","title":"Consumer"},{"location":"request-reply/#putting-it-together","text":"producer.php <?php require_once __DIR__ . '/../vendor/autoload.php'; //directory of library folder use PhpAmqpLib\\Connection\\AMQPConnection; use PhpAmqpLib\\Message\\AMQPMessage; $GLOBALS[\"channel\"] = $channel; $GLOBALS[\"consumerTag\"] = $consumerTag; $server = \"hostname\"; $port = 5672; $vhost = \"yourvhost\"; $username = \"username\"; $password = \"password\"; $exchangeName = \"testEx\"; $replyQueue = \"replyQ\"; $requestKey = \"request\"; $replyKey = \"reply\"; //callback funtion on receiving reply messages $onMessage = function ($message) { echo $message->body.PHP_EOL; //stop consuming once receives the reply $GLOBALS[\"channel\"]->basic_cancel($GLOBALS[\"consumerTag\"]); }; try { //connect $connection = new AMQPConnection($server, $port, $username, $password, $vhost, $heartbeat = 60); $channel = $connection->channel(); //listen for reply messages $channel->queue_declare($replyQueue, false, false, $exclusive = true, $auto_delete = true); $channel->queue_bind($replyQueue, $exchangeName, $replyKey); $consumerTag = $channel->basic_consume($replyQueue, \"\", false, $no_ack = true, false, false, $callback = $onMessage); //send request message $message = new AMQPMessage(\"Hello World!\", array(\"content_type\" => \"text/plain\", \"delivery_mode\" => 1, \"reply_to\" => $replyKey)); $channel->basic_publish($message, $exchangeName, $requestKey); //start consuming while(count($channel->callbacks)) { $channel->wait(); } //disconnect $connection->close(); } catch(Exception $e) { echo $e.PHP_EOL; } ?> consumer.php <?php require_once __DIR__.\"/../vendor/autoload.php\"; //directory of library folder use PhpAmqpLib\\Connection\\AMQPConnection; use PhpAmqpLib\\Message\\AMQPMessage; $GLOBALS[\"channel\"] = $channel; $GLOBALS[\"exchangeName\"] = $exchangeName; $server = \"hostname\"; $port = 5672; $vhost = \"yourvhost\"; $username = \"username\"; $password = \"password\"; $exchangeName = \"testEx\"; $requestQueue = \"requestQ\"; $requestKey = \"request\"; //callback funtion on receiving request messages, reply to the reply_to header $onMessage = function ($message) { echo $message->body.PHP_EOL; try { $replyMessage = new AMQPMessage(\"Reply to \".$message->body, array(\"content_type\" => \"text/plain\", \"delivery_mode\" => 1)); $GLOBALS[\"channel\"]->basic_publish($replyMessage, $GLOBALS[\"exchangeName\"], $message->get(\"reply_to\")); $GLOBALS[\"channel\"]->basic_ack($message->delivery_info[\"delivery_tag\"]); } catch (Exception $e) { $GLOBALS[\"channel\"]->basic_nack($message->delivery_info[\"delivery_tag\"]); } }; while (true) { try { //connect $connection = new AMQPConnection($server, $port, $username, $password, $vhost, $heartbeat = 60); $channel = $connection->channel(); //declare exchange and queue, bind them and consume messages $channel->exchange_declare($exchangeName, $type = \"direct\", false, false, $auto_delete = true); $channel->queue_declare($requestQueue, false, false, $exclusive = true, $auto_delete = true); $channel->queue_bind($requestQueue, $exchangeName, $requestKey); $channel->basic_consume($requestQueue, \"\", false, $no_ack = false, false, false, $callback = $onMessage); //start consuming while(count($channel->callbacks)) { $channel->wait(); } } catch(Exception $e) { //reconnect on exception echo \"Exception handled, reconnecting...\\nDetail:\\n\".$e.PHP_EOL; if ($connection != null) { try { $connection->close(); } catch (Exception $e1) {} } sleep(5); } } ?>","title":"Putting it together"},{"location":"request-reply/#ruby","text":"","title":"Ruby"},{"location":"request-reply/#prerequisites_2","text":"Ruby client AMQP library The Ruby library we use for this example can be found at http://rubybunny.info/ . With Ruby version >= 2.0, you can install it through sudo gem install bunny . Finally, import this library in your program. require \"bunny\" The full documentation of this library is at http://rubybunny.info/articles/guides.html . We recommend combining the documentation with the source code of this library when you use it because some of the documentation out there is not being updated timely from our observation.","title":"Prerequisites"},{"location":"request-reply/#producer_3","text":"The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. Although the library provides a connection property named recover_from_connection_close , we discourage you to use it. The reason will be explained in the Consumer section. connection = Bunny.new(:host => server, :port => port, :vhost => vhost, :user => username, :pass => password, :heartbeat => 60, :recover_from_connection_close => false) connection.start channel = connection.create_channel Then producer will do what consumer does, listen on the replyQueue on its side. exchange = channel.direct(exchangeName, :auto_delete => true) queue = channel.queue(replyQueue, :exclusive => true, :auto_delete => true) queue.bind(exchange, :routing_key => replyKey) isReplied = false consumer = queue.subscribe(:block => false, :manual_ack => false) do |delivery_info, metadata, payload| puts payload isReplied = true end After that producer can publish messages to the exchange through routing key of the requestQueue on consumer side. The message carries a reply-to property to indicate consumer where to reply to. It's the routing key of producer's replyQueue. exchange.publish(\"Hello World!\", :routing_key => requestKey, :content_type => \"text/plain\", :delivery_mode => 1, :reply_to => replyKey) In this example, producer is blocked until it receives the reply, then it will disconnect with the RoboMQ broker. while !isReplied end cancel_ok = consumer.cancel connection.close","title":"Producer"},{"location":"request-reply/#consumer_3","text":"The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will listen on its requestQueue. When requests are received, a callback function will be invoked to print the message content and reply according to the reply-to property of request message. This time, we have set manual_ack to true. If reply succeeds, ACK the request message; otherwise, NACK it, so it will be re-queued. As we mentioned in the Producer section, recover_from_connection_close is set to false when connecting to RoboMQ broker. It matters for consumers because recover_from_connection_close will only recover the connection, it won't recreate exchange and queue in case they are gone. Therefore, a more robust approach is letting your code handle reconnecting on its own and keep checking the existence of the subscribed queue. exchange = channel.direct(exchangeName, :auto_delete => true) queue = channel.queue(requestQueue, :exclusive => true, :auto_delete => true) queue.bind(exchange, :routing_key => requestKey) queue.subscribe(:block => false, :manual_ack => true) do |delivery_info, metadata, payload| puts payload #reply according to the reply_to header begin exchange.publish(\"Reply to %s\" % payload, :routing_key => metadata.reply_to, :content_type => \"text/plain\", :delivery_mode => 1) channel.basic_ack(delivery_info.delivery_tag, false) rescue channel.basic_nack(delivery_info.delivery_tag, false, false) end end #keep checking the existence of the subscribed queue while true raise \"Lost the subscribed queue %s\" % requestQueue unless connection.queue_exists?(requestQueue) sleep 1 end","title":"Consumer"},{"location":"request-reply/#putting-it-all-together_2","text":"producer.rb require \"bunny\" server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" exchangeName = \"testEx\" replyQueue = \"replyQ\" requestKey = \"request\" replyKey = \"reply\" begin #connect connection = Bunny.new(:host => server, :port => port, :vhost => vhost, :user => username, :pass => password, :heartbeat => 60, :recover_from_connection_close => false) connection.start channel = connection.create_channel #listen for reply message exchange = channel.direct(exchangeName, :auto_delete => true) queue = channel.queue(replyQueue, :exclusive => true, :auto_delete => true) queue.bind(exchange, :routing_key => replyKey) isReplied = false consumer = queue.subscribe(:block => false, :manual_ack => false) do |delivery_info, metadata, payload| puts payload isReplied = true end #send request message exchange.publish(\"Hello World!\", :routing_key => requestKey, :content_type => \"text/plain\", :delivery_mode => 1, :reply_to => replyKey) #wait until receives the reply while !isReplied end #close connection once receives the reply cancel_ok = consumer.cancel connection.close rescue Exception => e puts e end consumer.rb require \"bunny\" server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" exchangeName = \"testEx\" requestQueue = \"requestQ\" requestKey = \"request\" while true begin #connect, disable auto-reconnect so as to manually reconnect connection = Bunny.new(:host => server, :port => port, :vhost => vhost, :user => username, :pass => password, :heartbeat => 60, :recover_from_connection_close => false) connection.start channel = connection.create_channel #declare exchange and queue, bind them and consume messages exchange = channel.direct(exchangeName, :auto_delete => true) queue = channel.queue(requestQueue, :exclusive => true, :auto_delete => true) queue.bind(exchange, :routing_key => requestKey) queue.subscribe(:block => false, :manual_ack => true) do |delivery_info, metadata, payload| puts payload #reply according to the reply_to header begin exchange.publish(\"Reply to %s\" % payload, :routing_key => metadata.reply_to, :content_type => \"text/plain\", :delivery_mode => 1) channel.basic_ack(delivery_info.delivery_tag, false) rescue channel.basic_nack(delivery_info.delivery_tag, false, false) end end #keep checking the existence of the subscribed queue while true raise \"Lost the subscribed queue %s\" % requestQueue unless connection.queue_exists?(requestQueue) sleep 1 end rescue Exception => e #reconnect on exception puts \"Exception handled, reconnecting...\\nDetail:\\n%s\" % e #blindly clean old connection begin connection.close end sleep 5 end end","title":"Putting it all together"},{"location":"request-reply/#java","text":"","title":"Java"},{"location":"request-reply/#prerequisites_3","text":"Java client AMQP library The Java library we use for this example can be found at https://www.rabbitmq.com/java-client.html . Download the library jar file, then import this library in your program import com.rabbitmq.client.*; and compile your source code with the jar file. For example, javac -cp \".:./rabbitmq-client.jar\" Producer.java Consumer.java Run the producer and consumer classes. For example, java -cp \".:./rabbitmq-client.jar\" Consumer java -cp \".:./rabbitmq-client.jar\" Producer Of course, you can eventually compress your producer and consumer classes into jar files.","title":"Prerequisites"},{"location":"request-reply/#producer_4","text":"The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. ConnectionFactory factory = new ConnectionFactory(); factory.setHost(server); factory.setPort(port); factory.setVirtualHost(vhost); factory.setUsername(username); factory.setPassword(password); factory.setRequestedHeartbeat(60); connection = factory.newConnection(); channel = connection.createChannel(); Then producer will do what consumer does, listen on the replyQueue on its side. String message = \"Hello World!\"; channel.queueDeclare(replyQueue, false, true, true, null); channel.queueBind(replyQueue, exchangeName, replyKey, null); QueueingConsumer qc = new QueueingConsumer(channel); channel.basicConsume(replyQueue, true, qc); After that producer can publish messages to the exchange through routing key of the requestQueue on consumer side. The message carries a reply-to property to indicate consumer where to reply to. It's the routing key of producer's replyQueue. BasicProperties properties = new BasicProperties.Builder(). contentType(\"text/plain\"). deliveryMode(1). replyTo(replyKey). build(); channel.basicPublish(exchangeName, requestKey, properties, message.getBytes()); Once producer has received the reply, the callback function will disconnect with the RoboMQ broker. QueueingConsumer.Delivery delivery = qc.nextDelivery(); String replyMessage = new String(delivery.getBody()); System.out.println(replyMessage); connection.close();","title":"Producer"},{"location":"request-reply/#consumer_4","text":"The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will listen on its requestQueue. channel.exchangeDeclare(exchangeName, \"direct\", false, true, false, null); channel.queueDeclare(requestQueue, false, true, true, null); channel.queueBind(requestQueue, exchangeName, requestKey, null); QueueingConsumer qc = new QueueingConsumer(channel); channel.basicConsume(requestQueue, false, qc); When requests are received, it will print the message content and reply according to the reply-to property of request message. This time, we have set no-ack to false in basicConsume() . If reply succeeds, ACK the request message; otherwise, NACK it, so it will be re-queued. while (true) { QueueingConsumer.Delivery delivery = qc.nextDelivery(); String message = new String(delivery.getBody()); System.out.println(message); //when receives messages, reply to the reply_to header String replyMessage = \"Reply to \" + message; BasicProperties properties = new BasicProperties.Builder(). contentType(\"text/plain\"). deliveryMode(1). build(); try { channel.basicPublish(exchangeName, delivery.getProperties().getReplyTo(), properties, replyMessage.getBytes()); channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); } catch(Exception e) { channel.basicNack(delivery.getEnvelope().getDeliveryTag(), false, false); } }","title":"Consumer"},{"location":"request-reply/#putting-it-all-together_3","text":"Producer.java import com.rabbitmq.client.ConnectionFactory; import com.rabbitmq.client.Connection; import com.rabbitmq.client.Channel; import com.rabbitmq.client.QueueingConsumer; import com.rabbitmq.client.AMQP.BasicProperties; public class Producer { private Connection connection; private Channel channel; private static String server = \"hostname\"; private static int port = 5672; private static String vhost = \"yourvhost\"; private static String username = \"username\"; private static String password = \"password\"; private String exchangeName = \"testEx\"; private String replyQueue = \"replyQ\"; private String requestKey = \"request\"; private String replyKey = \"reply\"; private void produce() { try { //connect ConnectionFactory factory = new ConnectionFactory(); factory.setHost(server); factory.setPort(port); factory.setVirtualHost(vhost); factory.setUsername(username); factory.setPassword(password); factory.setRequestedHeartbeat(60); connection = factory.newConnection(); channel = connection.createChannel(); //listen for reply messages String message = \"Hello World!\"; channel.queueDeclare(replyQueue, false, true, true, null); channel.queueBind(replyQueue, exchangeName, replyKey, null); QueueingConsumer qc = new QueueingConsumer(channel); channel.basicConsume(replyQueue, true, qc); //send request message BasicProperties properties = new BasicProperties.Builder(). contentType(\"text/plain\"). deliveryMode(1). replyTo(replyKey). build(); channel.basicPublish(exchangeName, requestKey, properties, message.getBytes()); //receive the reply message QueueingConsumer.Delivery delivery = qc.nextDelivery(); String replyMessage = new String(delivery.getBody()); System.out.println(replyMessage); //disconnect connection.close(); } catch(Exception e) { System.out.println(e); System.exit(-1); } } public static void main(String[] args) { Producer p = new Producer(); p.produce(); } } Consumer.java import com.rabbitmq.client.ConnectionFactory; import com.rabbitmq.client.Connection; import com.rabbitmq.client.Channel; import com.rabbitmq.client.QueueingConsumer; import com.rabbitmq.client.AMQP.BasicProperties; public class Consumer { private Connection connection; private Channel channel; private static String server = \"hostname\"; private static int port = 5672; private static String vhost = \"yourvhost\"; private static String username = \"username\"; private static String password = \"password\"; private String exchangeName = \"testEx\"; private String requestQueue = \"requestQ\"; private String requestKey = \"request\"; private void consume() { while (true) { try { //connect ConnectionFactory factory = new ConnectionFactory(); factory.setHost(server); factory.setPort(port); factory.setVirtualHost(vhost); factory.setUsername(username); factory.setPassword(password); factory.setRequestedHeartbeat(60); connection = factory.newConnection(); channel = connection.createChannel(); //declare exchange and queue, bind them and consume messages channel.exchangeDeclare(exchangeName, \"direct\", false, true, false, null); channel.queueDeclare(requestQueue, false, true, true, null); channel.queueBind(requestQueue, exchangeName, requestKey, null); QueueingConsumer qc = new QueueingConsumer(channel); channel.basicConsume(requestQueue, false, qc); while (true) { QueueingConsumer.Delivery delivery = qc.nextDelivery(); String message = new String(delivery.getBody()); System.out.println(message); //when receives messages, reply to the reply_to header String replyMessage = \"Reply to \" + message; BasicProperties properties = new BasicProperties.Builder(). contentType(\"text/plain\"). deliveryMode(1). build(); try { channel.basicPublish(exchangeName, delivery.getProperties().getReplyTo(), properties, replyMessage.getBytes()); channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); } catch(Exception e) { channel.basicNack(delivery.getEnvelope().getDeliveryTag(), false, false); } } } catch(Exception e) { //reconnect on exception System.out.printf(\"Exception handled, reconnecting...\\nDetail:\\n%s\\n\", e); try { connection.close(); } catch (Exception e1) {} try { Thread.sleep(5000); } catch(Exception e2) {} } } } public static void main(String[] args) { Consumer c = new Consumer(); c.consume(); } }","title":"Putting it all together"},{"location":"request-reply/#go","text":"","title":"Go"},{"location":"request-reply/#prerequisites_4","text":"Go client AMQP library The Go library we use for this example can be found at https://github.com/streadway/amqp . You can install it through go get github.com/streadway/amqp . Finally, import this library in your program. import \"github.com/streadway/amqp\" The full documentation of this library is at https://godoc.org/github.com/streadway/amqp .","title":"Prerequisites"},{"location":"request-reply/#producer_5","text":"The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. connection, err := amqp.DialConfig(fmt.Sprintf(\"amqp://%s:%s@%s:%d/%s\", username, password, server, port, vhost), amqp.Config{Heartbeat: 60 * time.Second}) channel, err := connection.Channel() Then producer will do what consumer does, listen on the replyQueue on its side. queue, err := channel.QueueDeclare(replyQueue, false, true, true, false, nil) err = channel.QueueBind(replyQueue, replyKey, exchangeName, false, nil) messageChan, err := channel.Consume(queue.Name, \"replyConsumer\", true, true, false, false, nil) message := <-messageChan fmt.Println(string(message.Body)) After that producer can publish a message to the exchange through routing key of the requestQueue on consumer side. The message carries a reply-to property to indicate consumer where to reply to. It's the routing key of producer's replyQueue. err = channel.Publish(exchangeName, requestKey, false, false, amqp.Publishing{ContentType: \"text/plain\", DeliveryMode: 1, ReplyTo: replyKey, Body: []byte(\"Hello World!\")}) Producer should be blocked until it receives the reply before exiting.","title":"Producer"},{"location":"request-reply/#consumer_5","text":"The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will listen on its requestQueue. err = channel.ExchangeDeclare(exchangeName, \"direct\", false, true, false, false, nil) queue, err := channel.QueueDeclare(requestQueue, false, true, true, false, nil) err = channel.QueueBind(requestQueue, requestKey, exchangeName, false, nil) messageChan, err := channel.Consume(queue.Name, \"requestConsumer\", false, true, false, false, nil) When requests are received, it will print the message content and reply according to the reply-to property of request message. Note that auto-ack has been set to false above. If reply succeeds, ACK the request message; otherwise, NACK it, so it will be re-queued. for message := range messageChan { fmt.Println(string(message.Body)) err = channel.Publish(exchangeName, message.ReplyTo, false, false, amqp.Publishing{ContentType: \"text/plain\", DeliveryMode: 1, Body: append([]byte(\"Reply to \"), message.Body...)}) if err != nil { err = message.Nack(false, true) } else { err = message.Ack(false) } }","title":"Consumer"},{"location":"request-reply/#putting-it-all-together_4","text":"producer.go package main import ( \"fmt\" \"github.com/streadway/amqp\" \"os\" \"time\" ) var server = \"hostname\" var port = 5672 var vhost = \"yourvhost\" var username = \"username\" var password = \"password\" var exchangeName = \"testEx\" var replyQueue = \"replyQ\" var requestKey = \"request\" var replyKey = \"reply\" func main() { connection, err := amqp.DialConfig(fmt.Sprintf(\"amqp://%s:%s@%s:%d/%s\", username, password, server, port, vhost), amqp.Config{Heartbeat: 60 * time.Second}) if err != nil { fmt.Printf(\"Failed to connect, err: %v\\n\", err) os.Exit(1) } defer connection.Close() channel, err := connection.Channel() if err != nil { fmt.Printf(\"Failed to create channel, err: %v\\n\", err) os.Exit(1) } defer channel.Close() queue, err := channel.QueueDeclare( replyQueue, // name false, // durable true, // auto-delete true, // exclusive false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to declare reply queue, err: %v\\n\", err) os.Exit(1) } err = channel.QueueBind( replyQueue, // queue replyKey, // key exchangeName, // exchange false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to bind reply queue with exchange, err: %v\\n\", err) os.Exit(1) } messageChan, err := channel.Consume( queue.Name, // queue \"replyConsumer\", // consumer tag true, // auto-ack true, // exclusive false, // no-local false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to consume reply messages, err: %v\\n\", err) os.Exit(1) } // use a channel to communicate between goroutines gotReply := make(chan bool) // listen for reply message go func(messageChan <-chan amqp.Delivery, gotReply chan bool) { message := <-messageChan fmt.Println(string(message.Body)) // notify main goroutine it has got the reply gotReply <- true }(messageChan, gotReply) err = channel.Publish( exchangeName, // exchange requestKey, // routing key false, // mandatory false, // immediate amqp.Publishing{ ContentType: \"text/plain\", DeliveryMode: 1, ReplyTo: replyKey, Body: []byte(\"Hello World!\"), }) if err != nil { fmt.Printf(\"Failed to publish request message, err: %v\\n\", err) os.Exit(1) } // block until it has got the reply _ = <-gotReply } consumer.go package main import ( \"fmt\" \"github.com/streadway/amqp\" \"time\" ) var server = \"hostname\" var port = 5672 var vhost = \"yourvhost\" var username = \"username\" var password = \"password\" var exchangeName = \"testEx\" var requestQueue = \"requestQ\" var requestKey = \"request\" func main() { // Infinite loop to auto-reconnect on failure Loop: for { fmt.Println(\"Starting in 5 seconds...\") time.Sleep(5 * time.Second) connection, err := amqp.DialConfig(fmt.Sprintf(\"amqp://%s:%s@%s:%d/%s\", username, password, server, port, vhost), amqp.Config{Heartbeat: 60 * time.Second}) if err != nil { fmt.Printf(\"Failed to connect, err: %v\\n\", err) continue Loop } defer connection.Close() channel, err := connection.Channel() if err != nil { fmt.Printf(\"Failed to create channel, err: %v\\n\", err) continue Loop } defer channel.Close() err = channel.ExchangeDeclare( exchangeName, // name \"direct\", // type false, // durable true, // audo-delete false, // internal false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to declare exchange, err: %v\\n\", err) continue Loop } queue, err := channel.QueueDeclare( requestQueue, // name false, // durable true, // auto-delete true, // exclusive false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to declare request queue, err: %v\\n\", err) continue Loop } err = channel.QueueBind( requestQueue, // queue requestKey, // key exchangeName, // exchange false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to bind request queue with exchange, err: %v\\n\", err) continue Loop } messageChan, err := channel.Consume( queue.Name, // queue \"requestConsumer\", // consumer tag false, // auto-ack true, // exclusive false, // no-local false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to consume request messages, err: %v\\n\", err) continue Loop } fmt.Println(\"Started consuming messages.\") for message := range messageChan { fmt.Println(string(message.Body)) // on receiving request messages, reply to the reply_to header err = channel.Publish( exchangeName, // exchange message.ReplyTo, // routing key false, // mandatory false, // immediate amqp.Publishing{ ContentType: \"text/plain\", DeliveryMode: 1, Body: append([]byte(\"Reply to \"), message.Body...), }) if err != nil { fmt.Printf(\"Failed to publish reply message, err: %v\\n\", err) err = message.Nack( false, // multiple true, // requeued ) if err != nil { fmt.Printf(\"Failed to NACK request message, err: %v\\n\", err) break } } else { err = message.Ack( false, // multiple ) if err != nil { fmt.Printf(\"Failed to ACK request message, err: %v\\n\", err) break } } } } }","title":"Putting it all together"},{"location":"request-reply/#c","text":"","title":"C"},{"location":"request-reply/#prerequisites_5","text":"C client AMQP library Robomq.io is built on AMQP, an open, general-purpose protocol for messaging. There are a number of clients for AMQP in many different languages. However, we'll choose a simple C-language AMQP client library written for use with v2.0+ of the RabbitMQ broker. https://github.com/alanxz/rabbitmq-c/tree/master/librabbitmq You can copy librabbitmq subfolder from latest release located here on GitHub: https://github.com/alanxz/rabbitmq-c Alternatively, thanks to Subversion support in GitHub, you can use svn export directly: svn export https://github.com/alanxz/rabbitmq-c/trunk/librabbitmq Copy the librabbitmq package into your working directory: cp librabbitmq ./ Also copy all source files and Makefile from RoboMQ SDK at https://github.com/robomq/robomq.io/tree/master/sdk/AMQP/C into the same directory. Now your working directory should have the content as bellow: broadcast config.h librabbitmq Makefile one-to-one request-reply routing-key topic Use the Makefile to compile under a Linux terminal. Run make type={sub-directory} to compile the producer and consumer under the sub-directory. Before compiling the next sub-directory, run make clean to clean up the compiled files. Note that these examples provide a simple client implementation to get started but does not go into detailed description of all flags passed into the AMQP methods. A complete reference to RabbitMQ's implementaton of version 0-9-1 of the AMQP specification can be found in this guide. https://www.rabbitmq.com/amqp-0-9-1-reference.html","title":"Prerequisites"},{"location":"request-reply/#producer_6","text":"For request-reply messaging pattern, the producer also uses direct exchange, however, a the reply queue will be created and bound to an exchange allowing more than one consumer to subscribe to and send replies asynchronously. Therefore, after publishing a message, the producer will simply wait on a separate queue bound to with with key \"reply_key\" for replies sent by receiving consumer. char queue_name[] = \"reply-queue\"; char binding_key[] = \"reply_key\"; // Declaring exchange amqp_exchange_declare(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(exchange_type), passive, durable, auto_delete, internal, amqp_empty_table); // Declaring queue amqp_queue_declare_ok_t *r = amqp_queue_declare(conn, channel, amqp_cstring_bytes(queue_name), passive, durable, exclusive, auto_delete, amqp_empty_table); reply_queue = amqp_bytes_malloc_dup(r->queue); // Binding to queue amqp_queue_bind(conn, channel, reply_queue, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(binding_key), amqp_empty_table); // Now wait for the reply message amqp_basic_consume(conn, channel, reply_queue, amqp_empty_bytes, no_local, no_ack, exclusive, amqp_empty_table); while (1) { amqp_rpc_reply_t result; amqp_envelope_t envelope; amqp_maybe_release_buffers(conn); result = amqp_consume_message(conn, &envelope, NULL, 0); if (AMQP_RESPONSE_NORMAL == result.reply_type) { printf(\"Received reply message size: %d\\nbody: %s\\n\", (int)envelope.message.body.len, (char *)envelope.message.body.bytes); amqp_destroy_envelope(&envelope); } }","title":"Producer"},{"location":"request-reply/#consumer_6","text":"This consumer after successfully receiving message from producer will simply send a reply with routing key \"reply_key\" indicating that exchange will deliver reply directly to the reply queue subscribed to by the producer. char routing_key[] = \"reply_key\"; result = amqp_consume_message(conn, &envelope, NULL, 0); if (AMQP_RESPONSE_NORMAL == result.reply_type) { // Now sending reply amqp_basic_publish(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(routing_key), 0, 0, &props, amqp_cstring_bytes(\"Hello back at you\")); amqp_destroy_envelope(&envelope); } At this point, consumer should start consuming messages.","title":"Consumer"},{"location":"request-reply/#putting-it-all-together_5","text":"The full code below includes some basic AMQP error handling for consumer that is useful when declaring exchanges and queues. In addition, main receiver loop attempts to reconnect upon network connection failure. producer.c #include <stdlib.h> #include <stdio.h> #include <string.h> #include <amqp_tcp_socket.h> #include <amqp.h> #include <amqp_framing.h> amqp_connection_state_t mqconnect() { amqp_connection_state_t conn = amqp_new_connection(); amqp_socket_t *socket = NULL; char hostname[] = \"localhost\"; // RoboMQ hostname int port = 5672; //default char user[] = \"guest\"; // RoboMQ username char password[] = \"guest\"; // RoboMQ password char vhost[] = \"/\"; // RoboMQ account vhost amqp_channel_t channel = 1; int channel_max = 0; int frame_max = 131072; int heartbeat = 60; int status = 0; // Opening socket socket = amqp_tcp_socket_new(conn); status = amqp_socket_open(socket, hostname, port); if (status) { printf(\"Error opening TCP socket, status = %d, exiting.\", status); } amqp_login(conn, vhost, channel_max, frame_max, heartbeat, AMQP_SASL_METHOD_PLAIN, user, password); amqp_channel_open(conn, channel); return conn; } amqp_bytes_t mqdeclare(amqp_connection_state_t conn) { amqp_bytes_t queue; amqp_channel_t channel = 1; amqp_boolean_t passive = 0; amqp_boolean_t durable = 0; amqp_boolean_t exclusive = 0; amqp_boolean_t auto_delete = 1; amqp_boolean_t internal = 0; char exchange_name[] = \"hello-exchange\"; char exchange_type[] = \"direct\"; char queue_name[] = \"reply-queue\"; char binding_key[] = \"reply_key\"; amqp_rpc_reply_t reply; // Declaring exchange amqp_exchange_declare(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(exchange_type), passive, durable, auto_delete, internal, amqp_empty_table); reply = amqp_get_rpc_reply(conn); if(reply.reply_type != AMQP_RESPONSE_NORMAL) { amqp_connection_close_t *m = (amqp_connection_close_t *) reply.reply.decoded; fprintf(stderr, \"%s: server connection error %d, message: %.*s\\n\", \"Error declaring exchange\", m->reply_code, (int) m->reply_text.len, (char *) m->reply_text.bytes); exit(1); } // Declaring queue amqp_queue_declare_ok_t *r = amqp_queue_declare(conn, channel, amqp_cstring_bytes(queue_name), passive, durable, exclusive, auto_delete, amqp_empty_table); reply = amqp_get_rpc_reply(conn); if(reply.reply_type != AMQP_RESPONSE_NORMAL) { amqp_connection_close_t *m = (amqp_connection_close_t *) reply.reply.decoded; fprintf(stderr, \"%s: server connection error %d, message: %.*s\\n\", \"Error declaring queue\", m->reply_code, (int) m->reply_text.len, (char *) m->reply_text.bytes); exit(1); } queue = amqp_bytes_malloc_dup(r->queue); // Binding to queue amqp_queue_bind(conn, channel, queue, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(binding_key), amqp_empty_table); return queue; } int main(int argc, char const *const *argv) { amqp_connection_state_t conn; amqp_bytes_t reply_queue; amqp_channel_t channel = 1; amqp_basic_properties_t props; props._flags = AMQP_BASIC_CONTENT_TYPE_FLAG | AMQP_BASIC_DELIVERY_MODE_FLAG; props.content_type = amqp_cstring_bytes(\"text/plain\"); props.delivery_mode = 1; /* non-persistent delivery mode */ amqp_boolean_t mandatory = 0; amqp_boolean_t immediate = 0; amqp_boolean_t no_local = 0; amqp_boolean_t no_ack = 1; amqp_boolean_t exclusive = 0; char exchange_name[] = \"hello-exchange\"; char routing_key[] = \"request_key\"; char *msg_body = \"Hello\\n\"; int result; conn = mqconnect(); reply_queue = mqdeclare(conn); // Sending message result = amqp_basic_publish(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(routing_key), mandatory, immediate, &props, amqp_cstring_bytes(msg_body)); // Now wait for the reply message amqp_basic_consume(conn, channel, reply_queue, amqp_empty_bytes, no_local, no_ack, exclusive, amqp_empty_table); while (1) { amqp_rpc_reply_t result; amqp_envelope_t envelope; amqp_maybe_release_buffers(conn); result = amqp_consume_message(conn, &envelope, NULL, 0); if (AMQP_RESPONSE_NORMAL == result.reply_type) { printf(\"Received reply message size: %d\\nbody: %s\\n\", (int)envelope.message.body.len, (char *)envelope.message.body.bytes); amqp_destroy_envelope(&envelope); } } // Closing connection amqp_connection_close(conn, AMQP_REPLY_SUCCESS); amqp_destroy_connection(conn); return 0; } consumer.c #include <stdlib.h> #include <stdio.h> #include <string.h> #include <amqp_tcp_socket.h> #include <amqp.h> #include <amqp_framing.h> amqp_connection_state_t mqconnect() { amqp_connection_state_t conn = amqp_new_connection(); amqp_socket_t *socket = NULL; char hostname[] = \"localhost\"; // RoboMQ hostname int port = 5672; //default char user[] = \"guest\"; // RoboMQ username char password[] = \"guest\"; // RoboMQ password char vhost[] = \"/\"; // RoboMQ account vhost amqp_channel_t channel = 1; amqp_rpc_reply_t reply; int channel_max = 0; int frame_max = 131072; int heartbeat = 60; int status = 0; // Opening socket socket = amqp_tcp_socket_new(conn); status = amqp_socket_open(socket, hostname, port); if (status) { printf(\"Error opening TCP socket, status = %d\\n\", status); } reply = amqp_login(conn, vhost, channel_max, frame_max, heartbeat, AMQP_SASL_METHOD_PLAIN, user, password); if(reply.reply_type != AMQP_RESPONSE_NORMAL) { fprintf(stderr, \"%s: server connection reply code: %d\\n\", \"Error logging in\", reply.reply_type); } amqp_channel_open(conn, channel); return conn; } amqp_bytes_t mqdeclare(amqp_connection_state_t conn, const char *exchange_name, const char *queue_name) { amqp_bytes_t queue; amqp_channel_t channel = 1; amqp_boolean_t passive = 0; amqp_boolean_t durable = 0; amqp_boolean_t exclusive = 0; amqp_boolean_t auto_delete = 1; amqp_boolean_t internal = 0; char exchange_type[] = \"direct\"; char binding_key[] = \"request_key\"; amqp_rpc_reply_t reply; // Declaring exchange amqp_exchange_declare(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(exchange_type), passive, durable, auto_delete, internal, amqp_empty_table); reply = amqp_get_rpc_reply(conn); if(reply.reply_type != AMQP_RESPONSE_NORMAL) { amqp_connection_close_t *m = (amqp_connection_close_t *) reply.reply.decoded; if(NULL != m) { fprintf(stderr, \"%s: server connection error %d, message: %.*s\\n\", \"Error declaring exchange\", m->reply_code, (int) m->reply_text.len, (char *) m->reply_text.bytes); } } // Declaring queue amqp_queue_declare_ok_t *r = amqp_queue_declare(conn, channel, amqp_cstring_bytes(queue_name), passive, durable, exclusive, auto_delete, amqp_empty_table); reply = amqp_get_rpc_reply(conn); if(reply.reply_type != AMQP_RESPONSE_NORMAL) { fprintf(stderr, \"%s: server connection reply code: %d\\n\", \"Error declaring queue\", reply.reply_type); } else { queue = amqp_bytes_malloc_dup(r->queue); // Binding to queue amqp_queue_bind(conn, channel, queue, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(binding_key), amqp_empty_table); } return queue; } int main(int argc, char const *const *argv) { amqp_connection_state_t conn; amqp_bytes_t queue; amqp_channel_t channel = 1; amqp_boolean_t no_local = 0; amqp_boolean_t no_ack = 1; amqp_boolean_t exclusive = 0; char exchange_name[] = \"hello-exchange\"; char routing_key[] = \"reply_key\"; amqp_basic_properties_t props; props._flags = AMQP_BASIC_CONTENT_TYPE_FLAG | AMQP_BASIC_DELIVERY_MODE_FLAG; props.content_type = amqp_cstring_bytes(\"text/plain\"); props.delivery_mode = 1; /* non-persistent delivery mode */ char queue_name[] = \"hello-queue\"; int retry_time = 5; // retry time in seconds conn = mqconnect(); queue = mqdeclare(conn, &exchange_name[0], &queue_name[0]); // Consuming the message amqp_basic_consume(conn, channel, queue, amqp_empty_bytes, no_local, no_ack, exclusive, amqp_empty_table); while (1) { amqp_rpc_reply_t result; amqp_envelope_t envelope; amqp_maybe_release_buffers(conn); result = amqp_consume_message(conn, &envelope, NULL, 0); if (AMQP_RESPONSE_NORMAL != result.reply_type) { printf(\"Consumer AMQP failure occurred, response code = %d, retrying in %d seconds...\\n\", result.reply_type, retry_time); // Closing current connection before reconnecting amqp_connection_close(conn, AMQP_CONNECTION_FORCED); amqp_destroy_connection(conn); // Reconnecting on exception conn = mqconnect(); queue = mqdeclare(conn, &exchange_name[0], &queue_name[0]); amqp_basic_consume(conn, channel, queue, amqp_empty_bytes, no_local, no_ack, exclusive, amqp_empty_table); sleep(retry_time); } else { printf(\"Received message size: %d\\nbody: %s\\n\", (int)envelope.message.body.len, (char *)envelope.message.body.bytes); // Now sending reply amqp_basic_publish(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(routing_key), 0, 0, &props, amqp_cstring_bytes(\"Hello back at you\")); amqp_destroy_envelope(&envelope); } } return 0; }","title":"Putting it all together"},{"location":"routing-key/","text":"Routing - Key Based Routing - Key based messaging is an extension of direct exchange allowing filtering of messages based on a producer\u2019s routing key. Messages published to the exchange will be routed to queues bound to that exchange with matching binding key. All other messages will be filtered. A consumer will define callback functions to process messages that are selectively received. Browse the chapter of AMQP Introduction first if you're new to AMQP. Python Prerequisites Python client AMQP library The Python library we use for this example can be found at https://github.com/pika/pika . You can install it through sudo pip install pika . Finally, import this library in your program. import pika The full documentation of this library is at https://pika.readthedocs.org/en/0.9.14/ . pika library is not thread safe. Do not use a connection or channel across threads. Producer The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. credentials = pika.PlainCredentials(username, password) connection = pika.BlockingConnection(pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60)) channel = connection.channel() Then producer can publish messages to a direct exchange where messages will be delivered to queues whose routing key matches. Delivery mode = 1 means it's a non-persistent message. properties = pika.spec.BasicProperties(content_type = \"text/plain\", delivery_mode = 1) channel.basic_publish(exchange = exchangeName, routing_key = routingKey, body = \"Hello World!\", properties = properties) At last, producer will disconnect with the RoboMQ broker. connection.close() Consumer The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a direct exchange, a queue, and bind the queue to the exchange with a routing key. The routing key decides what messages will a queue receive. Auto-delete means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. Exclusive means no other consumer can consume the queue when this one is consuming it. channel.exchange_declare(exchange = exchangeName, exchange_type = \"direct\", auto_delete = True) channel.queue_declare(queue = queueName, exclusive = True, auto_delete = True) channel.queue_bind(exchange = exchangeName, queue = queueName, routing_key = routingKey) Finally, consumer can consume messages from the queue. The no_ack parameter indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, no_ack equals to true, so producer does not explicitly acknowledge received messages. The start_consuming() function will be blocking the process until stop_consuming() is invoked or exception happens. channel.basic_consume(consumer_callback = onMessage, queue = queueName, no_ack = True) channel.start_consuming() When messages are received, a callback function onMessage() will be invoked to print the message content. def onMessage(channel, method, properties, body): print body Putting it all together producer.py import pika server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" exchangeName = \"testEx\" routingKey = \"test\" try: #connect credentials = pika.PlainCredentials(username, password) connection = pika.BlockingConnection(pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60)) channel = connection.channel() #send message properties = pika.spec.BasicProperties(content_type = \"text/plain\", delivery_mode = 1) channel.basic_publish(exchange = exchangeName, routing_key = routingKey, body = \"Hello World!\", properties = properties) #disconnect connection.close() except Exception, e: print e consumer.py import pika import time server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" exchangeName = \"testEx\" queueName = \"testQ1\" routingKey = \"test\" #callback funtion on receiving messages def onMessage(channel, method, properties, body): print body while True: try: #connect credentials = pika.PlainCredentials(username, password) connection = pika.BlockingConnection(pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60)) channel = connection.channel() #declare exchange and queue, bind them and consume messages channel.exchange_declare(exchange = exchangeName, exchange_type = \"direct\", auto_delete = True) channel.queue_declare(queue = queueName, exclusive = True, auto_delete = True) channel.queue_bind(exchange = exchangeName, queue = queueName, routing_key = routingKey) channel.basic_consume(consumer_callback = onMessage, queue = queueName, no_ack = True) channel.start_consuming() except Exception, e: #reconnect on exception print \"Exception handled, reconnecting...\\nDetail:\\n%s\" % e try: connection.close() except: pass time.sleep(5) Node.js Prerequisites Node.js client AMQP library The Node.js library we use for this example can be found at https://github.com/squaremo/amqp.node . You can install the library through sudo npm install amqplib . Finally, require this library in your program. var amqp = require(\"amqplib\"); The full documentation of this library is at https://www.squaremobius.net/amqp.node/doc/channel_api.html . Producer The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. As shown in the code, this library provides chainable callback API in the form of .then(callback) . For the default vhost \"/\", you will need to insert \"%2f\" (its hexadecimal ASCII code) to the AMQP URI, instead of \"/\" itself. producer = amqp.connect(\"amqp://\" + username + \":\" + password + \"@\" + server + \":\" + port + \"/\" + vhost + \"?heartbeat=60\"); producer.then(function(conn) { return conn.createConfirmChannel().then(successCallback); }).then(null, failureCallback); Then producer can publish messages to a direct exchange where messages will be delivered to queues whose routing key matches. Delivery mode = 1 means it's a non-persistent message. ch.publish(exchangeName, routingKey, content = new Buffer(\"Hello World!\"), options = {contentType: \"text/plain\", deliveryMode: 1}, callback); At last, producer will disconnect with the RoboMQ broker. conn.close(); Consumer The same as producer, consumer needs to first connect to RoboMQ broker. The difference is that consumer uses conn.createChannel() function, while producer uses conn.createConfirmChannel() because the latter one is only useful for publish confirm. Then consumer will declare a direct exchange, a queue, and bind the queue to the exchange with a routing key. The routing key decides what messages will a queue receive. Durable means the exchange or queue will survive possible broker failover. It's false in this example. Auto-delete means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. Exclusive means no other consumer can consume the queue when this one is consuming it. ch.assertExchange(exchangeName, \"direct\", {durable: false, autoDelete: true}); ch.assertQueue(queueName, {durable: false, autoDelete: true, exclusive: true}); ch.bindQueue(queueName, exchangeName, routingKey); Finally, consumer can consume messages from the queue. The noAck option indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, noAck is true, so producer does not explicitly acknowledge received messages. The second parameter of consume() function is the callback on receiving messages. In this example, when messages are received, the callback function will be invoked to print the message content. ch.consume(queueName, function(message) { console.log(message.content.toString()); }, {noAck: true}); Putting it all together producer.js var amqp = require(\"amqplib\"); var server = \"hostname\"; var port = \"5672\"; var vhost = \"yourvhost\"; //for \"/\" vhost, use \"%2f\" instead var username = \"username\"; var password = \"password\"; var exchangeName = \"testEx\"; var routingKey = \"test\"; producer = amqp.connect(\"amqp://\" + username + \":\" + password + \"@\" + server + \":\" + port + \"/\" + vhost + \"?heartbeat=60\"); producer.then(function(conn) { return conn.createConfirmChannel().then(function(ch) { ch.publish(exchangeName, routingKey, content = new Buffer(\"Hello World!\"), options = {contentType: \"text/plain\", deliveryMode: 1}, function(err, ok) { if (err != null) { console.error(\"Error: failed to send message\\n\" + err); } conn.close(); }); }); }).then(null, function(err) { console.error(err); }); consumer.js var amqp = require(\"amqplib\"); var domain = require(\"domain\"); var server = \"hostname\"; var port = \"5672\"; var vhost = \"yourvhost\"; //for \"/\" vhost, use \"%2f\" instead var username = \"username\"; var password = \"password\"; var exchangeName = \"testEx\"; var queueName = \"testQ1\"; var routingKey = \"test\"; //use domain module to handle reconnecting var consumer = null; var dom = domain.create(); dom.on(\"error\", relisten); dom.run(listen); function listen() { consumer = amqp.connect(\"amqp://\" + username + \":\" + password + \"@\" + server + \":\" + port + \"/\" + vhost + \"?heartbeat=60\"); consumer.then(function(conn) { return conn.createChannel().then(function(ch) { ch.assertExchange(exchangeName, \"direct\", {durable: false, autoDelete: true}); ch.assertQueue(queueName, {durable: false, autoDelete: true, exclusive: true}); ch.bindQueue(queueName, exchangeName, routingKey); ch.consume(queueName, function(message) { //callback funtion on receiving messages console.log(message.content.toString()); }, {noAck: true}); }); }).then(null, function(err) { console.error(\"Exception handled, reconnecting...\\nDetail:\\n\" + err); setTimeout(listen, 5000); }); } function relisten() { consumer.then(function(conn) { conn.close(); }); setTimeout(listen, 5000); } PHP Prerequisite PHP client AMQP library The PHP library we use for this example can be found at https://github.com/videlalvaro/php-amqplib . It uses composer to install in a few steps. Add a composer.json file to your project: { \"require\": { \"videlalvaro/php-amqplib\": \"2.2.*\" } } Download the latest composer in the same path: curl -sS https://getcomposer.org/installer | php Install the library through composer: ./composer.phar install Finally, require this library in your program and use the classes. require_once __DIR__ . '/../vendor/autoload.php'; //directory of library folder use PhpAmqpLib\\Connection\\AMQPConnection; use PhpAmqpLib\\Message\\AMQPMessage; Producer The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. $connection = new AMQPConnection($server, $port, $username, $password, $vhost, $heartbeat = 60); $channel = $connection->channel(); Then producer can publish messages to a direct exchange where messages will be delivered to queues whose routing key matches. Delivery mode = 1 means it's a non-persistent message. $message = new AMQPMessage(\"Hello World!\", array(\"content_type\" => \"text/plain\", \"delivery_mode\" => 1)); $channel->basic_publish($message, $exchangeName, $routingKey); At last, producer will disconnect with the RoboMQ broker. $connection->close(); Consumer The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a direct exchange, a queue, and bind the queue to the exchange with a routing key. The routing key decides what messages will a queue receive. Auto-delete means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. Exclusive means no other consumer can consume the queue when this one is consuming it. $channel->exchange_declare($exchangeName, $type = \"direct\", false, false, $auto_delete = true); $channel->queue_declare($queueName, false, false, $exclusive = true, $auto_delete = true); $channel->queue_bind($queueName, $exchangeName, $routingKey); Finally, consumer can consume messages from the queue. The no_ack parameter indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, no_ack equals to true, so producer does not explicitly acknowledge received messages. The while loop will be blocking the process and listening for messages until exception happens. $channel->basic_consume($queueName, \"\", false, $no_ack = true, false, false, $callback = $onMessage); while(count($channel->callbacks)) { $channel->wait(); } When messages are received, a callback function will be invoked to print the message content. $onMessage = function ($message) { echo $message->body.PHP_EOL; }; Putting it together producer.php <?php require_once __DIR__ . '/../vendor/autoload.php'; //directory of library folder use PhpAmqpLib\\Connection\\AMQPConnection; use PhpAmqpLib\\Message\\AMQPMessage; $server = \"hostname\"; $port = 5672; $vhost = \"yourvhost\"; $username = \"username\"; $password = \"password\"; $exchangeName = \"testEx\"; $routingKey = \"test\"; try { //connect $connection = new AMQPConnection($server, $port, $username, $password, $vhost, $heartbeat = 60); $channel = $connection->channel(); //send message $message = new AMQPMessage(\"Hello World!\", array(\"content_type\" => \"text/plain\", \"delivery_mode\" => 1)); $channel->basic_publish($message, $exchangeName, $routingKey); //disconnect $connection->close(); } catch(Exception $e) { echo $e.PHP_EOL; } ?> consumer.php <?php require_once __DIR__.\"/../vendor/autoload.php\"; //directory of library folder use PhpAmqpLib\\Connection\\AMQPConnection; $server = \"hostname\"; $port = 5672; $vhost = \"yourvhost\"; $username = \"username\"; $password = \"password\"; $exchangeName = \"testEx\"; $queueName = \"testQ1\"; $routingKey = \"test\"; //callback funtion on receiving messages $onMessage = function ($message) { echo $message->body.PHP_EOL; }; while (true) { try { //connect $connection = new AMQPConnection($server, $port, $username, $password, $vhost, $heartbeat = 60); $channel = $connection->channel(); //declare exchange and queue, bind them and consume messages $channel->exchange_declare($exchangeName, $type = \"direct\", false, false, $auto_delete = true); $channel->queue_declare($queueName, false, false, $exclusive = true, $auto_delete = true); $channel->queue_bind($queueName, $exchangeName, $routingKey); $channel->basic_consume($queueName, \"\", false, $no_ack = true, false, false, $callback = $onMessage); //start consuming while(count($channel->callbacks)) { $channel->wait(); } } catch(Exception $e) { //reconnect on exception echo \"Exception handled, reconnecting...\\nDetail:\\n\".$e.PHP_EOL; if ($connection != null) { try { $connection->close(); } catch (Exception $e1) {} } sleep(5); } } ?> Ruby Prerequisites Ruby client AMQP library The Ruby library we use for this example can be found at http://rubybunny.info/ . With Ruby version >= 2.0, you can install it through sudo gem install bunny . Finally, import this library in your program. require \"bunny\" The full documentation of this library is at http://rubybunny.info/articles/guides.html . We recommend combining the documentation with the source code of this library when you use it because some of the documentation out there is not being updated timely from our observation. Producer The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. Although the library provides a connection property named recover_from_connection_close , we discourage you to use it. The reason will be explained in the Consumer section. connection = Bunny.new(:host => server, :port => port, :vhost => vhost, :user => username, :pass => password, :heartbeat => 60, :recover_from_connection_close => false) connection.start channel = connection.create_channel Then producer can publish messages to a direct exchange where messages will be delivered to queues whose routing key matches. Delivery mode = 1 means it's a non-persistent message. exchange = channel.direct(exchangeName, :auto_delete => true) exchange.publish(\"Hello World!\", :routing_key => routingKey, :content_type => \"text/plain\", :delivery_mode => 1) At last, producer will disconnect with the RoboMQ broker. connection.close Consumer The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a direct exchange, a queue, and bind the queue to the exchange with a routing key. The routing key decides what messages will a queue receive. Auto-delete means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. Exclusive means no other consumer can consume the queue when this one is consuming it. exchange = channel.direct(exchangeName, :auto_delete => true) queue = channel.queue(queueName, :exclusive => true, :auto_delete => true) queue.bind(exchange, :routing_key => routingKey) After that, consumer can consume messages from the queue. The manual_ack parameter indicates if consumer needs to manually send acknowledgment back to broker when it has received the message. In this example, manual_ack equals to false, so producer does not manually acknowledge received messages. The subscribe() function is followed by a callback which will be invoked to print the message payload on receiving a message. queue.subscribe(:block => false, :manual_ack => false) do |delivery_info, metadata, payload| puts payload end As we mentioned in the Producer section, recover_from_connection_close is set to false when connecting to RoboMQ broker. It matters for consumers because recover_from_connection_close will only recover the connection, it won't recreate exchange and queue in case they are gone. Therefore, a more robust approach is letting your code handle reconnecting on its own and keep checking the existence of the subscribed queue. while true raise \"Lost the subscribed queue %s\" % queueName unless connection.queue_exists?(queueName) sleep 1 end Putting it all together producer.rb require \"bunny\" server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" exchangeName = \"testEx\" routingKey = \"test\" begin #connect connection = Bunny.new(:host => server, :port => port, :vhost => vhost, :user => username, :pass => password, :heartbeat => 60, :recover_from_connection_close => false) connection.start channel = connection.create_channel #send message exchange = channel.direct(exchangeName, :auto_delete => true) exchange.publish(\"Hello World!\", :routing_key => routingKey, :content_type => \"text/plain\", :delivery_mode => 1) #disconnect connection.close rescue Exception => e puts e end consumer.rb require \"bunny\" server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" exchangeName = \"testEx\" queueName = \"testQ1\" routingKey = \"test\" while true begin #connect, disable auto-reconnect so as to manually reconnect connection = Bunny.new(:host => server, :port => port, :vhost => vhost, :user => username, :pass => password, :heartbeat => 60, :recover_from_connection_close => false) connection.start channel = connection.create_channel #declare exchange and queue, bind them and consume messages exchange = channel.direct(exchangeName, :auto_delete => true) queue = channel.queue(queueName, :exclusive => true, :auto_delete => true) queue.bind(exchange, :routing_key => routingKey) queue.subscribe(:block => false, :manual_ack => false) do |delivery_info, metadata, payload| puts payload end #keep checking the existence of the subscribed queue while true raise \"Lost the subscribed queue %s\" % queueName unless connection.queue_exists?(queueName) sleep 1 end rescue Exception => e #reconnect on exception puts \"Exception handled, reconnecting...\\nDetail:\\n%s\" % e #blindly clean old connection begin connection.close end sleep 5 end end Java Prerequisites Java client AMQP library The Java library we use for this example can be found at https://www.rabbitmq.com/java-client.html . Download the library jar file, then import this library in your program import com.rabbitmq.client.*; and compile your source code with the jar file. For example, javac -cp \".:./rabbitmq-client.jar\" Producer.java Consumer.java Run the producer and consumer classes. For example, java -cp \".:./rabbitmq-client.jar\" Consumer java -cp \".:./rabbitmq-client.jar\" Producer Of course, you can eventually compress your producer and consumer classes into jar files. Producer The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. ConnectionFactory factory = new ConnectionFactory(); factory.setHost(server); factory.setPort(port); factory.setVirtualHost(vhost); factory.setUsername(username); factory.setPassword(password); factory.setRequestedHeartbeat(60); connection = factory.newConnection(); channel = connection.createChannel(); Then producer can publish messages to a direct exchange where messages will be delivered to queues whose routing key matches. String message = \"Hello World!\"; channel.basicPublish(exchangeName, routingKey, MessageProperties.TEXT_PLAIN, message.getBytes()); At last, producer will disconnect with the RoboMQ broker. connection.close(); Consumer The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a direct exchange, a queue, and bind the queue to the exchange with a routing key. The routing key decides what messages will a queue receive. The fourth parameter of exchangeDeclare() and queueDeclare() are auto-delete. That means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. The third parameter of queueDeclare() is exclusive. That means no other consumer can consume the queue when this one is consuming it. channel.exchangeDeclare(exchangeName, \"direct\", false, true, false, null); channel.queueDeclare(queueName, false, true, true, null); channel.queueBind(queueName, exchangeName, routingKey, null); Finally, consumer can consume messages from the queue. The second parameter of basicConsume() function no-ack indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, no-ack equals to true, so producer does not explicitly acknowledge received messages. The while loop will be blocking the process and listening for messages until exception happens. When messages are received, it will print the message content. QueueingConsumer qc = new QueueingConsumer(channel); channel.basicConsume(queueName, true, qc); while (true) { QueueingConsumer.Delivery delivery = qc.nextDelivery(); String message = new String(delivery.getBody()); System.out.println(message); } Putting it all together Producer.java import com.rabbitmq.client.ConnectionFactory; import com.rabbitmq.client.Connection; import com.rabbitmq.client.Channel; import com.rabbitmq.client.MessageProperties; public class Producer { private Connection connection; private Channel channel; private static String server = \"hostname\"; private static int port = 5672; private static String vhost = \"yourvhost\"; private static String username = \"username\"; private static String password = \"password\"; private static String exchangeName = \"testEx\"; private static String routingKey = \"test\"; private void produce() { try { //connect ConnectionFactory factory = new ConnectionFactory(); factory.setHost(server); factory.setPort(port); factory.setVirtualHost(vhost); factory.setUsername(username); factory.setPassword(password); factory.setRequestedHeartbeat(60); connection = factory.newConnection(); channel = connection.createChannel(); //send message String message = \"Hello World!\"; channel.basicPublish(exchangeName, routingKey, MessageProperties.TEXT_PLAIN, message.getBytes()); //disconnect connection.close(); } catch(Exception e) { System.out.println(e); System.exit(-1); } } public static void main(String[] args) { Producer p = new Producer(); p.produce(); } } Consumer.java import com.rabbitmq.client.ConnectionFactory; import com.rabbitmq.client.Connection; import com.rabbitmq.client.Channel; import com.rabbitmq.client.QueueingConsumer; public class Consumer { private Connection connection; private Channel channel; private static String server = \"hostname\"; private static int port = 5672; private static String vhost = \"yourvhost\"; private static String username = \"username\"; private static String password = \"password\"; private static String exchangeName = \"testEx\"; private static String queueName = \"testQ1\"; private static String routingKey = \"test\"; private void consume() { while (true) { try { //connect ConnectionFactory factory = new ConnectionFactory(); factory.setHost(server); factory.setPort(port); factory.setVirtualHost(vhost); factory.setUsername(username); factory.setPassword(password); factory.setRequestedHeartbeat(60); connection = factory.newConnection(); channel = connection.createChannel(); //declare exchange and queue, bind them and consume messages channel.exchangeDeclare(exchangeName, \"direct\", false, true, false, null); channel.queueDeclare(queueName, false, true, true, null); channel.queueBind(queueName, exchangeName, routingKey, null); QueueingConsumer qc = new QueueingConsumer(channel); channel.basicConsume(queueName, true, qc); while (true) { QueueingConsumer.Delivery delivery = qc.nextDelivery(); String message = new String(delivery.getBody()); System.out.println(message); } } catch(Exception e) { //reconnect on exception System.out.printf(\"Exception handled, reconnecting...\\nDetail:\\n%s\\n\", e); try { connection.close(); } catch (Exception e1) {} try { Thread.sleep(5000); } catch(Exception e2) {} } } } public static void main(String[] args) { Consumer c = new Consumer(); c.consume(); } } Go Prerequisites Go client AMQP library The Go library we use for this example can be found at https://github.com/streadway/amqp . You can install it through go get github.com/streadway/amqp . Finally, import this library in your program. import \"github.com/streadway/amqp\" The full documentation of this library is at https://godoc.org/github.com/streadway/amqp . Producer The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. connection, err := amqp.DialConfig(fmt.Sprintf(\"amqp://%s:%s@%s:%d/%s\", username, password, server, port, vhost), amqp.Config{Heartbeat: 60 * time.Second}) channel, err := connection.Channel() Then producer can publish messages to a direct exchange where messages will be delivered to queues whose routing key matches. Delivery mode = 1 means it's a non-persistent message. err = channel.Publish(exchangeName, routingKey, false, false, amqp.Publishing{ContentType: \"text/plain\", DeliveryMode: 1, Body: []byte(\"Hello World!\")}) At last, producer will disconnect with the RoboMQ broker. connection.Close() Consumer The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a direct exchange, a queue, and bind the queue to the exchange with a routing key. The routing key decides what messages will a queue receive. Durable means the exchange or queue will survive possible broker failover. It's false in this example. Auto-delete means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. Exclusive means no other consumer can consume the queue when this one is consuming it. // audo-delete = true err = channel.ExchangeDeclare(exchangeName, \"direct\", false, true, false, false, nil) // durable = false; auto-delete = true; exclusive = true queue, err := channel.QueueDeclare(queueName, false, true, true, false, nil) err = channel.QueueBind(queueName, routingKey, exchangeName, false, nil) Finally, consumer can consume messages from the queue. Consumer-tag can be later used to Cancel() this consumer when it's no longer needed. Auto-ack parameter indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, auto-ack equals to true, so producer does not explicitly acknowledge received messages. // consumer-tag = \"consumer\"; auto-ack = true messageChan, err := channel.Consume(queue.Name, \"consumer\", true, true, false, false, nil) Note a message channel is returned by the Consume() function. Incoming messages will be received through that channel. Channel in Golang is a typed conduit through which you can send and receive values. Sends and receives block until the other side is ready. for message := range messageChan { fmt.Println(string(message.Body)) } Putting it all together producer.go package main import ( \"fmt\" \"github.com/streadway/amqp\" \"os\" \"time\" ) var server = \"hostname\" var port = 5672 var vhost = \"yourvhost\" var username = \"username\" var password = \"password\" var exchangeName = \"testEx\" var routingKey = \"test\" func main() { connection, err := amqp.DialConfig(fmt.Sprintf(\"amqp://%s:%s@%s:%d/%s\", username, password, server, port, vhost), amqp.Config{Heartbeat: 60 * time.Second}) if err != nil { fmt.Printf(\"Failed to connect, err: %v\\n\", err) os.Exit(1) } defer connection.Close() channel, err := connection.Channel() if err != nil { fmt.Printf(\"Failed to create channel, err: %v\\n\", err) os.Exit(1) } defer channel.Close() err = channel.Publish( exchangeName, // exchange routingKey, // routing key false, // mandatory false, // immediate amqp.Publishing{ ContentType: \"text/plain\", DeliveryMode: 1, Body: []byte(\"Hello World!\"), }) if err != nil { fmt.Printf(\"Failed to publish message, err: %v\\n\", err) os.Exit(1) } } consumer.go package main import ( \"fmt\" \"github.com/streadway/amqp\" \"time\" ) var server = \"hostname\" var port = 5672 var vhost = \"yourvhost\" var username = \"username\" var password = \"password\" var exchangeName = \"testEx\" var queueName = \"testQ1\" var routingKey = \"test\" func main() { // Infinite loop to auto-reconnect on failure Loop: for { fmt.Println(\"Starting in 5 seconds...\") time.Sleep(5 * time.Second) connection, err := amqp.DialConfig(fmt.Sprintf(\"amqp://%s:%s@%s:%d/%s\", username, password, server, port, vhost), amqp.Config{Heartbeat: 60 * time.Second}) if err != nil { fmt.Printf(\"Failed to connect, err: %v\\n\", err) continue Loop } defer connection.Close() channel, err := connection.Channel() if err != nil { fmt.Printf(\"Failed to create channel, err: %v\\n\", err) continue Loop } defer channel.Close() err = channel.ExchangeDeclare( exchangeName, // name \"direct\", // type false, // durable true, // audo-delete false, // internal false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to declare exchange, err: %v\\n\", err) continue Loop } queue, err := channel.QueueDeclare( queueName, // name false, // durable true, // auto-delete true, // exclusive false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to declare queue, err: %v\\n\", err) continue Loop } err = channel.QueueBind( queueName, // queue routingKey, // key exchangeName, // exchange false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to bind queue with exchange, err: %v\\n\", err) continue Loop } messageChan, err := channel.Consume( queue.Name, // queue \"consumer\", // consumer tag true, // auto-ack true, // exclusive false, // no-local false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to consume messages, err: %v\\n\", err) continue Loop } fmt.Println(\"Started consuming messages.\") for message := range messageChan { fmt.Println(string(message.Body)) } } } C Prerequisites C client AMQP library RoboMQ is built on AMQP, an open, general-purpose protocol for messaging. There are a number of clients for AMQP in many different languages. However, we'll choose a simple C-language AMQP client library written for use with v2.0+ of the RabbitMQ broker. https://github.com/alanxz/rabbitmq-c/tree/master/librabbitmq You can copy librabbitmq subfolder from latest release located here on GitHub: https://github.com/alanxz/rabbitmq-c Alternatively, thanks to Subversion support in GitHub, you can use svn export directly: svn export https://github.com/alanxz/rabbitmq-c/trunk/librabbitmq Copy the librabbitmq package into your working directory: cp librabbitmq ./ Also copy all source files and Makefile from RoboMQ SDK at https://github.com/robomq/robomq.io/tree/master/sdk/AMQP/C into the same directory. Now your working directory should have the content as bellow: broadcast config.h librabbitmq Makefile one-to-one request-reply routing-key topic Use the Makefile to compile under a Linux terminal. Run make type={sub-directory} to compile the producer and consumer under the sub-directory. Before compiling the next sub-directory, run make clean to clean up the compiled files. Note that these examples provide a simple client implementation to get started but does not go into detailed description of all flags passed into the AMQP methods. A complete reference to RabbitMQ's implementaton of version 0-9-1 of the AMQP specification can be found in this guide. https://www.rabbitmq.com/amqp-0-9-1-reference.html Producer For routing-Key based messaging, the producer should publish messages to the specified exchange allowing filtering of messages based on a producer\u2019s routing key. Based on that routing key, messages will be sent through the exchange and distributed to the right queue. If not specified, that routing key is the queue name. amqp_basic_properties_t props; props._flags = AMQP_BASIC_CONTENT_TYPE_FLAG | AMQP_BASIC_DELIVERY_MODE_FLAG; props.content_type = amqp_cstring_bytes(\"text/plain\"); props.delivery_mode = 1; /* non-persistent delivery mode */ amqp_boolean_t mandatory = 0; amqp_boolean_t immediate = 0; char exchange_name[] = \"hello-exchange\"; char routing_key[] = \"routingKey\"; int result; // Sending message result = amqp_basic_publish(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(routing_key), mandatory, immediate, &props, amqp_cstring_bytes(\"Hello\")); Consumer Then the consumer should create a queue and subscribe to a queue. This queue will work similarly to the one-to-one example using the direct exchange type, however, only messages published to this exchange with routing key matching \"routingKey\" will be received by consumer. All other messages will be filtered. amqp_bytes_t queue; amqp_channel_t channel = 1; amqp_boolean_t passive = 0; amqp_boolean_t durable = 0; amqp_boolean_t exclusive = 0; amqp_boolean_t auto_delete = 1; amqp_boolean_t internal = 0; char exchange_name[] = \"hello-exchange\"; char exchange_type[] = \"direct\"; char queue_name[] = \"hello-queue\"; char binding_key[] = \"routingKey\"; // Declaring exchange amqp_exchange_declare(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(exchange_type), passive, durable, auto_delete, internal, amqp_empty_table); // Declaring queue amqp_queue_declare_ok_t *r = amqp_queue_declare(conn, channel, amqp_cstring_bytes(queue_name), passive, durable, exclusive, auto_delete, amqp_empty_table); queue = amqp_bytes_malloc_dup(r->queue); // Binding to queue amqp_queue_bind(conn, channel, queue, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(binding_key), amqp_empty_table); Note that all the queues declared without specific binding key use the queue name as the default binding key. At this point, consumer should start consuming messages. Putting it all together The full code below includes some basic AMQP error handling for consumer that is useful when declaring exchanges and queues. In addition, main receiver loop attempts to reconnect upon network connection failure. producer.c #include <stdlib.h> #include <stdio.h> #include <string.h> #include <amqp_tcp_socket.h> #include <amqp.h> #include <amqp_framing.h> amqp_connection_state_t mqconnect() { amqp_connection_state_t conn = amqp_new_connection(); amqp_socket_t *socket = NULL; char hostname[] = \"localhost\"; // RoboMQ hostname int port = 5672; //default char user[] = \"guest\"; // RoboMQ username char password[] = \"guest\"; // RoboMQ password char vhost[] = \"/\"; // RoboMQ account vhost amqp_channel_t channel = 1; int channel_max = 0; int frame_max = 131072; int heartbeat = 60; int status = 0; // Opening socket socket = amqp_tcp_socket_new(conn); status = amqp_socket_open(socket, hostname, port); if (status) { printf(\"Error opening TCP socket, status = %d, exiting.\", status); } amqp_login(conn, vhost, channel_max, frame_max, heartbeat, AMQP_SASL_METHOD_PLAIN, user, password); amqp_channel_open(conn, channel); return conn; } int main(int argc, char const *const *argv) { amqp_connection_state_t conn; amqp_channel_t channel = 1; amqp_basic_properties_t props; props._flags = AMQP_BASIC_CONTENT_TYPE_FLAG | AMQP_BASIC_DELIVERY_MODE_FLAG; props.content_type = amqp_cstring_bytes(\"text/plain\"); props.delivery_mode = 1; /* non-persistent delivery mode */ amqp_boolean_t mandatory = 0; amqp_boolean_t immediate = 0; char exchange_name[] = \"hello-exchange\"; const char *routing_key; char *msg_body = \"Hello\\n\"; int result; if(argc < 2) { printf(\"Syntax error:\\n\" \"Usage: mqsend <routing_key>\\n\"); exit(-1); } routing_key = (char *)argv[1]; conn = mqconnect(); // Sending message result = amqp_basic_publish(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(routing_key), mandatory, immediate, &props, amqp_cstring_bytes(msg_body)); // Closing connection amqp_connection_close(conn, AMQP_REPLY_SUCCESS); amqp_destroy_connection(conn); return 0; } consumer.c #include <stdlib.h> #include <stdio.h> #include <string.h> #include <amqp_tcp_socket.h> #include <amqp.h> #include <amqp_framing.h> amqp_connection_state_t mqconnect() { amqp_connection_state_t conn = amqp_new_connection(); amqp_socket_t *socket = NULL; char hostname[] = \"localhost\"; // RoboMQ hostname int port = 5672; //default char user[] = \"guest\"; // RoboMQ username char password[] = \"guest\"; // RoboMQ password char vhost[] = \"/\"; // RoboMQ account vhost amqp_channel_t channel = 1; amqp_rpc_reply_t reply; int channel_max = 0; int frame_max = 131072; int heartbeat = 60; int status = 0; // Opening socket socket = amqp_tcp_socket_new(conn); status = amqp_socket_open(socket, hostname, port); if (status) { printf(\"Error opening TCP socket, status = %d\\n\", status); } reply = amqp_login(conn, vhost, channel_max, frame_max, heartbeat, AMQP_SASL_METHOD_PLAIN, user, password); if(reply.reply_type != AMQP_RESPONSE_NORMAL) { fprintf(stderr, \"%s: server connection reply code: %d\\n\", \"Error logging in\", reply.reply_type); } amqp_channel_open(conn, channel); return conn; } amqp_bytes_t mqdeclare(amqp_connection_state_t conn, const char *exchange_name, const char *queue_name, const char *binding_key) { amqp_bytes_t queue; amqp_channel_t channel = 1; amqp_boolean_t passive = 0; amqp_boolean_t durable = 0; amqp_boolean_t exclusive = 0; amqp_boolean_t auto_delete = 1; amqp_boolean_t internal = 0; char exchange_type[] = \"direct\"; amqp_rpc_reply_t reply; // Declaring exchange amqp_exchange_declare(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(exchange_type), passive, durable, auto_delete, internal, amqp_empty_table); reply = amqp_get_rpc_reply(conn); if(reply.reply_type != AMQP_RESPONSE_NORMAL) { amqp_connection_close_t *m = (amqp_connection_close_t *) reply.reply.decoded; if(NULL != m) { fprintf(stderr, \"%s: server connection error %d, message: %.*s\\n\", \"Error declaring exchange\", m->reply_code, (int) m->reply_text.len, (char *) m->reply_text.bytes); } } // Declaring queue amqp_queue_declare_ok_t *r = amqp_queue_declare(conn, channel, amqp_cstring_bytes(queue_name), passive, durable, exclusive, auto_delete, amqp_empty_table); reply = amqp_get_rpc_reply(conn); if(reply.reply_type != AMQP_RESPONSE_NORMAL) { fprintf(stderr, \"%s: server connection reply code: %d\\n\", \"Error declaring queue\", reply.reply_type); } else { queue = amqp_bytes_malloc_dup(r->queue); // Binding to queue amqp_queue_bind(conn, channel, queue, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(binding_key), amqp_empty_table); } return queue; } int main(int argc, char const *const *argv) { amqp_connection_state_t conn; amqp_bytes_t queue; amqp_channel_t channel = 1; amqp_boolean_t no_local = 0; amqp_boolean_t no_ack = 1; amqp_boolean_t exclusive = 0; char exchange_name[] = \"hello-exchange\"; char queue_name[] = \"hello-queue\"; const char *binding_key; int retry_time = 5; // retry time in seconds if(argc < 2) { printf(\"Syntax error:\\n\" \"Usage: mqlisten <binding_key>\\n\"); exit(-1); } binding_key = (char *)argv[1]; conn = mqconnect(); queue = mqdeclare(conn, &exchange_name[0], &queue_name[0], binding_key); // Consuming the message amqp_basic_consume(conn, channel, queue, amqp_empty_bytes, no_local, no_ack, exclusive, amqp_empty_table); while (1) { amqp_rpc_reply_t result; amqp_envelope_t envelope; amqp_maybe_release_buffers(conn); result = amqp_consume_message(conn, &envelope, NULL, 0); if (AMQP_RESPONSE_NORMAL != result.reply_type) { printf(\"Consumer AMQP failure occurred, response code = %d, retrying in %d seconds...\\n\", result.reply_type, retry_time); // Closing current connection before reconnecting amqp_connection_close(conn, AMQP_CONNECTION_FORCED); amqp_destroy_connection(conn); // Reconnecting on exception conn = mqconnect(); queue = mqdeclare(conn, &exchange_name[0], &queue_name[0], binding_key); amqp_basic_consume(conn, channel, queue, amqp_empty_bytes, no_local, no_ack, exclusive, amqp_empty_table); sleep(retry_time); } else { printf(\"Received message size: %d\\nbody: %s\\n\", (int)envelope.message.body.len, (char *)envelope.message.body.bytes); amqp_destroy_envelope(&envelope); } } return 0; }","title":"Key based message routing"},{"location":"routing-key/#routing-key-based","text":"Routing - Key based messaging is an extension of direct exchange allowing filtering of messages based on a producer\u2019s routing key. Messages published to the exchange will be routed to queues bound to that exchange with matching binding key. All other messages will be filtered. A consumer will define callback functions to process messages that are selectively received. Browse the chapter of AMQP Introduction first if you're new to AMQP.","title":"Routing - Key Based"},{"location":"routing-key/#python","text":"","title":"Python"},{"location":"routing-key/#prerequisites","text":"Python client AMQP library The Python library we use for this example can be found at https://github.com/pika/pika . You can install it through sudo pip install pika . Finally, import this library in your program. import pika The full documentation of this library is at https://pika.readthedocs.org/en/0.9.14/ . pika library is not thread safe. Do not use a connection or channel across threads.","title":"Prerequisites"},{"location":"routing-key/#producer","text":"The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. credentials = pika.PlainCredentials(username, password) connection = pika.BlockingConnection(pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60)) channel = connection.channel() Then producer can publish messages to a direct exchange where messages will be delivered to queues whose routing key matches. Delivery mode = 1 means it's a non-persistent message. properties = pika.spec.BasicProperties(content_type = \"text/plain\", delivery_mode = 1) channel.basic_publish(exchange = exchangeName, routing_key = routingKey, body = \"Hello World!\", properties = properties) At last, producer will disconnect with the RoboMQ broker. connection.close()","title":"Producer"},{"location":"routing-key/#consumer","text":"The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a direct exchange, a queue, and bind the queue to the exchange with a routing key. The routing key decides what messages will a queue receive. Auto-delete means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. Exclusive means no other consumer can consume the queue when this one is consuming it. channel.exchange_declare(exchange = exchangeName, exchange_type = \"direct\", auto_delete = True) channel.queue_declare(queue = queueName, exclusive = True, auto_delete = True) channel.queue_bind(exchange = exchangeName, queue = queueName, routing_key = routingKey) Finally, consumer can consume messages from the queue. The no_ack parameter indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, no_ack equals to true, so producer does not explicitly acknowledge received messages. The start_consuming() function will be blocking the process until stop_consuming() is invoked or exception happens. channel.basic_consume(consumer_callback = onMessage, queue = queueName, no_ack = True) channel.start_consuming() When messages are received, a callback function onMessage() will be invoked to print the message content. def onMessage(channel, method, properties, body): print body","title":"Consumer"},{"location":"routing-key/#putting-it-all-together","text":"producer.py import pika server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" exchangeName = \"testEx\" routingKey = \"test\" try: #connect credentials = pika.PlainCredentials(username, password) connection = pika.BlockingConnection(pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60)) channel = connection.channel() #send message properties = pika.spec.BasicProperties(content_type = \"text/plain\", delivery_mode = 1) channel.basic_publish(exchange = exchangeName, routing_key = routingKey, body = \"Hello World!\", properties = properties) #disconnect connection.close() except Exception, e: print e consumer.py import pika import time server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" exchangeName = \"testEx\" queueName = \"testQ1\" routingKey = \"test\" #callback funtion on receiving messages def onMessage(channel, method, properties, body): print body while True: try: #connect credentials = pika.PlainCredentials(username, password) connection = pika.BlockingConnection(pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60)) channel = connection.channel() #declare exchange and queue, bind them and consume messages channel.exchange_declare(exchange = exchangeName, exchange_type = \"direct\", auto_delete = True) channel.queue_declare(queue = queueName, exclusive = True, auto_delete = True) channel.queue_bind(exchange = exchangeName, queue = queueName, routing_key = routingKey) channel.basic_consume(consumer_callback = onMessage, queue = queueName, no_ack = True) channel.start_consuming() except Exception, e: #reconnect on exception print \"Exception handled, reconnecting...\\nDetail:\\n%s\" % e try: connection.close() except: pass time.sleep(5)","title":"Putting it all together"},{"location":"routing-key/#nodejs","text":"","title":"Node.js"},{"location":"routing-key/#prerequisites_1","text":"Node.js client AMQP library The Node.js library we use for this example can be found at https://github.com/squaremo/amqp.node . You can install the library through sudo npm install amqplib . Finally, require this library in your program. var amqp = require(\"amqplib\"); The full documentation of this library is at https://www.squaremobius.net/amqp.node/doc/channel_api.html .","title":"Prerequisites"},{"location":"routing-key/#producer_1","text":"The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. As shown in the code, this library provides chainable callback API in the form of .then(callback) . For the default vhost \"/\", you will need to insert \"%2f\" (its hexadecimal ASCII code) to the AMQP URI, instead of \"/\" itself. producer = amqp.connect(\"amqp://\" + username + \":\" + password + \"@\" + server + \":\" + port + \"/\" + vhost + \"?heartbeat=60\"); producer.then(function(conn) { return conn.createConfirmChannel().then(successCallback); }).then(null, failureCallback); Then producer can publish messages to a direct exchange where messages will be delivered to queues whose routing key matches. Delivery mode = 1 means it's a non-persistent message. ch.publish(exchangeName, routingKey, content = new Buffer(\"Hello World!\"), options = {contentType: \"text/plain\", deliveryMode: 1}, callback); At last, producer will disconnect with the RoboMQ broker. conn.close();","title":"Producer"},{"location":"routing-key/#consumer_1","text":"The same as producer, consumer needs to first connect to RoboMQ broker. The difference is that consumer uses conn.createChannel() function, while producer uses conn.createConfirmChannel() because the latter one is only useful for publish confirm. Then consumer will declare a direct exchange, a queue, and bind the queue to the exchange with a routing key. The routing key decides what messages will a queue receive. Durable means the exchange or queue will survive possible broker failover. It's false in this example. Auto-delete means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. Exclusive means no other consumer can consume the queue when this one is consuming it. ch.assertExchange(exchangeName, \"direct\", {durable: false, autoDelete: true}); ch.assertQueue(queueName, {durable: false, autoDelete: true, exclusive: true}); ch.bindQueue(queueName, exchangeName, routingKey); Finally, consumer can consume messages from the queue. The noAck option indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, noAck is true, so producer does not explicitly acknowledge received messages. The second parameter of consume() function is the callback on receiving messages. In this example, when messages are received, the callback function will be invoked to print the message content. ch.consume(queueName, function(message) { console.log(message.content.toString()); }, {noAck: true});","title":"Consumer"},{"location":"routing-key/#putting-it-all-together_1","text":"producer.js var amqp = require(\"amqplib\"); var server = \"hostname\"; var port = \"5672\"; var vhost = \"yourvhost\"; //for \"/\" vhost, use \"%2f\" instead var username = \"username\"; var password = \"password\"; var exchangeName = \"testEx\"; var routingKey = \"test\"; producer = amqp.connect(\"amqp://\" + username + \":\" + password + \"@\" + server + \":\" + port + \"/\" + vhost + \"?heartbeat=60\"); producer.then(function(conn) { return conn.createConfirmChannel().then(function(ch) { ch.publish(exchangeName, routingKey, content = new Buffer(\"Hello World!\"), options = {contentType: \"text/plain\", deliveryMode: 1}, function(err, ok) { if (err != null) { console.error(\"Error: failed to send message\\n\" + err); } conn.close(); }); }); }).then(null, function(err) { console.error(err); }); consumer.js var amqp = require(\"amqplib\"); var domain = require(\"domain\"); var server = \"hostname\"; var port = \"5672\"; var vhost = \"yourvhost\"; //for \"/\" vhost, use \"%2f\" instead var username = \"username\"; var password = \"password\"; var exchangeName = \"testEx\"; var queueName = \"testQ1\"; var routingKey = \"test\"; //use domain module to handle reconnecting var consumer = null; var dom = domain.create(); dom.on(\"error\", relisten); dom.run(listen); function listen() { consumer = amqp.connect(\"amqp://\" + username + \":\" + password + \"@\" + server + \":\" + port + \"/\" + vhost + \"?heartbeat=60\"); consumer.then(function(conn) { return conn.createChannel().then(function(ch) { ch.assertExchange(exchangeName, \"direct\", {durable: false, autoDelete: true}); ch.assertQueue(queueName, {durable: false, autoDelete: true, exclusive: true}); ch.bindQueue(queueName, exchangeName, routingKey); ch.consume(queueName, function(message) { //callback funtion on receiving messages console.log(message.content.toString()); }, {noAck: true}); }); }).then(null, function(err) { console.error(\"Exception handled, reconnecting...\\nDetail:\\n\" + err); setTimeout(listen, 5000); }); } function relisten() { consumer.then(function(conn) { conn.close(); }); setTimeout(listen, 5000); }","title":"Putting it all together"},{"location":"routing-key/#php","text":"","title":"PHP"},{"location":"routing-key/#prerequisite","text":"PHP client AMQP library The PHP library we use for this example can be found at https://github.com/videlalvaro/php-amqplib . It uses composer to install in a few steps. Add a composer.json file to your project: { \"require\": { \"videlalvaro/php-amqplib\": \"2.2.*\" } } Download the latest composer in the same path: curl -sS https://getcomposer.org/installer | php Install the library through composer: ./composer.phar install Finally, require this library in your program and use the classes. require_once __DIR__ . '/../vendor/autoload.php'; //directory of library folder use PhpAmqpLib\\Connection\\AMQPConnection; use PhpAmqpLib\\Message\\AMQPMessage;","title":"Prerequisite"},{"location":"routing-key/#producer_2","text":"The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. $connection = new AMQPConnection($server, $port, $username, $password, $vhost, $heartbeat = 60); $channel = $connection->channel(); Then producer can publish messages to a direct exchange where messages will be delivered to queues whose routing key matches. Delivery mode = 1 means it's a non-persistent message. $message = new AMQPMessage(\"Hello World!\", array(\"content_type\" => \"text/plain\", \"delivery_mode\" => 1)); $channel->basic_publish($message, $exchangeName, $routingKey); At last, producer will disconnect with the RoboMQ broker. $connection->close();","title":"Producer"},{"location":"routing-key/#consumer_2","text":"The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a direct exchange, a queue, and bind the queue to the exchange with a routing key. The routing key decides what messages will a queue receive. Auto-delete means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. Exclusive means no other consumer can consume the queue when this one is consuming it. $channel->exchange_declare($exchangeName, $type = \"direct\", false, false, $auto_delete = true); $channel->queue_declare($queueName, false, false, $exclusive = true, $auto_delete = true); $channel->queue_bind($queueName, $exchangeName, $routingKey); Finally, consumer can consume messages from the queue. The no_ack parameter indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, no_ack equals to true, so producer does not explicitly acknowledge received messages. The while loop will be blocking the process and listening for messages until exception happens. $channel->basic_consume($queueName, \"\", false, $no_ack = true, false, false, $callback = $onMessage); while(count($channel->callbacks)) { $channel->wait(); } When messages are received, a callback function will be invoked to print the message content. $onMessage = function ($message) { echo $message->body.PHP_EOL; };","title":"Consumer"},{"location":"routing-key/#putting-it-together","text":"producer.php <?php require_once __DIR__ . '/../vendor/autoload.php'; //directory of library folder use PhpAmqpLib\\Connection\\AMQPConnection; use PhpAmqpLib\\Message\\AMQPMessage; $server = \"hostname\"; $port = 5672; $vhost = \"yourvhost\"; $username = \"username\"; $password = \"password\"; $exchangeName = \"testEx\"; $routingKey = \"test\"; try { //connect $connection = new AMQPConnection($server, $port, $username, $password, $vhost, $heartbeat = 60); $channel = $connection->channel(); //send message $message = new AMQPMessage(\"Hello World!\", array(\"content_type\" => \"text/plain\", \"delivery_mode\" => 1)); $channel->basic_publish($message, $exchangeName, $routingKey); //disconnect $connection->close(); } catch(Exception $e) { echo $e.PHP_EOL; } ?> consumer.php <?php require_once __DIR__.\"/../vendor/autoload.php\"; //directory of library folder use PhpAmqpLib\\Connection\\AMQPConnection; $server = \"hostname\"; $port = 5672; $vhost = \"yourvhost\"; $username = \"username\"; $password = \"password\"; $exchangeName = \"testEx\"; $queueName = \"testQ1\"; $routingKey = \"test\"; //callback funtion on receiving messages $onMessage = function ($message) { echo $message->body.PHP_EOL; }; while (true) { try { //connect $connection = new AMQPConnection($server, $port, $username, $password, $vhost, $heartbeat = 60); $channel = $connection->channel(); //declare exchange and queue, bind them and consume messages $channel->exchange_declare($exchangeName, $type = \"direct\", false, false, $auto_delete = true); $channel->queue_declare($queueName, false, false, $exclusive = true, $auto_delete = true); $channel->queue_bind($queueName, $exchangeName, $routingKey); $channel->basic_consume($queueName, \"\", false, $no_ack = true, false, false, $callback = $onMessage); //start consuming while(count($channel->callbacks)) { $channel->wait(); } } catch(Exception $e) { //reconnect on exception echo \"Exception handled, reconnecting...\\nDetail:\\n\".$e.PHP_EOL; if ($connection != null) { try { $connection->close(); } catch (Exception $e1) {} } sleep(5); } } ?>","title":"Putting it together"},{"location":"routing-key/#ruby","text":"","title":"Ruby"},{"location":"routing-key/#prerequisites_2","text":"Ruby client AMQP library The Ruby library we use for this example can be found at http://rubybunny.info/ . With Ruby version >= 2.0, you can install it through sudo gem install bunny . Finally, import this library in your program. require \"bunny\" The full documentation of this library is at http://rubybunny.info/articles/guides.html . We recommend combining the documentation with the source code of this library when you use it because some of the documentation out there is not being updated timely from our observation.","title":"Prerequisites"},{"location":"routing-key/#producer_3","text":"The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. Although the library provides a connection property named recover_from_connection_close , we discourage you to use it. The reason will be explained in the Consumer section. connection = Bunny.new(:host => server, :port => port, :vhost => vhost, :user => username, :pass => password, :heartbeat => 60, :recover_from_connection_close => false) connection.start channel = connection.create_channel Then producer can publish messages to a direct exchange where messages will be delivered to queues whose routing key matches. Delivery mode = 1 means it's a non-persistent message. exchange = channel.direct(exchangeName, :auto_delete => true) exchange.publish(\"Hello World!\", :routing_key => routingKey, :content_type => \"text/plain\", :delivery_mode => 1) At last, producer will disconnect with the RoboMQ broker. connection.close","title":"Producer"},{"location":"routing-key/#consumer_3","text":"The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a direct exchange, a queue, and bind the queue to the exchange with a routing key. The routing key decides what messages will a queue receive. Auto-delete means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. Exclusive means no other consumer can consume the queue when this one is consuming it. exchange = channel.direct(exchangeName, :auto_delete => true) queue = channel.queue(queueName, :exclusive => true, :auto_delete => true) queue.bind(exchange, :routing_key => routingKey) After that, consumer can consume messages from the queue. The manual_ack parameter indicates if consumer needs to manually send acknowledgment back to broker when it has received the message. In this example, manual_ack equals to false, so producer does not manually acknowledge received messages. The subscribe() function is followed by a callback which will be invoked to print the message payload on receiving a message. queue.subscribe(:block => false, :manual_ack => false) do |delivery_info, metadata, payload| puts payload end As we mentioned in the Producer section, recover_from_connection_close is set to false when connecting to RoboMQ broker. It matters for consumers because recover_from_connection_close will only recover the connection, it won't recreate exchange and queue in case they are gone. Therefore, a more robust approach is letting your code handle reconnecting on its own and keep checking the existence of the subscribed queue. while true raise \"Lost the subscribed queue %s\" % queueName unless connection.queue_exists?(queueName) sleep 1 end","title":"Consumer"},{"location":"routing-key/#putting-it-all-together_2","text":"producer.rb require \"bunny\" server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" exchangeName = \"testEx\" routingKey = \"test\" begin #connect connection = Bunny.new(:host => server, :port => port, :vhost => vhost, :user => username, :pass => password, :heartbeat => 60, :recover_from_connection_close => false) connection.start channel = connection.create_channel #send message exchange = channel.direct(exchangeName, :auto_delete => true) exchange.publish(\"Hello World!\", :routing_key => routingKey, :content_type => \"text/plain\", :delivery_mode => 1) #disconnect connection.close rescue Exception => e puts e end consumer.rb require \"bunny\" server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" exchangeName = \"testEx\" queueName = \"testQ1\" routingKey = \"test\" while true begin #connect, disable auto-reconnect so as to manually reconnect connection = Bunny.new(:host => server, :port => port, :vhost => vhost, :user => username, :pass => password, :heartbeat => 60, :recover_from_connection_close => false) connection.start channel = connection.create_channel #declare exchange and queue, bind them and consume messages exchange = channel.direct(exchangeName, :auto_delete => true) queue = channel.queue(queueName, :exclusive => true, :auto_delete => true) queue.bind(exchange, :routing_key => routingKey) queue.subscribe(:block => false, :manual_ack => false) do |delivery_info, metadata, payload| puts payload end #keep checking the existence of the subscribed queue while true raise \"Lost the subscribed queue %s\" % queueName unless connection.queue_exists?(queueName) sleep 1 end rescue Exception => e #reconnect on exception puts \"Exception handled, reconnecting...\\nDetail:\\n%s\" % e #blindly clean old connection begin connection.close end sleep 5 end end","title":"Putting it all together"},{"location":"routing-key/#java","text":"","title":"Java"},{"location":"routing-key/#prerequisites_3","text":"Java client AMQP library The Java library we use for this example can be found at https://www.rabbitmq.com/java-client.html . Download the library jar file, then import this library in your program import com.rabbitmq.client.*; and compile your source code with the jar file. For example, javac -cp \".:./rabbitmq-client.jar\" Producer.java Consumer.java Run the producer and consumer classes. For example, java -cp \".:./rabbitmq-client.jar\" Consumer java -cp \".:./rabbitmq-client.jar\" Producer Of course, you can eventually compress your producer and consumer classes into jar files.","title":"Prerequisites"},{"location":"routing-key/#producer_4","text":"The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. ConnectionFactory factory = new ConnectionFactory(); factory.setHost(server); factory.setPort(port); factory.setVirtualHost(vhost); factory.setUsername(username); factory.setPassword(password); factory.setRequestedHeartbeat(60); connection = factory.newConnection(); channel = connection.createChannel(); Then producer can publish messages to a direct exchange where messages will be delivered to queues whose routing key matches. String message = \"Hello World!\"; channel.basicPublish(exchangeName, routingKey, MessageProperties.TEXT_PLAIN, message.getBytes()); At last, producer will disconnect with the RoboMQ broker. connection.close();","title":"Producer"},{"location":"routing-key/#consumer_4","text":"The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a direct exchange, a queue, and bind the queue to the exchange with a routing key. The routing key decides what messages will a queue receive. The fourth parameter of exchangeDeclare() and queueDeclare() are auto-delete. That means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. The third parameter of queueDeclare() is exclusive. That means no other consumer can consume the queue when this one is consuming it. channel.exchangeDeclare(exchangeName, \"direct\", false, true, false, null); channel.queueDeclare(queueName, false, true, true, null); channel.queueBind(queueName, exchangeName, routingKey, null); Finally, consumer can consume messages from the queue. The second parameter of basicConsume() function no-ack indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, no-ack equals to true, so producer does not explicitly acknowledge received messages. The while loop will be blocking the process and listening for messages until exception happens. When messages are received, it will print the message content. QueueingConsumer qc = new QueueingConsumer(channel); channel.basicConsume(queueName, true, qc); while (true) { QueueingConsumer.Delivery delivery = qc.nextDelivery(); String message = new String(delivery.getBody()); System.out.println(message); }","title":"Consumer"},{"location":"routing-key/#putting-it-all-together_3","text":"Producer.java import com.rabbitmq.client.ConnectionFactory; import com.rabbitmq.client.Connection; import com.rabbitmq.client.Channel; import com.rabbitmq.client.MessageProperties; public class Producer { private Connection connection; private Channel channel; private static String server = \"hostname\"; private static int port = 5672; private static String vhost = \"yourvhost\"; private static String username = \"username\"; private static String password = \"password\"; private static String exchangeName = \"testEx\"; private static String routingKey = \"test\"; private void produce() { try { //connect ConnectionFactory factory = new ConnectionFactory(); factory.setHost(server); factory.setPort(port); factory.setVirtualHost(vhost); factory.setUsername(username); factory.setPassword(password); factory.setRequestedHeartbeat(60); connection = factory.newConnection(); channel = connection.createChannel(); //send message String message = \"Hello World!\"; channel.basicPublish(exchangeName, routingKey, MessageProperties.TEXT_PLAIN, message.getBytes()); //disconnect connection.close(); } catch(Exception e) { System.out.println(e); System.exit(-1); } } public static void main(String[] args) { Producer p = new Producer(); p.produce(); } } Consumer.java import com.rabbitmq.client.ConnectionFactory; import com.rabbitmq.client.Connection; import com.rabbitmq.client.Channel; import com.rabbitmq.client.QueueingConsumer; public class Consumer { private Connection connection; private Channel channel; private static String server = \"hostname\"; private static int port = 5672; private static String vhost = \"yourvhost\"; private static String username = \"username\"; private static String password = \"password\"; private static String exchangeName = \"testEx\"; private static String queueName = \"testQ1\"; private static String routingKey = \"test\"; private void consume() { while (true) { try { //connect ConnectionFactory factory = new ConnectionFactory(); factory.setHost(server); factory.setPort(port); factory.setVirtualHost(vhost); factory.setUsername(username); factory.setPassword(password); factory.setRequestedHeartbeat(60); connection = factory.newConnection(); channel = connection.createChannel(); //declare exchange and queue, bind them and consume messages channel.exchangeDeclare(exchangeName, \"direct\", false, true, false, null); channel.queueDeclare(queueName, false, true, true, null); channel.queueBind(queueName, exchangeName, routingKey, null); QueueingConsumer qc = new QueueingConsumer(channel); channel.basicConsume(queueName, true, qc); while (true) { QueueingConsumer.Delivery delivery = qc.nextDelivery(); String message = new String(delivery.getBody()); System.out.println(message); } } catch(Exception e) { //reconnect on exception System.out.printf(\"Exception handled, reconnecting...\\nDetail:\\n%s\\n\", e); try { connection.close(); } catch (Exception e1) {} try { Thread.sleep(5000); } catch(Exception e2) {} } } } public static void main(String[] args) { Consumer c = new Consumer(); c.consume(); } }","title":"Putting it all together"},{"location":"routing-key/#go","text":"","title":"Go"},{"location":"routing-key/#prerequisites_4","text":"Go client AMQP library The Go library we use for this example can be found at https://github.com/streadway/amqp . You can install it through go get github.com/streadway/amqp . Finally, import this library in your program. import \"github.com/streadway/amqp\" The full documentation of this library is at https://godoc.org/github.com/streadway/amqp .","title":"Prerequisites"},{"location":"routing-key/#producer_5","text":"The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. connection, err := amqp.DialConfig(fmt.Sprintf(\"amqp://%s:%s@%s:%d/%s\", username, password, server, port, vhost), amqp.Config{Heartbeat: 60 * time.Second}) channel, err := connection.Channel() Then producer can publish messages to a direct exchange where messages will be delivered to queues whose routing key matches. Delivery mode = 1 means it's a non-persistent message. err = channel.Publish(exchangeName, routingKey, false, false, amqp.Publishing{ContentType: \"text/plain\", DeliveryMode: 1, Body: []byte(\"Hello World!\")}) At last, producer will disconnect with the RoboMQ broker. connection.Close()","title":"Producer"},{"location":"routing-key/#consumer_5","text":"The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a direct exchange, a queue, and bind the queue to the exchange with a routing key. The routing key decides what messages will a queue receive. Durable means the exchange or queue will survive possible broker failover. It's false in this example. Auto-delete means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. Exclusive means no other consumer can consume the queue when this one is consuming it. // audo-delete = true err = channel.ExchangeDeclare(exchangeName, \"direct\", false, true, false, false, nil) // durable = false; auto-delete = true; exclusive = true queue, err := channel.QueueDeclare(queueName, false, true, true, false, nil) err = channel.QueueBind(queueName, routingKey, exchangeName, false, nil) Finally, consumer can consume messages from the queue. Consumer-tag can be later used to Cancel() this consumer when it's no longer needed. Auto-ack parameter indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, auto-ack equals to true, so producer does not explicitly acknowledge received messages. // consumer-tag = \"consumer\"; auto-ack = true messageChan, err := channel.Consume(queue.Name, \"consumer\", true, true, false, false, nil) Note a message channel is returned by the Consume() function. Incoming messages will be received through that channel. Channel in Golang is a typed conduit through which you can send and receive values. Sends and receives block until the other side is ready. for message := range messageChan { fmt.Println(string(message.Body)) }","title":"Consumer"},{"location":"routing-key/#putting-it-all-together_4","text":"producer.go package main import ( \"fmt\" \"github.com/streadway/amqp\" \"os\" \"time\" ) var server = \"hostname\" var port = 5672 var vhost = \"yourvhost\" var username = \"username\" var password = \"password\" var exchangeName = \"testEx\" var routingKey = \"test\" func main() { connection, err := amqp.DialConfig(fmt.Sprintf(\"amqp://%s:%s@%s:%d/%s\", username, password, server, port, vhost), amqp.Config{Heartbeat: 60 * time.Second}) if err != nil { fmt.Printf(\"Failed to connect, err: %v\\n\", err) os.Exit(1) } defer connection.Close() channel, err := connection.Channel() if err != nil { fmt.Printf(\"Failed to create channel, err: %v\\n\", err) os.Exit(1) } defer channel.Close() err = channel.Publish( exchangeName, // exchange routingKey, // routing key false, // mandatory false, // immediate amqp.Publishing{ ContentType: \"text/plain\", DeliveryMode: 1, Body: []byte(\"Hello World!\"), }) if err != nil { fmt.Printf(\"Failed to publish message, err: %v\\n\", err) os.Exit(1) } } consumer.go package main import ( \"fmt\" \"github.com/streadway/amqp\" \"time\" ) var server = \"hostname\" var port = 5672 var vhost = \"yourvhost\" var username = \"username\" var password = \"password\" var exchangeName = \"testEx\" var queueName = \"testQ1\" var routingKey = \"test\" func main() { // Infinite loop to auto-reconnect on failure Loop: for { fmt.Println(\"Starting in 5 seconds...\") time.Sleep(5 * time.Second) connection, err := amqp.DialConfig(fmt.Sprintf(\"amqp://%s:%s@%s:%d/%s\", username, password, server, port, vhost), amqp.Config{Heartbeat: 60 * time.Second}) if err != nil { fmt.Printf(\"Failed to connect, err: %v\\n\", err) continue Loop } defer connection.Close() channel, err := connection.Channel() if err != nil { fmt.Printf(\"Failed to create channel, err: %v\\n\", err) continue Loop } defer channel.Close() err = channel.ExchangeDeclare( exchangeName, // name \"direct\", // type false, // durable true, // audo-delete false, // internal false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to declare exchange, err: %v\\n\", err) continue Loop } queue, err := channel.QueueDeclare( queueName, // name false, // durable true, // auto-delete true, // exclusive false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to declare queue, err: %v\\n\", err) continue Loop } err = channel.QueueBind( queueName, // queue routingKey, // key exchangeName, // exchange false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to bind queue with exchange, err: %v\\n\", err) continue Loop } messageChan, err := channel.Consume( queue.Name, // queue \"consumer\", // consumer tag true, // auto-ack true, // exclusive false, // no-local false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to consume messages, err: %v\\n\", err) continue Loop } fmt.Println(\"Started consuming messages.\") for message := range messageChan { fmt.Println(string(message.Body)) } } }","title":"Putting it all together"},{"location":"routing-key/#c","text":"","title":"C"},{"location":"routing-key/#prerequisites_5","text":"C client AMQP library RoboMQ is built on AMQP, an open, general-purpose protocol for messaging. There are a number of clients for AMQP in many different languages. However, we'll choose a simple C-language AMQP client library written for use with v2.0+ of the RabbitMQ broker. https://github.com/alanxz/rabbitmq-c/tree/master/librabbitmq You can copy librabbitmq subfolder from latest release located here on GitHub: https://github.com/alanxz/rabbitmq-c Alternatively, thanks to Subversion support in GitHub, you can use svn export directly: svn export https://github.com/alanxz/rabbitmq-c/trunk/librabbitmq Copy the librabbitmq package into your working directory: cp librabbitmq ./ Also copy all source files and Makefile from RoboMQ SDK at https://github.com/robomq/robomq.io/tree/master/sdk/AMQP/C into the same directory. Now your working directory should have the content as bellow: broadcast config.h librabbitmq Makefile one-to-one request-reply routing-key topic Use the Makefile to compile under a Linux terminal. Run make type={sub-directory} to compile the producer and consumer under the sub-directory. Before compiling the next sub-directory, run make clean to clean up the compiled files. Note that these examples provide a simple client implementation to get started but does not go into detailed description of all flags passed into the AMQP methods. A complete reference to RabbitMQ's implementaton of version 0-9-1 of the AMQP specification can be found in this guide. https://www.rabbitmq.com/amqp-0-9-1-reference.html","title":"Prerequisites"},{"location":"routing-key/#producer_6","text":"For routing-Key based messaging, the producer should publish messages to the specified exchange allowing filtering of messages based on a producer\u2019s routing key. Based on that routing key, messages will be sent through the exchange and distributed to the right queue. If not specified, that routing key is the queue name. amqp_basic_properties_t props; props._flags = AMQP_BASIC_CONTENT_TYPE_FLAG | AMQP_BASIC_DELIVERY_MODE_FLAG; props.content_type = amqp_cstring_bytes(\"text/plain\"); props.delivery_mode = 1; /* non-persistent delivery mode */ amqp_boolean_t mandatory = 0; amqp_boolean_t immediate = 0; char exchange_name[] = \"hello-exchange\"; char routing_key[] = \"routingKey\"; int result; // Sending message result = amqp_basic_publish(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(routing_key), mandatory, immediate, &props, amqp_cstring_bytes(\"Hello\"));","title":"Producer"},{"location":"routing-key/#consumer_6","text":"Then the consumer should create a queue and subscribe to a queue. This queue will work similarly to the one-to-one example using the direct exchange type, however, only messages published to this exchange with routing key matching \"routingKey\" will be received by consumer. All other messages will be filtered. amqp_bytes_t queue; amqp_channel_t channel = 1; amqp_boolean_t passive = 0; amqp_boolean_t durable = 0; amqp_boolean_t exclusive = 0; amqp_boolean_t auto_delete = 1; amqp_boolean_t internal = 0; char exchange_name[] = \"hello-exchange\"; char exchange_type[] = \"direct\"; char queue_name[] = \"hello-queue\"; char binding_key[] = \"routingKey\"; // Declaring exchange amqp_exchange_declare(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(exchange_type), passive, durable, auto_delete, internal, amqp_empty_table); // Declaring queue amqp_queue_declare_ok_t *r = amqp_queue_declare(conn, channel, amqp_cstring_bytes(queue_name), passive, durable, exclusive, auto_delete, amqp_empty_table); queue = amqp_bytes_malloc_dup(r->queue); // Binding to queue amqp_queue_bind(conn, channel, queue, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(binding_key), amqp_empty_table); Note that all the queues declared without specific binding key use the queue name as the default binding key. At this point, consumer should start consuming messages.","title":"Consumer"},{"location":"routing-key/#putting-it-all-together_5","text":"The full code below includes some basic AMQP error handling for consumer that is useful when declaring exchanges and queues. In addition, main receiver loop attempts to reconnect upon network connection failure. producer.c #include <stdlib.h> #include <stdio.h> #include <string.h> #include <amqp_tcp_socket.h> #include <amqp.h> #include <amqp_framing.h> amqp_connection_state_t mqconnect() { amqp_connection_state_t conn = amqp_new_connection(); amqp_socket_t *socket = NULL; char hostname[] = \"localhost\"; // RoboMQ hostname int port = 5672; //default char user[] = \"guest\"; // RoboMQ username char password[] = \"guest\"; // RoboMQ password char vhost[] = \"/\"; // RoboMQ account vhost amqp_channel_t channel = 1; int channel_max = 0; int frame_max = 131072; int heartbeat = 60; int status = 0; // Opening socket socket = amqp_tcp_socket_new(conn); status = amqp_socket_open(socket, hostname, port); if (status) { printf(\"Error opening TCP socket, status = %d, exiting.\", status); } amqp_login(conn, vhost, channel_max, frame_max, heartbeat, AMQP_SASL_METHOD_PLAIN, user, password); amqp_channel_open(conn, channel); return conn; } int main(int argc, char const *const *argv) { amqp_connection_state_t conn; amqp_channel_t channel = 1; amqp_basic_properties_t props; props._flags = AMQP_BASIC_CONTENT_TYPE_FLAG | AMQP_BASIC_DELIVERY_MODE_FLAG; props.content_type = amqp_cstring_bytes(\"text/plain\"); props.delivery_mode = 1; /* non-persistent delivery mode */ amqp_boolean_t mandatory = 0; amqp_boolean_t immediate = 0; char exchange_name[] = \"hello-exchange\"; const char *routing_key; char *msg_body = \"Hello\\n\"; int result; if(argc < 2) { printf(\"Syntax error:\\n\" \"Usage: mqsend <routing_key>\\n\"); exit(-1); } routing_key = (char *)argv[1]; conn = mqconnect(); // Sending message result = amqp_basic_publish(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(routing_key), mandatory, immediate, &props, amqp_cstring_bytes(msg_body)); // Closing connection amqp_connection_close(conn, AMQP_REPLY_SUCCESS); amqp_destroy_connection(conn); return 0; } consumer.c #include <stdlib.h> #include <stdio.h> #include <string.h> #include <amqp_tcp_socket.h> #include <amqp.h> #include <amqp_framing.h> amqp_connection_state_t mqconnect() { amqp_connection_state_t conn = amqp_new_connection(); amqp_socket_t *socket = NULL; char hostname[] = \"localhost\"; // RoboMQ hostname int port = 5672; //default char user[] = \"guest\"; // RoboMQ username char password[] = \"guest\"; // RoboMQ password char vhost[] = \"/\"; // RoboMQ account vhost amqp_channel_t channel = 1; amqp_rpc_reply_t reply; int channel_max = 0; int frame_max = 131072; int heartbeat = 60; int status = 0; // Opening socket socket = amqp_tcp_socket_new(conn); status = amqp_socket_open(socket, hostname, port); if (status) { printf(\"Error opening TCP socket, status = %d\\n\", status); } reply = amqp_login(conn, vhost, channel_max, frame_max, heartbeat, AMQP_SASL_METHOD_PLAIN, user, password); if(reply.reply_type != AMQP_RESPONSE_NORMAL) { fprintf(stderr, \"%s: server connection reply code: %d\\n\", \"Error logging in\", reply.reply_type); } amqp_channel_open(conn, channel); return conn; } amqp_bytes_t mqdeclare(amqp_connection_state_t conn, const char *exchange_name, const char *queue_name, const char *binding_key) { amqp_bytes_t queue; amqp_channel_t channel = 1; amqp_boolean_t passive = 0; amqp_boolean_t durable = 0; amqp_boolean_t exclusive = 0; amqp_boolean_t auto_delete = 1; amqp_boolean_t internal = 0; char exchange_type[] = \"direct\"; amqp_rpc_reply_t reply; // Declaring exchange amqp_exchange_declare(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(exchange_type), passive, durable, auto_delete, internal, amqp_empty_table); reply = amqp_get_rpc_reply(conn); if(reply.reply_type != AMQP_RESPONSE_NORMAL) { amqp_connection_close_t *m = (amqp_connection_close_t *) reply.reply.decoded; if(NULL != m) { fprintf(stderr, \"%s: server connection error %d, message: %.*s\\n\", \"Error declaring exchange\", m->reply_code, (int) m->reply_text.len, (char *) m->reply_text.bytes); } } // Declaring queue amqp_queue_declare_ok_t *r = amqp_queue_declare(conn, channel, amqp_cstring_bytes(queue_name), passive, durable, exclusive, auto_delete, amqp_empty_table); reply = amqp_get_rpc_reply(conn); if(reply.reply_type != AMQP_RESPONSE_NORMAL) { fprintf(stderr, \"%s: server connection reply code: %d\\n\", \"Error declaring queue\", reply.reply_type); } else { queue = amqp_bytes_malloc_dup(r->queue); // Binding to queue amqp_queue_bind(conn, channel, queue, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(binding_key), amqp_empty_table); } return queue; } int main(int argc, char const *const *argv) { amqp_connection_state_t conn; amqp_bytes_t queue; amqp_channel_t channel = 1; amqp_boolean_t no_local = 0; amqp_boolean_t no_ack = 1; amqp_boolean_t exclusive = 0; char exchange_name[] = \"hello-exchange\"; char queue_name[] = \"hello-queue\"; const char *binding_key; int retry_time = 5; // retry time in seconds if(argc < 2) { printf(\"Syntax error:\\n\" \"Usage: mqlisten <binding_key>\\n\"); exit(-1); } binding_key = (char *)argv[1]; conn = mqconnect(); queue = mqdeclare(conn, &exchange_name[0], &queue_name[0], binding_key); // Consuming the message amqp_basic_consume(conn, channel, queue, amqp_empty_bytes, no_local, no_ack, exclusive, amqp_empty_table); while (1) { amqp_rpc_reply_t result; amqp_envelope_t envelope; amqp_maybe_release_buffers(conn); result = amqp_consume_message(conn, &envelope, NULL, 0); if (AMQP_RESPONSE_NORMAL != result.reply_type) { printf(\"Consumer AMQP failure occurred, response code = %d, retrying in %d seconds...\\n\", result.reply_type, retry_time); // Closing current connection before reconnecting amqp_connection_close(conn, AMQP_CONNECTION_FORCED); amqp_destroy_connection(conn); // Reconnecting on exception conn = mqconnect(); queue = mqdeclare(conn, &exchange_name[0], &queue_name[0], binding_key); amqp_basic_consume(conn, channel, queue, amqp_empty_bytes, no_local, no_ack, exclusive, amqp_empty_table); sleep(retry_time); } else { printf(\"Received message size: %d\\nbody: %s\\n\", (int)envelope.message.body.len, (char *)envelope.message.body.bytes); amqp_destroy_envelope(&envelope); } } return 0; }","title":"Putting it all together"},{"location":"topic/","text":"Routing - Filter Based (Topic) For filter based routing, a producer declares the topic exchange when publishing a message. Messages sent with a particular routing key will be delivered to all the queues that are bound with a matching binding key. Filter based routing provides a method to use filter policies on routing key for choosing the recipients of messages. * (star) can substitute for exactly one word. example: 'topic.*' can be : topic1, topic2, topic3 etc. # (hash) can substitute for zero or more words. example: \"#.topic\" can be: topic, Ftopic, Secondtopic, 123topic etc. Browse the chapter of AMQP Introduction first if you're new to AMQP. Python Prerequisites Python client AMQP library The Python library we use for this example can be found at https://github.com/pika/pika . You can install it through sudo pip install pika . Finally, import this library in your program. import pika The full documentation of this library is at https://pika.readthedocs.org/en/0.9.14/ . pika library is not thread safe. Do not use a connection or channel across threads. Producer The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. credentials = pika.PlainCredentials(username, password) connection = pika.BlockingConnection(pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60)) channel = connection.channel() Then producer can publish messages to a topic exchange where messages will be delivered to queues whose routing key matches. The essential difference between normal routing key and topic is that consumer can subscribe a topic with wild cards inside. Delivery mode = 1 means it's a non-persistent message. properties = pika.spec.BasicProperties(content_type = \"text/plain\", delivery_mode = 1) channel.basic_publish(exchange = exchangeName, routing_key = routingKey, body = \"Hello World!\", properties = properties) At last, producer will disconnect with the RoboMQ broker. connection.close() Consumer The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a direct exchange, a queue, and bind the queue to the exchange with a routing key (topic). The routing key can contain wildcards to receive messages sent through different routing keys. Auto-delete means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. Exclusive means no other consumer can consume the queue when this one is consuming it. channel.exchange_declare(exchange = exchangeName, exchange_type = \"topic\", auto_delete = True) channel.queue_declare(queue = queueName, exclusive = True, auto_delete = True) channel.queue_bind(exchange = exchangeName, queue = queueName, routing_key = routingKey) Finally, consumer can consume messages from the queue. The no_ack parameter indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, no_ack equals to true, so producer does not explicitly acknowledge received messages. The start_consuming() function will be blocking the process until stop_consuming() is invoked or exception happens. channel.basic_consume(consumer_callback = onMessage, queue = queueName, no_ack = True) channel.start_consuming() When messages are received, a callback function onMessage() will be invoked to print the message content. def onMessage(channel, method, properties, body): print body Putting it all together producer.py import pika server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" exchangeName = \"testEx\" routingKey = \"test.any\" try: #connect credentials = pika.PlainCredentials(username, password) connection = pika.BlockingConnection(pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60)) channel = connection.channel() #send message properties = pika.spec.BasicProperties(content_type = \"text/plain\", delivery_mode = 1) channel.basic_publish(exchange = exchangeName, routing_key = routingKey, body = \"Hello World!\", properties = properties) #disconnect connection.close() except Exception, e: print e consumer.py import pika import time server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" exchangeName = \"testEx\" queueName = \"testQ1\" routingKey = \"test.#\" #topic with wildcard #callback funtion on receiving messages def onMessage(channel, method, properties, body): print body while True: try: #connect credentials = pika.PlainCredentials(username, password) connection = pika.BlockingConnection(pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60)) channel = connection.channel() #declare exchange and queue, bind them and consume messages channel.exchange_declare(exchange = exchangeName, exchange_type = \"topic\", auto_delete = True) channel.queue_declare(queue = queueName, exclusive = True, auto_delete = True) channel.queue_bind(exchange = exchangeName, queue = queueName, routing_key = routingKey) channel.basic_consume(consumer_callback = onMessage, queue = queueName, no_ack = True) channel.start_consuming() except Exception, e: #reconnect on exception print \"Exception handled, reconnecting...\\nDetail:\\n%s\" % e try: connection.close() except: pass time.sleep(5) Node.js Prerequisites Node.js client AMQP library The Node.js library we use for this example can be found at https://github.com/squaremo/amqp.node . You can install the library through sudo npm install amqplib . Finally, require this library in your program. var amqp = require(\"amqplib\"); The full documentation of this library is at https://www.squaremobius.net/amqp.node/doc/channel_api.html Producer The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. As shown in the code, this library provides chainable callback API in the form of .then(callback) . For the default vhost \"/\", you will need to insert \"%2f\" (its hexadecimal ASCII code) to the AMQP URI, instead of \"/\" itself. producer = amqp.connect(\"amqp://\" + username + \":\" + password + \"@\" + server + \":\" + port + \"/\" + vhost + \"?heartbeat=60\"); producer.then(function(conn) { return conn.createConfirmChannel().then(successCallback); }).then(null, failureCallback); Then producer can publish messages to a topic exchange where messages will be delivered to queues whose routing key matches. The essential difference between normal routing key and topic is that consumer can subscribe a topic with wild cards inside. Delivery mode = 1 means it's a non-persistent message. ch.publish(exchangeName, routingKey, content = new Buffer(\"Hello World!\"), options = {contentType: \"text/plain\", deliveryMode: 1}, callback); At last, producer will disconnect with the RoboMQ broker. conn.close(); Consumer The same as producer, consumer needs to first connect to RoboMQ broker. The difference is that consumer uses conn.createChannel() function, while producer uses conn.createConfirmChannel() because the latter one is only useful for publish confirm. Then consumer will declare a direct exchange, a queue, and bind the queue to the exchange with a routing key (topic). The routing key can contain wildcards to receive messages sent through different routing keys. Durable means the exchange or queue will survive possible broker failover. It's false in this example. Auto-delete means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. Exclusive means no other consumer can consume the queue when this one is consuming it. ch.assertExchange(exchangeName, \"topic\", {durable: false, autoDelete: true}); ch.assertQueue(queueName, {durable: false, autoDelete: true, exclusive: true}); ch.bindQueue(queueName, exchangeName, routingKey); Finally, consumer can consume messages from the queue. The noAck option indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, noAck is true, so producer does not explicitly acknowledge received messages. The second parameter of consume() function is the callback on receiving messages. In this example, when messages are received, the callback function will be invoked to print the message content. ch.consume(queueName, function(message) { console.log(message.content.toString()); }, {noAck: true}); Putting it all together producer.js var amqp = require(\"amqplib\"); var server = \"hostname\"; var port = \"5672\"; var vhost = \"yourvhost\"; //for \"/\" vhost, use \"%2f\" instead var username = \"username\"; var password = \"password\"; var exchangeName = \"testEx\"; var routingKey = \"test.any\"; producer = amqp.connect(\"amqp://\" + username + \":\" + password + \"@\" + server + \":\" + port + \"/\" + vhost + \"?heartbeat=60\"); producer.then(function(conn) { return conn.createConfirmChannel().then(function(ch) { ch.publish(exchangeName, routingKey, content = new Buffer(\"Hello World!\"), options = {contentType: \"text/plain\", deliveryMode: 1}, function(err, ok) { if (err != null) { console.error(\"Error: failed to send message\\n\" + err); } conn.close(); }); }); }).then(null, function(err) { console.error(err); }); consumer.js var amqp = require(\"amqplib\"); var domain = require(\"domain\"); var server = \"hostname\"; var port = \"5672\"; var vhost = \"yourvhost\"; //for \"/\" vhost, use \"%2f\" instead var username = \"username\"; var password = \"password\"; var exchangeName = \"testEx\"; var queueName = \"testQ1\"; var routingKey = \"test.#\"; //topic with wildcard //use domain module to handle reconnecting var consumer = null; var dom = domain.create(); dom.on(\"error\", relisten); dom.run(listen); function listen() { consumer = amqp.connect(\"amqp://\" + username + \":\" + password + \"@\" + server + \":\" + port + \"/\" + vhost + \"?heartbeat=60\"); consumer.then(function(conn) { return conn.createChannel().then(function(ch) { ch.assertExchange(exchangeName, \"topic\", {durable: false, autoDelete: true}); ch.assertQueue(queueName, {durable: false, autoDelete: true, exclusive: true}); ch.bindQueue(queueName, exchangeName, routingKey); ch.consume(queueName, function(message) { //callback funtion on receiving messages console.log(message.content.toString()); }, {noAck: true}); }); }).then(null, function(err) { console.error(\"Exception handled, reconnecting...\\nDetail:\\n\" + err); setTimeout(listen, 5000); }); } function relisten() { consumer.then(function(conn) { conn.close(); }); setTimeout(listen, 5000); } PHP Prerequisite PHP client AMQP library The PHP library we use for this example can be found at https://github.com/videlalvaro/php-amqplib . It uses composer to install in a few steps. Add a composer.json file to your project: { \"require\": { \"videlalvaro/php-amqplib\": \"2.2.*\" } } Download the latest composer in the same path: curl -sS https://getcomposer.org/installer | php Install the library through composer: ./composer.phar install Finally, require this library in your program and use the classes. require_once __DIR__ . '/../vendor/autoload.php'; //directory of library folder use PhpAmqpLib\\Connection\\AMQPConnection; use PhpAmqpLib\\Message\\AMQPMessage; Producer The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. $connection = new AMQPConnection($server, $port, $username, $password, $vhost, $heartbeat = 60); $channel = $connection->channel(); Then producer can publish messages to a topic exchange where messages will be delivered to queues whose routing key matches. The essential difference between normal routing key and topic is that consumer can subscribe a topic with wild cards inside. Delivery mode = 1 means it's a non-persistent message. $message = new AMQPMessage(\"Hello World!\", array(\"content_type\" => \"text/plain\", \"delivery_mode\" => 1)); $channel->basic_publish($message, $exchangeName, $routingKey); At last, producer will disconnect with the RoboMQ broker. $connection->close(); Consumer The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a direct exchange, a queue, and bind the queue to the exchange with a routing key (topic). The routing key can contain wildcards to receive messages sent through different routing keys. Auto-delete means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. Exclusive means no other consumer can consume the queue when this one is consuming it. $channel->exchange_declare($exchangeName, $type = \"topic\", false, false, $auto_delete = true); $channel->queue_declare($queueName, false, false, $exclusive = true, $auto_delete = true); $channel->queue_bind($queueName, $exchangeName, $routingKey); Finally, consumer can consume messages from the queue. The no_ack parameter indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, no_ack equals to true, so producer does not explicitly acknowledge received messages. The while loop will be blocking the process and listening for messages until exception happens. $channel->basic_consume($queueName, \"\", false, $no_ack = true, false, false, $callback = $onMessage); while(count($channel->callbacks)) { $channel->wait(); } When messages are received, a callback function will be invoked to print the message content. $onMessage = function ($message) { echo $message->body.PHP_EOL; }; Putting it together producer.php <?php require_once __DIR__ . '/../vendor/autoload.php'; //directory of library folder use PhpAmqpLib\\Connection\\AMQPConnection; use PhpAmqpLib\\Message\\AMQPMessage; $server = \"hostname\"; $port = 5672; $vhost = \"yourvhost\"; $username = \"username\"; $password = \"password\"; $exchangeName = \"testEx\"; $routingKey = \"test.any\"; try { //connect $connection = new AMQPConnection($server, $port, $username, $password, $vhost, $heartbeat = 60); $channel = $connection->channel(); //send message $message = new AMQPMessage(\"Hello World!\", array(\"content_type\" => \"text/plain\", \"delivery_mode\" => 1)); $channel->basic_publish($message, $exchangeName, $routingKey); //disconnect $connection->close(); } catch(Exception $e) { echo $e.PHP_EOL; } ?> consumer.php <?php require_once __DIR__.\"/../vendor/autoload.php\"; //directory of library folder use PhpAmqpLib\\Connection\\AMQPConnection; $server = \"hostname\"; $port = 5672; $vhost = \"yourvhost\"; $username = \"username\"; $password = \"password\"; $exchangeName = \"testEx\"; $queueName = \"testQ1\"; $routingKey = \"test.#\"; //topic with wildcard //callback funtion on receiving messages $onMessage = function ($message) { echo $message->body.PHP_EOL; }; while (true) { try { //connect $connection = new AMQPConnection($server, $port, $username, $password, $vhost, $heartbeat = 60); $channel = $connection->channel(); //declare exchange and queue, bind them and consume messages $channel->exchange_declare($exchangeName, $type = \"topic\", false, false, $auto_delete = true); $channel->queue_declare($queueName, false, false, $exclusive = true, $auto_delete = true); $channel->queue_bind($queueName, $exchangeName, $routingKey); $channel->basic_consume($queueName, \"\", false, $no_ack = true, false, false, $callback = $onMessage); //start consuming while(count($channel->callbacks)) { $channel->wait(); } } catch(Exception $e) { //reconnect on exception echo \"Exception handled, reconnecting...\\nDetail:\\n\".$e.PHP_EOL; if ($connection != null) { try { $connection->close(); } catch (Exception $e1) {} } sleep(5); } } ?> Ruby Prerequisites Ruby client AMQP library The Ruby library we use for this example can be found at http://rubybunny.info/ . With Ruby version >= 2.0, you can install it through sudo gem install bunny . Finally, import this library in your program. require \"bunny\" The full documentation of this library is at http://rubybunny.info/articles/guides.html . We recommend combining the documentation with the source code of this library when you use it because some of the documentation out there is not being updated timely from our observation. Producer The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. Although the library provides a connection property named recover_from_connection_close , we discourage you to use it. The reason will be explained in the Consumer section. connection = Bunny.new(:host => server, :port => port, :vhost => vhost, :user => username, :pass => password, :heartbeat => 60, :recover_from_connection_close => false) connection.start channel = connection.create_channel Then producer can publish messages to a topic exchange where messages will be delivered to queues whose routing key matches. The essential difference between normal routing key and topic is that consumer can subscribe a topic with wild cards inside. Delivery mode = 1 means it's a non-persistent message. exchange = channel.topic(exchangeName, :auto_delete => true) exchange.publish(\"Hello World!\", :routing_key => routingKey, :content_type => \"text/plain\", :delivery_mode => 1) At last, producer will disconnect with the RoboMQ broker. connection.close Consumer The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a direct exchange, a queue, and bind the queue to the exchange with a routing key (topic). The routing key can contain wildcards to receive messages sent through different routing keys. Auto-delete means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. Exclusive means no other consumer can consume the queue when this one is consuming it. exchange = channel.topic(exchangeName, :auto_delete => true) queue = channel.queue(queueName, :exclusive => true, :auto_delete => true) queue.bind(exchange, :routing_key => routingKey) After that, consumer can consume messages from the queue. The manual_ack parameter indicates if consumer needs to manually send acknowledgment back to broker when it has received the message. In this example, manual_ack equals to false, so producer does not manually acknowledge received messages. The subscribe() function is followed by a callback which will be invoked to print the message payload on receiving a message. queue.subscribe(:block => false, :manual_ack => false) do |delivery_info, metadata, payload| puts payload end As we mentioned in the Producer section, recover_from_connection_close is set to false when connecting to RoboMQ broker. It matters for consumers because recover_from_connection_close will only recover the connection, it won't recreate exchange and queue in case they are gone. Therefore, a more robust approach is letting your code handle reconnecting on its own and keep checking the existence of the subscribed queue. while true raise \"Lost the subscribed queue %s\" % queueName unless connection.queue_exists?(queueName) sleep 1 end Putting it all together producer.rb require \"bunny\" server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" exchangeName = \"testEx\" routingKey = \"test.any\" begin #connect connection = Bunny.new(:host => server, :port => port, :vhost => vhost, :user => username, :pass => password, :heartbeat => 60, :recover_from_connection_close => false) connection.start channel = connection.create_channel #send message exchange = channel.topic(exchangeName, :auto_delete => true) exchange.publish(\"Hello World!\", :routing_key => routingKey, :content_type => \"text/plain\", :delivery_mode => 1) #disconnect connection.close rescue Exception => e puts e end consumer.rb require \"bunny\" server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" exchangeName = \"testEx\" queueName = \"testQ1\" routingKey = \"test.#\" #topic with wildcard while true begin #connect, disable auto-reconnect so as to manually reconnect connection = Bunny.new(:host => server, :port => port, :vhost => vhost, :user => username, :pass => password, :heartbeat => 60, :recover_from_connection_close => false) connection.start channel = connection.create_channel #declare exchange and queue, bind them and consume messages exchange = channel.topic(exchangeName, :auto_delete => true) queue = channel.queue(queueName, :exclusive => true, :auto_delete => true) queue.bind(exchange, :routing_key => routingKey) queue.subscribe(:block => false, :manual_ack => false) do |delivery_info, metadata, payload| puts payload end #keep checking the existence of the subscribed queue while true raise \"Lost the subscribed queue %s\" % queueName unless connection.queue_exists?(queueName) sleep 1 end rescue Exception => e #reconnect on exception puts \"Exception handled, reconnecting...\\nDetail:\\n%s\" % e #blindly clean old connection begin connection.close end sleep 5 end end Java Prerequisites Java client AMQP library The Java library we use for this example can be found at https://www.rabbitmq.com/java-client.html . Download the library jar file, then import this library in your program import com.rabbitmq.client.*; and compile your source code with the jar file. For example, javac -cp \".:./rabbitmq-client.jar\" Producer.java Consumer.java Run the producer and consumer classes. For example, java -cp \".:./rabbitmq-client.jar\" Consumer java -cp \".:./rabbitmq-client.jar\" Producer Of course, you can eventually compress your producer and consumer classes into jar files. Producer The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. ConnectionFactory factory = new ConnectionFactory(); factory.setHost(server); factory.setPort(port); factory.setVirtualHost(vhost); factory.setUsername(username); factory.setPassword(password); factory.setRequestedHeartbeat(60); connection = factory.newConnection(); channel = connection.createChannel(); Then producer can publish messages to a topic exchange where messages will be delivered to queues whose routing key matches. The essential difference between normal routing key and topic is that consumer can subscribe a topic with wild cards inside. String message = \"Hello World!\"; channel.basicPublish(exchangeName, routingKey, MessageProperties.TEXT_PLAIN, message.getBytes()); At last, producer will disconnect with the RoboMQ broker. connection.close(); Consumer The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a direct exchange, a queue, and bind the queue to the exchange with a routing key (topic). The routing key can contain wildcards to receive messages sent through different routing keys. The fourth parameter of exchangeDeclare() and queueDeclare() are auto-delete. That means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. The third parameter of queueDeclare() is exclusive. That means no other consumer can consume the queue when this one is consuming it. channel.exchangeDeclare(exchangeName, \"topic\", false, true, false, null); channel.queueDeclare(queueName, false, true, true, null); channel.queueBind(queueName, exchangeName, routingKey, null); Finally, consumer can consume messages from the queue. The second parameter of basicConsume() function no-ack indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, no-ack equals to true, so producer does not explicitly acknowledge received messages. The while loop will be blocking the process and listening for messages until exception happens. When messages are received, it will print the message content. QueueingConsumer qc = new QueueingConsumer(channel); channel.basicConsume(queueName, true, qc); while (true) { QueueingConsumer.Delivery delivery = qc.nextDelivery(); String message = new String(delivery.getBody()); System.out.println(message); } Putting it all together Producer.java import com.rabbitmq.client.ConnectionFactory; import com.rabbitmq.client.Connection; import com.rabbitmq.client.Channel; import com.rabbitmq.client.MessageProperties; public class Producer { private Connection connection; private Channel channel; private static String server = \"hostname\"; private static int port = 5672; private static String vhost = \"yourvhost\"; private static String username = \"username\"; private static String password = \"password\"; private static String exchangeName = \"testEx\"; private static String routingKey = \"test.any\"; private void produce() { try { //connect ConnectionFactory factory = new ConnectionFactory(); factory.setHost(server); factory.setPort(port); factory.setVirtualHost(vhost); factory.setUsername(username); factory.setPassword(password); factory.setRequestedHeartbeat(60); connection = factory.newConnection(); channel = connection.createChannel(); //send message String message = \"Hello World!\"; channel.basicPublish(exchangeName, routingKey, MessageProperties.TEXT_PLAIN, message.getBytes()); //disconnect connection.close(); } catch(Exception e) { System.out.println(e); System.exit(-1); } } public static void main(String[] args) { Producer p = new Producer(); p.produce(); } } Consumer.java import com.rabbitmq.client.ConnectionFactory; import com.rabbitmq.client.Connection; import com.rabbitmq.client.Channel; import com.rabbitmq.client.QueueingConsumer; public class Consumer { private Connection connection; private Channel channel; private static String server = \"hostname\"; private static int port = 5672; private static String vhost = \"yourvhost\"; private static String username = \"username\"; private static String password = \"password\"; private static String exchangeName = \"testEx\"; private static String queueName = \"testQ1\"; private static String routingKey = \"test.#\"; //topic with wildcard private void consume() { while (true) { try { //connect ConnectionFactory factory = new ConnectionFactory(); factory.setHost(server); factory.setPort(port); factory.setVirtualHost(vhost); factory.setUsername(username); factory.setPassword(password); factory.setRequestedHeartbeat(60); connection = factory.newConnection(); channel = connection.createChannel(); //declare exchange and queue, bind them and consume messages channel.exchangeDeclare(exchangeName, \"topic\", false, true, false, null); channel.queueDeclare(queueName, false, true, true, null); channel.queueBind(queueName, exchangeName, routingKey, null); QueueingConsumer qc = new QueueingConsumer(channel); channel.basicConsume(queueName, true, qc); while (true) { QueueingConsumer.Delivery delivery = qc.nextDelivery(); String message = new String(delivery.getBody()); System.out.println(message); } } catch(Exception e) { //reconnect on exception System.out.printf(\"Exception handled, reconnecting...\\nDetail:\\n%s\\n\", e); try { connection.close(); } catch (Exception e1) {} try { Thread.sleep(5000); } catch(Exception e2) {} } } } public static void main(String[] args) { Consumer c = new Consumer(); c.consume(); } } Go Prerequisites Go client AMQP library The Go library we use for this example can be found at https://github.com/streadway/amqp . You can install it through go get github.com/streadway/amqp . Finally, import this library in your program. import \"github.com/streadway/amqp\" The full documentation of this library is at https://godoc.org/github.com/streadway/amqp . Producer The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. connection, err := amqp.DialConfig(fmt.Sprintf(\"amqp://%s:%s@%s:%d/%s\", username, password, server, port, vhost), amqp.Config{Heartbeat: 60 * time.Second}) channel, err := connection.Channel() Then producer can publish messages to a topic exchange where messages will be delivered to queues whose routing key matches. The essential difference between normal routing key and topic is that consumer can subscribe a topic with wild cards inside. Delivery mode = 1 means it's a non-persistent message. err = channel.Publish(exchangeName, routingKey, false, false, amqp.Publishing{ContentType: \"text/plain\", DeliveryMode: 1, Body: []byte(\"Hello World!\")}) At last, producer will disconnect with the RoboMQ broker. connection.Close() Consumer The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a direct exchange, a queue, and bind the queue to the exchange with a routing key (topic). The routing key can contain wildcards to receive messages sent through different routing keys. Durable means the exchange or queue will survive possible broker failover. It's false in this example. Auto-delete means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. Exclusive means no other consumer can consume the queue when this one is consuming it. // audo-delete = true err = channel.ExchangeDeclare(exchangeName, \"topic\", false, true, false, false, nil) // durable = false; auto-delete = true; exclusive = true queue, err := channel.QueueDeclare(queueName, false, true, true, false, nil) err = channel.QueueBind(queueName, routingKey, exchangeName, false, nil) Finally, consumer can consume messages from the queue. Consumer-tag can be later used to Cancel() this consumer when it's no longer needed. Auto-ack parameter indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, auto-ack equals to true, so producer does not explicitly acknowledge received messages. // consumer-tag = \"consumer\"; auto-ack = true messageChan, err := channel.Consume(queue.Name, \"consumer\", true, true, false, false, nil) Note a message channel is returned by the Consume() function. Incoming messages will be received through that channel. Channel in Golang is a typed conduit through which you can send and receive values. Sends and receives block until the other side is ready. for message := range messageChan { fmt.Println(string(message.Body)) } Putting it all together producer.go package main import ( \"fmt\" \"github.com/streadway/amqp\" \"os\" \"time\" ) var server = \"hostname\" var port = 5672 var vhost = \"yourvhost\" var username = \"username\" var password = \"password\" var exchangeName = \"testEx\" var routingKey = \"test.any\" func main() { connection, err := amqp.DialConfig(fmt.Sprintf(\"amqp://%s:%s@%s:%d/%s\", username, password, server, port, vhost), amqp.Config{Heartbeat: 60 * time.Second}) if err != nil { fmt.Printf(\"Failed to connect, err: %v\\n\", err) os.Exit(1) } defer connection.Close() channel, err := connection.Channel() if err != nil { fmt.Printf(\"Failed to create channel, err: %v\\n\", err) os.Exit(1) } defer channel.Close() err = channel.Publish( exchangeName, // exchange routingKey, // routing key false, // mandatory false, // immediate amqp.Publishing{ ContentType: \"text/plain\", DeliveryMode: 1, Body: []byte(\"Hello World!\"), }) if err != nil { fmt.Printf(\"Failed to publish message, err: %v\\n\", err) os.Exit(1) } } consumer.go package main import ( \"fmt\" \"github.com/streadway/amqp\" \"time\" ) var server = \"hostname\" var port = 5672 var vhost = \"yourvhost\" var username = \"username\" var password = \"password\" var exchangeName = \"testEx\" var queueName = \"testQ1\" var routingKey = \"test.#\" // topic with wildcard func main() { // Infinite loop to auto-reconnect on failure Loop: for { fmt.Println(\"Starting in 5 seconds...\") time.Sleep(5 * time.Second) connection, err := amqp.DialConfig(fmt.Sprintf(\"amqp://%s:%s@%s:%d/%s\", username, password, server, port, vhost), amqp.Config{Heartbeat: 60 * time.Second}) if err != nil { fmt.Printf(\"Failed to connect, err: %v\\n\", err) continue Loop } defer connection.Close() channel, err := connection.Channel() if err != nil { fmt.Printf(\"Failed to create channel, err: %v\\n\", err) continue Loop } defer channel.Close() err = channel.ExchangeDeclare( exchangeName, // name \"topic\", // type false, // durable true, // audo-delete false, // internal false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to declare exchange, err: %v\\n\", err) continue Loop } queue, err := channel.QueueDeclare( queueName, // name false, // durable true, // auto-delete true, // exclusive false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to declare queue, err: %v\\n\", err) continue Loop } err = channel.QueueBind( queueName, // queue routingKey, // key exchangeName, // exchange false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to bind queue with exchange, err: %v\\n\", err) continue Loop } messageChan, err := channel.Consume( queue.Name, // queue \"consumer\", // consumer tag true, // auto-ack true, // exclusive false, // no-local false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to consume messages, err: %v\\n\", err) continue Loop } fmt.Println(\"Started consuming messages.\") for message := range messageChan { fmt.Println(string(message.Body)) } } } C Prerequisites C client AMQP library RoboMQ is built on AMQP, an open, general-purpose protocol for messaging. There are a number of clients for AMQP in many different languages. However, we'll choose a simple C-language AMQP client library written for use with v2.0+ of the RabbitMQ broker. https://github.com/alanxz/rabbitmq-c/tree/master/librabbitmq You can copy librabbitmq subfolder from latest release located here on GitHub: https://github.com/alanxz/rabbitmq-c Alternatively, thanks to Subversion support in GitHub, you can use svn export directly: svn export https://github.com/alanxz/rabbitmq-c/trunk/librabbitmq Copy the librabbitmq package into your working directory: cp librabbitmq ./ Also copy all source files and Makefile from RoboMQ SDK at https://github.com/robomq/robomq.io/tree/master/sdk/AMQP/C into the same directory. Now your working directory should have the content as bellow: broadcast config.h librabbitmq Makefile one-to-one request-reply routing-key topic Use the Makefile to compile under a Linux terminal. Run make type={sub-directory} to compile the producer and consumer under the sub-directory. Before compiling the next sub-directory, run make clean to clean up the compiled files. Note that these examples provide a simple client implementation to get started but does not go into detailed description of all flags passed into the AMQP methods. A complete reference to RabbitMQ's implementaton of version 0-9-1 of the AMQP specification can be found in this guide. https://www.rabbitmq.com/amqp-0-9-1-reference.html Producer For filter based routing, the producer should publish messages to the topic type exchange. All messages sent with the routing key, \"mytopic.new\" , will be delivered to all the queues that are bound with a matching binding key. Note that the routing key must be a list of words, delimited by dots. The words can be anything, but usually they specify some features connected to the message. A few valid routing key examples: \"log.warning\" , \"log.error\" . amqp_basic_properties_t props; props._flags = AMQP_BASIC_CONTENT_TYPE_FLAG | AMQP_BASIC_DELIVERY_MODE_FLAG; props.content_type = amqp_cstring_bytes(\"text/plain\"); props.delivery_mode = 1; /* non-persistent delivery mode */ amqp_boolean_t mandatory = 0; amqp_boolean_t immediate = 0; char exchange_name[] = \"topic-exchange\"; char routing_key[] = \"mytopic.new\"; int result; // Sending message result = amqp_basic_publish(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(routing_key), mandatory, immediate, &props, amqp_cstring_bytes(\"Hello\")); Consumer Then the consumer should create an exchange and subscribe to a queue. This exchange will be defined similarly to the one-to-one example, however, the topic exchange type is specified below as exchange_type . amqp_bytes_t queue; amqp_channel_t channel = 1; amqp_boolean_t passive = 0; amqp_boolean_t durable = 0; amqp_boolean_t exclusive = 0; amqp_boolean_t auto_delete = 1; char exchange_name[] = \"topic-exchange\"; char exchange_type[] = \"topic\"; char queue_name[] = \"hello-queue\"; char binding_key[] = \"mytopic.new\"; // Declaring exchange amqp_exchange_declare(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(exchange_type), passive, durable, amqp_empty_table); // Declaring queue amqp_queue_declare_ok_t *r = amqp_queue_declare(conn, channel, amqp_cstring_bytes(queue_name), passive, durable, exclusive, auto_delete, amqp_empty_table); queue = amqp_bytes_malloc_dup(r->queue); // Binding to queue amqp_queue_bind(conn, channel, queue, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(binding_key), amqp_empty_table); At this point, consumer should start consuming messages. Putting it all together The full code below includes some basic AMQP error handling for consumer that is useful when declaring exchanges and queues. In addition, main receiver loop attempts to reconnect upon network connection failure. producer.c #include <stdlib.h> #include <stdio.h> #include <string.h> #include <amqp_tcp_socket.h> #include <amqp.h> #include <amqp_framing.h> amqp_connection_state_t mqconnect() { amqp_connection_state_t conn = amqp_new_connection(); amqp_socket_t *socket = NULL; char hostname[] = \"localhost\"; // RoboMQ hostname int port = 5672; //default char user[] = \"guest\"; // RoboMQ username char password[] = \"guest\"; // RoboMQ password char vhost[] = \"/\"; // RoboMQ account vhost amqp_channel_t channel = 1; int channel_max = 0; int frame_max = 131072; int heartbeat = 60; int status = 0; // Opening socket socket = amqp_tcp_socket_new(conn); status = amqp_socket_open(socket, hostname, port); if (status) { printf(\"Error opening TCP socket, status = %d, exiting.\", status); } amqp_login(conn, vhost, channel_max, frame_max, heartbeat, AMQP_SASL_METHOD_PLAIN, user, password); amqp_channel_open(conn, channel); return conn; } int main(int argc, char const *const *argv) { amqp_connection_state_t conn; amqp_channel_t channel = 1; amqp_basic_properties_t props; props._flags = AMQP_BASIC_CONTENT_TYPE_FLAG | AMQP_BASIC_DELIVERY_MODE_FLAG; props.content_type = amqp_cstring_bytes(\"text/plain\"); props.delivery_mode = 1; /* non-persistent delivery mode */ amqp_boolean_t mandatory = 0; amqp_boolean_t immediate = 0; char exchange_name[] = \"topic-exchange\"; char routing_key[] = \"mytopic.new\"; char *msg_body = \"Hello\\n\"; int result; conn = mqconnect(); // Sending message result = amqp_basic_publish(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(routing_key), mandatory, immediate, &props, amqp_cstring_bytes(msg_body)); // Closing connection amqp_connection_close(conn, AMQP_REPLY_SUCCESS); amqp_destroy_connection(conn); return 0; } consumer.c #include <stdlib.h> #include <stdio.h> #include <string.h> #include <amqp_tcp_socket.h> #include <amqp.h> #include <amqp_framing.h> amqp_connection_state_t mqconnect() { amqp_connection_state_t conn = amqp_new_connection(); amqp_socket_t *socket = NULL; char hostname[] = \"localhost\"; // RoboMQ hostname int port = 5672; //default char user[] = \"guest\"; // RoboMQ username char password[] = \"guest\"; // RoboMQ password char vhost[] = \"/\"; // RoboMQ account vhost amqp_channel_t channel = 1; amqp_rpc_reply_t reply; int channel_max = 0; int frame_max = 131072; int heartbeat = 60; int status = 0; // Opening socket socket = amqp_tcp_socket_new(conn); status = amqp_socket_open(socket, hostname, port); if (status) { printf(\"Error opening TCP socket, status = %d\\n\", status); } reply = amqp_login(conn, vhost, channel_max, frame_max, heartbeat, AMQP_SASL_METHOD_PLAIN, user, password); if(reply.reply_type != AMQP_RESPONSE_NORMAL) { fprintf(stderr, \"%s: server connection reply code: %d\\n\", \"Error logging in\", reply.reply_type); } amqp_channel_open(conn, channel); return conn; } amqp_bytes_t mqdeclare(amqp_connection_state_t conn, const char *exchange_name, const char *queue_name) { amqp_bytes_t queue; amqp_channel_t channel = 1; amqp_boolean_t passive = 0; amqp_boolean_t durable = 0; amqp_boolean_t exclusive = 0; amqp_boolean_t auto_delete = 1; amqp_boolean_t internal = 0; char exchange_type[] = \"topic\"; char binding_key[] = \"mytopic.*\"; amqp_rpc_reply_t reply; // Declaring exchange amqp_exchange_declare(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(exchange_type), passive, durable, auto_delete, internal, amqp_empty_table); reply = amqp_get_rpc_reply(conn); if(reply.reply_type != AMQP_RESPONSE_NORMAL) { amqp_connection_close_t *m = (amqp_connection_close_t *) reply.reply.decoded; if(NULL != m) { fprintf(stderr, \"%s: server connection error %d, message: %.*s\\n\", \"Error declaring exchange\", m->reply_code, (int) m->reply_text.len, (char *) m->reply_text.bytes); } } // Declaring queue amqp_queue_declare_ok_t *r = amqp_queue_declare(conn, channel, amqp_cstring_bytes(queue_name), passive, durable, exclusive, auto_delete, amqp_empty_table); reply = amqp_get_rpc_reply(conn); if(reply.reply_type != AMQP_RESPONSE_NORMAL) { fprintf(stderr, \"%s: server connection reply code: %d\\n\", \"Error declaring queue\", reply.reply_type); } else { queue = amqp_bytes_malloc_dup(r->queue); // Binding to queue amqp_queue_bind(conn, channel, queue, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(binding_key), amqp_empty_table); } return queue; } int main(int argc, char const *const *argv) { amqp_connection_state_t conn; amqp_bytes_t queue; amqp_channel_t channel = 1; amqp_boolean_t no_local = 0; amqp_boolean_t no_ack = 1; amqp_boolean_t exclusive = 0; char exchange_name[] = \"topic-exchange\"; char queue_name[] = \"hello-queue\"; int retry_time = 5; // retry time in seconds conn = mqconnect(); queue = mqdeclare(conn, &exchange_name[0], &queue_name[0]); // Consuming the message amqp_basic_consume(conn, channel, queue, amqp_empty_bytes, no_local, no_ack, exclusive, amqp_empty_table); while (1) { amqp_rpc_reply_t result; amqp_envelope_t envelope; amqp_maybe_release_buffers(conn); result = amqp_consume_message(conn, &envelope, NULL, 0); if (AMQP_RESPONSE_NORMAL != result.reply_type) { printf(\"Consumer AMQP failure occurred, response code = %d, retrying in %d seconds...\\n\", result.reply_type, retry_time); // Closing current connection before reconnecting amqp_connection_close(conn, AMQP_CONNECTION_FORCED); amqp_destroy_connection(conn); // Reconnecting on exception conn = mqconnect(); queue = mqdeclare(conn, &exchange_name[0], &queue_name[0]); amqp_basic_consume(conn, channel, queue, amqp_empty_bytes, no_local, no_ack, exclusive, amqp_empty_table); sleep(retry_time); } else { printf(\"Received message size: %d\\nbody: %s\\n\", (int)envelope.message.body.len, (char *)envelope.message.body.bytes); amqp_destroy_envelope(&envelope); } } return 0; }","title":"Filter based routing (topic)"},{"location":"topic/#routing-filter-based-topic","text":"For filter based routing, a producer declares the topic exchange when publishing a message. Messages sent with a particular routing key will be delivered to all the queues that are bound with a matching binding key. Filter based routing provides a method to use filter policies on routing key for choosing the recipients of messages. * (star) can substitute for exactly one word. example: 'topic.*' can be : topic1, topic2, topic3 etc. # (hash) can substitute for zero or more words. example: \"#.topic\" can be: topic, Ftopic, Secondtopic, 123topic etc. Browse the chapter of AMQP Introduction first if you're new to AMQP.","title":"Routing - Filter Based (Topic)"},{"location":"topic/#python","text":"","title":"Python"},{"location":"topic/#prerequisites","text":"Python client AMQP library The Python library we use for this example can be found at https://github.com/pika/pika . You can install it through sudo pip install pika . Finally, import this library in your program. import pika The full documentation of this library is at https://pika.readthedocs.org/en/0.9.14/ . pika library is not thread safe. Do not use a connection or channel across threads.","title":"Prerequisites"},{"location":"topic/#producer","text":"The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. credentials = pika.PlainCredentials(username, password) connection = pika.BlockingConnection(pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60)) channel = connection.channel() Then producer can publish messages to a topic exchange where messages will be delivered to queues whose routing key matches. The essential difference between normal routing key and topic is that consumer can subscribe a topic with wild cards inside. Delivery mode = 1 means it's a non-persistent message. properties = pika.spec.BasicProperties(content_type = \"text/plain\", delivery_mode = 1) channel.basic_publish(exchange = exchangeName, routing_key = routingKey, body = \"Hello World!\", properties = properties) At last, producer will disconnect with the RoboMQ broker. connection.close()","title":"Producer"},{"location":"topic/#consumer","text":"The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a direct exchange, a queue, and bind the queue to the exchange with a routing key (topic). The routing key can contain wildcards to receive messages sent through different routing keys. Auto-delete means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. Exclusive means no other consumer can consume the queue when this one is consuming it. channel.exchange_declare(exchange = exchangeName, exchange_type = \"topic\", auto_delete = True) channel.queue_declare(queue = queueName, exclusive = True, auto_delete = True) channel.queue_bind(exchange = exchangeName, queue = queueName, routing_key = routingKey) Finally, consumer can consume messages from the queue. The no_ack parameter indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, no_ack equals to true, so producer does not explicitly acknowledge received messages. The start_consuming() function will be blocking the process until stop_consuming() is invoked or exception happens. channel.basic_consume(consumer_callback = onMessage, queue = queueName, no_ack = True) channel.start_consuming() When messages are received, a callback function onMessage() will be invoked to print the message content. def onMessage(channel, method, properties, body): print body","title":"Consumer"},{"location":"topic/#putting-it-all-together","text":"producer.py import pika server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" exchangeName = \"testEx\" routingKey = \"test.any\" try: #connect credentials = pika.PlainCredentials(username, password) connection = pika.BlockingConnection(pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60)) channel = connection.channel() #send message properties = pika.spec.BasicProperties(content_type = \"text/plain\", delivery_mode = 1) channel.basic_publish(exchange = exchangeName, routing_key = routingKey, body = \"Hello World!\", properties = properties) #disconnect connection.close() except Exception, e: print e consumer.py import pika import time server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" exchangeName = \"testEx\" queueName = \"testQ1\" routingKey = \"test.#\" #topic with wildcard #callback funtion on receiving messages def onMessage(channel, method, properties, body): print body while True: try: #connect credentials = pika.PlainCredentials(username, password) connection = pika.BlockingConnection(pika.ConnectionParameters(host = server, port = port, virtual_host = vhost, credentials = credentials, heartbeat_interval = 60)) channel = connection.channel() #declare exchange and queue, bind them and consume messages channel.exchange_declare(exchange = exchangeName, exchange_type = \"topic\", auto_delete = True) channel.queue_declare(queue = queueName, exclusive = True, auto_delete = True) channel.queue_bind(exchange = exchangeName, queue = queueName, routing_key = routingKey) channel.basic_consume(consumer_callback = onMessage, queue = queueName, no_ack = True) channel.start_consuming() except Exception, e: #reconnect on exception print \"Exception handled, reconnecting...\\nDetail:\\n%s\" % e try: connection.close() except: pass time.sleep(5)","title":"Putting it all together"},{"location":"topic/#nodejs","text":"","title":"Node.js"},{"location":"topic/#prerequisites_1","text":"Node.js client AMQP library The Node.js library we use for this example can be found at https://github.com/squaremo/amqp.node . You can install the library through sudo npm install amqplib . Finally, require this library in your program. var amqp = require(\"amqplib\"); The full documentation of this library is at https://www.squaremobius.net/amqp.node/doc/channel_api.html","title":"Prerequisites"},{"location":"topic/#producer_1","text":"The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. As shown in the code, this library provides chainable callback API in the form of .then(callback) . For the default vhost \"/\", you will need to insert \"%2f\" (its hexadecimal ASCII code) to the AMQP URI, instead of \"/\" itself. producer = amqp.connect(\"amqp://\" + username + \":\" + password + \"@\" + server + \":\" + port + \"/\" + vhost + \"?heartbeat=60\"); producer.then(function(conn) { return conn.createConfirmChannel().then(successCallback); }).then(null, failureCallback); Then producer can publish messages to a topic exchange where messages will be delivered to queues whose routing key matches. The essential difference between normal routing key and topic is that consumer can subscribe a topic with wild cards inside. Delivery mode = 1 means it's a non-persistent message. ch.publish(exchangeName, routingKey, content = new Buffer(\"Hello World!\"), options = {contentType: \"text/plain\", deliveryMode: 1}, callback); At last, producer will disconnect with the RoboMQ broker. conn.close();","title":"Producer"},{"location":"topic/#consumer_1","text":"The same as producer, consumer needs to first connect to RoboMQ broker. The difference is that consumer uses conn.createChannel() function, while producer uses conn.createConfirmChannel() because the latter one is only useful for publish confirm. Then consumer will declare a direct exchange, a queue, and bind the queue to the exchange with a routing key (topic). The routing key can contain wildcards to receive messages sent through different routing keys. Durable means the exchange or queue will survive possible broker failover. It's false in this example. Auto-delete means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. Exclusive means no other consumer can consume the queue when this one is consuming it. ch.assertExchange(exchangeName, \"topic\", {durable: false, autoDelete: true}); ch.assertQueue(queueName, {durable: false, autoDelete: true, exclusive: true}); ch.bindQueue(queueName, exchangeName, routingKey); Finally, consumer can consume messages from the queue. The noAck option indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, noAck is true, so producer does not explicitly acknowledge received messages. The second parameter of consume() function is the callback on receiving messages. In this example, when messages are received, the callback function will be invoked to print the message content. ch.consume(queueName, function(message) { console.log(message.content.toString()); }, {noAck: true});","title":"Consumer"},{"location":"topic/#putting-it-all-together_1","text":"producer.js var amqp = require(\"amqplib\"); var server = \"hostname\"; var port = \"5672\"; var vhost = \"yourvhost\"; //for \"/\" vhost, use \"%2f\" instead var username = \"username\"; var password = \"password\"; var exchangeName = \"testEx\"; var routingKey = \"test.any\"; producer = amqp.connect(\"amqp://\" + username + \":\" + password + \"@\" + server + \":\" + port + \"/\" + vhost + \"?heartbeat=60\"); producer.then(function(conn) { return conn.createConfirmChannel().then(function(ch) { ch.publish(exchangeName, routingKey, content = new Buffer(\"Hello World!\"), options = {contentType: \"text/plain\", deliveryMode: 1}, function(err, ok) { if (err != null) { console.error(\"Error: failed to send message\\n\" + err); } conn.close(); }); }); }).then(null, function(err) { console.error(err); }); consumer.js var amqp = require(\"amqplib\"); var domain = require(\"domain\"); var server = \"hostname\"; var port = \"5672\"; var vhost = \"yourvhost\"; //for \"/\" vhost, use \"%2f\" instead var username = \"username\"; var password = \"password\"; var exchangeName = \"testEx\"; var queueName = \"testQ1\"; var routingKey = \"test.#\"; //topic with wildcard //use domain module to handle reconnecting var consumer = null; var dom = domain.create(); dom.on(\"error\", relisten); dom.run(listen); function listen() { consumer = amqp.connect(\"amqp://\" + username + \":\" + password + \"@\" + server + \":\" + port + \"/\" + vhost + \"?heartbeat=60\"); consumer.then(function(conn) { return conn.createChannel().then(function(ch) { ch.assertExchange(exchangeName, \"topic\", {durable: false, autoDelete: true}); ch.assertQueue(queueName, {durable: false, autoDelete: true, exclusive: true}); ch.bindQueue(queueName, exchangeName, routingKey); ch.consume(queueName, function(message) { //callback funtion on receiving messages console.log(message.content.toString()); }, {noAck: true}); }); }).then(null, function(err) { console.error(\"Exception handled, reconnecting...\\nDetail:\\n\" + err); setTimeout(listen, 5000); }); } function relisten() { consumer.then(function(conn) { conn.close(); }); setTimeout(listen, 5000); }","title":"Putting it all together"},{"location":"topic/#php","text":"","title":"PHP"},{"location":"topic/#prerequisite","text":"PHP client AMQP library The PHP library we use for this example can be found at https://github.com/videlalvaro/php-amqplib . It uses composer to install in a few steps. Add a composer.json file to your project: { \"require\": { \"videlalvaro/php-amqplib\": \"2.2.*\" } } Download the latest composer in the same path: curl -sS https://getcomposer.org/installer | php Install the library through composer: ./composer.phar install Finally, require this library in your program and use the classes. require_once __DIR__ . '/../vendor/autoload.php'; //directory of library folder use PhpAmqpLib\\Connection\\AMQPConnection; use PhpAmqpLib\\Message\\AMQPMessage;","title":"Prerequisite"},{"location":"topic/#producer_2","text":"The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. $connection = new AMQPConnection($server, $port, $username, $password, $vhost, $heartbeat = 60); $channel = $connection->channel(); Then producer can publish messages to a topic exchange where messages will be delivered to queues whose routing key matches. The essential difference between normal routing key and topic is that consumer can subscribe a topic with wild cards inside. Delivery mode = 1 means it's a non-persistent message. $message = new AMQPMessage(\"Hello World!\", array(\"content_type\" => \"text/plain\", \"delivery_mode\" => 1)); $channel->basic_publish($message, $exchangeName, $routingKey); At last, producer will disconnect with the RoboMQ broker. $connection->close();","title":"Producer"},{"location":"topic/#consumer_2","text":"The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a direct exchange, a queue, and bind the queue to the exchange with a routing key (topic). The routing key can contain wildcards to receive messages sent through different routing keys. Auto-delete means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. Exclusive means no other consumer can consume the queue when this one is consuming it. $channel->exchange_declare($exchangeName, $type = \"topic\", false, false, $auto_delete = true); $channel->queue_declare($queueName, false, false, $exclusive = true, $auto_delete = true); $channel->queue_bind($queueName, $exchangeName, $routingKey); Finally, consumer can consume messages from the queue. The no_ack parameter indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, no_ack equals to true, so producer does not explicitly acknowledge received messages. The while loop will be blocking the process and listening for messages until exception happens. $channel->basic_consume($queueName, \"\", false, $no_ack = true, false, false, $callback = $onMessage); while(count($channel->callbacks)) { $channel->wait(); } When messages are received, a callback function will be invoked to print the message content. $onMessage = function ($message) { echo $message->body.PHP_EOL; };","title":"Consumer"},{"location":"topic/#putting-it-together","text":"producer.php <?php require_once __DIR__ . '/../vendor/autoload.php'; //directory of library folder use PhpAmqpLib\\Connection\\AMQPConnection; use PhpAmqpLib\\Message\\AMQPMessage; $server = \"hostname\"; $port = 5672; $vhost = \"yourvhost\"; $username = \"username\"; $password = \"password\"; $exchangeName = \"testEx\"; $routingKey = \"test.any\"; try { //connect $connection = new AMQPConnection($server, $port, $username, $password, $vhost, $heartbeat = 60); $channel = $connection->channel(); //send message $message = new AMQPMessage(\"Hello World!\", array(\"content_type\" => \"text/plain\", \"delivery_mode\" => 1)); $channel->basic_publish($message, $exchangeName, $routingKey); //disconnect $connection->close(); } catch(Exception $e) { echo $e.PHP_EOL; } ?> consumer.php <?php require_once __DIR__.\"/../vendor/autoload.php\"; //directory of library folder use PhpAmqpLib\\Connection\\AMQPConnection; $server = \"hostname\"; $port = 5672; $vhost = \"yourvhost\"; $username = \"username\"; $password = \"password\"; $exchangeName = \"testEx\"; $queueName = \"testQ1\"; $routingKey = \"test.#\"; //topic with wildcard //callback funtion on receiving messages $onMessage = function ($message) { echo $message->body.PHP_EOL; }; while (true) { try { //connect $connection = new AMQPConnection($server, $port, $username, $password, $vhost, $heartbeat = 60); $channel = $connection->channel(); //declare exchange and queue, bind them and consume messages $channel->exchange_declare($exchangeName, $type = \"topic\", false, false, $auto_delete = true); $channel->queue_declare($queueName, false, false, $exclusive = true, $auto_delete = true); $channel->queue_bind($queueName, $exchangeName, $routingKey); $channel->basic_consume($queueName, \"\", false, $no_ack = true, false, false, $callback = $onMessage); //start consuming while(count($channel->callbacks)) { $channel->wait(); } } catch(Exception $e) { //reconnect on exception echo \"Exception handled, reconnecting...\\nDetail:\\n\".$e.PHP_EOL; if ($connection != null) { try { $connection->close(); } catch (Exception $e1) {} } sleep(5); } } ?>","title":"Putting it together"},{"location":"topic/#ruby","text":"","title":"Ruby"},{"location":"topic/#prerequisites_2","text":"Ruby client AMQP library The Ruby library we use for this example can be found at http://rubybunny.info/ . With Ruby version >= 2.0, you can install it through sudo gem install bunny . Finally, import this library in your program. require \"bunny\" The full documentation of this library is at http://rubybunny.info/articles/guides.html . We recommend combining the documentation with the source code of this library when you use it because some of the documentation out there is not being updated timely from our observation.","title":"Prerequisites"},{"location":"topic/#producer_3","text":"The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. Although the library provides a connection property named recover_from_connection_close , we discourage you to use it. The reason will be explained in the Consumer section. connection = Bunny.new(:host => server, :port => port, :vhost => vhost, :user => username, :pass => password, :heartbeat => 60, :recover_from_connection_close => false) connection.start channel = connection.create_channel Then producer can publish messages to a topic exchange where messages will be delivered to queues whose routing key matches. The essential difference between normal routing key and topic is that consumer can subscribe a topic with wild cards inside. Delivery mode = 1 means it's a non-persistent message. exchange = channel.topic(exchangeName, :auto_delete => true) exchange.publish(\"Hello World!\", :routing_key => routingKey, :content_type => \"text/plain\", :delivery_mode => 1) At last, producer will disconnect with the RoboMQ broker. connection.close","title":"Producer"},{"location":"topic/#consumer_3","text":"The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a direct exchange, a queue, and bind the queue to the exchange with a routing key (topic). The routing key can contain wildcards to receive messages sent through different routing keys. Auto-delete means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. Exclusive means no other consumer can consume the queue when this one is consuming it. exchange = channel.topic(exchangeName, :auto_delete => true) queue = channel.queue(queueName, :exclusive => true, :auto_delete => true) queue.bind(exchange, :routing_key => routingKey) After that, consumer can consume messages from the queue. The manual_ack parameter indicates if consumer needs to manually send acknowledgment back to broker when it has received the message. In this example, manual_ack equals to false, so producer does not manually acknowledge received messages. The subscribe() function is followed by a callback which will be invoked to print the message payload on receiving a message. queue.subscribe(:block => false, :manual_ack => false) do |delivery_info, metadata, payload| puts payload end As we mentioned in the Producer section, recover_from_connection_close is set to false when connecting to RoboMQ broker. It matters for consumers because recover_from_connection_close will only recover the connection, it won't recreate exchange and queue in case they are gone. Therefore, a more robust approach is letting your code handle reconnecting on its own and keep checking the existence of the subscribed queue. while true raise \"Lost the subscribed queue %s\" % queueName unless connection.queue_exists?(queueName) sleep 1 end","title":"Consumer"},{"location":"topic/#putting-it-all-together_2","text":"producer.rb require \"bunny\" server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" exchangeName = \"testEx\" routingKey = \"test.any\" begin #connect connection = Bunny.new(:host => server, :port => port, :vhost => vhost, :user => username, :pass => password, :heartbeat => 60, :recover_from_connection_close => false) connection.start channel = connection.create_channel #send message exchange = channel.topic(exchangeName, :auto_delete => true) exchange.publish(\"Hello World!\", :routing_key => routingKey, :content_type => \"text/plain\", :delivery_mode => 1) #disconnect connection.close rescue Exception => e puts e end consumer.rb require \"bunny\" server = \"hostname\" port = 5672 vhost = \"yourvhost\" username = \"username\" password = \"password\" exchangeName = \"testEx\" queueName = \"testQ1\" routingKey = \"test.#\" #topic with wildcard while true begin #connect, disable auto-reconnect so as to manually reconnect connection = Bunny.new(:host => server, :port => port, :vhost => vhost, :user => username, :pass => password, :heartbeat => 60, :recover_from_connection_close => false) connection.start channel = connection.create_channel #declare exchange and queue, bind them and consume messages exchange = channel.topic(exchangeName, :auto_delete => true) queue = channel.queue(queueName, :exclusive => true, :auto_delete => true) queue.bind(exchange, :routing_key => routingKey) queue.subscribe(:block => false, :manual_ack => false) do |delivery_info, metadata, payload| puts payload end #keep checking the existence of the subscribed queue while true raise \"Lost the subscribed queue %s\" % queueName unless connection.queue_exists?(queueName) sleep 1 end rescue Exception => e #reconnect on exception puts \"Exception handled, reconnecting...\\nDetail:\\n%s\" % e #blindly clean old connection begin connection.close end sleep 5 end end","title":"Putting it all together"},{"location":"topic/#java","text":"","title":"Java"},{"location":"topic/#prerequisites_3","text":"Java client AMQP library The Java library we use for this example can be found at https://www.rabbitmq.com/java-client.html . Download the library jar file, then import this library in your program import com.rabbitmq.client.*; and compile your source code with the jar file. For example, javac -cp \".:./rabbitmq-client.jar\" Producer.java Consumer.java Run the producer and consumer classes. For example, java -cp \".:./rabbitmq-client.jar\" Consumer java -cp \".:./rabbitmq-client.jar\" Producer Of course, you can eventually compress your producer and consumer classes into jar files.","title":"Prerequisites"},{"location":"topic/#producer_4","text":"The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. ConnectionFactory factory = new ConnectionFactory(); factory.setHost(server); factory.setPort(port); factory.setVirtualHost(vhost); factory.setUsername(username); factory.setPassword(password); factory.setRequestedHeartbeat(60); connection = factory.newConnection(); channel = connection.createChannel(); Then producer can publish messages to a topic exchange where messages will be delivered to queues whose routing key matches. The essential difference between normal routing key and topic is that consumer can subscribe a topic with wild cards inside. String message = \"Hello World!\"; channel.basicPublish(exchangeName, routingKey, MessageProperties.TEXT_PLAIN, message.getBytes()); At last, producer will disconnect with the RoboMQ broker. connection.close();","title":"Producer"},{"location":"topic/#consumer_4","text":"The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a direct exchange, a queue, and bind the queue to the exchange with a routing key (topic). The routing key can contain wildcards to receive messages sent through different routing keys. The fourth parameter of exchangeDeclare() and queueDeclare() are auto-delete. That means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. The third parameter of queueDeclare() is exclusive. That means no other consumer can consume the queue when this one is consuming it. channel.exchangeDeclare(exchangeName, \"topic\", false, true, false, null); channel.queueDeclare(queueName, false, true, true, null); channel.queueBind(queueName, exchangeName, routingKey, null); Finally, consumer can consume messages from the queue. The second parameter of basicConsume() function no-ack indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, no-ack equals to true, so producer does not explicitly acknowledge received messages. The while loop will be blocking the process and listening for messages until exception happens. When messages are received, it will print the message content. QueueingConsumer qc = new QueueingConsumer(channel); channel.basicConsume(queueName, true, qc); while (true) { QueueingConsumer.Delivery delivery = qc.nextDelivery(); String message = new String(delivery.getBody()); System.out.println(message); }","title":"Consumer"},{"location":"topic/#putting-it-all-together_3","text":"Producer.java import com.rabbitmq.client.ConnectionFactory; import com.rabbitmq.client.Connection; import com.rabbitmq.client.Channel; import com.rabbitmq.client.MessageProperties; public class Producer { private Connection connection; private Channel channel; private static String server = \"hostname\"; private static int port = 5672; private static String vhost = \"yourvhost\"; private static String username = \"username\"; private static String password = \"password\"; private static String exchangeName = \"testEx\"; private static String routingKey = \"test.any\"; private void produce() { try { //connect ConnectionFactory factory = new ConnectionFactory(); factory.setHost(server); factory.setPort(port); factory.setVirtualHost(vhost); factory.setUsername(username); factory.setPassword(password); factory.setRequestedHeartbeat(60); connection = factory.newConnection(); channel = connection.createChannel(); //send message String message = \"Hello World!\"; channel.basicPublish(exchangeName, routingKey, MessageProperties.TEXT_PLAIN, message.getBytes()); //disconnect connection.close(); } catch(Exception e) { System.out.println(e); System.exit(-1); } } public static void main(String[] args) { Producer p = new Producer(); p.produce(); } } Consumer.java import com.rabbitmq.client.ConnectionFactory; import com.rabbitmq.client.Connection; import com.rabbitmq.client.Channel; import com.rabbitmq.client.QueueingConsumer; public class Consumer { private Connection connection; private Channel channel; private static String server = \"hostname\"; private static int port = 5672; private static String vhost = \"yourvhost\"; private static String username = \"username\"; private static String password = \"password\"; private static String exchangeName = \"testEx\"; private static String queueName = \"testQ1\"; private static String routingKey = \"test.#\"; //topic with wildcard private void consume() { while (true) { try { //connect ConnectionFactory factory = new ConnectionFactory(); factory.setHost(server); factory.setPort(port); factory.setVirtualHost(vhost); factory.setUsername(username); factory.setPassword(password); factory.setRequestedHeartbeat(60); connection = factory.newConnection(); channel = connection.createChannel(); //declare exchange and queue, bind them and consume messages channel.exchangeDeclare(exchangeName, \"topic\", false, true, false, null); channel.queueDeclare(queueName, false, true, true, null); channel.queueBind(queueName, exchangeName, routingKey, null); QueueingConsumer qc = new QueueingConsumer(channel); channel.basicConsume(queueName, true, qc); while (true) { QueueingConsumer.Delivery delivery = qc.nextDelivery(); String message = new String(delivery.getBody()); System.out.println(message); } } catch(Exception e) { //reconnect on exception System.out.printf(\"Exception handled, reconnecting...\\nDetail:\\n%s\\n\", e); try { connection.close(); } catch (Exception e1) {} try { Thread.sleep(5000); } catch(Exception e2) {} } } } public static void main(String[] args) { Consumer c = new Consumer(); c.consume(); } }","title":"Putting it all together"},{"location":"topic/#go","text":"","title":"Go"},{"location":"topic/#prerequisites_4","text":"Go client AMQP library The Go library we use for this example can be found at https://github.com/streadway/amqp . You can install it through go get github.com/streadway/amqp . Finally, import this library in your program. import \"github.com/streadway/amqp\" The full documentation of this library is at https://godoc.org/github.com/streadway/amqp .","title":"Prerequisites"},{"location":"topic/#producer_5","text":"The first thing we need to do is to establish a connection with RoboMQ broker. Set heartbeat to 60 seconds, so that client will confirm the connectivity with broker. connection, err := amqp.DialConfig(fmt.Sprintf(\"amqp://%s:%s@%s:%d/%s\", username, password, server, port, vhost), amqp.Config{Heartbeat: 60 * time.Second}) channel, err := connection.Channel() Then producer can publish messages to a topic exchange where messages will be delivered to queues whose routing key matches. The essential difference between normal routing key and topic is that consumer can subscribe a topic with wild cards inside. Delivery mode = 1 means it's a non-persistent message. err = channel.Publish(exchangeName, routingKey, false, false, amqp.Publishing{ContentType: \"text/plain\", DeliveryMode: 1, Body: []byte(\"Hello World!\")}) At last, producer will disconnect with the RoboMQ broker. connection.Close()","title":"Producer"},{"location":"topic/#consumer_5","text":"The same as producer, consumer needs to first connect to RoboMQ broker. Then consumer will declare a direct exchange, a queue, and bind the queue to the exchange with a routing key (topic). The routing key can contain wildcards to receive messages sent through different routing keys. Durable means the exchange or queue will survive possible broker failover. It's false in this example. Auto-delete means after all consumers have finished consuming it, the exchange or queue will be deleted by broker. Exclusive means no other consumer can consume the queue when this one is consuming it. // audo-delete = true err = channel.ExchangeDeclare(exchangeName, \"topic\", false, true, false, false, nil) // durable = false; auto-delete = true; exclusive = true queue, err := channel.QueueDeclare(queueName, false, true, true, false, nil) err = channel.QueueBind(queueName, routingKey, exchangeName, false, nil) Finally, consumer can consume messages from the queue. Consumer-tag can be later used to Cancel() this consumer when it's no longer needed. Auto-ack parameter indicates if consumer needs to explicitly send acknowledgment back to broker when it has received the message. In this example, auto-ack equals to true, so producer does not explicitly acknowledge received messages. // consumer-tag = \"consumer\"; auto-ack = true messageChan, err := channel.Consume(queue.Name, \"consumer\", true, true, false, false, nil) Note a message channel is returned by the Consume() function. Incoming messages will be received through that channel. Channel in Golang is a typed conduit through which you can send and receive values. Sends and receives block until the other side is ready. for message := range messageChan { fmt.Println(string(message.Body)) }","title":"Consumer"},{"location":"topic/#putting-it-all-together_4","text":"producer.go package main import ( \"fmt\" \"github.com/streadway/amqp\" \"os\" \"time\" ) var server = \"hostname\" var port = 5672 var vhost = \"yourvhost\" var username = \"username\" var password = \"password\" var exchangeName = \"testEx\" var routingKey = \"test.any\" func main() { connection, err := amqp.DialConfig(fmt.Sprintf(\"amqp://%s:%s@%s:%d/%s\", username, password, server, port, vhost), amqp.Config{Heartbeat: 60 * time.Second}) if err != nil { fmt.Printf(\"Failed to connect, err: %v\\n\", err) os.Exit(1) } defer connection.Close() channel, err := connection.Channel() if err != nil { fmt.Printf(\"Failed to create channel, err: %v\\n\", err) os.Exit(1) } defer channel.Close() err = channel.Publish( exchangeName, // exchange routingKey, // routing key false, // mandatory false, // immediate amqp.Publishing{ ContentType: \"text/plain\", DeliveryMode: 1, Body: []byte(\"Hello World!\"), }) if err != nil { fmt.Printf(\"Failed to publish message, err: %v\\n\", err) os.Exit(1) } } consumer.go package main import ( \"fmt\" \"github.com/streadway/amqp\" \"time\" ) var server = \"hostname\" var port = 5672 var vhost = \"yourvhost\" var username = \"username\" var password = \"password\" var exchangeName = \"testEx\" var queueName = \"testQ1\" var routingKey = \"test.#\" // topic with wildcard func main() { // Infinite loop to auto-reconnect on failure Loop: for { fmt.Println(\"Starting in 5 seconds...\") time.Sleep(5 * time.Second) connection, err := amqp.DialConfig(fmt.Sprintf(\"amqp://%s:%s@%s:%d/%s\", username, password, server, port, vhost), amqp.Config{Heartbeat: 60 * time.Second}) if err != nil { fmt.Printf(\"Failed to connect, err: %v\\n\", err) continue Loop } defer connection.Close() channel, err := connection.Channel() if err != nil { fmt.Printf(\"Failed to create channel, err: %v\\n\", err) continue Loop } defer channel.Close() err = channel.ExchangeDeclare( exchangeName, // name \"topic\", // type false, // durable true, // audo-delete false, // internal false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to declare exchange, err: %v\\n\", err) continue Loop } queue, err := channel.QueueDeclare( queueName, // name false, // durable true, // auto-delete true, // exclusive false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to declare queue, err: %v\\n\", err) continue Loop } err = channel.QueueBind( queueName, // queue routingKey, // key exchangeName, // exchange false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to bind queue with exchange, err: %v\\n\", err) continue Loop } messageChan, err := channel.Consume( queue.Name, // queue \"consumer\", // consumer tag true, // auto-ack true, // exclusive false, // no-local false, // no-wait nil, // args ) if err != nil { fmt.Printf(\"Failed to consume messages, err: %v\\n\", err) continue Loop } fmt.Println(\"Started consuming messages.\") for message := range messageChan { fmt.Println(string(message.Body)) } } }","title":"Putting it all together"},{"location":"topic/#c","text":"","title":"C"},{"location":"topic/#prerequisites_5","text":"C client AMQP library RoboMQ is built on AMQP, an open, general-purpose protocol for messaging. There are a number of clients for AMQP in many different languages. However, we'll choose a simple C-language AMQP client library written for use with v2.0+ of the RabbitMQ broker. https://github.com/alanxz/rabbitmq-c/tree/master/librabbitmq You can copy librabbitmq subfolder from latest release located here on GitHub: https://github.com/alanxz/rabbitmq-c Alternatively, thanks to Subversion support in GitHub, you can use svn export directly: svn export https://github.com/alanxz/rabbitmq-c/trunk/librabbitmq Copy the librabbitmq package into your working directory: cp librabbitmq ./ Also copy all source files and Makefile from RoboMQ SDK at https://github.com/robomq/robomq.io/tree/master/sdk/AMQP/C into the same directory. Now your working directory should have the content as bellow: broadcast config.h librabbitmq Makefile one-to-one request-reply routing-key topic Use the Makefile to compile under a Linux terminal. Run make type={sub-directory} to compile the producer and consumer under the sub-directory. Before compiling the next sub-directory, run make clean to clean up the compiled files. Note that these examples provide a simple client implementation to get started but does not go into detailed description of all flags passed into the AMQP methods. A complete reference to RabbitMQ's implementaton of version 0-9-1 of the AMQP specification can be found in this guide. https://www.rabbitmq.com/amqp-0-9-1-reference.html","title":"Prerequisites"},{"location":"topic/#producer_6","text":"For filter based routing, the producer should publish messages to the topic type exchange. All messages sent with the routing key, \"mytopic.new\" , will be delivered to all the queues that are bound with a matching binding key. Note that the routing key must be a list of words, delimited by dots. The words can be anything, but usually they specify some features connected to the message. A few valid routing key examples: \"log.warning\" , \"log.error\" . amqp_basic_properties_t props; props._flags = AMQP_BASIC_CONTENT_TYPE_FLAG | AMQP_BASIC_DELIVERY_MODE_FLAG; props.content_type = amqp_cstring_bytes(\"text/plain\"); props.delivery_mode = 1; /* non-persistent delivery mode */ amqp_boolean_t mandatory = 0; amqp_boolean_t immediate = 0; char exchange_name[] = \"topic-exchange\"; char routing_key[] = \"mytopic.new\"; int result; // Sending message result = amqp_basic_publish(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(routing_key), mandatory, immediate, &props, amqp_cstring_bytes(\"Hello\"));","title":"Producer"},{"location":"topic/#consumer_6","text":"Then the consumer should create an exchange and subscribe to a queue. This exchange will be defined similarly to the one-to-one example, however, the topic exchange type is specified below as exchange_type . amqp_bytes_t queue; amqp_channel_t channel = 1; amqp_boolean_t passive = 0; amqp_boolean_t durable = 0; amqp_boolean_t exclusive = 0; amqp_boolean_t auto_delete = 1; char exchange_name[] = \"topic-exchange\"; char exchange_type[] = \"topic\"; char queue_name[] = \"hello-queue\"; char binding_key[] = \"mytopic.new\"; // Declaring exchange amqp_exchange_declare(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(exchange_type), passive, durable, amqp_empty_table); // Declaring queue amqp_queue_declare_ok_t *r = amqp_queue_declare(conn, channel, amqp_cstring_bytes(queue_name), passive, durable, exclusive, auto_delete, amqp_empty_table); queue = amqp_bytes_malloc_dup(r->queue); // Binding to queue amqp_queue_bind(conn, channel, queue, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(binding_key), amqp_empty_table); At this point, consumer should start consuming messages.","title":"Consumer"},{"location":"topic/#putting-it-all-together_5","text":"The full code below includes some basic AMQP error handling for consumer that is useful when declaring exchanges and queues. In addition, main receiver loop attempts to reconnect upon network connection failure. producer.c #include <stdlib.h> #include <stdio.h> #include <string.h> #include <amqp_tcp_socket.h> #include <amqp.h> #include <amqp_framing.h> amqp_connection_state_t mqconnect() { amqp_connection_state_t conn = amqp_new_connection(); amqp_socket_t *socket = NULL; char hostname[] = \"localhost\"; // RoboMQ hostname int port = 5672; //default char user[] = \"guest\"; // RoboMQ username char password[] = \"guest\"; // RoboMQ password char vhost[] = \"/\"; // RoboMQ account vhost amqp_channel_t channel = 1; int channel_max = 0; int frame_max = 131072; int heartbeat = 60; int status = 0; // Opening socket socket = amqp_tcp_socket_new(conn); status = amqp_socket_open(socket, hostname, port); if (status) { printf(\"Error opening TCP socket, status = %d, exiting.\", status); } amqp_login(conn, vhost, channel_max, frame_max, heartbeat, AMQP_SASL_METHOD_PLAIN, user, password); amqp_channel_open(conn, channel); return conn; } int main(int argc, char const *const *argv) { amqp_connection_state_t conn; amqp_channel_t channel = 1; amqp_basic_properties_t props; props._flags = AMQP_BASIC_CONTENT_TYPE_FLAG | AMQP_BASIC_DELIVERY_MODE_FLAG; props.content_type = amqp_cstring_bytes(\"text/plain\"); props.delivery_mode = 1; /* non-persistent delivery mode */ amqp_boolean_t mandatory = 0; amqp_boolean_t immediate = 0; char exchange_name[] = \"topic-exchange\"; char routing_key[] = \"mytopic.new\"; char *msg_body = \"Hello\\n\"; int result; conn = mqconnect(); // Sending message result = amqp_basic_publish(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(routing_key), mandatory, immediate, &props, amqp_cstring_bytes(msg_body)); // Closing connection amqp_connection_close(conn, AMQP_REPLY_SUCCESS); amqp_destroy_connection(conn); return 0; } consumer.c #include <stdlib.h> #include <stdio.h> #include <string.h> #include <amqp_tcp_socket.h> #include <amqp.h> #include <amqp_framing.h> amqp_connection_state_t mqconnect() { amqp_connection_state_t conn = amqp_new_connection(); amqp_socket_t *socket = NULL; char hostname[] = \"localhost\"; // RoboMQ hostname int port = 5672; //default char user[] = \"guest\"; // RoboMQ username char password[] = \"guest\"; // RoboMQ password char vhost[] = \"/\"; // RoboMQ account vhost amqp_channel_t channel = 1; amqp_rpc_reply_t reply; int channel_max = 0; int frame_max = 131072; int heartbeat = 60; int status = 0; // Opening socket socket = amqp_tcp_socket_new(conn); status = amqp_socket_open(socket, hostname, port); if (status) { printf(\"Error opening TCP socket, status = %d\\n\", status); } reply = amqp_login(conn, vhost, channel_max, frame_max, heartbeat, AMQP_SASL_METHOD_PLAIN, user, password); if(reply.reply_type != AMQP_RESPONSE_NORMAL) { fprintf(stderr, \"%s: server connection reply code: %d\\n\", \"Error logging in\", reply.reply_type); } amqp_channel_open(conn, channel); return conn; } amqp_bytes_t mqdeclare(amqp_connection_state_t conn, const char *exchange_name, const char *queue_name) { amqp_bytes_t queue; amqp_channel_t channel = 1; amqp_boolean_t passive = 0; amqp_boolean_t durable = 0; amqp_boolean_t exclusive = 0; amqp_boolean_t auto_delete = 1; amqp_boolean_t internal = 0; char exchange_type[] = \"topic\"; char binding_key[] = \"mytopic.*\"; amqp_rpc_reply_t reply; // Declaring exchange amqp_exchange_declare(conn, channel, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(exchange_type), passive, durable, auto_delete, internal, amqp_empty_table); reply = amqp_get_rpc_reply(conn); if(reply.reply_type != AMQP_RESPONSE_NORMAL) { amqp_connection_close_t *m = (amqp_connection_close_t *) reply.reply.decoded; if(NULL != m) { fprintf(stderr, \"%s: server connection error %d, message: %.*s\\n\", \"Error declaring exchange\", m->reply_code, (int) m->reply_text.len, (char *) m->reply_text.bytes); } } // Declaring queue amqp_queue_declare_ok_t *r = amqp_queue_declare(conn, channel, amqp_cstring_bytes(queue_name), passive, durable, exclusive, auto_delete, amqp_empty_table); reply = amqp_get_rpc_reply(conn); if(reply.reply_type != AMQP_RESPONSE_NORMAL) { fprintf(stderr, \"%s: server connection reply code: %d\\n\", \"Error declaring queue\", reply.reply_type); } else { queue = amqp_bytes_malloc_dup(r->queue); // Binding to queue amqp_queue_bind(conn, channel, queue, amqp_cstring_bytes(exchange_name), amqp_cstring_bytes(binding_key), amqp_empty_table); } return queue; } int main(int argc, char const *const *argv) { amqp_connection_state_t conn; amqp_bytes_t queue; amqp_channel_t channel = 1; amqp_boolean_t no_local = 0; amqp_boolean_t no_ack = 1; amqp_boolean_t exclusive = 0; char exchange_name[] = \"topic-exchange\"; char queue_name[] = \"hello-queue\"; int retry_time = 5; // retry time in seconds conn = mqconnect(); queue = mqdeclare(conn, &exchange_name[0], &queue_name[0]); // Consuming the message amqp_basic_consume(conn, channel, queue, amqp_empty_bytes, no_local, no_ack, exclusive, amqp_empty_table); while (1) { amqp_rpc_reply_t result; amqp_envelope_t envelope; amqp_maybe_release_buffers(conn); result = amqp_consume_message(conn, &envelope, NULL, 0); if (AMQP_RESPONSE_NORMAL != result.reply_type) { printf(\"Consumer AMQP failure occurred, response code = %d, retrying in %d seconds...\\n\", result.reply_type, retry_time); // Closing current connection before reconnecting amqp_connection_close(conn, AMQP_CONNECTION_FORCED); amqp_destroy_connection(conn); // Reconnecting on exception conn = mqconnect(); queue = mqdeclare(conn, &exchange_name[0], &queue_name[0]); amqp_basic_consume(conn, channel, queue, amqp_empty_bytes, no_local, no_ack, exclusive, amqp_empty_table); sleep(retry_time); } else { printf(\"Received message size: %d\\nbody: %s\\n\", (int)envelope.message.body.len, (char *)envelope.message.body.bytes); amqp_destroy_envelope(&envelope); } } return 0; }","title":"Putting it all together"}]}